{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DB_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Kts4G8Re9lexF0rZOC-zipkUf_Sew2Up",
      "authorship_tag": "ABX9TyMmDoKe9UQE2N7a5d2FIAHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresha97/MSc_Project/blob/main/DB_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IO13abESYHx"
      },
      "source": [
        "#load packages\n",
        "import scipy\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "from IPython import display\n",
        "import copy \n",
        "import pickle\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Normalize, Resize, ToTensor\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TreaId9rKbDe"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxW9oK5yIegb"
      },
      "source": [
        "#Function to extract windowed segments of spectrograms\n",
        "def overlap_windows(data, overlap_rate, window_size):\n",
        "    window_list = []\n",
        "    start = 0\n",
        "    end = window_size\n",
        "    remain_length = len(data)\n",
        "    \n",
        "    while remain_length>=window_size:\n",
        "        window_list.append(data[:,int(round(start+0.01)):int(round(end+0.01))])\n",
        "        start += overlap_rate*window_size #start and end overlap 1\n",
        "        end += overlap_rate*window_size\n",
        "        remain_length -= overlap_rate*window_size \n",
        "    \n",
        "    return window_list\n",
        "\n",
        "def make_data(olr, window_size, augment, fusion):\n",
        "\n",
        "  #List of strings for each particiapnt\n",
        "  parts = []\n",
        "  nums = [str(x) for x in range(1,10,1)]\n",
        "  ten = ['0'+x for x in nums]\n",
        "  others = [str(x) for x in range(10,24,1)]\n",
        "  participants = ten+others\n",
        "\n",
        "  ppg_full_list = [] # 32 elements of 40 x 80 x 80 arrays\n",
        "  resp_full_list = []\n",
        "\n",
        "  #Load spectorgrams of PPG and RESP signals for each particiapnt\n",
        "  for part in participants: \n",
        "    l_ppg = np.load('/content/drive/My Drive/PHYSIO/Generated_Specs/PPG_120/ppg_spec_{}_120.npy'.format(part)) #40 x 80 x 80\n",
        "    l_resp = np.load('/content/drive/My Drive/PHYSIO/Generated_Specs/20RESP_120/20resp_spec_{}_120.npy'.format(part)) #40 x 80 x 80 \n",
        "    \n",
        "    ppg_full_list.append(l_ppg)\n",
        "    resp_full_list.append(l_resp)\n",
        "\n",
        "  ppg_full_array = np.vstack(ppg_full_list)\n",
        "  resp_full_array = np.vstack(resp_full_list)\n",
        "\n",
        "  print(\"PPG:\",ppg_full_array.shape)\n",
        "  print(\"RESP:\",resp_full_array.shape)\n",
        "\n",
        "  if augment == True:\n",
        "    #Define resize dimensions for extracted segments\n",
        "    composed1 = transforms.Compose([ Resize(size=(120,120)),\n",
        "                                    ToTensor()])\n",
        "\n",
        "    composed2 = transforms.Compose([ Resize(size=(28,28)),\n",
        "                                    ToTensor()])\n",
        "    ppg_aug = []\n",
        "    resp_aug = []\n",
        "\n",
        "    #For each sample\n",
        "    for i in range(len(ppg_full_array)):\n",
        "\n",
        "      #Extract windowed segemnts for current spectrograms for each signal \n",
        "      test_win = overlap_windows(ppg_full_array[i], olr, window_size) \n",
        "      test_win2 = overlap_windows(resp_full_array[i], olr, window_size) \n",
        "      spec_list = []\n",
        "      spec_list2 = []\n",
        "\n",
        "      #Resise current PPG spectrogram segments to 120 x 120 then 28 x 28\n",
        "      for spec in test_win: \n",
        "        out2 = composed1(Image.fromarray(spec))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        out2 = composed2(Image.fromarray(out2))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        spec_list.append(out2)\n",
        "\n",
        "      #Resise current RESP spectrogram segments to 120 x 120 then 28 x 28\n",
        "      for spec2 in test_win2: \n",
        "        out2 = composed1(Image.fromarray(spec2))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        out2 = composed2(Image.fromarray(out2))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        spec_list2.append(out2)\n",
        "      \n",
        "      ppg_aug.append(np.asarray(spec_list))\n",
        "      resp_aug.append(np.asarray(spec_list2))\n",
        "\n",
        "    ppg_aug_array = np.vstack(ppg_aug)\n",
        "    resp_aug_array = np.vstack(resp_aug)\n",
        "    print(\"PPG Augmented :\",ppg_aug_array.shape)\n",
        "    print(\"RESP Augmented :\",resp_aug_array.shape)\n",
        "    ppg_full_array = ppg_aug_array\n",
        "    resp_full_array = resp_aug_array\n",
        "\n",
        "  if fusion == 'two_channel':\n",
        "    to_stack = [ppg_full_array, resp_full_array]\n",
        "    two_sig = np.stack(np.asarray(to_stack), axis = 1)\n",
        "    print(\"Multi Channel Data:\",two_sig.shape)\n",
        "\n",
        "    return two_sig\n",
        "\n",
        "  if fusion == 'alpha_blend':\n",
        "    blend = np.load('/content/drive/My Drive/PHYSIO/spec_alpha_blend.npy')\n",
        "\n",
        "    if augment == True:\n",
        "      blend_array = []\n",
        "      for i in range(len(blend)):\n",
        "\n",
        "        #Extract windowed segemnts for current spectrograms for each signal \n",
        "        test_win = overlap_windows(blend[i], overlap_rate, window_size) \n",
        "        spec_list = []\n",
        "\n",
        "        #Resise current PPG spectrogram segments to 120 x 120 then 28 x 28\n",
        "        for spec in test_win: \n",
        "          out2 = composed1(Image.fromarray(spec))\n",
        "          out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "          out2 = out2[:,:,0]\n",
        "          out2 = composed2(Image.fromarray(out2))\n",
        "          out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "          out2 = out2[:,:,0]\n",
        "          spec_list.append(out2)\n",
        "\n",
        "        blend_array.append(np.asarray(spec_list))\n",
        "\n",
        "      blend_aug = np.vstack(blend_array)\n",
        "      blend = blend_aug\n",
        "\n",
        "    print(\"Alpha-blended Data :\",blend.shape)\n",
        "    return blend\n",
        "\n",
        "  return ppg_full_array, resp_full_array\n",
        "\n",
        "def make_labels(file_name,rating,aug_num):\n",
        "  labels_tdf = pd.read_csv(\"/content/drive/My Drive/PHYSIO/Generated_Specs/{}.csv\".format(file_name)) \n",
        "  data_Y = labels_tdf[rating].to_numpy()[0:920]\n",
        "\n",
        "  #Label encoding for clusterins with quadrant names as labels\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  data_Y = le.fit_transform(data_Y)\n",
        "\n",
        "  #Augment labels to match spectrograms\n",
        "  aug_labs = []\n",
        "  for ele in data_Y:\n",
        "    t_list = [ele]*int(aug_num/920)\n",
        "    aug_labs.extend(t_list)\n",
        "\n",
        "  aug_labs = np.asarray(aug_labs)\n",
        "  print(\"Labels:\",aug_labs.shape)\n",
        "\n",
        "  return aug_labs\n",
        "\n",
        "\n",
        "#Accuracy function\n",
        "def accuracy(features1,features2, labels,task ):\n",
        "  #Get predictions from model\n",
        "\n",
        "  outputs = net.forward(features1)\n",
        "  if task == 'multi':\n",
        "    outputs = F.softmax(outputs, dim = 0)\n",
        "    _, preds = torch.max(outputs.data,1)\n",
        "\n",
        "  if task == 'binary':\n",
        "    preds = []\n",
        "    for el in outputs.data:\n",
        "      if el >= 0.5:\n",
        "        preds.append(1)\n",
        "      elif el < 0.5:\n",
        "        preds.append(0)\n",
        "\n",
        "  preds = np.array(preds)\n",
        "\n",
        "  #Find number that are coorect and accuracy\n",
        "  num_correct = (torch.tensor(preds).int() == labels.int()).sum().numpy()\n",
        "  accuracy = num_correct/(labels.size()[0])\n",
        "\n",
        "  return accuracy*100, preds"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NMm964mB_Ez"
      },
      "source": [
        "ppg_11 = np.split(sub_splits_ppg[0:21], 11)\n",
        "resp_11 = np.split(sub_splits_resp[0:21], 11)\n",
        "fold_10 = [x for x in range(1,11,1)]\n",
        "\n",
        "print(ppg_11.shape)\n",
        "print(resp_11.shape)\n",
        "print(fold_11.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7bP3tD0KkM8"
      },
      "source": [
        "# CNN Architecures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZEAbfzJohAC"
      },
      "source": [
        "\n",
        "\n",
        "class Single_Net(nn.Module):\n",
        "    \n",
        "    # Define the neural network layers\n",
        "    def __init__(self,fcsize,in_channel,num_c1, num_c2,outsize, task):\n",
        "        \n",
        "        super(Single_Net, self).__init__()\n",
        "        self.fcsize = fcsize\n",
        "        self.task = task\n",
        "        self.in_channel = in_channel\n",
        "        self.num_c1 = num_c1\n",
        "        self.num_c2 = num_c2\n",
        "        self.outsize = outsize\n",
        "\n",
        "        #Conv layer\n",
        "        self.conv1 = nn.Conv2d(self.in_channel, self.num_c1, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(self.num_c1, self.num_c2, kernel_size=5)\n",
        "\n",
        "        #FC layers\n",
        "        self.fc1 = nn.Linear(self.fcsize, self.outsize)\n",
        "        self.fc2 = nn.Linear(self.fcsize*2,1)\n",
        "\n",
        "\n",
        "    # Define the forward pass.    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #Conv1 Block 1 - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv1(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #Conv1 Block 2 - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv2(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #Flatten array\n",
        "        x = x.view(-1, self.fcsize)\n",
        "\n",
        "        if self.task == 'binary':\n",
        "          x = torch.sigmoid(self.fc1(x))\n",
        "        if self.task == 'multi':\n",
        "          x = self.fc1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "'''For Fusion Method 1 (FUSE 1 )'''\n",
        "class Multi_Net(nn.Module):\n",
        "    \n",
        "    # Define the neural network layers\n",
        "    def __init__(self,fcsize,in_channel,num_c1, num_c2,outsize,task):\n",
        "        \n",
        "        super(Single_Net, self).__init__()\n",
        "        self.fcsize = fcsize\n",
        "        self.task = task\n",
        "        self.in_channel = in_channel\n",
        "        self.num_c1 = num_c1\n",
        "        self.num_c2 = num_c2\n",
        "        self.outsize = outsize\n",
        "\n",
        "        #Conv layer\n",
        "        self.conv1 = nn.Conv2d(self.in_channel, self.num_c1, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(self.num_c1, self.num_c2, kernel_size=5)\n",
        "\n",
        "        #FC layers\n",
        "        self.fc1 = nn.Linear(self.fcsize, self.outsize)\n",
        "        self.fc2 = nn.Linear(self.fcsize*2,1)\n",
        "\n",
        "    # Define the forward pass.    \n",
        "    \n",
        "    def forward(self, x, x2):\n",
        "    \n",
        "        #Conv1 Block 1 (Singal 1) - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv1(x), 2, stride = 2)\n",
        "        x = F.sigmoid(x)\n",
        "        \n",
        "        #Conv1 Block 2 (Singal 1) - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv2(x), 2, stride = 2)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        #Conv1 Block 1 (Singal 2) - Convolution + Pooling + Non-linearity\n",
        "        x2 = F.max_pool2d(self.conv1(x2), 2)\n",
        "        x2 = F.sigmoid(x2)\n",
        "        \n",
        "        #Conv1 Block 2 (Singal 2) - Convolution + Pooling + Non-linearity\n",
        "        x2 = F.max_pool2d(self.conv2(x2), 2)\n",
        "        x2 = F.sigmoid(x2)\n",
        "        \n",
        "        #Flatten layers for both signal\n",
        "        x = x.view(-1, self.fcsize)\n",
        "        x2 = x2.view(-1, self.fcsize)\n",
        "\n",
        "        #Concatenate features extracted from both spectrograms\n",
        "        x_combined = torch.cat((x,x2),dim=1)\n",
        "\n",
        "        #FC layers, non-linearities and predcition layers\n",
        "        if self.task == 'binary':\n",
        "          x_combined = torch.sigmoid(self.fc2(x_combined))\n",
        "\n",
        "        if self.task == 'multi':\n",
        "          x_combined = self.fc2(x_combined)\n",
        "        \n",
        "        return x_combined"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBF0reCbsVOH"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtQZrRwXoooX"
      },
      "source": [
        "# Train the CNN\n",
        "def train_net(train_set, no_epochs, lr, m, opt, task, fuse):\n",
        "\n",
        "    #Define tloss functionhe loss\n",
        "    if task == 'multi':\n",
        "      loss_func = nn.CrossEntropyLoss()\n",
        "    if task == 'binary':\n",
        "      loss_func = nn.BCELoss()\n",
        "\n",
        "    #Define Optimiser\n",
        "    if opt == 'ADAM':\n",
        "      optimizer = optim.AdamW(net.parameters(), lr = lr)\n",
        "    elif opt == 'SGD':\n",
        "      optimizer=optim.SGD(net.parameters(), lr = lr, momentum = m, nesterov = True)\n",
        "\n",
        "    best_val_loss = 10000\n",
        "    best_epoch = 0\n",
        "    best_val_acc = 0\n",
        "\n",
        "    losses_train = []\n",
        "    losses_val = []\n",
        "\n",
        "    # Loop over the number of epochs\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        #Initialise loss and acc\n",
        "        current_loss = 0.0\n",
        "        current_accuracy = 0.0\n",
        "\n",
        "        # Loop over each mini-batch\n",
        "        for batch_index, training_batch in enumerate(train_set, 0):\n",
        "  \n",
        "            #Load the mini-batch and wrap with variable\n",
        "            inputs, labels = training_batch\n",
        "            inputs,  labels = inputs, labels\n",
        "\n",
        "            if fuse == 1:\n",
        "              inputs, inputs2, labels = training_batch\n",
        "              inputs, inputs2, labels = inputs, inputs2, labels\n",
        "\n",
        "            #Initalise parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #Forward pass\n",
        "            outputs = net.forward(inputs)\n",
        "\n",
        "            if fuse == 1:\n",
        "              outputs = net.forward(inputs, inputs2)\n",
        "\n",
        "            if task == 'multi':\n",
        "              labels = labels.long()\n",
        "\n",
        "            loss = loss_func(outputs, labels)\n",
        "            \n",
        "            #Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #Add loss \n",
        "            current_loss += loss.item()\n",
        "\n",
        "            #Add accuracy to the overall accuracy\n",
        "            current_accuracy += accuracy(inputs,'_',labels, task)[0]\n",
        "\n",
        "            if fuse == 1:\n",
        "              current_accuracy += accuracy(inputs,inputs2,labels, task)[0]\n",
        "\n",
        "\n",
        "        test_ac, preds = accuracy(testf_tensor, '_', testl_tensor, task)\n",
        "        if fuse == 2:\n",
        "          test_ac, preds = accuracy(testf_tensor, testf_tensor2, testl_tensor, task)\n",
        "\n",
        "        true_y = testl_tensor.detach().numpy()\n",
        "        F1_test = sklearn.metrics.f1_score(true_y, preds, average = 'weighted')\n",
        "\n",
        "        print('[Epoch: %d Batch: %5d] loss: %.3f, acc: %.3f, test_acc:%.3f, F1:%.3f' % (epoch + 1, batch_index+1, current_loss/batchsize, current_accuracy/batchsize, test_ac, F1_test))\n",
        "        losses_train.append(current_loss/batchsize)\n",
        "\n",
        "    print(\"------------------------------------------------------\")\n",
        "    print('Training has finished')\n",
        "\n",
        "    test_ac, preds = accuracy(testf_tensor, '_', testl_tensor, task)\n",
        "    if fuse == 2:\n",
        "      test_ac, preds = accuracy(testf_tensor, testf_tensor2, testl_tensor, task)\n",
        "    print('Test Accuracy: ',test_ac)\n",
        "\n",
        "    #Test F1 score\n",
        "    true_y = testl_tensor.detach().numpy()\n",
        "    F1_test = sklearn.metrics.f1_score(true_y, preds, average = 'weighted')\n",
        "    print('Test F1 Score :', F1_test)\n",
        "    print(\"All :\",sklearn.metrics.classification_report(true_y, preds))\n",
        "    print(\"Confusion Matrix :\")\n",
        "    print(sklearn.metrics.confusion_matrix(true_y, preds))\n",
        "    #sklearn.metrics.plot_confusion_matrix(best_model, testf_tensor)\n",
        "    \n",
        "    #Plot learning curves\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.2))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax1.plot(losses_train,'r')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return test_ac, F1_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0m8BzMJphMV"
      },
      "source": [
        "# Load and make Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Po1FlS5pfWV",
        "outputId": "3bc46755-209a-4ef0-b8a1-c36e330e38e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "#Choose data augmentation parameters for running augment = True\n",
        "window_size = 40\n",
        "overlap_rate = \n",
        "\n",
        "#Choose clustering strategy and rating to load \n",
        "file_n = 'all_labels_threshold_5.0' #all_labels for k-means, all_labels_threshold_5.0 for manual threhsold, class_4 only in all_labels\n",
        "ratings = 'val3' #val/aro for binary classification, val3/aro3 for multiclass, class_4 for 4 class classification\n",
        "\n",
        "#Split data by particiapnts for LOSO CV *ALSO NEED FILEN_NAME FOR SPECTROGRAM FILES*\n",
        "ppg_array, resp_array = make_data(overlap_rate, window_size, augment=True, fusion = None)\n",
        "sub_splits_ppg = np.split(ppg_array, 23)\n",
        "sub_splits_resp = np.split(resp_array, 23)\n",
        "\n",
        "'''For Fusion Method 2 (FUSE 2)'''\n",
        "two_s = make_data(overlap_rate, window_size, augment=True, fusion ='two_channel')\n",
        "sub_splits_both = np.split(two_s, 23)\n",
        "\n",
        "'''For Fusion Method 3 (FUSE 3)'''\n",
        "alpha_s = make_data(overlap_rate, window_size, augment=True, fusion = 'alpha_blend')\n",
        "sub_splits_alpha = np.split(alpha_s, 23)\n",
        "\n",
        "len_aug = len(ppg_array)\n",
        "labs = make_labels(file_n, ratings, len_aug)\n",
        "sub_splits_labs = np.split(labs, 23)\n",
        "\n",
        "print(\"LOSO Features:\",np.asarray(sub_splits_resp).shape)\n",
        "print(\"LOSO Features :\",np.asarray(sub_splits_both).shape)\n",
        "print(\"LOSO Features:\",np.asarray(sub_splits_alpha).shape)\n",
        "print(\"LOSO Labels:\",np.asarray(sub_splits_labs).shape)\n",
        "\n",
        "#Choose input method (PPG, RESP, FUSE 2, FUSE 3)\n",
        "dat = sub_splits_both"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PPG: (920, 120, 120)\n",
            "RESP: (920, 120, 120)\n",
            "PPG Augmented : (2760, 28, 28)\n",
            "RESP Augmented : (2760, 28, 28)\n",
            "PPG: (920, 120, 120)\n",
            "RESP: (920, 120, 120)\n",
            "PPG Augmented : (2760, 28, 28)\n",
            "RESP Augmented : (2760, 28, 28)\n",
            "Multi Channel Data: (2760, 2, 28, 28)\n",
            "Labels: (2760,)\n",
            "LOSO Features: (23, 120, 28, 28)\n",
            "LOSO Features : (23, 120, 2, 28, 28)\n",
            "LOSO Labels: (23, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqZtYBcmpkfn"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61_oG9hZotpu",
        "outputId": "f5faa004-7dd7-4dd2-ba71-8f142d65e927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "image_size = np.asarray(dat).shape[2]\n",
        "subjects = [x for x in range(0,23,1)]\n",
        "\n",
        "accuracies_test = []\n",
        "f1s = []\n",
        "\n",
        "#Train model 23 times - differnet particiapnt data each time \n",
        "for s in subjects:\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_inds = np.where(np.asarray(subjects) != s)[0]\n",
        "  train_feats = np.take(np.asarray(dat), train_inds, axis = 0)\n",
        "  train_feats = np.vstack(train_feats)\n",
        "  \n",
        "  train_labs = np.take(np.asarray(sub_splits_labs), train_inds, axis = 0)\n",
        "  train_labs = np.reshape(train_labs, (train_feats.shape[0]))\n",
        "  print(\"Training Features\",train_feats.shape)\n",
        "  print(\"Training Labels\",train_labs.shape)\n",
        "\n",
        "  #Get test fo ld\n",
        "  test_feats = np.take(np.asarray(dat), s, axis = 0)  \n",
        "  test_labs = np.take(np.asarray(sub_splits_labs), s, axis = 0)\n",
        "  test_labs = np.reshape(test_labs, (test_feats.shape[0]))\n",
        "  print(\"Training Features\",test_feats.shape)\n",
        "  print(\"Training Labels\",test_labs.shape)\n",
        "\n",
        "  #Reshape train and test arrays to specify number of input chanenels\n",
        "  #train_feats = train_feats.reshape(len(train_feats),1,image_size,image_size)\n",
        "  #test_feats = test_feats.reshape(len(test_feats),1,image_size,image_size)\n",
        "\n",
        "  #Convert to torch tensors\n",
        "  trainf_tensor = torch.tensor(train_feats, dtype=torch.float)\n",
        "  trainl_tensor = torch.tensor(train_labs, dtype=torch.float)\n",
        "  testf_tensor = torch.tensor(test_feats, requires_grad=False, dtype=torch.float)\n",
        " \n",
        "  testl_tensor = torch.tensor(test_labs, requires_grad=False, dtype=torch.float)\n",
        "  print(\"Trainf\",trainf_tensor.shape)\n",
        "  print(\"Trainl\",trainl_tensor.shape)\n",
        "  print(\"Testf\",testf_tensor.shape)\n",
        "  print(\"Testl\",testl_tensor.shape)\n",
        "\n",
        "  ''' For Fusion Method 1 (FUSE 1)'''\n",
        "  #train_feats2 = np.take(np.asarray(dat2), train_inds, axis = 0)\n",
        "  #train_feats2 = np.vstack(train_feats2)\n",
        "  #test_feats2 = np.take(np.asarray(dat2), s, axis = 0)\n",
        "  #train_feats2 = train_feats.reshape(len(train_feats2),1,image_size,image_size)\n",
        "  #test_feats2 = test_feats.reshape(len(test_feats2),1,image_size,image_size)\n",
        "  #trainf_tensor2 = torch.tensor(train_feats2, dtype=torch.float)\n",
        "  #testf_tensor2 = torch.tensor(test_feats2, requires_grad=False, dtype=torch.float)\n",
        "  #print(\"Trainf\",trainf_tensor2.shape)\n",
        "\n",
        "  #Batchify training data using trainloader\n",
        "  batch_size = 25\n",
        "  trainset = torch.utils.data.TensorDataset(trainf_tensor, trainl_tensor)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  batchsize = len(trainloader)\n",
        "\n",
        "  print(\"Participant : \",s+1)\n",
        "  net = Single_Net(fcsize = 288, in_channel = 2, num_c1 = 9, num_c2 = 18, outsize = 3, task = 'multi' )\n",
        "  #net = Multi_Net(fcsize = 288, in_channel = 1, num_c1 = 9, num_c2 = 18, outsize = 3, task = 'multi' )\n",
        "  test_accuracy,testf1 = train_net(trainloader, no_epochs = 300, lr = 0.01, m = 0.9, opt = 'SGD', task = 'multi', fuse = None)    \n",
        "  accuracies_test.append(test_accuracy) \n",
        "  f1s.append(testf1)\n",
        "  print(\"Pre-processing time  validation sets --- %s minutes ---\" % (((time.time() - start_time)/60)))\n",
        "\n",
        "#Print average metrics across all participants\n",
        "avg_acc = sum(accuracies_test)/len(accuracies_test)\n",
        "print(\"Accuracies :\", accuracies_test)\n",
        "print(\"Average test accuracy: {}%\".format(round(avg_acc,2)))\n",
        "print(\"Average test F1 Score :\", sum(f1s)/len(f1s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  1\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 35.107, test_acc:30.000, F1:0.310\n",
            "[Epoch: 2 Batch:   106] loss: 1.086, acc: 38.377, test_acc:30.833, F1:0.322\n",
            "[Epoch: 3 Batch:   106] loss: 1.084, acc: 36.931, test_acc:28.333, F1:0.302\n",
            "[Epoch: 4 Batch:   106] loss: 1.081, acc: 38.000, test_acc:27.500, F1:0.299\n",
            "[Epoch: 5 Batch:   106] loss: 1.079, acc: 36.969, test_acc:30.833, F1:0.322\n",
            "[Epoch: 6 Batch:   106] loss: 1.077, acc: 39.031, test_acc:30.000, F1:0.316\n",
            "[Epoch: 7 Batch:   106] loss: 1.075, acc: 39.610, test_acc:26.667, F1:0.278\n",
            "[Epoch: 8 Batch:   106] loss: 1.075, acc: 38.277, test_acc:25.833, F1:0.267\n",
            "[Epoch: 9 Batch:   106] loss: 1.073, acc: 37.786, test_acc:21.667, F1:0.223\n",
            "[Epoch: 10 Batch:   106] loss: 1.071, acc: 39.547, test_acc:24.167, F1:0.246\n",
            "[Epoch: 11 Batch:   106] loss: 1.069, acc: 38.943, test_acc:27.500, F1:0.272\n",
            "[Epoch: 12 Batch:   106] loss: 1.068, acc: 39.270, test_acc:24.167, F1:0.241\n",
            "[Epoch: 13 Batch:   106] loss: 1.066, acc: 39.044, test_acc:31.667, F1:0.330\n",
            "[Epoch: 14 Batch:   106] loss: 1.065, acc: 39.119, test_acc:30.000, F1:0.325\n",
            "[Epoch: 15 Batch:   106] loss: 1.063, acc: 39.937, test_acc:31.667, F1:0.331\n",
            "[Epoch: 16 Batch:   106] loss: 1.062, acc: 40.101, test_acc:30.833, F1:0.325\n",
            "[Epoch: 17 Batch:   106] loss: 1.060, acc: 41.862, test_acc:33.333, F1:0.365\n",
            "[Epoch: 18 Batch:   106] loss: 1.059, acc: 42.226, test_acc:31.667, F1:0.341\n",
            "[Epoch: 19 Batch:   106] loss: 1.058, acc: 40.704, test_acc:36.667, F1:0.400\n",
            "[Epoch: 20 Batch:   106] loss: 1.058, acc: 41.069, test_acc:35.000, F1:0.383\n",
            "[Epoch: 21 Batch:   106] loss: 1.055, acc: 42.591, test_acc:35.000, F1:0.381\n",
            "[Epoch: 22 Batch:   106] loss: 1.055, acc: 42.453, test_acc:35.833, F1:0.390\n",
            "[Epoch: 23 Batch:   106] loss: 1.054, acc: 42.352, test_acc:37.500, F1:0.412\n",
            "[Epoch: 24 Batch:   106] loss: 1.047, acc: 42.818, test_acc:32.500, F1:0.349\n",
            "[Epoch: 25 Batch:   106] loss: 1.048, acc: 44.013, test_acc:35.000, F1:0.381\n",
            "[Epoch: 26 Batch:   106] loss: 1.044, acc: 44.440, test_acc:35.000, F1:0.375\n",
            "[Epoch: 27 Batch:   106] loss: 1.043, acc: 44.164, test_acc:35.000, F1:0.381\n",
            "[Epoch: 28 Batch:   106] loss: 1.043, acc: 43.572, test_acc:31.667, F1:0.347\n",
            "[Epoch: 29 Batch:   106] loss: 1.040, acc: 45.836, test_acc:32.500, F1:0.365\n",
            "[Epoch: 30 Batch:   106] loss: 1.036, acc: 44.591, test_acc:31.667, F1:0.350\n",
            "[Epoch: 31 Batch:   106] loss: 1.038, acc: 44.931, test_acc:34.167, F1:0.378\n",
            "[Epoch: 32 Batch:   106] loss: 1.029, acc: 45.937, test_acc:32.500, F1:0.371\n",
            "[Epoch: 33 Batch:   106] loss: 1.031, acc: 46.981, test_acc:34.167, F1:0.368\n",
            "[Epoch: 34 Batch:   106] loss: 1.024, acc: 46.616, test_acc:35.000, F1:0.382\n",
            "[Epoch: 35 Batch:   106] loss: 1.027, acc: 47.623, test_acc:33.333, F1:0.362\n",
            "[Epoch: 36 Batch:   106] loss: 1.023, acc: 47.774, test_acc:30.833, F1:0.341\n",
            "[Epoch: 37 Batch:   106] loss: 1.017, acc: 48.101, test_acc:35.000, F1:0.398\n",
            "[Epoch: 38 Batch:   106] loss: 1.017, acc: 50.289, test_acc:37.500, F1:0.425\n",
            "[Epoch: 39 Batch:   106] loss: 1.015, acc: 48.604, test_acc:36.667, F1:0.418\n",
            "[Epoch: 40 Batch:   106] loss: 1.009, acc: 50.604, test_acc:32.500, F1:0.369\n",
            "[Epoch: 41 Batch:   106] loss: 1.008, acc: 49.874, test_acc:34.167, F1:0.389\n",
            "[Epoch: 42 Batch:   106] loss: 1.002, acc: 50.403, test_acc:32.500, F1:0.369\n",
            "[Epoch: 43 Batch:   106] loss: 0.998, acc: 49.698, test_acc:30.000, F1:0.347\n",
            "[Epoch: 44 Batch:   106] loss: 0.998, acc: 50.818, test_acc:31.667, F1:0.355\n",
            "[Epoch: 45 Batch:   106] loss: 0.996, acc: 50.818, test_acc:34.167, F1:0.373\n",
            "[Epoch: 46 Batch:   106] loss: 0.991, acc: 50.025, test_acc:30.833, F1:0.348\n",
            "[Epoch: 47 Batch:   106] loss: 0.986, acc: 50.491, test_acc:32.500, F1:0.373\n",
            "[Epoch: 48 Batch:   106] loss: 0.986, acc: 52.314, test_acc:30.833, F1:0.350\n",
            "[Epoch: 49 Batch:   106] loss: 0.984, acc: 53.107, test_acc:29.167, F1:0.316\n",
            "[Epoch: 50 Batch:   106] loss: 0.976, acc: 53.107, test_acc:33.333, F1:0.372\n",
            "[Epoch: 51 Batch:   106] loss: 0.975, acc: 53.899, test_acc:30.000, F1:0.332\n",
            "[Epoch: 52 Batch:   106] loss: 0.978, acc: 53.132, test_acc:35.000, F1:0.393\n",
            "[Epoch: 53 Batch:   106] loss: 0.972, acc: 53.208, test_acc:29.167, F1:0.322\n",
            "[Epoch: 54 Batch:   106] loss: 0.961, acc: 53.497, test_acc:26.667, F1:0.302\n",
            "[Epoch: 55 Batch:   106] loss: 0.958, acc: 54.566, test_acc:30.000, F1:0.331\n",
            "[Epoch: 56 Batch:   106] loss: 0.961, acc: 53.673, test_acc:27.500, F1:0.306\n",
            "[Epoch: 57 Batch:   106] loss: 0.954, acc: 55.824, test_acc:33.333, F1:0.376\n",
            "[Epoch: 58 Batch:   106] loss: 0.951, acc: 55.610, test_acc:33.333, F1:0.367\n",
            "[Epoch: 59 Batch:   106] loss: 0.944, acc: 54.994, test_acc:28.333, F1:0.314\n",
            "[Epoch: 60 Batch:   106] loss: 0.943, acc: 55.572, test_acc:25.000, F1:0.271\n",
            "[Epoch: 61 Batch:   106] loss: 0.938, acc: 55.597, test_acc:30.000, F1:0.335\n",
            "[Epoch: 62 Batch:   106] loss: 0.940, acc: 56.956, test_acc:32.500, F1:0.366\n",
            "[Epoch: 63 Batch:   106] loss: 0.924, acc: 56.465, test_acc:23.333, F1:0.260\n",
            "[Epoch: 64 Batch:   106] loss: 0.929, acc: 57.484, test_acc:30.000, F1:0.344\n",
            "[Epoch: 65 Batch:   106] loss: 0.925, acc: 58.252, test_acc:30.833, F1:0.360\n",
            "[Epoch: 66 Batch:   106] loss: 0.916, acc: 58.013, test_acc:33.333, F1:0.364\n",
            "[Epoch: 67 Batch:   106] loss: 0.915, acc: 59.346, test_acc:20.000, F1:0.233\n",
            "[Epoch: 68 Batch:   106] loss: 0.912, acc: 59.107, test_acc:34.167, F1:0.382\n",
            "[Epoch: 69 Batch:   106] loss: 0.902, acc: 58.742, test_acc:30.000, F1:0.333\n",
            "[Epoch: 70 Batch:   106] loss: 0.895, acc: 58.667, test_acc:34.167, F1:0.391\n",
            "[Epoch: 71 Batch:   106] loss: 0.898, acc: 59.786, test_acc:29.167, F1:0.335\n",
            "[Epoch: 72 Batch:   106] loss: 0.895, acc: 59.182, test_acc:28.333, F1:0.327\n",
            "[Epoch: 73 Batch:   106] loss: 0.884, acc: 60.063, test_acc:30.833, F1:0.367\n",
            "[Epoch: 74 Batch:   106] loss: 0.882, acc: 59.925, test_acc:29.167, F1:0.332\n",
            "[Epoch: 75 Batch:   106] loss: 0.879, acc: 60.956, test_acc:20.833, F1:0.242\n",
            "[Epoch: 76 Batch:   106] loss: 0.870, acc: 61.296, test_acc:29.167, F1:0.325\n",
            "[Epoch: 77 Batch:   106] loss: 0.862, acc: 62.453, test_acc:27.500, F1:0.318\n",
            "[Epoch: 78 Batch:   106] loss: 0.867, acc: 62.050, test_acc:24.167, F1:0.283\n",
            "[Epoch: 79 Batch:   106] loss: 0.858, acc: 62.843, test_acc:28.333, F1:0.332\n",
            "[Epoch: 80 Batch:   106] loss: 0.864, acc: 62.415, test_acc:27.500, F1:0.321\n",
            "[Epoch: 81 Batch:   106] loss: 0.851, acc: 62.881, test_acc:24.167, F1:0.286\n",
            "[Epoch: 82 Batch:   106] loss: 0.848, acc: 63.774, test_acc:25.833, F1:0.292\n",
            "[Epoch: 83 Batch:   106] loss: 0.840, acc: 63.623, test_acc:25.833, F1:0.302\n",
            "[Epoch: 84 Batch:   106] loss: 0.846, acc: 62.792, test_acc:29.167, F1:0.333\n",
            "[Epoch: 85 Batch:   106] loss: 0.828, acc: 64.730, test_acc:29.167, F1:0.327\n",
            "[Epoch: 86 Batch:   106] loss: 0.821, acc: 64.151, test_acc:24.167, F1:0.290\n",
            "[Epoch: 87 Batch:   106] loss: 0.828, acc: 65.384, test_acc:29.167, F1:0.313\n",
            "[Epoch: 88 Batch:   106] loss: 0.827, acc: 64.805, test_acc:30.833, F1:0.332\n",
            "[Epoch: 89 Batch:   106] loss: 0.819, acc: 64.616, test_acc:20.833, F1:0.235\n",
            "[Epoch: 90 Batch:   106] loss: 0.823, acc: 64.855, test_acc:26.667, F1:0.288\n",
            "[Epoch: 91 Batch:   106] loss: 0.819, acc: 65.547, test_acc:26.667, F1:0.301\n",
            "[Epoch: 92 Batch:   106] loss: 0.801, acc: 64.730, test_acc:36.667, F1:0.401\n",
            "[Epoch: 93 Batch:   106] loss: 0.792, acc: 65.748, test_acc:24.167, F1:0.289\n",
            "[Epoch: 94 Batch:   106] loss: 0.789, acc: 66.528, test_acc:31.667, F1:0.357\n",
            "[Epoch: 95 Batch:   106] loss: 0.784, acc: 67.572, test_acc:23.333, F1:0.270\n",
            "[Epoch: 96 Batch:   106] loss: 0.799, acc: 67.094, test_acc:27.500, F1:0.297\n",
            "[Epoch: 97 Batch:   106] loss: 0.785, acc: 65.610, test_acc:22.500, F1:0.232\n",
            "[Epoch: 98 Batch:   106] loss: 0.776, acc: 68.189, test_acc:30.833, F1:0.346\n",
            "[Epoch: 99 Batch:   106] loss: 0.759, acc: 68.088, test_acc:21.667, F1:0.245\n",
            "[Epoch: 100 Batch:   106] loss: 0.774, acc: 68.214, test_acc:32.500, F1:0.360\n",
            "[Epoch: 101 Batch:   106] loss: 0.762, acc: 69.094, test_acc:27.500, F1:0.305\n",
            "[Epoch: 102 Batch:   106] loss: 0.758, acc: 69.409, test_acc:30.000, F1:0.330\n",
            "[Epoch: 103 Batch:   106] loss: 0.759, acc: 68.969, test_acc:31.667, F1:0.335\n",
            "[Epoch: 104 Batch:   106] loss: 0.746, acc: 68.704, test_acc:25.833, F1:0.284\n",
            "[Epoch: 105 Batch:   106] loss: 0.739, acc: 70.201, test_acc:30.833, F1:0.352\n",
            "[Epoch: 106 Batch:   106] loss: 0.733, acc: 70.189, test_acc:29.167, F1:0.324\n",
            "[Epoch: 107 Batch:   106] loss: 0.744, acc: 69.547, test_acc:32.500, F1:0.370\n",
            "[Epoch: 108 Batch:   106] loss: 0.740, acc: 70.013, test_acc:25.833, F1:0.298\n",
            "[Epoch: 109 Batch:   106] loss: 0.735, acc: 70.428, test_acc:21.667, F1:0.260\n",
            "[Epoch: 110 Batch:   106] loss: 0.735, acc: 70.050, test_acc:32.500, F1:0.360\n",
            "[Epoch: 111 Batch:   106] loss: 0.735, acc: 70.491, test_acc:30.000, F1:0.322\n",
            "[Epoch: 112 Batch:   106] loss: 0.704, acc: 71.472, test_acc:37.500, F1:0.396\n",
            "[Epoch: 113 Batch:   106] loss: 0.705, acc: 70.541, test_acc:26.667, F1:0.284\n",
            "[Epoch: 114 Batch:   106] loss: 0.708, acc: 70.868, test_acc:34.167, F1:0.388\n",
            "[Epoch: 115 Batch:   106] loss: 0.693, acc: 70.792, test_acc:28.333, F1:0.312\n",
            "[Epoch: 116 Batch:   106] loss: 0.682, acc: 72.742, test_acc:28.333, F1:0.321\n",
            "[Epoch: 117 Batch:   106] loss: 0.695, acc: 70.818, test_acc:21.667, F1:0.248\n",
            "[Epoch: 118 Batch:   106] loss: 0.668, acc: 73.459, test_acc:27.500, F1:0.295\n",
            "[Epoch: 119 Batch:   106] loss: 0.690, acc: 72.491, test_acc:25.000, F1:0.258\n",
            "[Epoch: 120 Batch:   106] loss: 0.671, acc: 72.679, test_acc:27.500, F1:0.282\n",
            "[Epoch: 121 Batch:   106] loss: 0.646, acc: 74.415, test_acc:26.667, F1:0.288\n",
            "[Epoch: 122 Batch:   106] loss: 0.649, acc: 72.767, test_acc:30.833, F1:0.352\n",
            "[Epoch: 123 Batch:   106] loss: 0.678, acc: 73.270, test_acc:25.833, F1:0.276\n",
            "[Epoch: 124 Batch:   106] loss: 0.653, acc: 74.252, test_acc:29.167, F1:0.299\n",
            "[Epoch: 125 Batch:   106] loss: 0.646, acc: 74.704, test_acc:30.000, F1:0.326\n",
            "[Epoch: 126 Batch:   106] loss: 0.645, acc: 73.132, test_acc:27.500, F1:0.309\n",
            "[Epoch: 127 Batch:   106] loss: 0.663, acc: 73.107, test_acc:30.000, F1:0.326\n",
            "[Epoch: 128 Batch:   106] loss: 0.632, acc: 74.881, test_acc:32.500, F1:0.347\n",
            "[Epoch: 129 Batch:   106] loss: 0.628, acc: 74.440, test_acc:30.000, F1:0.323\n",
            "[Epoch: 130 Batch:   106] loss: 0.606, acc: 75.912, test_acc:39.167, F1:0.429\n",
            "[Epoch: 131 Batch:   106] loss: 0.626, acc: 75.321, test_acc:34.167, F1:0.377\n",
            "[Epoch: 132 Batch:   106] loss: 0.612, acc: 74.893, test_acc:30.833, F1:0.336\n",
            "[Epoch: 133 Batch:   106] loss: 0.609, acc: 75.975, test_acc:28.333, F1:0.313\n",
            "[Epoch: 134 Batch:   106] loss: 0.638, acc: 75.006, test_acc:34.167, F1:0.354\n",
            "[Epoch: 135 Batch:   106] loss: 0.583, acc: 75.421, test_acc:33.333, F1:0.377\n",
            "[Epoch: 136 Batch:   106] loss: 0.599, acc: 75.937, test_acc:37.500, F1:0.398\n",
            "[Epoch: 137 Batch:   106] loss: 0.587, acc: 74.642, test_acc:28.333, F1:0.318\n",
            "[Epoch: 138 Batch:   106] loss: 0.572, acc: 76.075, test_acc:28.333, F1:0.305\n",
            "[Epoch: 139 Batch:   106] loss: 0.581, acc: 75.748, test_acc:32.500, F1:0.352\n",
            "[Epoch: 140 Batch:   106] loss: 0.590, acc: 75.245, test_acc:31.667, F1:0.343\n",
            "[Epoch: 141 Batch:   106] loss: 0.573, acc: 74.730, test_acc:30.000, F1:0.333\n",
            "[Epoch: 142 Batch:   106] loss: 0.575, acc: 75.233, test_acc:37.500, F1:0.389\n",
            "[Epoch: 143 Batch:   106] loss: 0.578, acc: 76.302, test_acc:31.667, F1:0.333\n",
            "[Epoch: 144 Batch:   106] loss: 0.563, acc: 77.648, test_acc:30.000, F1:0.331\n",
            "[Epoch: 145 Batch:   106] loss: 0.558, acc: 76.214, test_acc:35.000, F1:0.351\n",
            "[Epoch: 146 Batch:   106] loss: 0.568, acc: 75.836, test_acc:29.167, F1:0.320\n",
            "[Epoch: 147 Batch:   106] loss: 0.543, acc: 76.843, test_acc:34.167, F1:0.370\n",
            "[Epoch: 148 Batch:   106] loss: 0.585, acc: 74.792, test_acc:31.667, F1:0.349\n",
            "[Epoch: 149 Batch:   106] loss: 0.539, acc: 76.667, test_acc:35.000, F1:0.362\n",
            "[Epoch: 150 Batch:   106] loss: 0.530, acc: 77.547, test_acc:34.167, F1:0.363\n",
            "[Epoch: 151 Batch:   106] loss: 0.528, acc: 76.453, test_acc:37.500, F1:0.388\n",
            "[Epoch: 152 Batch:   106] loss: 0.553, acc: 76.327, test_acc:42.500, F1:0.445\n",
            "[Epoch: 153 Batch:   106] loss: 0.540, acc: 75.610, test_acc:35.000, F1:0.353\n",
            "[Epoch: 154 Batch:   106] loss: 0.556, acc: 78.277, test_acc:43.333, F1:0.446\n",
            "[Epoch: 155 Batch:   106] loss: 0.542, acc: 76.528, test_acc:34.167, F1:0.366\n",
            "[Epoch: 156 Batch:   106] loss: 0.507, acc: 76.969, test_acc:30.833, F1:0.318\n",
            "[Epoch: 157 Batch:   106] loss: 0.536, acc: 76.277, test_acc:37.500, F1:0.403\n",
            "[Epoch: 158 Batch:   106] loss: 0.493, acc: 78.692, test_acc:31.667, F1:0.325\n",
            "[Epoch: 159 Batch:   106] loss: 0.497, acc: 76.629, test_acc:32.500, F1:0.351\n",
            "[Epoch: 160 Batch:   106] loss: 0.500, acc: 78.654, test_acc:38.333, F1:0.406\n",
            "[Epoch: 161 Batch:   106] loss: 0.490, acc: 78.465, test_acc:40.833, F1:0.431\n",
            "[Epoch: 162 Batch:   106] loss: 0.506, acc: 78.730, test_acc:35.000, F1:0.359\n",
            "[Epoch: 163 Batch:   106] loss: 0.538, acc: 78.025, test_acc:43.333, F1:0.453\n",
            "[Epoch: 164 Batch:   106] loss: 0.509, acc: 79.950, test_acc:34.167, F1:0.369\n",
            "[Epoch: 165 Batch:   106] loss: 0.491, acc: 78.566, test_acc:30.833, F1:0.326\n",
            "[Epoch: 166 Batch:   106] loss: 0.497, acc: 77.220, test_acc:27.500, F1:0.322\n",
            "[Epoch: 167 Batch:   106] loss: 0.495, acc: 77.384, test_acc:34.167, F1:0.357\n",
            "[Epoch: 168 Batch:   106] loss: 0.483, acc: 78.654, test_acc:34.167, F1:0.365\n",
            "[Epoch: 169 Batch:   106] loss: 0.470, acc: 77.849, test_acc:39.167, F1:0.418\n",
            "[Epoch: 170 Batch:   106] loss: 0.448, acc: 79.547, test_acc:30.000, F1:0.328\n",
            "[Epoch: 171 Batch:   106] loss: 0.502, acc: 77.296, test_acc:36.667, F1:0.398\n",
            "[Epoch: 172 Batch:   106] loss: 0.465, acc: 76.289, test_acc:32.500, F1:0.343\n",
            "[Epoch: 173 Batch:   106] loss: 0.476, acc: 77.824, test_acc:25.833, F1:0.274\n",
            "[Epoch: 174 Batch:   106] loss: 0.458, acc: 77.585, test_acc:31.667, F1:0.337\n",
            "[Epoch: 175 Batch:   106] loss: 0.473, acc: 79.396, test_acc:35.833, F1:0.374\n",
            "[Epoch: 176 Batch:   106] loss: 0.474, acc: 77.296, test_acc:30.000, F1:0.338\n",
            "[Epoch: 177 Batch:   106] loss: 0.479, acc: 77.509, test_acc:35.000, F1:0.370\n",
            "[Epoch: 178 Batch:   106] loss: 0.484, acc: 77.937, test_acc:25.833, F1:0.289\n",
            "[Epoch: 179 Batch:   106] loss: 0.471, acc: 76.918, test_acc:29.167, F1:0.322\n",
            "[Epoch: 180 Batch:   106] loss: 0.476, acc: 79.522, test_acc:24.167, F1:0.268\n",
            "[Epoch: 181 Batch:   106] loss: 0.463, acc: 78.918, test_acc:41.667, F1:0.457\n",
            "[Epoch: 182 Batch:   106] loss: 0.414, acc: 77.899, test_acc:41.667, F1:0.444\n",
            "[Epoch: 183 Batch:   106] loss: 0.408, acc: 79.547, test_acc:27.500, F1:0.309\n",
            "[Epoch: 184 Batch:   106] loss: 0.432, acc: 79.434, test_acc:33.333, F1:0.370\n",
            "[Epoch: 185 Batch:   106] loss: 0.400, acc: 79.082, test_acc:33.333, F1:0.366\n",
            "[Epoch: 186 Batch:   106] loss: 0.437, acc: 78.013, test_acc:31.667, F1:0.339\n",
            "[Epoch: 187 Batch:   106] loss: 0.428, acc: 78.365, test_acc:31.667, F1:0.346\n",
            "[Epoch: 188 Batch:   106] loss: 0.454, acc: 79.711, test_acc:40.833, F1:0.432\n",
            "[Epoch: 189 Batch:   106] loss: 0.448, acc: 78.805, test_acc:30.833, F1:0.356\n",
            "[Epoch: 190 Batch:   106] loss: 0.419, acc: 79.761, test_acc:31.667, F1:0.362\n",
            "[Epoch: 191 Batch:   106] loss: 0.419, acc: 79.358, test_acc:28.333, F1:0.310\n",
            "[Epoch: 192 Batch:   106] loss: 0.441, acc: 77.031, test_acc:29.167, F1:0.315\n",
            "[Epoch: 193 Batch:   106] loss: 0.437, acc: 76.616, test_acc:28.333, F1:0.320\n",
            "[Epoch: 194 Batch:   106] loss: 0.424, acc: 77.396, test_acc:28.333, F1:0.325\n",
            "[Epoch: 195 Batch:   106] loss: 0.439, acc: 77.937, test_acc:27.500, F1:0.305\n",
            "[Epoch: 196 Batch:   106] loss: 0.383, acc: 81.434, test_acc:24.167, F1:0.253\n",
            "[Epoch: 197 Batch:   106] loss: 0.456, acc: 78.503, test_acc:32.500, F1:0.352\n",
            "[Epoch: 198 Batch:   106] loss: 0.416, acc: 78.553, test_acc:26.667, F1:0.265\n",
            "[Epoch: 199 Batch:   106] loss: 0.375, acc: 78.453, test_acc:34.167, F1:0.364\n",
            "[Epoch: 200 Batch:   106] loss: 0.377, acc: 79.585, test_acc:26.667, F1:0.311\n",
            "[Epoch: 201 Batch:   106] loss: 0.380, acc: 78.667, test_acc:37.500, F1:0.408\n",
            "[Epoch: 202 Batch:   106] loss: 0.374, acc: 78.516, test_acc:31.667, F1:0.356\n",
            "[Epoch: 203 Batch:   106] loss: 0.394, acc: 78.314, test_acc:33.333, F1:0.374\n",
            "[Epoch: 204 Batch:   106] loss: 0.395, acc: 80.692, test_acc:32.500, F1:0.347\n",
            "[Epoch: 205 Batch:   106] loss: 0.464, acc: 77.874, test_acc:24.167, F1:0.265\n",
            "[Epoch: 206 Batch:   106] loss: 0.427, acc: 77.836, test_acc:25.833, F1:0.287\n",
            "[Epoch: 207 Batch:   106] loss: 0.382, acc: 79.182, test_acc:33.333, F1:0.363\n",
            "[Epoch: 208 Batch:   106] loss: 0.394, acc: 77.145, test_acc:24.167, F1:0.262\n",
            "[Epoch: 209 Batch:   106] loss: 0.362, acc: 78.189, test_acc:22.500, F1:0.271\n",
            "[Epoch: 210 Batch:   106] loss: 0.412, acc: 79.233, test_acc:32.500, F1:0.357\n",
            "[Epoch: 211 Batch:   106] loss: 0.417, acc: 79.283, test_acc:32.500, F1:0.347\n",
            "[Epoch: 212 Batch:   106] loss: 0.394, acc: 78.579, test_acc:31.667, F1:0.339\n",
            "[Epoch: 213 Batch:   106] loss: 0.363, acc: 80.352, test_acc:25.833, F1:0.283\n",
            "[Epoch: 214 Batch:   106] loss: 0.370, acc: 78.667, test_acc:35.000, F1:0.391\n",
            "[Epoch: 215 Batch:   106] loss: 0.414, acc: 77.472, test_acc:25.000, F1:0.302\n",
            "[Epoch: 216 Batch:   106] loss: 0.402, acc: 79.245, test_acc:32.500, F1:0.331\n",
            "[Epoch: 217 Batch:   106] loss: 0.377, acc: 80.704, test_acc:26.667, F1:0.297\n",
            "[Epoch: 218 Batch:   106] loss: 0.440, acc: 79.258, test_acc:25.833, F1:0.268\n",
            "[Epoch: 219 Batch:   106] loss: 0.452, acc: 78.189, test_acc:25.000, F1:0.271\n",
            "[Epoch: 220 Batch:   106] loss: 0.386, acc: 81.208, test_acc:26.667, F1:0.297\n",
            "[Epoch: 221 Batch:   106] loss: 0.353, acc: 79.962, test_acc:31.667, F1:0.350\n",
            "[Epoch: 222 Batch:   106] loss: 0.366, acc: 79.170, test_acc:31.667, F1:0.335\n",
            "[Epoch: 223 Batch:   106] loss: 0.357, acc: 80.252, test_acc:31.667, F1:0.351\n",
            "[Epoch: 224 Batch:   106] loss: 0.369, acc: 78.994, test_acc:30.833, F1:0.343\n",
            "[Epoch: 225 Batch:   106] loss: 0.378, acc: 78.906, test_acc:41.667, F1:0.423\n",
            "[Epoch: 226 Batch:   106] loss: 0.380, acc: 81.006, test_acc:24.167, F1:0.270\n",
            "[Epoch: 227 Batch:   106] loss: 0.352, acc: 79.535, test_acc:31.667, F1:0.334\n",
            "[Epoch: 228 Batch:   106] loss: 0.412, acc: 77.132, test_acc:36.667, F1:0.389\n",
            "[Epoch: 229 Batch:   106] loss: 0.423, acc: 78.553, test_acc:30.000, F1:0.331\n",
            "[Epoch: 230 Batch:   106] loss: 0.449, acc: 77.371, test_acc:27.500, F1:0.315\n",
            "[Epoch: 231 Batch:   106] loss: 0.383, acc: 78.113, test_acc:27.500, F1:0.302\n",
            "[Epoch: 232 Batch:   106] loss: 0.347, acc: 80.931, test_acc:30.833, F1:0.336\n",
            "[Epoch: 233 Batch:   106] loss: 0.443, acc: 79.849, test_acc:30.000, F1:0.337\n",
            "[Epoch: 234 Batch:   106] loss: 0.365, acc: 78.352, test_acc:24.167, F1:0.264\n",
            "[Epoch: 235 Batch:   106] loss: 0.479, acc: 76.289, test_acc:33.333, F1:0.350\n",
            "[Epoch: 236 Batch:   106] loss: 0.386, acc: 78.465, test_acc:20.833, F1:0.239\n",
            "[Epoch: 237 Batch:   106] loss: 0.377, acc: 78.491, test_acc:22.500, F1:0.248\n",
            "[Epoch: 238 Batch:   106] loss: 0.428, acc: 79.371, test_acc:27.500, F1:0.306\n",
            "[Epoch: 239 Batch:   106] loss: 0.398, acc: 79.585, test_acc:25.833, F1:0.297\n",
            "[Epoch: 240 Batch:   106] loss: 0.336, acc: 80.126, test_acc:25.000, F1:0.297\n",
            "[Epoch: 241 Batch:   106] loss: 0.312, acc: 79.509, test_acc:29.167, F1:0.320\n",
            "[Epoch: 242 Batch:   106] loss: 0.378, acc: 79.660, test_acc:33.333, F1:0.365\n",
            "[Epoch: 243 Batch:   106] loss: 0.379, acc: 78.453, test_acc:33.333, F1:0.365\n",
            "[Epoch: 244 Batch:   106] loss: 0.408, acc: 77.497, test_acc:33.333, F1:0.351\n",
            "[Epoch: 245 Batch:   106] loss: 0.450, acc: 78.843, test_acc:25.000, F1:0.266\n",
            "[Epoch: 246 Batch:   106] loss: 0.370, acc: 79.925, test_acc:26.667, F1:0.313\n",
            "[Epoch: 247 Batch:   106] loss: 0.353, acc: 78.478, test_acc:30.000, F1:0.349\n",
            "[Epoch: 248 Batch:   106] loss: 0.342, acc: 78.843, test_acc:27.500, F1:0.320\n",
            "[Epoch: 249 Batch:   106] loss: 0.410, acc: 78.151, test_acc:19.167, F1:0.231\n",
            "[Epoch: 250 Batch:   106] loss: 0.382, acc: 79.270, test_acc:25.833, F1:0.295\n",
            "[Epoch: 251 Batch:   106] loss: 0.399, acc: 78.767, test_acc:27.500, F1:0.318\n",
            "[Epoch: 252 Batch:   106] loss: 0.376, acc: 78.943, test_acc:24.167, F1:0.272\n",
            "[Epoch: 253 Batch:   106] loss: 0.355, acc: 79.774, test_acc:22.500, F1:0.267\n",
            "[Epoch: 254 Batch:   106] loss: 0.386, acc: 78.340, test_acc:37.500, F1:0.402\n",
            "[Epoch: 255 Batch:   106] loss: 0.454, acc: 77.849, test_acc:30.833, F1:0.345\n",
            "[Epoch: 256 Batch:   106] loss: 0.362, acc: 78.252, test_acc:26.667, F1:0.311\n",
            "[Epoch: 257 Batch:   106] loss: 0.306, acc: 78.465, test_acc:22.500, F1:0.239\n",
            "[Epoch: 258 Batch:   106] loss: 0.332, acc: 79.698, test_acc:22.500, F1:0.255\n",
            "[Epoch: 259 Batch:   106] loss: 0.303, acc: 79.497, test_acc:24.167, F1:0.275\n",
            "[Epoch: 260 Batch:   106] loss: 0.370, acc: 78.566, test_acc:29.167, F1:0.333\n",
            "[Epoch: 261 Batch:   106] loss: 0.298, acc: 78.113, test_acc:31.667, F1:0.350\n",
            "[Epoch: 262 Batch:   106] loss: 0.318, acc: 78.679, test_acc:26.667, F1:0.288\n",
            "[Epoch: 263 Batch:   106] loss: 0.332, acc: 77.874, test_acc:30.000, F1:0.347\n",
            "[Epoch: 264 Batch:   106] loss: 0.351, acc: 82.189, test_acc:20.833, F1:0.229\n",
            "[Epoch: 265 Batch:   106] loss: 0.352, acc: 78.780, test_acc:27.500, F1:0.311\n",
            "[Epoch: 266 Batch:   106] loss: 0.357, acc: 78.704, test_acc:31.667, F1:0.348\n",
            "[Epoch: 267 Batch:   106] loss: 0.345, acc: 79.597, test_acc:36.667, F1:0.412\n",
            "[Epoch: 268 Batch:   106] loss: 0.395, acc: 77.535, test_acc:31.667, F1:0.331\n",
            "[Epoch: 269 Batch:   106] loss: 0.370, acc: 78.981, test_acc:28.333, F1:0.310\n",
            "[Epoch: 270 Batch:   106] loss: 0.421, acc: 77.031, test_acc:25.833, F1:0.290\n",
            "[Epoch: 271 Batch:   106] loss: 0.411, acc: 77.509, test_acc:35.000, F1:0.385\n",
            "[Epoch: 272 Batch:   106] loss: 0.372, acc: 77.774, test_acc:25.833, F1:0.281\n",
            "[Epoch: 273 Batch:   106] loss: 0.349, acc: 80.566, test_acc:22.500, F1:0.256\n",
            "[Epoch: 274 Batch:   106] loss: 0.367, acc: 77.673, test_acc:24.167, F1:0.256\n",
            "[Epoch: 275 Batch:   106] loss: 0.305, acc: 77.836, test_acc:27.500, F1:0.299\n",
            "[Epoch: 276 Batch:   106] loss: 0.308, acc: 77.673, test_acc:22.500, F1:0.240\n",
            "[Epoch: 277 Batch:   106] loss: 0.349, acc: 78.969, test_acc:20.833, F1:0.234\n",
            "[Epoch: 278 Batch:   106] loss: 0.340, acc: 79.044, test_acc:25.833, F1:0.290\n",
            "[Epoch: 279 Batch:   106] loss: 0.296, acc: 78.981, test_acc:25.000, F1:0.272\n",
            "[Epoch: 280 Batch:   106] loss: 0.373, acc: 80.692, test_acc:29.167, F1:0.318\n",
            "[Epoch: 281 Batch:   106] loss: 0.351, acc: 77.057, test_acc:30.000, F1:0.324\n",
            "[Epoch: 282 Batch:   106] loss: 0.457, acc: 74.553, test_acc:31.667, F1:0.312\n",
            "[Epoch: 283 Batch:   106] loss: 0.486, acc: 77.673, test_acc:26.667, F1:0.291\n",
            "[Epoch: 284 Batch:   106] loss: 0.385, acc: 78.855, test_acc:29.167, F1:0.317\n",
            "[Epoch: 285 Batch:   106] loss: 0.387, acc: 78.805, test_acc:33.333, F1:0.336\n",
            "[Epoch: 286 Batch:   106] loss: 0.491, acc: 75.862, test_acc:34.167, F1:0.362\n",
            "[Epoch: 287 Batch:   106] loss: 0.423, acc: 76.855, test_acc:40.000, F1:0.406\n",
            "[Epoch: 288 Batch:   106] loss: 0.457, acc: 76.390, test_acc:34.167, F1:0.359\n",
            "[Epoch: 289 Batch:   106] loss: 0.342, acc: 78.956, test_acc:38.333, F1:0.395\n",
            "[Epoch: 290 Batch:   106] loss: 0.421, acc: 79.019, test_acc:33.333, F1:0.345\n",
            "[Epoch: 291 Batch:   106] loss: 0.410, acc: 78.226, test_acc:30.833, F1:0.313\n",
            "[Epoch: 292 Batch:   106] loss: 0.304, acc: 79.132, test_acc:27.500, F1:0.310\n",
            "[Epoch: 293 Batch:   106] loss: 0.332, acc: 79.673, test_acc:29.167, F1:0.312\n",
            "[Epoch: 294 Batch:   106] loss: 0.345, acc: 77.849, test_acc:40.833, F1:0.423\n",
            "[Epoch: 295 Batch:   106] loss: 0.416, acc: 79.182, test_acc:25.000, F1:0.259\n",
            "[Epoch: 296 Batch:   106] loss: 0.460, acc: 77.006, test_acc:28.333, F1:0.295\n",
            "[Epoch: 297 Batch:   106] loss: 0.415, acc: 75.094, test_acc:29.167, F1:0.315\n",
            "[Epoch: 298 Batch:   106] loss: 0.465, acc: 78.629, test_acc:35.833, F1:0.378\n",
            "[Epoch: 299 Batch:   106] loss: 0.343, acc: 79.245, test_acc:20.833, F1:0.244\n",
            "[Epoch: 300 Batch:   106] loss: 0.342, acc: 78.654, test_acc:20.000, F1:0.236\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  20.0\n",
            "Test F1 Score : 0.23626573644775326\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.41      0.28      0.33        54\n",
            "         1.0       0.04      0.25      0.07        12\n",
            "         2.0       0.46      0.11      0.18        54\n",
            "\n",
            "    accuracy                           0.20       120\n",
            "   macro avg       0.30      0.21      0.19       120\n",
            "weighted avg       0.39      0.20      0.24       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[15 32  7]\n",
            " [ 9  3  0]\n",
            " [13 35  6]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAADbCAYAAAAGVmpVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxd8/3H8dcnk31fRTJJjCxoEMRYYougEmuKUrEWtasfRYsWrbaI2kprbZUS1C6oJWKJ2LIgYgsji+xBNiSyfn9/fO7puTO5dzKTzJ1z5877+XjM49577pk73zM3ue/57hZCQERERNbVIOkCiIiI5CuFpIiISBYKSRERkSwUkiIiIlkoJEVERLJQSIqIiGTRMOkCVFfHjh1DSUlJ0sUQEZECMXHixK9DCJ0yPVfnQrKkpIQJEyYkXQwRESkQZjYj23NqbhUREclCISkiIpKFQlJERCQLhaSIiEgW9TMkQ4DFi5MuhYiI5Ln6GZKTJkGnTjB4MNx5J3zzTdIlEhGRPFQ/Q7JdOzj/fCgrg9NPh5ISuPBCGDMGVq5MunQiIpInrK7tJ1laWhpqbJ5kCPDeezB8ODz2GKxZAy1bwt57w7bbengOHQqdO9fMzxMRkbxjZhNDCKUZn6vXIZluyRJ45RV48UUYNQqmT4fVq6FBAxg4EI48EvbcE3r3hqZNa/7ni4hIIhSSGyIE+PBDeOQR//r0Uz/eujUMG+Y1zb33hh/9yINURETqJIXkxgoBPv4YJk+GkSPhqadg2TJ/rqgItt4aDjvMA3PQIGjeHJo18+dERCSvKSRrWgjw5Zfw0kswdSq8+iq8+Wb5c4qL4bjjoG1bb6I95BBo0iSR4oqISHaVhWSdW+A8L5jBZpvBKafEx5Yt89rmSy95iL7wgg8IihxyCPznP167bNy49sssIiLVpppkLq1dC8uX+1zMX/3Kw7VtW7j6ajjiCGjRwptlRUQkMZXVJDXiJJcaNPAgPP98uPtu+M1vvP/yjDN8MYPmzWHAAHj7bT//22+TLa+IiJSj5tbactJJfrt2Lbz1lvdhfv+91zIHDICttvIRtCNGwDHHJFtWEREB1NyavO++g2uugdde8/VkZ86E44+HLbeEc85JunQiIgVPA3fyWcuW8Kc/+f2pU2H77eG223z1n3HjYNEiOPNMOPDAZMspIlIPqU8yn/TsCdOm+eo/hx0G990H77wDBx0EZ5/tKwCJiEitUUjmmw4dfLDPI4/AggUwaxZccAHceit07Aj9+vli7NFiBiIikjM5C0kzu9vMFpjZh1meNzO72czKzOwDM+ufq7LUSUVFPgK2cWO47jp4+GHvq+zSBW64AY4+Gr7+OulSiogUtFzWJO8BhlTy/AFAn9TXacBtOSxL3XfkkXDLLb5IwS23wNNPe4gecYTPxRQRkRqXs5AMIYwBFlZyylDg38G9DbQ1sy65Kk9BOfts3/vykkvgiSdgr718abwvv/TVfkREpEYk2SdZDMxMezwrdWwdZnaamU0wswlfffVVrRQu7+25J1x1FTz6qIfjoEG+VN422/jemCIistHqxMCdEMKdIYTSEEJpp06dki5Ofjn8cPj8cx/o89e/QsOG8NOf+uAejYYVEdkoSc6TnA10T3vcLXVMqqt1aw9G8CXvLrgArr8ennsOevWCffeFk0+GVq2SLaeISB2TZE1yJHBCapTrrsCSEMLcBMtTGBo39oE9I0b4lJHPPoPzzvMQXbvWz1G/pYhIleRyCsiDwFvAlmY2y8xOMbMzzOyM1Cn/BaYCZcBdwFm5Kku9dMwxvtTdp5/6HMsXX4Sf/czDsk0bePDBpEsoIpL3ctbcGkIYtp7nA3B2rn6+pDnjDPjkE7j3Xt+ZpKTEQ7RRo7iZVkRE1qEFzuuTEPxr1SrfeWThQpgyBZo0SbpkIiKJ0X6S4sy8JtmkCVx7LcyYAeeeC3fd5XMvlyxJuoQiInlFu4DUV/vt5yNe77zTv8D7L595Bpo1S7ZsIiJ5QjXJ+uyf//RdR9591/srX34ZttjCp46IiIhCst4rKYEddoATTvCQbNfOt+l69FEtoC4i9Z6aWyU2aBC88grssYcvqN64MQwf7n2Ygwf7fpciIvWIQlLK69ABxo2DsWN9mbvzz/fjhx+uNWFFpN5Rc6usq1UrOOAAePZZeOklH+Dz9NO+RuzrryddOhGRWqOQlOyKinzd1/PO87mV/fr5tlwnnAA//JB06UREck4hKeu37bawyy7eN3nWWXDfffD73yddKhGRnFOfpFTN00/7AumdO8PKlfCXv3jtco894OCDfYk7EZECo5qkVE2nTh6QANdd58va/e1vPqBnxx1h+fJkyycikgMKSam+Nm189OuyZXDPPTB5sgeniEiBUUjKhisqghNP9J1Err4aPv4Y1qyJ960UEanjFJKy8W66yWuXP/6xN8uWlPgydyIidZxCUjZecbEP7Pn+e9h1V+jSxedWfvxx0iUTEdkoGt0qNaO01PenbNDA13zt3Rt+9StfA7Zly6RLJyKyQVSTlJrTIPXPqWNHuOIKeOEFb3497TSYMyfZsomIbACFpOTGeefBq6/C8cfDv/8NBx0EK1YkXSoRkWpRSEpumMHAgb6h8yOPwPvvw+WXJ10qEZFqUUhK7h1yCJx+uq/S89vfen/lmDGwZIl/iYjkKQshJF2GaiktLQ0TJkxIuhhSXd9/D/37w2efeS2zuNibX7t1gwkT4v5MEZFaZmYTQwilmZ7TJ5PUjhYt4MknfWH00aN9IM/KlfDee35cRCQPaQqI1J4f/chHvQK8+67XInfbDS6+2EfE7rVXsuUTEalANUlJxnbbQYcOvkj6okU+yGfECLjoIrj77qRLJyICqCYpSfvxj+HLL2G//eC44/zYppv6mrBFRcmWTUTqPdUkJXnNmnktsqTEQ3PePHjttaRLJSKikJQ8UVICU6f6IJ6WLeGhh/z49Onaq1JEEqOQlPxhBs2bw09+Ag88ANdcAz17Qrt2vhVXCLB4cdKlFJF6RCEp+efqq6F1a7jkEthpJ9h/f7j0UthlFx8F++c/a89KEakVCknJP926wTPP+LqvI0fCww97WH70EQwaBL/7XdwcKyKSQzkNSTMbYmZTzKzMzC7O8HwPM3vFzN4zsw/M7MBclkfqkP79fWH0zp2haVNfLH3GDN9ZpEcPuP/+pEsoIvVAzkLSzIqAvwMHAH2BYWbWt8JpvwMeDiHsABwN3Jqr8kgd17y5N7U2aABHHw2jRvm+lSIiOZTLmuTOQFkIYWoIYSXwEDC0wjkBaJ263wbQpoOyfsOGwerV6za5Tp2q7bhEpEblMiSLgZlpj2eljqX7PXCcmc0C/gv8MtMLmdlpZjbBzCZ89dVXuSir1CXbbefL2V1xBcyd68fmzIG+fX2wj4hIDUl64M4w4J4QQjfgQOA+M1unTCGEO0MIpSGE0k6dOtV6ISXPmPnSdcuX++ID99/v+1auWOG3ixYlXUIRKRC5DMnZQPe0x91Sx9KdAjwMEEJ4C2gKdMxhmaRQbLklPPigz508/ni46iqvSX7/Pdyqrm0RqRm5DMnxQB8z29zMGuMDc0ZWOOdLYF8AM/sRHpJqT5WqGToUJk+GCy6AVavgxhvh4IM9MKdMSbp0IlIAchaSIYTVwDnAC8An+CjWj8zsSjM7NHXaBcCpZjYJeBD4eahru0BLsho0gOuug6++8kUHbr/d14I9/nivZY4ZA8uWJV1KEamjrK5lUmlpaZgwYULSxZB8duedcPrpcMcdfvvLX8LNNyddKhHJU2Y2MYRQmvE5haQUnMWLfbutEGDlSmjSBL74AoorDq4WEak8JJMe3SpS89q2hUMP9YAcPBjWrIFf/ALGj4fRo5MunYjUIQpJKUynneY1yGuv9QE9o0fDzjv75s4vv5x06USkjlBISmHabz9YsgT69YNzzoH33oP77vO1YK+5JunSiUgdoZCUwtWkSXx/663huOPg/PN93dexY/34qlU+jaSO9c2LSO1QSEr9cuaZUFICRx4JX34JF13ktc3994dp05IunYjkmYZJF0CkVrVuDc8+62u/DhrkQbnbbj6op7QUjjjCt+baZhvv1xSReq1KU0DMrAWwPISw1sy2ALYCngshrMp1ASvSFBCpEW++CUOGeDNrWRl8+y2ccgp8/jksXerL2339NXTokHRJRSTHamIKyBigqZkVAy8CxwP31EzxRBKw224wbpyPdO3cGXr3htde891EnnrKz3n33WTLKCKJq2pIWghhGXA4cGsI4Uhg69wVS6QWbLUV7LTTusf79/dbtViI1HtVDkkzGwAcCzybOlaUmyKJJKxdO69ZTpyYdElEJGFVDcnzgEuAJ1KLlPcEXsldsUQStuOOcU1y1SpYvTrZ8ohIIqoUkiGE10IIh4YQhqc2Rf46hHBujssmkpzSUpgxw+dVdu4Mw4YlXSIRSUCVQtLMHjCz1qlRrh8CH5vZRbktmkiC9tnHt+H66199LdjHHvNF0kWkXqlqc2vfEMJS4CfAc8Dm+AhXkcLUv79PC1mxwlfnKSqCW2/1KSP33gsLFyZdQhGpBVUNyUZm1ggPyZGp+ZFax0sKW/Pm0KgRdO3qiwz84x9w993w85/75s7jx3sNU0QKVlVD8g5gOtACGGNmmwFLc1Uokbxz+eW+wMCpp/rjN9+ECy/09WC//z7ZsolIzlR14M7NIYTiEMKBwc0ABuW4bCL5o29fD8gQfEPnsWM9KH/4AZ5/Pj7vu+9802cRKQhVHbjTxsxuMLMJqa/r8VqlSP1xzTVw221w5ZW+Ddfq1WAGjz8en3PSSXDAAcmVUURqVFWbW+8GvgWOSn0tBf6Vq0KJ5KU2beCMM2DgQH/cogUceyw884wP8AkBXnkF3nlHtUmRAlHVkOwVQrgihDA19fUHoGcuCyaSt/r08SbX/fbzAT1Ll/o6sNOmwTffeFi+8UZ8/tKlPlJWROqcqm6VtdzM9gghjAUws92B5bkrlkgeM/ONm9u39221zHxx9F694nPGjIGDDvL7Bx3ktdBnnkmmvCKywaoakmcA/zazNqnHi4ATc1MkkTpgm23i+9tuC6++6rXIZs18E+fXX/fnpk71QT5t2ngN0yyR4orIhqnq6NZJIYTtgH5AvxDCDsA+OS2ZSF0xcKCPdB0zxtd83Wcfn0M5fjw88oifs2SJB6aI1ClV7ZMEIISwNLXyDsCvclAekbpn771h+XLff3LwYDj3XOje3Td1vvnmeONm7SoiUudUKyQrULuRCMD++/sC6PfeC5de6oN6XnwRdtjBm1iHD4fGjSsPyW+/9XNFJK9UtU8yE/2PFgFo2RIeeKD8sd694aWX4se33eY1zUxmz/bzH34YDjkkd+UUkWqrtCZpZt+a2dIMX98CXWupjCJ13447wltvwbPPrvvc2LG+cs8HH9R+uUSkUpXWJEMIrWqrICIF7cILPQwPPthrlC+8AF26wIkn+uIDADNnJltGEVnHxjS3ikhV9enjcyk32cSbZm++2XcZOfxwhaRIHlNIitSWjh2htBRuuQVWrvSv9L5KhaRI3tmY0a3rZWZDzGyKmZWZ2cVZzjnKzD42s4/M7IFM54gUjCFDfJ3X9u1hjz3gssu8P3KTTRSSInkoZyFpZkXA34EDgL7AMDPrW+GcPsAlwO4hhK2B83JVHpG8MGSI3x5yiE8Z2W8/Xyj96KN9UfTvvku2fCJSTi5rkjsDZakF0VcCDwFDK5xzKvD3EMIigBDCghyWRyR5O+8Mp58O550HPXv6aNelS/04+AjYDz9Mtowi8j+57JMsBtLbj2YBu1Q4ZwsAM3sDKAJ+H0J4vsI5mNlpwGkAPXr0yElhRWpFw4Zw++3ljzVo4Cv0gA/kKSqC6dOhbdtaL56IlJfTPskqaAj0AfYGhgF3mdk6nwwhhDtDCKUhhNJOnTrVchFFakEUkt995+u83nhj/NwLL2SeXykiOZfLkJwNdE973C11LN0sYGQIYVUIYRrwGR6aIvVLcbHfNmwIgwZ5SC5eDFOmwGGH+XzKlSsrf4077/RAFZEak8uQHA/0MbPNzawxcDQwssI5T+K1SMysI978qq0SpP5p3Bg23xyGDoXrrvO1XO+6C447Dlav9m24nnvOz/3++8zrvF5yCdx0U+2WW6TA5SwkQwirgXOAF4BPgIdDCB+Z2ZVmdmjqtBeAb8zsY+AV4KIQwje5KpNIXnv5ZfjnP6F/f9htNw+9CRPgvvt8ishVV8GBB0Lr1nD99eW/d+FC/5o2LZmyixQoC3Vs54HS0tIwYcKEpIshklsPPeQ7i5x4Itxzjy9rd/310K0bNG3qW3NNnx4P8lmwAHbd1Wuky5f7YCARqRIzmxhCKM30nP4nieSjo46CJ5+EW2/1x1de6cvXTZ/uYTl7Nowc6av39OwJjz3m561cCXPmJFZskUKjmqRIXbNmDfTq5f2Sixf7PMsOHbzfEnyN2L32SraMInWIapIihaSoCB59FNau9SXuNtnEA7JJE39+atrYtwULfNm755+HgQNh2bJkyixSRykkReqi0lLff3LSJN9+C3ywT4MGcUiuXQs77ACnnQbDh8OYMfDgg8mVWaQOUkiK1FXt2sGWW3oNEWDrraFHjzgkP/zQ+ydHjIBXX/Vjf/tb5ukjIpKRQlKkrhs0yJtgt93WB/FEITlmjN82aABmvuPI++/D+PGVv14IGvwjkqKQFKnrunf3ptef/9yDcuJED8PXXvOa5R/+AGefDWee6ee/8w784x++WEEmTz/t3/fFF7V2CSL5SpsuixSCvqld6H73O3j4YZ9C8s03cNBBcOml/lwIvvHzpEnw0kvQvDmceuq6r/X66z6CduxYH0UrUo+pJilSSDp29IUIlizxFXj23Td+zgz69fOAnDHDa4pr1qz7Gu++67fjxtVOmUXymEJSpNDstRfMnAlvvOFrv6br188DEnzhgZkzyz8fgkJSJI1CUqQQNW7sU0KKisof79ev/OPPPy//ePp0X6Bgk028WfaHH3JaTJF8p5AUqU+ikIz2r6wYklEt8uSTYdUqD0qRekwhKVKf9O3rtcwjjoAWLdYNyfHjvfYZDeh55ZXaL6NIHlFIitQnzZr5/MnLLoPeveGzz3y6yMUXwyefwCOPeJ9mz54wYAA88ED213r8cV/RZ9Wq2iu/SC1TSIrUN7vsAu3bQ58+MGqUB93w4T4SdupUOOkkP+/YY2HyZJ9GUlICZ51VPhBfe80DtqwskcsQqQ0KSZH6qn9/nwLy61/DHXfA3LnQqhUcfrg/f+SR3vT63//6fMnbboP774+/PxoZ+9FHtV92qbvuvx+OOSbpUlSZQlKkvrrgAg+64cO9D/L44/1Yixb+/CabeDA++aTPrezfH/78Z1i92p//8ku//fjj7D/j+ed9NSCpvxYsgBNOgG+/9cejR3uz/tq1yZarihSSIvVV48bQtavfN4N//xuuuKL8OaeeCkOH+vOXX+4LEEQ7iUQ1yUwhGYKff8ABvvpPHflArDWzZsETTyRditrxxBNw332+XCL4QherV8OiRcmWq4oUkiJSNYce6lNI/vQn+P57ryGA90seeig88wx8953XHk84Af74R9h5Z5gyBS65BH7xC39evHn7pz+Na+WF7J13/HbxYr9dssRv581LpjzVpLVbRaRqop1EjjwSbrzRj3Xu7CE4ZYoH4DPPeAAAXHmlh2OfPnDttX5syy3hoouSKX8+WbTIa9eLF/tSgoUsWrmpYkjOn+/bu+U51SRFpOoOP9xHut50kz8ePNhvGzb00a733efNq9One6A2bAi33w6/+Q3svTdcdx0sX167ZV60CN57r3Z/5vpE/XN1pMlxgy1dGjfHR+GYHpLVNWIEPPpozZStihSSIlJ1DRrAgQf6DiPg00R69YJ//tNrRsuW+eCfzTaLv2fwYLjmGu+jXLAAnnqqdst8442+RN+KFbX7cyuzdKnfFnpITpwYb/KdqSZZFStW+ICx5cv99m9/q/lyVkIhKSLVE9UeAfbc0+dJnnCC72XZvz/stFPm7xswwG8/+yz7ay9f7n2cVTF5Mhx22PrXl/3ySz+nsp9b22ojJCdNijfgTkq0wXejRh6SIcRhOWUKbLVVvDl4NqNG+RZwzz/vi/NHtfBaopAUkeoZNMg/9Dp29BV8Is89532SZpm/r2lTH007bVr21/7jH31xgz//Oa6BZDNqlE9PmTy58vOiGsvGzOecNMn7UysreyZz5mRebKG6IblmDdxwQ/x9VXHMMd7MnaS5c6FlS++7XrLE/1iJFqR49lkPyvX9URT9/saN85YKhaSI5LVWrTwot9yy/PHiYujSpfLvLSnx/spsRo/2fszf/Q7eeqvy1/rqK7+dMqXy82oiJC++2Gui1e3bPPVUH8UaKSvzAU7VDclx47wZe+TIqv/sWbPiEchJWbIE2rSBtm29Bhk1tUI8hWh9wR+tLzx6tN8qJEUk7z3wwIYNoNh888y1sRUr/MNv4kQ45RQ/Nnas344c6UETNd29/bY3I0YBkOuQHDvWm/rAa0ZVtXq1NyVG+3eG4E3R119f/YE70TV+/XXVzv/hBw+fpPs8KwvJyPpCMqpJRvMsFZIikvc6dIBNN63+922+uddw0ucHhuDTRPbd15sVjzjCF1iPpg7ccAM89pj3ab76Kuy3H/z2t1WrSa5dG4fphobkc8/58nwNGlRvbt+kSV5rXLzYQ2vZMr//5ZfVr0lG/alVDcnoD4N8Dcn0fztVDcloQYrvv6/VxSkUkiJSe0pKPAhnzoSHH/al7z75xB9H23QNGOCLEIwb5x+gb7wBp5/uzbyHHeYfkjNmVK0muWiRB3Lbtv5huyGbSM+Z4x/qm2xSvZB8/fX4/vz58YCV+fP9GiA+NmNG5a+9oSG5cGHVy5sLUUi2aeP3o5DcYov4nMpqhitXevN8o0blj9fiohQKSRGpPZtv7rfTpnlz7VdfxdtxtWnjUzVatvSQnDnT58WtXu2DUM4+Ow6V9P62zz/PXrOIwmLvvf2cDRnhOneu97V26VK95tb0kJw3L67VpTc3R8eOPDJuZs5kQ0Ny2TIPmqRUrElG7196SFZWk5w+3d+33Xcvf7wWm1wVkiJSe0pK/Hbq1HhD5ygkJ06MB6bssovfXn211yAHDIBzz/Vm2R139Nrd/Pn+3PLl8SCQiqKw2HNPv624yTSsv3YZheSmm1a9JvnNN/Dyy/GKMvPmxQGRKSSnTPGBSplG9K5dG5e7qiGZXs6NbXItK/NpP7NnV/9700NyyZL4dzBggK8dXFLiITliBPzqV5l/NpSfdgSFE5JmNsTMpphZmZldXMl5R5hZMLPSXJZHRBLWvbv37Y0cGX/gT5sGnTr5ogRt2/qxHXaAdu08/A4/3JvbNtnEa1S/+IU32S5bFtcwPv0088+LQjKao/nFF+Wfv+suD9r0xcZDgIceilcGmjPHp65UJyQvucQ/yP/yF3+cXpNMX3Fo0SIPj2iQTaZBTTNnxkFe3Zpk9DM2xssvw4svek1+fdNyKkpvbl2zxn+X4P3OCxb43Npvv4WTT/ZFH158sfz3VwzJaJGKQghJMysC/g4cAPQFhplZ3wzntQL+D3gnV2URkTzRqBGUlsLTT/vjvn3L30aaNfMBLgsWwL/+Vf65bt3i+3vs4bfZ+iWjsOjTx4M4fc7iyy/Daad5c+7jj8fHx42DYcN8rubKlR5MUU1y/vz1DxqZPdvD99xzfZARlK9JRjp18gCLRr8CTJiw7utFTa1bbFE+JFeu9Jr2smXZrxs2vl8yKt9TT8ELL1T9+1as8K+oJhm9lpn/YdKmDbRu7X8gbLutP3/RReV/v7Nne41zu+188++jjvLjhRCSwM5AWQhhaghhJfAQMDTDeX8EhgMb0KMuInXO4497rXHbbeGQQ/xYxZAE75vs1GndxQnSQ3Lbbf2DtrKQLCqC9u39Z6bXJKMpBUOG+By8qJYUhdJf/xqPiI36JFevjpfkyyZa5ebAA+NFF+bOXbdG16NH1UIyWvt09909JKNyjhkDl17qI38zXXdkY2uS06f7HNhGjXx93qqKBulUDMlWrbw1Afz+0qVx6H3wQflm3QULvAWhQQNfqOJnP/PjBRKSxUB6R8Gs1LH/MbP+QPcQwrM5LIeI5JPiYv8wfOUVb1aFzCGZTXpIbrKJL2qQLSTTP2R79Spfk5w+3T+8Dz/cQyx6jS++8GBetsynmkBck4T1N7lGH/LRXp1dumSuSW62mQdJ1MTavXvmkBw/3l9rm228ybLiVlNvveVh/skn8ffMnx8v7LCxITljBvTu7V/ZmrUzyRaS0X2Ia5Jff+1/EEH5gTzR+xdp1cpvCyQkK2VmDYAbgAuqcO5pZjbBzCZ8Fc2NEpG6q3lzn2s5cCBsv33cLFkVHTpAkyZ+v7KQfOkl38uwc2d/3Lu39++NHg0ffugf2CUlPj8T4hVdysq8lrfzznHzYtQnCesPyajfLQrJqC+zYlhF/WuTJ3uT4pAhPreyovHjvSzRllpRk2tUW3zzTa+RH3dc/D3z5vm6qLDhIfnQQ97EOn26/5622qp8EK9Peki2aeP3Z8yI74OH5IoV3iTcq1f57wO/xuj9g4ILydlA97TH3VLHIq2AbYBXzWw6sCswMtPgnRDCnSGE0hBCaaforw0Rqfs23dSXeos+0KvCLK5NdurkITlrVjz3EDxIhgzxpsooBHv18qbKwYPhvPP8w3+zzXzhgh494oW2y8o8UKNpI1D9mmSzZnEYRCGZqSYJvnZpjx4eRAsXlh/Ys3ixN//utFMcklFzb1SOSZO8Nvruu/ECC/Pnx8sGbmhIXnGFL4U3Z46X9Uc/8lp2tPbq+mSqSa5evW5IRjKFZIHXJMcDfcxsczNrDBwN/G/hwRDCkhBCxxBCSQihBHgbODSEkKG9QUQkTbduvmB6y5ZxGKTPgXz2WW+afOcd38MS4g/hNWs8UKKaJHgIvfuu349CcuBAf2zmH9RRSEY1xWzmzPEm5agvNb0m2aFDfF73VB1i8mQPyajmmT4XM2p+TQ/JijXJqIzgg5F++MGDprjYQ2VDBu6E4AOnvvjC70c1ydWrMy/YnkmmkAQ/VvUAAA68SURBVAQftRypLCRD8JBMr0m2aOHXWosh2TBXLxxCWG1m5wAvAEXA3SGEj8zsSmBCCKEaK/WKiKTp08fDxCyuhX70kTdNjh/vzarFxT6nMv17wD+wo9pVVJvr398HwMyY4TW13r19oExRkYdTw4YeOJtumrnJcdYsuOMOPyeaMhLp2tWbFKPw/eYbb27ebbe4T26zzeI+xLlzvXb7zTfxoJzS0rjMUUjOm+d/IHz+ue/r+fTTvjNK9EdDr14eSBtSk1ywoPz80c02iwPt00+9Vrk+6SHZoQPsv7//7i+6KD4nqhlG5U3/vqVL/feWXpM08z+ManHFnZyFJEAI4b/AfyscuzzLuXvnsiwiUkCuuSb+MO3d2z88Tzqp/JqwZ55ZfmRsp06+UHkIcMABfiwKyShMH344fs1WrbwGl/6a2223br/h/Pn+/QsWeJh27hwvXgBxoHz8MRx6qH/It2zpgXvzzfDzn3tNLQrWqKa6zz4+wKl/fw+7oiI/nl6T3Gor34R4u+28uXnUqHghhp128lG9GxKSFXdq2WyzOKw++cSXB6xMWVncHNymjZc90/SRymqS0YpK6SEJ/r4UQk1SRCRnOnSImy6bNfP5josW+eCVBQvgrLN8KbuKBg/2MDGLmxHBgwjgwQf9tndvv73nnvLLuvXr51NDVq3yKREheMgtXep7YV52mfdJFqcN5N9mG78NwWtSHTvGa5GecIIHyL77xsfmzPFzy8rgxBPh1lv9eKtWfk7U7zhvHuy6azzoafBgn15z770eTNlqkk8/7TXts87K/vuNpqX06OHndu/ug4u6d4/371y7Np7KkW7tWv+jIeq7TA/CitKf69HDfxcVQzK9uTX6PSgkRUSq4fbbyz8+9ljvs8ykRQtvkvz007gm2amTB8B77/mxqGm24p6Z223noXnddT6i9pBDvHZ6880+h++yy/y8is2t0dql7dp5SEZzHc3iUakheAjOnevNicuW+bJ2zZvH526zjfc7rlnjNcr03TQOPthv33jDQ9fMf17Fkb+33+5BV1lIRjXJm27yftHGjf3x7rv7TixPPOF/HEyfXr6PEeIVhKLfdcNKYiY9JDt2jBdCh7ypSWrtVhEpPNkCMrLjjv5h2759fGyXXTyQnnwynmJS0Xbb+e2ll3qN7dhjvf/wjDP8wzxqMkwPySjcwMPyyCN9bmZFZt4vOWdO3FRZcRPrY4/1PtexY73Gll7L6trVm1ghvm3fft3FD+bN8wDKtsTcsmXxfMbDDvOVhyL77eff/5vfeBBWXOYP4poulB/JmknUJ9mihbcItG4dh2Q0MEkhKSJSy6680psm0/ssb7nFV+HZfvvs37fllnGtaocdfGDJZZfFTaXRGrHFxeW/L1p2rV07+PWvPWQz6drVa5JRSFbcs/OYY7yJ8/rrMz8frWBUWhq/3oIF5ftV582LN7lOFwJcfrkH1RNPxE3R6aKm3WjB9Uy7oqQvnbe+kIxqktHUvkw1yYrT/hSSIiI51rPnugsYbLrp+udrNmrk/Zf9+nlt7plnvF8xstdefhs140bSa5KVqViTrBiCXbr4KNFo7duK/XUnneTNvtHc0G7dvMYZhVn6JtTRLfjI3OJi71c18/MrXkN0XVFtGeJBRlOmxJtkRzXJoqL1X280pSOa3lIxJNu3X3cvSYWkiEgee/RR362ieXNfdDt98MpJJ8Hbb/sglHRR7bRiqFXUtWvlIQnwhz/E9ys+362br5QThVNUo501y28XLoxrlVFIrlrlNdvOnX2gUlRLzVSTBDj6aG+ujsIUfJurvff2uapRTfKOOzx0K9OggYdeppCcN2/dplbw85cs2bANtDeAQlJEpDqKi7OHXcOG8RSMdAMG+LJ3P/5x5a/dtasP8Jk2zV8rvc80svPO8abFmUI0XbQyURSS6QsQRCH52msenldc4aNpTz0VBg3yGmsmf/qTD+bp1CmuSX78sa8UdPzx8esOGxbXaCvToUN8HVFILl7sU0ZKM+ye2Lmz97O2aeOLReSYRreKiOSamc97XJ9ooM7EiR4GmaZYgK8O9OGH3lxZmYohmb6kXhRmjz3mrxPt2dismY+grUpZ5871cJwxw4Nu3DivgTZvHo/KXZ9HHolrjG3a+ICgu+7yEb6ZNmK++GKvmb/1VvWWM9xAqkmKiOSLfv389o03Kq8ltmiRucZaUbt2HnrvveehO2JE/NyCBT6d5fHHfVuvZs2qV9ZokFFZmQ/6iaagvPVW3HxaFTvuGC/RF9Ukb7nFa6HRLjHpmjaFn/wEhg9f/8CgGqCQFBHJF9tv7x/8a9asvym1KqLF4B97zEMxWiyhUSN//J//+O3JJ1f/taP+02ge5kEH+e3MmdULyXTRtc+c6VNl8oBCUkQkXxQVxSNkayIkwUNy2TK//8MPPoWlpMTD8YYbfC/PqKm1Orp08T7OaC3bffaJp8ds6G5N6TXDXXfdsNeoYQpJEZF8MmiQ39ZkSKbbdFPvAxw1yrfpOu+88vNFq6prV59SMnas/4zWrX1qDWxcTRK8OXnrrTfsNWqYQlJEJJ9EA3zSV+3ZGFFIRnM1O3f2kFy40Jtdjzpqw143GmT02mvxaNtozduNrUnuvHPly9nVIoWkiEg+6dfPdyM59tiaeb0oJC+80G+jmiR4rXVDB79EIb5iRTxVIwrJja1J5klTK2gKiIhIfjGr2UErQ4f6CNRhw3xEaN++cd/h+ra8qsw22/hr7747nHOOH9vYmmTPnh6U0SCgPKCQFBEpZMXFPkAHfHH0Jk18VGvz5h5yGypaDD7dxtYkN93Ut/bakD7SHFFzq4hIfRFtXTVsmC8wUHGXkY01cCBccsn6VxaqTB4FJKgmKSJS/zRosO4+kDWhaVO46qqaf90EqSYpIiKShUJSREQkC4WkiIhIFgpJERGRLBSSIiIiWSgkRUREsrAQQtJlqBYz+wqYUUMv1xH4uoZeq66oj9cMuu76pD5eM+i6N8ZmIYSMywTVuZCsSWY2IYRQmnQ5alN9vGbQdSddjtpUH68ZdN25en01t4qIiGShkBQREcmivofknUkXIAH18ZpB112f1MdrBl13TtTrPkkREZHK1PeapIiISFb1MiTNbIiZTTGzMjO7OOny5JKZTTezyWb2vplNSB1rb2ajzOzz1G0OtgOoXWZ2t5ktMLMP045lvE5zN6fe/w/MrH9yJd9wWa7592Y2O/V+v29mB6Y9d0nqmqeY2eBkSr3xzKy7mb1iZh+b2Udm9n+p4wX7fldyzQX9fptZUzMbZ2aTUtf9h9Txzc3sndT1/cfMGqeON0k9Lks9X7LRhQgh1KsvoAj4AugJNAYmAX2TLlcOr3c60LHCsWuBi1P3LwaGJ13OGrjOvYD+wIfru07gQOA5wIBdgXeSLn8NXvPvgQsznNs39W+9CbB56v9AUdLXsIHX3QXon7rfCvgsdX0F+35Xcs0F/X6n3rOWqfuNgHdS7+HDwNGp47cDZ6bunwXcnrp/NPCfjS1DfaxJ7gyUhRCmhhBWAg8BG7E9d500FLg3df9e4CcJlqVGhBDGAAsrHM52nUOBfwf3NtDWzGp499ncy3LN2QwFHgohrAghTAPK8P8LdU4IYW4I4d3U/W+BT4BiCvj9ruSasymI9zv1nn2Xetgo9RWAfYBHU8crvtfRv4FHgX3NNm4X5/oYksXAzLTHs6j8H1tdF4AXzWyimZ2WOtY5hDA3dX8e0DmZouVctuss9H8D56SaFe9Oa0ovyGtONaftgNcw6sX7XeGaocDfbzMrMrP3gQXAKLxWvDiEsDp1Svq1/e+6U88vATpszM+vjyFZ3+wRQugPHACcbWZ7pT8ZvF2i4Ic415frBG4DegHbA3OB65MtTu6YWUvgMeC8EMLS9OcK9f3OcM0F/36HENaEELYHuuG14a1q8+fXx5CcDXRPe9wtdawghRBmp24XAE/g/8jmR81NqdsFyZUwp7JdZ8H+GwghzE99qKwF7iJuYiuoazazRnhYjAghPJ46XNDvd6Zrri/vN0AIYTHwCjAAbzJvmHoq/dr+d92p59sA32zMz62PITke6JMaHdUY79wdmXCZcsLMWphZq+g+sD/wIX69J6ZOOxF4KpkS5ly26xwJnJAa9bgrsCStma5Oq9DXdhj+foNf89Gp0X+bA32AcbVdvpqQ6mP6J/BJCOGGtKcK9v3Ods2F/n6bWScza5u63wz4Md4f+wrw09RpFd/r6N/AT4GXU60KGy7p0UtJfOGj3T7D27Z/m3R5cnidPfERbpOAj6JrxdvoRwOfAy8B7ZMuaw1c64N4c9MqvI/ilGzXiY+Y+3vq/Z8MlCZd/hq85vtS1/RB6gOjS9r5v01d8xTggKTLvxHXvQfelPoB8H7q68BCfr8rueaCfr+BfsB7qev7ELg8dbwnHvplwCNAk9TxpqnHZanne25sGbTijoiISBb1sblVRESkShSSIiIiWSgkRUREslBIioiIZKGQFBERyUIhKZLnzGxN2i4P71sN7lxjZiXpu4iISHkN13+KiCRsefBluUSklqkmKVJHme8Veq35fqHjzKx36niJmb2cWvR6tJn1SB3vbGZPpPbmm2Rmu6VeqsjM7krt1/diamUTEUEhKVIXNKvQ3PqztOeWhBC2Bf4G3JQ6dgtwbwihHzACuDl1/GbgtRDCdvg+lB+ljvcB/h5C2BpYDByR4+sRqTO04o5InjOz70IILTMcnw7sE0KYmlr8el4IoYOZfY0vT7YqdXxuCKGjmX0FdAshrEh7jRJgVAihT+rxb4BGIYQ/5f7KRPKfapIidVvIcr86VqTdX4PGKoj8j0JSpG77WdrtW6n7b+K72wAcC7yeuj8aOBP+t5Ftm9oqpEhdpb8YRfJfs9TO7JHnQwjRNJB2ZvYBXhscljr2S+BfZnYR8BVwUur4/wF3mtkpeI3xTHwXERHJQn2SInVUqk+yNITwddJlESlUam4VERHJQjVJERGRLFSTFBERyUIhKSIikoVCUkREJAuFpIiISBYKSRERkSwUkiIiIln8P5uLQTrP3wTIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.185043489933014 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  2\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 37.031, test_acc:38.333, F1:0.388\n",
            "[Epoch: 2 Batch:   106] loss: 1.084, acc: 37.673, test_acc:30.000, F1:0.304\n",
            "[Epoch: 3 Batch:   106] loss: 1.081, acc: 37.497, test_acc:25.000, F1:0.254\n",
            "[Epoch: 4 Batch:   106] loss: 1.078, acc: 37.208, test_acc:28.333, F1:0.294\n",
            "[Epoch: 5 Batch:   106] loss: 1.076, acc: 36.881, test_acc:30.000, F1:0.305\n",
            "[Epoch: 6 Batch:   106] loss: 1.074, acc: 37.233, test_acc:32.500, F1:0.331\n",
            "[Epoch: 7 Batch:   106] loss: 1.075, acc: 38.025, test_acc:28.333, F1:0.282\n",
            "[Epoch: 8 Batch:   106] loss: 1.073, acc: 39.057, test_acc:30.000, F1:0.301\n",
            "[Epoch: 9 Batch:   106] loss: 1.072, acc: 38.390, test_acc:35.833, F1:0.366\n",
            "[Epoch: 10 Batch:   106] loss: 1.071, acc: 38.868, test_acc:32.500, F1:0.324\n",
            "[Epoch: 11 Batch:   106] loss: 1.070, acc: 38.956, test_acc:34.167, F1:0.346\n",
            "[Epoch: 12 Batch:   106] loss: 1.066, acc: 37.987, test_acc:37.500, F1:0.382\n",
            "[Epoch: 13 Batch:   106] loss: 1.067, acc: 39.950, test_acc:34.167, F1:0.341\n",
            "[Epoch: 14 Batch:   106] loss: 1.065, acc: 40.113, test_acc:35.833, F1:0.351\n",
            "[Epoch: 15 Batch:   106] loss: 1.062, acc: 40.000, test_acc:35.833, F1:0.355\n",
            "[Epoch: 16 Batch:   106] loss: 1.060, acc: 40.264, test_acc:30.833, F1:0.299\n",
            "[Epoch: 17 Batch:   106] loss: 1.061, acc: 40.541, test_acc:35.000, F1:0.349\n",
            "[Epoch: 18 Batch:   106] loss: 1.057, acc: 41.799, test_acc:40.000, F1:0.401\n",
            "[Epoch: 19 Batch:   106] loss: 1.055, acc: 41.748, test_acc:40.833, F1:0.399\n",
            "[Epoch: 20 Batch:   106] loss: 1.055, acc: 42.717, test_acc:36.667, F1:0.363\n",
            "[Epoch: 21 Batch:   106] loss: 1.059, acc: 41.346, test_acc:36.667, F1:0.369\n",
            "[Epoch: 22 Batch:   106] loss: 1.051, acc: 43.472, test_acc:32.500, F1:0.323\n",
            "[Epoch: 23 Batch:   106] loss: 1.051, acc: 42.654, test_acc:31.667, F1:0.327\n",
            "[Epoch: 24 Batch:   106] loss: 1.050, acc: 43.484, test_acc:34.167, F1:0.349\n",
            "[Epoch: 25 Batch:   106] loss: 1.043, acc: 43.371, test_acc:35.000, F1:0.354\n",
            "[Epoch: 26 Batch:   106] loss: 1.047, acc: 44.126, test_acc:35.833, F1:0.362\n",
            "[Epoch: 27 Batch:   106] loss: 1.043, acc: 44.214, test_acc:38.333, F1:0.388\n",
            "[Epoch: 28 Batch:   106] loss: 1.042, acc: 45.472, test_acc:37.500, F1:0.375\n",
            "[Epoch: 29 Batch:   106] loss: 1.039, acc: 45.447, test_acc:38.333, F1:0.387\n",
            "[Epoch: 30 Batch:   106] loss: 1.035, acc: 45.484, test_acc:25.833, F1:0.262\n",
            "[Epoch: 31 Batch:   106] loss: 1.037, acc: 45.723, test_acc:40.833, F1:0.415\n",
            "[Epoch: 32 Batch:   106] loss: 1.034, acc: 47.031, test_acc:34.167, F1:0.351\n",
            "[Epoch: 33 Batch:   106] loss: 1.029, acc: 46.541, test_acc:28.333, F1:0.285\n",
            "[Epoch: 34 Batch:   106] loss: 1.029, acc: 46.654, test_acc:34.167, F1:0.347\n",
            "[Epoch: 35 Batch:   106] loss: 1.024, acc: 47.082, test_acc:32.500, F1:0.330\n",
            "[Epoch: 36 Batch:   106] loss: 1.025, acc: 47.107, test_acc:37.500, F1:0.385\n",
            "[Epoch: 37 Batch:   106] loss: 1.022, acc: 47.484, test_acc:33.333, F1:0.342\n",
            "[Epoch: 38 Batch:   106] loss: 1.020, acc: 47.245, test_acc:40.833, F1:0.420\n",
            "[Epoch: 39 Batch:   106] loss: 1.014, acc: 48.679, test_acc:40.833, F1:0.415\n",
            "[Epoch: 40 Batch:   106] loss: 1.010, acc: 48.906, test_acc:35.000, F1:0.351\n",
            "[Epoch: 41 Batch:   106] loss: 1.011, acc: 49.786, test_acc:34.167, F1:0.352\n",
            "[Epoch: 42 Batch:   106] loss: 1.010, acc: 48.818, test_acc:36.667, F1:0.377\n",
            "[Epoch: 43 Batch:   106] loss: 1.004, acc: 50.767, test_acc:31.667, F1:0.316\n",
            "[Epoch: 44 Batch:   106] loss: 0.999, acc: 51.195, test_acc:35.000, F1:0.358\n",
            "[Epoch: 45 Batch:   106] loss: 0.998, acc: 49.736, test_acc:34.167, F1:0.349\n",
            "[Epoch: 46 Batch:   106] loss: 0.997, acc: 50.478, test_acc:34.167, F1:0.350\n",
            "[Epoch: 47 Batch:   106] loss: 0.991, acc: 50.994, test_acc:32.500, F1:0.329\n",
            "[Epoch: 48 Batch:   106] loss: 0.989, acc: 51.522, test_acc:35.833, F1:0.364\n",
            "[Epoch: 49 Batch:   106] loss: 0.982, acc: 52.415, test_acc:35.000, F1:0.357\n",
            "[Epoch: 50 Batch:   106] loss: 0.986, acc: 52.465, test_acc:33.333, F1:0.342\n",
            "[Epoch: 51 Batch:   106] loss: 0.977, acc: 52.843, test_acc:40.833, F1:0.414\n",
            "[Epoch: 52 Batch:   106] loss: 0.974, acc: 52.956, test_acc:36.667, F1:0.372\n",
            "[Epoch: 53 Batch:   106] loss: 0.972, acc: 53.824, test_acc:35.000, F1:0.354\n",
            "[Epoch: 54 Batch:   106] loss: 0.967, acc: 54.063, test_acc:32.500, F1:0.333\n",
            "[Epoch: 55 Batch:   106] loss: 0.959, acc: 55.333, test_acc:37.500, F1:0.382\n",
            "[Epoch: 56 Batch:   106] loss: 0.957, acc: 54.591, test_acc:36.667, F1:0.371\n",
            "[Epoch: 57 Batch:   106] loss: 0.960, acc: 53.610, test_acc:33.333, F1:0.340\n",
            "[Epoch: 58 Batch:   106] loss: 0.958, acc: 55.673, test_acc:39.167, F1:0.402\n",
            "[Epoch: 59 Batch:   106] loss: 0.949, acc: 55.774, test_acc:34.167, F1:0.353\n",
            "[Epoch: 60 Batch:   106] loss: 0.948, acc: 55.811, test_acc:38.333, F1:0.389\n",
            "[Epoch: 61 Batch:   106] loss: 0.943, acc: 55.899, test_acc:37.500, F1:0.380\n",
            "[Epoch: 62 Batch:   106] loss: 0.934, acc: 56.943, test_acc:37.500, F1:0.387\n",
            "[Epoch: 63 Batch:   106] loss: 0.931, acc: 58.428, test_acc:36.667, F1:0.375\n",
            "[Epoch: 64 Batch:   106] loss: 0.928, acc: 58.201, test_acc:44.167, F1:0.444\n",
            "[Epoch: 65 Batch:   106] loss: 0.936, acc: 57.748, test_acc:33.333, F1:0.338\n",
            "[Epoch: 66 Batch:   106] loss: 0.933, acc: 56.830, test_acc:31.667, F1:0.326\n",
            "[Epoch: 67 Batch:   106] loss: 0.920, acc: 57.044, test_acc:36.667, F1:0.376\n",
            "[Epoch: 68 Batch:   106] loss: 0.914, acc: 59.799, test_acc:36.667, F1:0.375\n",
            "[Epoch: 69 Batch:   106] loss: 0.911, acc: 58.642, test_acc:36.667, F1:0.375\n",
            "[Epoch: 70 Batch:   106] loss: 0.908, acc: 58.377, test_acc:35.833, F1:0.364\n",
            "[Epoch: 71 Batch:   106] loss: 0.901, acc: 59.849, test_acc:34.167, F1:0.348\n",
            "[Epoch: 72 Batch:   106] loss: 0.890, acc: 59.987, test_acc:35.833, F1:0.367\n",
            "[Epoch: 73 Batch:   106] loss: 0.895, acc: 59.962, test_acc:36.667, F1:0.377\n",
            "[Epoch: 74 Batch:   106] loss: 0.893, acc: 60.302, test_acc:34.167, F1:0.352\n",
            "[Epoch: 75 Batch:   106] loss: 0.879, acc: 61.547, test_acc:32.500, F1:0.331\n",
            "[Epoch: 76 Batch:   106] loss: 0.883, acc: 61.044, test_acc:33.333, F1:0.342\n",
            "[Epoch: 77 Batch:   106] loss: 0.880, acc: 60.792, test_acc:34.167, F1:0.351\n",
            "[Epoch: 78 Batch:   106] loss: 0.876, acc: 62.252, test_acc:31.667, F1:0.322\n",
            "[Epoch: 79 Batch:   106] loss: 0.872, acc: 61.774, test_acc:36.667, F1:0.379\n",
            "[Epoch: 80 Batch:   106] loss: 0.870, acc: 61.057, test_acc:35.833, F1:0.365\n",
            "[Epoch: 81 Batch:   106] loss: 0.848, acc: 63.057, test_acc:32.500, F1:0.328\n",
            "[Epoch: 82 Batch:   106] loss: 0.860, acc: 61.597, test_acc:32.500, F1:0.329\n",
            "[Epoch: 83 Batch:   106] loss: 0.847, acc: 63.774, test_acc:31.667, F1:0.325\n",
            "[Epoch: 84 Batch:   106] loss: 0.844, acc: 63.597, test_acc:31.667, F1:0.323\n",
            "[Epoch: 85 Batch:   106] loss: 0.843, acc: 63.686, test_acc:35.833, F1:0.368\n",
            "[Epoch: 86 Batch:   106] loss: 0.826, acc: 64.692, test_acc:34.167, F1:0.350\n",
            "[Epoch: 87 Batch:   106] loss: 0.821, acc: 64.050, test_acc:31.667, F1:0.324\n",
            "[Epoch: 88 Batch:   106] loss: 0.831, acc: 64.943, test_acc:32.500, F1:0.334\n",
            "[Epoch: 89 Batch:   106] loss: 0.826, acc: 64.629, test_acc:34.167, F1:0.350\n",
            "[Epoch: 90 Batch:   106] loss: 0.815, acc: 65.308, test_acc:30.000, F1:0.303\n",
            "[Epoch: 91 Batch:   106] loss: 0.819, acc: 65.585, test_acc:35.000, F1:0.360\n",
            "[Epoch: 92 Batch:   106] loss: 0.817, acc: 65.912, test_acc:32.500, F1:0.333\n",
            "[Epoch: 93 Batch:   106] loss: 0.801, acc: 66.491, test_acc:35.833, F1:0.363\n",
            "[Epoch: 94 Batch:   106] loss: 0.794, acc: 64.969, test_acc:35.000, F1:0.353\n",
            "[Epoch: 95 Batch:   106] loss: 0.793, acc: 67.296, test_acc:35.000, F1:0.350\n",
            "[Epoch: 96 Batch:   106] loss: 0.783, acc: 67.572, test_acc:28.333, F1:0.299\n",
            "[Epoch: 97 Batch:   106] loss: 0.782, acc: 67.119, test_acc:35.000, F1:0.361\n",
            "[Epoch: 98 Batch:   106] loss: 0.771, acc: 67.660, test_acc:45.833, F1:0.462\n",
            "[Epoch: 99 Batch:   106] loss: 0.778, acc: 69.308, test_acc:35.833, F1:0.365\n",
            "[Epoch: 100 Batch:   106] loss: 0.766, acc: 68.516, test_acc:40.000, F1:0.401\n",
            "[Epoch: 101 Batch:   106] loss: 0.751, acc: 68.994, test_acc:33.333, F1:0.337\n",
            "[Epoch: 102 Batch:   106] loss: 0.753, acc: 68.981, test_acc:35.000, F1:0.355\n",
            "[Epoch: 103 Batch:   106] loss: 0.749, acc: 69.975, test_acc:33.333, F1:0.339\n",
            "[Epoch: 104 Batch:   106] loss: 0.771, acc: 68.881, test_acc:33.333, F1:0.346\n",
            "[Epoch: 105 Batch:   106] loss: 0.746, acc: 70.314, test_acc:35.000, F1:0.360\n",
            "[Epoch: 106 Batch:   106] loss: 0.751, acc: 69.132, test_acc:35.000, F1:0.358\n",
            "[Epoch: 107 Batch:   106] loss: 0.748, acc: 70.164, test_acc:35.000, F1:0.366\n",
            "[Epoch: 108 Batch:   106] loss: 0.726, acc: 70.101, test_acc:40.000, F1:0.403\n",
            "[Epoch: 109 Batch:   106] loss: 0.728, acc: 70.277, test_acc:31.667, F1:0.332\n",
            "[Epoch: 110 Batch:   106] loss: 0.730, acc: 69.409, test_acc:33.333, F1:0.343\n",
            "[Epoch: 111 Batch:   106] loss: 0.702, acc: 70.239, test_acc:33.333, F1:0.346\n",
            "[Epoch: 112 Batch:   106] loss: 0.714, acc: 70.478, test_acc:40.000, F1:0.408\n",
            "[Epoch: 113 Batch:   106] loss: 0.705, acc: 71.698, test_acc:32.500, F1:0.328\n",
            "[Epoch: 114 Batch:   106] loss: 0.694, acc: 72.465, test_acc:34.167, F1:0.352\n",
            "[Epoch: 115 Batch:   106] loss: 0.709, acc: 71.094, test_acc:38.333, F1:0.380\n",
            "[Epoch: 116 Batch:   106] loss: 0.714, acc: 70.214, test_acc:30.000, F1:0.310\n",
            "[Epoch: 117 Batch:   106] loss: 0.688, acc: 72.289, test_acc:37.500, F1:0.388\n",
            "[Epoch: 118 Batch:   106] loss: 0.712, acc: 71.044, test_acc:35.000, F1:0.369\n",
            "[Epoch: 119 Batch:   106] loss: 0.672, acc: 74.314, test_acc:38.333, F1:0.386\n",
            "[Epoch: 120 Batch:   106] loss: 0.666, acc: 71.296, test_acc:33.333, F1:0.339\n",
            "[Epoch: 121 Batch:   106] loss: 0.671, acc: 72.616, test_acc:31.667, F1:0.330\n",
            "[Epoch: 122 Batch:   106] loss: 0.679, acc: 71.535, test_acc:37.500, F1:0.374\n",
            "[Epoch: 123 Batch:   106] loss: 0.668, acc: 73.346, test_acc:35.833, F1:0.359\n",
            "[Epoch: 124 Batch:   106] loss: 0.661, acc: 72.931, test_acc:35.833, F1:0.362\n",
            "[Epoch: 125 Batch:   106] loss: 0.659, acc: 71.962, test_acc:35.833, F1:0.371\n",
            "[Epoch: 126 Batch:   106] loss: 0.676, acc: 72.969, test_acc:35.833, F1:0.371\n",
            "[Epoch: 127 Batch:   106] loss: 0.645, acc: 72.692, test_acc:38.333, F1:0.394\n",
            "[Epoch: 128 Batch:   106] loss: 0.650, acc: 72.893, test_acc:34.167, F1:0.347\n",
            "[Epoch: 129 Batch:   106] loss: 0.631, acc: 73.962, test_acc:34.167, F1:0.340\n",
            "[Epoch: 130 Batch:   106] loss: 0.648, acc: 72.906, test_acc:34.167, F1:0.358\n",
            "[Epoch: 131 Batch:   106] loss: 0.632, acc: 72.969, test_acc:35.000, F1:0.360\n",
            "[Epoch: 132 Batch:   106] loss: 0.621, acc: 74.151, test_acc:37.500, F1:0.379\n",
            "[Epoch: 133 Batch:   106] loss: 0.630, acc: 75.107, test_acc:35.833, F1:0.366\n",
            "[Epoch: 134 Batch:   106] loss: 0.621, acc: 75.899, test_acc:34.167, F1:0.353\n",
            "[Epoch: 135 Batch:   106] loss: 0.623, acc: 75.082, test_acc:33.333, F1:0.339\n",
            "[Epoch: 136 Batch:   106] loss: 0.622, acc: 73.836, test_acc:33.333, F1:0.338\n",
            "[Epoch: 137 Batch:   106] loss: 0.597, acc: 73.899, test_acc:33.333, F1:0.340\n",
            "[Epoch: 138 Batch:   106] loss: 0.582, acc: 74.818, test_acc:35.000, F1:0.363\n",
            "[Epoch: 139 Batch:   106] loss: 0.600, acc: 73.987, test_acc:34.167, F1:0.340\n",
            "[Epoch: 140 Batch:   106] loss: 0.590, acc: 75.157, test_acc:30.833, F1:0.319\n",
            "[Epoch: 141 Batch:   106] loss: 0.581, acc: 76.742, test_acc:40.000, F1:0.413\n",
            "[Epoch: 142 Batch:   106] loss: 0.574, acc: 76.830, test_acc:31.667, F1:0.330\n",
            "[Epoch: 143 Batch:   106] loss: 0.583, acc: 76.642, test_acc:33.333, F1:0.343\n",
            "[Epoch: 144 Batch:   106] loss: 0.576, acc: 76.226, test_acc:34.167, F1:0.342\n",
            "[Epoch: 145 Batch:   106] loss: 0.561, acc: 77.497, test_acc:32.500, F1:0.340\n",
            "[Epoch: 146 Batch:   106] loss: 0.565, acc: 74.818, test_acc:37.500, F1:0.383\n",
            "[Epoch: 147 Batch:   106] loss: 0.575, acc: 76.214, test_acc:35.833, F1:0.360\n",
            "[Epoch: 148 Batch:   106] loss: 0.570, acc: 76.377, test_acc:33.333, F1:0.344\n",
            "[Epoch: 149 Batch:   106] loss: 0.555, acc: 76.239, test_acc:37.500, F1:0.391\n",
            "[Epoch: 150 Batch:   106] loss: 0.554, acc: 78.075, test_acc:35.833, F1:0.358\n",
            "[Epoch: 151 Batch:   106] loss: 0.568, acc: 76.692, test_acc:35.833, F1:0.369\n",
            "[Epoch: 152 Batch:   106] loss: 0.553, acc: 77.597, test_acc:33.333, F1:0.349\n",
            "[Epoch: 153 Batch:   106] loss: 0.529, acc: 77.258, test_acc:32.500, F1:0.340\n",
            "[Epoch: 154 Batch:   106] loss: 0.547, acc: 76.126, test_acc:34.167, F1:0.349\n",
            "[Epoch: 155 Batch:   106] loss: 0.520, acc: 77.484, test_acc:32.500, F1:0.315\n",
            "[Epoch: 156 Batch:   106] loss: 0.548, acc: 76.516, test_acc:35.000, F1:0.352\n",
            "[Epoch: 157 Batch:   106] loss: 0.543, acc: 76.629, test_acc:35.833, F1:0.369\n",
            "[Epoch: 158 Batch:   106] loss: 0.535, acc: 77.912, test_acc:35.000, F1:0.362\n",
            "[Epoch: 159 Batch:   106] loss: 0.536, acc: 77.321, test_acc:35.000, F1:0.357\n",
            "[Epoch: 160 Batch:   106] loss: 0.527, acc: 77.635, test_acc:32.500, F1:0.330\n",
            "[Epoch: 161 Batch:   106] loss: 0.501, acc: 78.013, test_acc:38.333, F1:0.394\n",
            "[Epoch: 162 Batch:   106] loss: 0.508, acc: 77.560, test_acc:33.333, F1:0.347\n",
            "[Epoch: 163 Batch:   106] loss: 0.507, acc: 77.824, test_acc:30.833, F1:0.314\n",
            "[Epoch: 164 Batch:   106] loss: 0.510, acc: 77.862, test_acc:30.000, F1:0.302\n",
            "[Epoch: 165 Batch:   106] loss: 0.518, acc: 77.774, test_acc:35.833, F1:0.371\n",
            "[Epoch: 166 Batch:   106] loss: 0.487, acc: 78.906, test_acc:31.667, F1:0.330\n",
            "[Epoch: 167 Batch:   106] loss: 0.503, acc: 79.057, test_acc:26.667, F1:0.281\n",
            "[Epoch: 168 Batch:   106] loss: 0.469, acc: 76.679, test_acc:35.000, F1:0.364\n",
            "[Epoch: 169 Batch:   106] loss: 0.498, acc: 77.384, test_acc:31.667, F1:0.334\n",
            "[Epoch: 170 Batch:   106] loss: 0.486, acc: 78.843, test_acc:32.500, F1:0.334\n",
            "[Epoch: 171 Batch:   106] loss: 0.487, acc: 77.597, test_acc:34.167, F1:0.355\n",
            "[Epoch: 172 Batch:   106] loss: 0.517, acc: 76.151, test_acc:34.167, F1:0.347\n",
            "[Epoch: 173 Batch:   106] loss: 0.483, acc: 77.321, test_acc:30.000, F1:0.311\n",
            "[Epoch: 174 Batch:   106] loss: 0.469, acc: 80.352, test_acc:30.833, F1:0.316\n",
            "[Epoch: 175 Batch:   106] loss: 0.457, acc: 78.994, test_acc:31.667, F1:0.325\n",
            "[Epoch: 176 Batch:   106] loss: 0.488, acc: 79.648, test_acc:29.167, F1:0.309\n",
            "[Epoch: 177 Batch:   106] loss: 0.469, acc: 77.736, test_acc:31.667, F1:0.335\n",
            "[Epoch: 178 Batch:   106] loss: 0.451, acc: 78.654, test_acc:35.833, F1:0.362\n",
            "[Epoch: 179 Batch:   106] loss: 0.461, acc: 78.113, test_acc:29.167, F1:0.310\n",
            "[Epoch: 180 Batch:   106] loss: 0.458, acc: 78.277, test_acc:36.667, F1:0.377\n",
            "[Epoch: 181 Batch:   106] loss: 0.460, acc: 79.132, test_acc:32.500, F1:0.323\n",
            "[Epoch: 182 Batch:   106] loss: 0.443, acc: 80.214, test_acc:29.167, F1:0.306\n",
            "[Epoch: 183 Batch:   106] loss: 0.459, acc: 80.679, test_acc:40.000, F1:0.417\n",
            "[Epoch: 184 Batch:   106] loss: 0.489, acc: 76.239, test_acc:31.667, F1:0.325\n",
            "[Epoch: 185 Batch:   106] loss: 0.447, acc: 78.931, test_acc:30.833, F1:0.323\n",
            "[Epoch: 186 Batch:   106] loss: 0.445, acc: 78.868, test_acc:29.167, F1:0.306\n",
            "[Epoch: 187 Batch:   106] loss: 0.458, acc: 78.830, test_acc:30.833, F1:0.310\n",
            "[Epoch: 188 Batch:   106] loss: 0.452, acc: 79.132, test_acc:35.833, F1:0.369\n",
            "[Epoch: 189 Batch:   106] loss: 0.433, acc: 79.811, test_acc:32.500, F1:0.343\n",
            "[Epoch: 190 Batch:   106] loss: 0.464, acc: 80.390, test_acc:27.500, F1:0.290\n",
            "[Epoch: 191 Batch:   106] loss: 0.465, acc: 79.170, test_acc:34.167, F1:0.355\n",
            "[Epoch: 192 Batch:   106] loss: 0.453, acc: 77.887, test_acc:32.500, F1:0.338\n",
            "[Epoch: 193 Batch:   106] loss: 0.464, acc: 77.799, test_acc:31.667, F1:0.320\n",
            "[Epoch: 194 Batch:   106] loss: 0.427, acc: 77.447, test_acc:32.500, F1:0.336\n",
            "[Epoch: 195 Batch:   106] loss: 0.395, acc: 80.730, test_acc:31.667, F1:0.324\n",
            "[Epoch: 196 Batch:   106] loss: 0.436, acc: 78.994, test_acc:27.500, F1:0.285\n",
            "[Epoch: 197 Batch:   106] loss: 0.401, acc: 79.157, test_acc:31.667, F1:0.334\n",
            "[Epoch: 198 Batch:   106] loss: 0.415, acc: 80.075, test_acc:40.000, F1:0.405\n",
            "[Epoch: 199 Batch:   106] loss: 0.428, acc: 80.604, test_acc:33.333, F1:0.344\n",
            "[Epoch: 200 Batch:   106] loss: 0.409, acc: 80.352, test_acc:31.667, F1:0.332\n",
            "[Epoch: 201 Batch:   106] loss: 0.400, acc: 79.434, test_acc:30.000, F1:0.315\n",
            "[Epoch: 202 Batch:   106] loss: 0.409, acc: 79.308, test_acc:33.333, F1:0.343\n",
            "[Epoch: 203 Batch:   106] loss: 0.397, acc: 77.459, test_acc:40.000, F1:0.405\n",
            "[Epoch: 204 Batch:   106] loss: 0.371, acc: 80.591, test_acc:27.500, F1:0.279\n",
            "[Epoch: 205 Batch:   106] loss: 0.487, acc: 79.031, test_acc:29.167, F1:0.308\n",
            "[Epoch: 206 Batch:   106] loss: 0.417, acc: 79.094, test_acc:30.833, F1:0.325\n",
            "[Epoch: 207 Batch:   106] loss: 0.379, acc: 81.409, test_acc:36.667, F1:0.377\n",
            "[Epoch: 208 Batch:   106] loss: 0.389, acc: 78.893, test_acc:30.000, F1:0.312\n",
            "[Epoch: 209 Batch:   106] loss: 0.362, acc: 78.239, test_acc:27.500, F1:0.290\n",
            "[Epoch: 210 Batch:   106] loss: 0.369, acc: 79.648, test_acc:31.667, F1:0.334\n",
            "[Epoch: 211 Batch:   106] loss: 0.354, acc: 81.182, test_acc:29.167, F1:0.306\n",
            "[Epoch: 212 Batch:   106] loss: 0.375, acc: 80.579, test_acc:31.667, F1:0.336\n",
            "[Epoch: 213 Batch:   106] loss: 0.386, acc: 78.390, test_acc:30.833, F1:0.316\n",
            "[Epoch: 214 Batch:   106] loss: 0.384, acc: 79.912, test_acc:34.167, F1:0.359\n",
            "[Epoch: 215 Batch:   106] loss: 0.359, acc: 80.943, test_acc:31.667, F1:0.326\n",
            "[Epoch: 216 Batch:   106] loss: 0.348, acc: 82.264, test_acc:27.500, F1:0.286\n",
            "[Epoch: 217 Batch:   106] loss: 0.404, acc: 80.377, test_acc:31.667, F1:0.330\n",
            "[Epoch: 218 Batch:   106] loss: 0.425, acc: 78.855, test_acc:31.667, F1:0.328\n",
            "[Epoch: 219 Batch:   106] loss: 0.336, acc: 82.516, test_acc:36.667, F1:0.379\n",
            "[Epoch: 220 Batch:   106] loss: 0.358, acc: 80.277, test_acc:30.833, F1:0.322\n",
            "[Epoch: 221 Batch:   106] loss: 0.379, acc: 80.201, test_acc:35.000, F1:0.355\n",
            "[Epoch: 222 Batch:   106] loss: 0.339, acc: 80.453, test_acc:34.167, F1:0.355\n",
            "[Epoch: 223 Batch:   106] loss: 0.367, acc: 80.981, test_acc:35.833, F1:0.367\n",
            "[Epoch: 224 Batch:   106] loss: 0.344, acc: 79.912, test_acc:33.333, F1:0.345\n",
            "[Epoch: 225 Batch:   106] loss: 0.370, acc: 80.906, test_acc:31.667, F1:0.330\n",
            "[Epoch: 226 Batch:   106] loss: 0.373, acc: 80.138, test_acc:30.833, F1:0.322\n",
            "[Epoch: 227 Batch:   106] loss: 0.346, acc: 80.138, test_acc:31.667, F1:0.323\n",
            "[Epoch: 228 Batch:   106] loss: 0.330, acc: 80.403, test_acc:30.000, F1:0.311\n",
            "[Epoch: 229 Batch:   106] loss: 0.332, acc: 80.692, test_acc:34.167, F1:0.351\n",
            "[Epoch: 230 Batch:   106] loss: 0.322, acc: 80.679, test_acc:30.833, F1:0.321\n",
            "[Epoch: 231 Batch:   106] loss: 0.364, acc: 80.465, test_acc:29.167, F1:0.299\n",
            "[Epoch: 232 Batch:   106] loss: 0.332, acc: 80.566, test_acc:30.833, F1:0.318\n",
            "[Epoch: 233 Batch:   106] loss: 0.291, acc: 79.723, test_acc:33.333, F1:0.344\n",
            "[Epoch: 234 Batch:   106] loss: 0.317, acc: 81.572, test_acc:30.833, F1:0.319\n",
            "[Epoch: 235 Batch:   106] loss: 0.359, acc: 80.013, test_acc:31.667, F1:0.326\n",
            "[Epoch: 236 Batch:   106] loss: 0.355, acc: 83.799, test_acc:30.833, F1:0.318\n",
            "[Epoch: 237 Batch:   106] loss: 0.350, acc: 80.277, test_acc:33.333, F1:0.343\n",
            "[Epoch: 238 Batch:   106] loss: 0.319, acc: 80.855, test_acc:35.000, F1:0.363\n",
            "[Epoch: 239 Batch:   106] loss: 0.369, acc: 78.868, test_acc:31.667, F1:0.329\n",
            "[Epoch: 240 Batch:   106] loss: 0.415, acc: 79.723, test_acc:31.667, F1:0.328\n",
            "[Epoch: 241 Batch:   106] loss: 0.368, acc: 81.019, test_acc:29.167, F1:0.301\n",
            "[Epoch: 242 Batch:   106] loss: 0.338, acc: 80.906, test_acc:32.500, F1:0.330\n",
            "[Epoch: 243 Batch:   106] loss: 0.290, acc: 82.465, test_acc:30.833, F1:0.319\n",
            "[Epoch: 244 Batch:   106] loss: 0.317, acc: 81.560, test_acc:33.333, F1:0.344\n",
            "[Epoch: 245 Batch:   106] loss: 0.302, acc: 79.623, test_acc:35.000, F1:0.355\n",
            "[Epoch: 246 Batch:   106] loss: 0.357, acc: 78.088, test_acc:27.500, F1:0.274\n",
            "[Epoch: 247 Batch:   106] loss: 0.384, acc: 80.302, test_acc:32.500, F1:0.328\n",
            "[Epoch: 248 Batch:   106] loss: 0.356, acc: 83.094, test_acc:23.333, F1:0.228\n",
            "[Epoch: 249 Batch:   106] loss: 0.420, acc: 79.912, test_acc:30.833, F1:0.301\n",
            "[Epoch: 250 Batch:   106] loss: 0.415, acc: 80.541, test_acc:28.333, F1:0.291\n",
            "[Epoch: 251 Batch:   106] loss: 0.485, acc: 78.239, test_acc:39.167, F1:0.397\n",
            "[Epoch: 252 Batch:   106] loss: 0.415, acc: 77.107, test_acc:30.000, F1:0.301\n",
            "[Epoch: 253 Batch:   106] loss: 0.331, acc: 80.780, test_acc:35.000, F1:0.365\n",
            "[Epoch: 254 Batch:   106] loss: 0.393, acc: 79.912, test_acc:34.167, F1:0.353\n",
            "[Epoch: 255 Batch:   106] loss: 0.338, acc: 78.377, test_acc:35.000, F1:0.360\n",
            "[Epoch: 256 Batch:   106] loss: 0.268, acc: 81.019, test_acc:29.167, F1:0.284\n",
            "[Epoch: 257 Batch:   106] loss: 0.354, acc: 79.346, test_acc:31.667, F1:0.325\n",
            "[Epoch: 258 Batch:   106] loss: 0.385, acc: 79.987, test_acc:30.000, F1:0.311\n",
            "[Epoch: 259 Batch:   106] loss: 0.338, acc: 79.686, test_acc:25.000, F1:0.251\n",
            "[Epoch: 260 Batch:   106] loss: 0.349, acc: 80.302, test_acc:32.500, F1:0.340\n",
            "[Epoch: 261 Batch:   106] loss: 0.353, acc: 79.447, test_acc:34.167, F1:0.355\n",
            "[Epoch: 262 Batch:   106] loss: 0.359, acc: 78.755, test_acc:35.833, F1:0.360\n",
            "[Epoch: 263 Batch:   106] loss: 0.351, acc: 80.113, test_acc:33.333, F1:0.343\n",
            "[Epoch: 264 Batch:   106] loss: 0.379, acc: 81.157, test_acc:32.500, F1:0.344\n",
            "[Epoch: 265 Batch:   106] loss: 0.389, acc: 77.132, test_acc:31.667, F1:0.328\n",
            "[Epoch: 266 Batch:   106] loss: 0.409, acc: 79.509, test_acc:33.333, F1:0.347\n",
            "[Epoch: 267 Batch:   106] loss: 0.299, acc: 81.774, test_acc:29.167, F1:0.298\n",
            "[Epoch: 268 Batch:   106] loss: 0.398, acc: 79.572, test_acc:31.667, F1:0.320\n",
            "[Epoch: 269 Batch:   106] loss: 0.381, acc: 78.151, test_acc:35.833, F1:0.371\n",
            "[Epoch: 270 Batch:   106] loss: 0.336, acc: 81.031, test_acc:27.500, F1:0.283\n",
            "[Epoch: 271 Batch:   106] loss: 0.332, acc: 81.786, test_acc:32.500, F1:0.338\n",
            "[Epoch: 272 Batch:   106] loss: 0.291, acc: 79.057, test_acc:28.333, F1:0.282\n",
            "[Epoch: 273 Batch:   106] loss: 0.315, acc: 82.906, test_acc:35.833, F1:0.369\n",
            "[Epoch: 274 Batch:   106] loss: 0.321, acc: 82.616, test_acc:26.667, F1:0.277\n",
            "[Epoch: 275 Batch:   106] loss: 0.342, acc: 79.472, test_acc:33.333, F1:0.343\n",
            "[Epoch: 276 Batch:   106] loss: 0.270, acc: 82.025, test_acc:29.167, F1:0.302\n",
            "[Epoch: 277 Batch:   106] loss: 0.321, acc: 81.786, test_acc:30.000, F1:0.298\n",
            "[Epoch: 278 Batch:   106] loss: 0.371, acc: 78.956, test_acc:30.833, F1:0.318\n",
            "[Epoch: 279 Batch:   106] loss: 0.331, acc: 80.164, test_acc:36.667, F1:0.377\n",
            "[Epoch: 280 Batch:   106] loss: 0.359, acc: 80.377, test_acc:28.333, F1:0.274\n",
            "[Epoch: 281 Batch:   106] loss: 0.374, acc: 79.635, test_acc:35.833, F1:0.372\n",
            "[Epoch: 282 Batch:   106] loss: 0.351, acc: 79.245, test_acc:29.167, F1:0.307\n",
            "[Epoch: 283 Batch:   106] loss: 0.537, acc: 77.874, test_acc:29.167, F1:0.302\n",
            "[Epoch: 284 Batch:   106] loss: 0.448, acc: 79.157, test_acc:30.833, F1:0.319\n",
            "[Epoch: 285 Batch:   106] loss: 0.381, acc: 81.635, test_acc:30.000, F1:0.309\n",
            "[Epoch: 286 Batch:   106] loss: 0.372, acc: 81.648, test_acc:40.000, F1:0.406\n",
            "[Epoch: 287 Batch:   106] loss: 0.327, acc: 81.346, test_acc:31.667, F1:0.314\n",
            "[Epoch: 288 Batch:   106] loss: 0.243, acc: 82.465, test_acc:31.667, F1:0.324\n",
            "[Epoch: 289 Batch:   106] loss: 0.357, acc: 80.717, test_acc:33.333, F1:0.343\n",
            "[Epoch: 290 Batch:   106] loss: 0.380, acc: 78.679, test_acc:33.333, F1:0.337\n",
            "[Epoch: 291 Batch:   106] loss: 0.346, acc: 79.484, test_acc:35.833, F1:0.363\n",
            "[Epoch: 292 Batch:   106] loss: 0.285, acc: 79.396, test_acc:32.500, F1:0.323\n",
            "[Epoch: 293 Batch:   106] loss: 0.298, acc: 80.050, test_acc:30.000, F1:0.300\n",
            "[Epoch: 294 Batch:   106] loss: 0.423, acc: 80.038, test_acc:32.500, F1:0.332\n",
            "[Epoch: 295 Batch:   106] loss: 0.275, acc: 82.994, test_acc:30.000, F1:0.299\n",
            "[Epoch: 296 Batch:   106] loss: 0.330, acc: 81.522, test_acc:35.833, F1:0.365\n",
            "[Epoch: 297 Batch:   106] loss: 0.322, acc: 82.553, test_acc:35.000, F1:0.361\n",
            "[Epoch: 298 Batch:   106] loss: 0.274, acc: 82.365, test_acc:34.167, F1:0.358\n",
            "[Epoch: 299 Batch:   106] loss: 0.295, acc: 81.597, test_acc:30.833, F1:0.311\n",
            "[Epoch: 300 Batch:   106] loss: 0.246, acc: 83.421, test_acc:35.000, F1:0.348\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  35.0\n",
            "Test F1 Score : 0.3478292295939355\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.48      0.34        27\n",
            "         1.0       0.36      0.42      0.38        36\n",
            "         2.0       0.50      0.25      0.33        57\n",
            "\n",
            "    accuracy                           0.35       120\n",
            "   macro avg       0.37      0.38      0.35       120\n",
            "weighted avg       0.40      0.35      0.35       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[13  8  6]\n",
            " [13 15  8]\n",
            " [24 19 14]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAADbCAYAAAAGVmpVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfrH8c8hBOm9twCKggoqGxu6KgooLorY61oXseyKq67oqiuW3d/qrm1XxYao2LBjo4hdKQZBECkCAhJBilRF6vn98czdOwmZkIRM7szk+3695nVn7kxmznUwT55TnuO894iIiMiOqkTdABERkVSlICkiIpKAgqSIiEgCCpIiIiIJKEiKiIgkoCApIiKSQNWoG1BajRs39u3atYu6GSIikiGmTJmy0nvfpKjn0i5ItmvXjry8vKibISIiGcI5tyjRc+puFRERSUBBUkREJAEFSRERkQQUJEVERBKovEFy+fKoWyAiIimucgbJL76ANm3gmmtg5cqoWyMiIimqcgbJtm3hvPPg3nuhVSu46CJYsCDqVomISIpx6bafZG5uri+3dZKzZsFDD8Fjj8GmTbDPPtCjB/z6KzRpAsccA126QNOm5fN5IiKScpxzU7z3uUU+V6mDZGDJEnjuOXjvPfjkE6hTB1avhq1b7fnGjS2AnnYaXHIJOAfVqpVvG0REJBIKkqXhvQXBtWtt7HLmTPj6a8jLg2nT7DVZWXDAAXDWWXDmmdC8OWzbBtnZyWuXiIgkhYJkefAe3n4bJk+2DHP8eLsPFhxr1ID77rOxzqwseOMN+O47GDTIgq6IiKSk4oJk2tVujYxz0Lev3QLffANvvgk//QQTJtgEoEGDoHZt+OEHe82yZXDKKdC5s3XjiohI2lAmWV62bbPs8b33YONGOPRQC5zDh9vzWVlw5ZVw6612vndvOyciIpFSd2tUtm6Fjz6CDRvg9dctYNasCb/8Al27Qs+ecOyx0KuXumRFRCKiIJkKvIe//hU+/xxOPdWWnXz7rWWd3bvDLbfYkpRjj7WuWRERqRAKkqlq0yZ46im4/npYsyY8f+ml8H//Z1mnlpqIiCRVcUGyclbcSRW77QYDBtgSkxdfhNmz4c9/hkcegQYNoGVLeOcdGDNG5fNERCKgTDIVffABTJpkWebs2Xaufn24/HIraLD//tG2T0Qkg6i7NV2tXm0ZZsuWMHSoZZTO2f1LLom6dSIiGSGSdZLOuWFAX2C5937fIp53wP3A8cAvwAXe+y+T1Z601KABDBxo9088EVatgnPOgT/8AcaNg5wcqFIFjjoKjjsu0qaKiGSiZI5JDgeK+83dB+gYuw0AHk5iWzJDo0ZWvGDIEHjtNbj/fvj3v6FPH1t/mWa9AiIiqS5pQdJ7/zHwUzEv6Qc87c1EoL5zrkWy2pMxsrNtuciaNbbe8uef4YILLHCeey58+CHMmQNbtkTdUhGRtBfl7NZWwPdxj5fEzu3AOTfAOZfnnMtbsWJFhTQu5dWsaRV7qlWDYcPgzjttJ5MePaBTJytWkJ8fdStFRNJaWiwB8d4/6r3P9d7nNmnSJOrmpB7n4MYbraD6+PG2hCQ/Hw46CK67Dtati7qFIiJpKcoC5/lAm7jHrWPnpKzatbPb0UfbVl433wz33mu7lWRn20Sfxx9XCTwRkRKKMpMcBfzemUOAtd77pRG2J7MceCCMHm31Yj/+GD791LplH3006paJiKSNpAVJ59zzwARgL+fcEufcxc65gc652JoG3gEWAPOAx4DLk9WWSu3cc2HiRFi82AqpDxwIRx4Jt91m23iJiEhCKiZQmaxfDw89BCNGwMyZ0Ly57U5y0EFRt0xEJDKq3SqmTh0rpj5jBnz1FVSvDr/7HXwfm2ScZn8wiYgkm4JkZdWlC7z7ru1EcuSRcOaZFkRzcmzsUkREFCQrtb32su7WVq2szN2pp1oX7MCBMG1a1K0TEYlclEtAJBUcfbTdAitXWiGC3FzLNocPh/32i6x5IiJRUiYpBTVubAUJbrgBli+H7t1hwoSoWyUiEgkFSdlR585w++2QlwfNmtl45apV9tyyZXDVVbYZtCb6iEiGU5CUxFq0sP0sly6FPfe07LJ/f3jgAZsV+49/RN1CEZGkUpCU4h14IHzyie1ZedddVpjguecsSN59t+rCikhGU5CUnTv4YHjlFZg3z0rcnXWW7V+5Zg3cc0/UrRMRSRrNbpWSa9/ebmCzX087zfax/OUXGDwYGjaMtn0iIuVMmaSU3YgRcPHF1u3aujUMGGAzYkVEMoSCpJRdtWq29db06XDOOfDUU9C3r2WWIiIZQEFSdl2XLvDYYzBypC0bueKKqFskIlIuFCSl/PTrBzfeaFV6TjnFStwNGABr10bdMhGRMlGQlPJ1001WE/bVV2HffeGJJ+COO6JulYhImWh2q5Sv6tVh9Gjbfuu3v7Wxyocftlmx69bBeedZQXURkTSgTZcluWbMsILpgexsuPRSyy7r1YuuXSIiMdp0WaLTpYvtT/n661aM4MILLbPs1s1mw6pij4ikMGWSUvE+/9y6XRcsgF69YOzYqFskIpWYMklJLd27w7ffwrXX2rZcS5daprl9e9QtExEpQEFSolGlim3BtX27FUvv39+WjoiIpBAFSYlOt27QsiVMnWqP77gDtmyJtk0iInEUJCU6zsGJJ1pW+c9/wnffwamnWuWe776LunUiIlonKRG74w44/3zbjuuXX+C++2DUKGjUCJYssXWXIiIRUSYp0WrUCA45xLLKW2+1STwjRsCqVfDGG1G3TkQqOQVJSS01atimzm3bwpNPwqZNNhv2pJNg5cqoWycilYyCpKSeKlWsC3bsWDj9dJgwAd55B444AjZvjrp1IlKJKEhKarrqKjj0UBufPPtsK5g+axZcdhmccALcfruq9YhI0iV14o5z7jjgfiALeNx7/3+Fnm8LPAXUj71msPf+nWS2SdJEo0bw4YcWHPv0gbp1bUPnYcOgYUN46y0rc/fUU1G3VEQyWNIySedcFvAg0AfYGzjLObd3oZfdBIz03h8AnAk8lKz2SBrKzoYzzrAACbax83//C4sXW0b54os2wUdEJEmS2d16EDDPe7/Ae78ZeAHoV+g1Hoj9BqQe8EMS2yPprnlzuOIKqFXLdhLZtAmefjrqVolIBktmkGwFfB/3eEnsXLxbgXOdc0uAd4A/JrE9kkn2289mvf797zB7dtStEZEMFfXEnbOA4d771sDxwDPOuR3a5Jwb4JzLc87lrVixosIbKSlq+HDIyoIDD4SePWHhwqhbJCIZJplBMh9oE/e4dexcvIuBkQDe+wlAdaBx4Tfy3j/qvc/13uc2adIkSc2VtNOxo03uOftsmDwZzj0Xtm6NulUikkGSGSS/ADo659o756phE3NGFXrNYuAYAOdcZyxIKlWUkuvUCR55xDZy/uwzaNbMKvcApNleqSKSepK2BMR7v9U5dyUwBlveMcx7P9M5dxuQ570fBVwDPOacuxqbxHOBT7ddoCU1nHMObNtmJe2GDIHVq+Gll2D0aOjaNerWiUiacukWk3Jzc31eXl7UzZBUtX69ZZc/xCZKH3usBcrA5s1w881WrKBly2jaKCIpxTk3xXufW9RzUU/cESlfderAs8/CtdfazNcxY2D8+PD5MWPgrrvg8ceja6OIpA0FSck8Rx0Fd98NV18NLVrYXpWBUbFh8fjAKSKSgIKkZK7q1eGPf4Rx42x88ssv4c037bkJE2DDBk3uEZFiKUhKZrv0UqhZ03YT+c1v4Mcf4fe/hy1brCBBmza2JZeISBEUJCWzNWxomzePGAG33AKHHQb/+AdUqwZLlkDTpnDRRfDtt1G3VERSUFJ3ARFJCT17hveHDLHjyy9bLdimTaFdO+uG/fOfI2meiKQuZZJSOZ1wgpWzy8mBLl3CCT0iInEUJEVOOAE+/RQuvhh23x0GDoy6RSKSIhQkRU49FbZvtw2et26F55+36j0iUukpSIoccIBV6Fm50goQrFsHM2ZE3SoRSQEKkiJgk3iysuDww+3x3XdDhw7wwQf2+Ndf4ZproHVryM+H++8vWO5ORDJSiYKkc65WsM+jc25P59yJzrns5DZNJAI5ObZ28rnn4LvvbH3l4sU28/WeeyxAvvoqXHcd3Hdf1K0VkSQraSb5MVDdOdcKGAucBwxPVqNEIhVkkzfeaBnkeefBsGFwySXQpInVft2yBb75Jtp2ikjSlXSdpPPe/+Kcuxh4yHt/l3NuWjIbJhKZgQOhbl247TZo3DhcP3nNNbB2rZW4A/j+exu/rFs3uraKSFKVNJN0zrlDgXOAt2PnspLTJJGIHXEEDB1qY5RXXgndutkM2E6drHg6WF1YgFmzImumiCRfSYPkIOAG4LXYxskdgA+S1yyRFJGdDRMnwgsv2OMePex43nl2VJerSEYrUXer9/4j4COA2ASeld77PyWzYSIpIztujlrnzraryCGHwDPPwMyZ4XNvvw377GNl7kQkI5R0dutzzrm6zrlawNfAN86565LbNJEU1bMn1K5t3a9BJvnkk9C3L/TrZwUJwI59+liBdRFJSyXtbt3be78OOAl4F2iPzXAVqbwOOAA+/BCuvx4GDIA99oDp0208E+Ctt2wt5XPPRdpMESm7kgbJ7Ni6yJOAUd77LYB2q5XK7c47oX17WxLSsydMmQK9etls2FdegUcesddNnBhtO0WkzEq6BOQRYCHwFfCxcy4HWJesRomkhRYt4OOPYfx4OOUUmw07ciQcd5zNhgVo2dKKESxdaq8XkbTivC9bQuicq+q931rO7dmp3Nxcn5eXV9EfK1JyP/9sk3omTYKTTrLba6/ZbiNZWjklkmqcc1O897lFPleSIOmcqwf8DTgiduoj4Dbv/dpya2UJKUhKWvn1Vys2ULMm1K9v6yrvvNOWkOy1V9StExGKD5IlHZMcBqwHTo/d1gFPlk/zRDJY9epw8MGwYQMsWmSTfO68E26+OeqWiUgJlDSTnOa9339n5yqCMklJO8uXw+bN0LUrrF5t56pWtaDZsmW0bRORcskkNzrnDo97w8OAjeXROJGM17SpbbF18sn2uG9fW0P56KM2fvn227bps4iknJLObh0IPB0bmwRYDZyfnCaJZKiLL7bi6P/8p2WSd98NEybA2LHwr39ZYfVq1QpW+BGRSJVqdqtzri6A936dc26Q977CN9RTd6tkhMWLrYTdhg22f+UPP4BzNsFn8GC44YaoWyhSaZRHdytgwTFWeQfgzyX44OOcc3Occ/Occ4MTvOZ059w3zrmZzjmVJpHKoW1beOopKzwwdap1xf75z7DffjBkCGzUaIZIKtiVdZLfe+/bFPN8FjAX6AUsAb4AzvLefxP3mo7ASOBo7/1q51xT7/3y4j5XmaRktHffheOPtyLqPXtG3RqRSqHcMslCdhZdDwLmee8XeO83Ay8A/Qq95g/Ag9771QA7C5AiGe+3v7UxyXHjom6JiLCTIOmcW++cW1fEbT2ws7nrrYDv4x4viZ2Ltyewp3PuM+fcROfccaW+ApFMUrs2HHoovPceeA9XXAGvvx51q0QqrWKDpPe+jve+bhG3Ot77ks6MLU5VoCNwFHAW8Jhzrn7hFznnBjjn8pxzeStWrCiHjxVJYb162TjlqFHw0ENw/vk20UdEKtyudLfuTD4QP2bZOnYu3hJiu4p477/DxjA7Fn4j7/2j3vtc731ukyZNktZgkZRw3nlQpYodq1WzNZQXXqi1lCIRSGaQ/ALo6Jxr75yrBpwJjCr0mtexLBLnXGOs+3VBEtskkvpycuD002H9eiuKfu+98P778N//WqC8+27bt1JEki5pQTK2Q8iVwBhgFjDSez/TOXebc+7E2MvGAKucc98AHwDXee9XJatNImnjL3+B3XaDSy+1IgS/+52dGzDAjr16wXffha8v4yx1ESlemZeAREVLQKTS2LTJAiXAypVw+OEwZ47NgJ0xw2rBfvQRzJsHhx1mS0fuv992HRGREkvWEhARSaYgQAI0bmzl6666ykrb/e1vtuHzhAlwySXWNfv005Z1Avz0kwVNdcuK7BJlkiLpaP16K2e3fbvdf/xxyyjvugsWLIDhw+HWW21s88UXo26tSEpTJimSaerUsRqvdevC0KFw0UVw+eVW//W22+A//7GiBK+8AkuWRN1akbSlICmSrgYPtgB46aUWHNu0gTPOgGHDYNUqO3pvW3LFS7PeI5EoKUiKZJLhw225yIcfwrnn2mSft96yxyeeCL/+Cp07Q//+4QbQIpJQeVTNEZFUkZ0NPXqEj3v3hptuguuug7w823lkzhy7zZ8Pn39upfBEpEjKJEUy2bHH2jGY7Hb33XYcOhRmzrSAOmAALNfeApIk338P3btDmpYUVZAUyWQHHACNGtn9Bg0se2zZ0gLj0KGwZo1ll6edBlu2RNtWyUxTp9pSpWnTom5JmShIimSyrCw4+2zLKPv3t3OHHWYTff7wB/j2W3jySVtzOXRotG2VzBRsIL4qPYupKUiKZLoHHoDRo61SD1jXV7yzz4Y994QxY3b82YkTYdGi4t8/TbvRpIIEQXLlymjbUUYKkiKVRd++cNxxcPLJOz7Xo4dlk1u3huc++sgC67XXJn7PvDxo1syCqUhR0jyT1OxWkcqicWN4992in+vRAx55BEaOtAo+mzdbxZ6tW4sPgO+/b+suP/kEDjkkKc2WNKcgKSJp76ij7HjOOeG5Qw+F3/zGtuj66iuYPNnqxDoXviYIoF9+WWFNlTTzyy92TNMgqe5WEbEu09xcaNcOvvjCCqN/9pmNV4JN+hkwAGbPtgxz/HjLICdMsOenTo2q5ZLqlEmKSEYYO9Z2HqlZMzx3wAFQtWq4d+X48TBkCLRtC+PGwbJltqRk7lzYsEGFCWRHaR4klUmKiGnQoGCABKheHfbbz+5XqRIuE1m82MregS0l8d66ZAF++AHOP9/WYBZn3Dg4+GArlZdMixZZofdMtnmz3VKRgqSIZLQLLrBbt25WpadKFZvo88UXsPfe9hzYmCXAyy/b3pbPPlv8+44caT8ze3YSGw88/LBtGZbJxRLOOsv+MElFCpIiktGuvNIKDnTrZo+7dLGu2fXrLWjm5Fi37IMPWiCaNMleN2JE8e8bjGfOmpW8toMVct++PbPXc86YAV9/HXUrihYEyXXr0vIPFQVJESmZAw6w46GH2jhlMP7onI1Tzp9vGeSkSfb8xIm2EXRR1q6Fb76x+8nOJNeuteOyZcn9nCgtXZq61xcESUjLbFJBUkRK5qCD7Hj44Ts+17evPX/zzRYsBw604Jmoy3Xy5HBfy0SZ5IIFVld22jR77Zw5ZWv3unV2TNUgsqs2bLDbypWpmamleZDU7FYRKZlu3awKz2GH7ficc3D77eGuI6ecYl2xI0bAgQda92zfvpbxnHyydbU6ZxV9giD58892rFXLfunvs49N6mnTxjaWvukmyz47dy5duzM9k/zxx4L3W7eOri1F2bjRxrG3b0/LIKlMUkRK7ogjrGh6UXr1siyzShVbc3nuudbd2r8/3H+/Pf/738O//22Vf7p2texz7lyr7NO7N+yxh82SzcuzAPmnP9lWSzfdZJ8RbPlVGpmeSS5dGt5PxWvcuBFatLD7CpIiUmk5Z92jL71k45WnnGLrLrOzrXv1rbcsc7zvPhuvPP98ywo3b7YZqJ9/blnf0UfDhx/ae95yiwXP7Gy7zZhR+nZleiYZf12peI0bN4bZbRoGSXW3ikj56dDBbgD16sFDD0HTptblCtaNeuaZUK2aZZXBDiNXX22zZIcOhT59LPPcfXfbC/OllyybPOccBcmipHqQ/OUXWyo0aVJazjBWkBSR5LnoooKPTzoJmje37LBRI7uNHGmzYi+5BHr2tKC6fDkcf7z9TN26Nj7ZtasVVC+N7dttqQqkZgApD0uXhmN+8V2vqWLjRvue69RJy+9A3a0iUnF2283GHB9+ODx32mnw5pvQr58tHTnlFDsfzKYNdOkC+fnw0082rnnqqTv/vA0bwlm0afgLukSWLbM/PBo0SM1r3LgRatSwcclUDOI7oSApIhWradMdy9/Fu+ACK4fXs2fB81272nHGDBg1Cl57LdxhYvx4WLhwx/cKJu3UqpWaAaQ8LFtmAahFi9S8xo0b7ftO1fbthIKkiKSWgw6y5SD77FPwfBAkp02zZSPbt1vAXLDAlp786U87vlcwHrnnntbtGiwzKY3nnrMsdtu20v9sRVi61DLJ5s1TLwht3Wq3GjWsfaXJJD/5BEaPTl7bSkhBUkRST5UifjUF2dLo0eEEkKlT4c47LYC9++6OsyfjgyQUXFNYUo8+aiXfVq8u/c8m08KFFni+/jp1g2RQSKAs3a233w433JCcdpVCUoOkc+4459wc59w859zgYl53inPOO+dyk9keEUlzQWGCwKuv2qSfo4+2jOXllwu+PuhuDQoQLF5cus9btcoymuB+suXl2SzfkswCnTrVgv6WLbYPaGkztYpQOEj+/HM4kWpn1q2zMeWIJS1IOueygAeBPsDewFnOub2LeF0d4CpgUrLaIiIZ4sADrZsVbKnJuHFW3OCZZ6BTJ1tC8umn1lU7eXKYSR56qB1LWwT87bfDz6uIIPnRRxbIS7KJ9Q8/2PHdd2HQIGjSxIJSME5bFlOn2gbcpf1jIpHCQRJKHsjXrStb93g5S2YmeRAwz3u/wHu/GXgB6FfE624H/gkkeVM5EUl7wXrLmjXhxBPt/oABtvHzbbfZeGWPHla+7qqrwiDZubPN/ixtkHznHSuSABUTJOfPt2OiwvDx8vNtNnDv3la8oXFjO79yZdk/f9AgW37z6adlf494RQXJknYJl3UMuZwlM0i2Ar6Pe7wkdu5/nHPdgDbe+7eLeyPn3ADnXJ5zLm9FGi5GFZFykhsbkenUydZR5uTA9dfbudNOs229srNtEs/EiTB8uD1Xrx7su2/pixHMmRN21aZakPzhBws8wfhtkyZ2LGuQ9B4+/tjuO2cFHq64omzvFdjVTDJ+CU9EIpu445yrAtwDXLOz13rvH/Xe53rvc5sE/xBEpPJp1Aj22w8OPthqwS5cCK3i/vZ+4AHLVO65x7LLoJB67do2Q/Xrr+G770o+gWfx4nCLsIoIkkFwLGmQbNkyfBxkkvn59t+otDNDv/givL92rZUPfOghW5daVkHXbzC7FUoWJL23THL7dti0qeyfXw6SGSTzgTZxj1vHzgXqAPsCHzrnFgKHAKM0eUdEivXJJ3DvvUU/55xV6MnKsm5XsEovVapYJrlunQWQiy/e8WdffdUy0YkT7fGGDRYg9t3XujWTHSS3bAnL9BUXJPPzbdlLfn7BPxCCIDllCkyfHta/DYweXXDbqsLi/5uuWRPeT7TdWUnEZ5ING1o5wpIEyZ9/DjPIiCfvJDNIfgF0dM61d85VA84ERgVPeu/Xeu8be+/bee/bAROBE733ZSjzLyKVRp06VrlnZ4IgWa+eHbt0seP69datuHVr+Noff4QLL4QHH7SdTr7/Ppy8kpNjv+CDIDl3rmWj5W3xYlvK0qSJdbsmWpd5wQU2Hpsok/zqKzsGARcsg+7TJ3HAGzcOXngB/vY3665es8YCGsATT5T9muKDpHOWTebn7/i6adNsAlIgfgZsxOOSSQuS3vutwJXAGGAWMNJ7P9M5d5tz7sRkfa6ICBAGybp17dili1Xy2Xtv+yU8bVr42htvtF/oL71kGd1774VBpm1b6+ZdtcqymxNOgD/8YcfPW7Zs14JnMB7Zu7ftjFJUMNm82SbVzJxpgSw+SNavbxlzcF3xQTLIjmfPLvqz//53aN8eBg+2PyqWLbPPqlXLgm5ZZswuXBjuFVqjhh27d7f/xoVn7151lW2tFmSPwdIdyOhMEu/9O977Pb33u3vv74ydu8V7P6qI1x6lLFJEyk379rZhc5BJ1qtnWeCYMfb4zTetvN3atbaEZMAAqxvbtKmVuYvPJIMgOWuWvcf06fZcMLZ5//32ed27h0tGSisIkscdZ8eiulynTLF9NgPx3a1ZWZbxBuX54pdxTJqU+D03bbKx25NOsj8i6tcPg/3BBxdsW3EmTIDTT7cMfft2C/bBpKqgDOEDD1imfMEF4c+tXQuffWZd20GbK0MmKSISKeds8knwixosaLZubdtw3XabFVUfONCyx7POsp/p2TPMJLOybFZmo0b2S3xU7O/7FStgxAjL5KZMsUw0qA8bZE+BJUusG3dnszTnz7cgdcQR9riorC8obFA1toFTfCYJYZcrWHfs5s12f/JkOyYKvJs22V6fYH9MBIE2KDI/d27xbQd44w3LEufNs6Uz334bPhdkkk2a2H/v6dPD4Pfee2HXcpBhxmeSCpIiIkly8snhesp4vXvbmFvjxjYW16xZWHDgmGMsQ3znHQuoWVlhJvnGG+FY3X33Wcb0179ad+TgWFGxYBlF4PHHbUJQfICaP992MomfDDRvnhVIaNPGstlJRdRX+eQT2GuvMHgVFyS9twD98882Jlm1qn1ukOn+9BMMGWKBDeDww+1Yv779HITrUuMDXiILFtjxm2/sv03QzQ1hkARrf3C9YGORderYf+cvv7Rz8ZlkJne3ioikpLvvtoAR1Abt1y9cb9inT7ilV9u2dq5RI8sSJ00KuwqnTLHjmDGWgV50kQWtwkEyyCzjl1jcfz9ce6110Y4YYefmz7cM1zkL2ME4YrwJE+CwwyygOVewuxXCtZLVq9tx0SILPNu3WxH4X3+1DHPhQstYb73VAtpee4U/W69eGEhzcuwPiJIEyaCL9tNPrbv66qvD5+KDZFBHN8hOP/rI/jDp3DkMksokRUQiVKuWZYmXXGITcS67LHyuRYsweObk2LFRI+sS9B4uv9wyH7D1l2BrKRs2tMDz8ccFu1aDbtP4IDl7NnTsCPvvD+edZ7NOFyywIAlwyCEWROIzzXXr7PFee8Ff/mJdv8F4ayDIJIMMcNGiMBidfLId//53W9ayeHF4nUEXLxR8zwYNrJ2lySSfftqOQeCDMPsG2GMPOwbtWrHCsudu3ZRJioiklLp1Ldjsv3/B89dfb2N0xxxjjxs1smNOjmmUYVYAAA0dSURBVG3ZtXesDPWgQXY8+mg7HnmkZWpBZZ9t28JgEB8kZ82ySTHvv2/LIoYPty7b+CAJBbtcC08k6tt3x+sJgmTw84sXhxV4gu7khx+2mb4zZljAHDvWln4E6tcP7zdoYJlfUWOS3sPIkdbutWvDogOrVllQPPBAa//UqWFpPwj/QJk7195j3ToLzPvvb2soV6xQJikiktKqV7eMMOhaDYJkv372Cz8+SA4ZYtklwKmnWoB47DF7vHixdXE2bGhZ0tatliUtWWJZVtWqFkzef99eHwTJAw+07t/4Ltf4JSmJBEGyQwcLvosWWZCsWdOCXbVqdm3PPhtmyb16Fey2DTJJ5+x+x442RhsfuMCKFZxxBrzyStjVGrQtN9c+p06dHf8AgTDwBmXn6tWzrmewNarr14eBVUFSRCTFdexoQeuMM+zxoEGWkTVqBLfcEv6Cb9zYAuUzz9g+l089ZefPOMPWYc6cafVgIeyKjN/ZJOiKrFXL6tMGhQEgDJJBcCtKECRbt7YuzPx8C5KNGtnEmMsus5m2HTokfo8gk6xXz675N7+xx0ceGU7oAXj9dTv+8EMYJIPsNpgElEgQJIMC9HXrWpvBPiPILqtWtUBaln1Ay4mCpIjIzuy7r2263L27Pe7a1ZYyFGXgQPvlf9NNlmUCnH22HadPDyfydOpkx2D8sEqVggGwY8eC6xMXL7ZMMKiBmqidu+1mx2AT5pUrw+B53302wag4QSbZoIEde/aE556zIgVB0Pc+DJI//hiOR55+uh179y7+M/bc07png5+rVy/MZpcssUyybl37Y+HTT+1a/vOf4t8zSRQkRURKIn5JQ3F++1vrinznHcveGje28ceqVS1Azp5t94OsMdjZpG3bghNcdt/dgkgwCWjRIssOqxTza7tbN+ueDDZhLhwkSyLIJIMg6ZytIW3TJpyENHVqOEb644+WSdarZ9nmokXhWG4iwR8DwdZl9erZspeqVS37XbfO/nvXrh2O5V59NXz+ecmvo5xUrfBPFBHJdEceacd77rGMKTvbguKsWRZ09tjDzoEFsA4dwvHIwB57WBftZ5/Z+sx584ofjwxkZdmxeXObBFOzZtgdXBKFM8lAp07W/vx8OPNMG29s0cKC5OrVYRduSdoYLDeJzySzsmwJTZBJ1qlTsDxfdrat6Qyy+QqiICkikix/+lN4v3NnW2i/dm04Gzbw/PPWtRgvCJp/+Yutj4SC5dx2pkULG+tcuBB+97uS/1yiINm5sxU7v+46G4ccOxb+9S8bW9y2LZzMVBJBZht0Jwef2aqVBcX16+3zgxJ8TZvaes2SlMcrZ+puFRGpCJ0726SdZcvC4uuBgw6CffYpeC7ojg0CJBQ/aaewYOzS+13rbg106mRdua++apOTune3wBUUdi9Ntlo4SAZd2a1bF8wkg3WobdvaHw0KkiIiGSqYzQpw1FE7f33btmGN1iAAlSVIQumCZHGZJFid12OPtfvNmtm6yE2bip8xW1iDBtbtHN/dCmGQDMYkg+w6Jyccoy1rAfkyUneriEhFCGaztmq14/hjUapWtQk48+bZ7hnTp9tOHSVV1iBZv35YDShe0P6gCDxYkAyUJpOsWtUC5U8/2USkIGNs1cqy1V9/tWUrwdrMnBwLwr/+aptHL1pUsEpSEilIiohUhCDIHHVUwQo0xdl9dxtT7NGj6Ao7xYkPkkExhJLIyiq6wk6zZhZAd989nHgT/xmlySTBAvdPP1nGGPz3CNZKbt8O559vNXYhzCTBlrAsX26bZAc1apNIQVJEpCLUrm1r/eLrpO7MRRfZOsrCk3pKokYN68Zcu7Z0mWQizsE//lFw9mp8JlmarmCwNs2dW3BpTRAkTz/dxmgLj0lCWFhg4cLwD48kUpAUEakoV15Zuteffnq4QL8smjcvvyAJOxZQCIJky5alz+qCNsUXVO/WzTLEm2+2x/Fjkjk5luUGe0/On18hQVITd0REMlXQHVqa7tbSCIJkabtaoeggWaMGDBsWjm8Gu63k5Ng6ybZtw2BcQTNdlUmKiGSq5s2tmED8fo7lqXZtu5Vm0k6gqCBZ2AUXWIBs2NAeX3SRTfq5445wZmySKUiKiGSq/v3Lr6s1kSeeKF0hgUBJgmTr1rbfZuCmm+z4/PPKJEVEZBedcUa4c0mylHXMNAiSJa2JG69Dh3A3lSTTmKSIiFS8kmSSiVRgYQEFSRERqXi7GiQ3bbIaskmmICkiIhVvV4NkjRqwdGn5tqkIGpMUEZGKt/vutil1//6l/9ljjrHydSWtXLQLFCRFRKTiVakCt9xStp8N9sysAOpuFRERSUBBUkREJAEFSRERkQQUJEVERBJQkBQREUlAQVJERCQB572Pug2l4pxbASwqp7drDKwsp/dKF5XxmkHXXZlUxmsGXfeuyPHeNynqibQLkuXJOZfnvc+Nuh0VqTJeM+i6o25HRaqM1wy67mS9v7pbRUREElCQFBERSaCyB8lHo25ABCrjNYOuuzKpjNcMuu6kqNRjkiIiIsWp7JmkiIhIQpUySDrnjnPOzXHOzXPODY66PcnknFvonJvhnJvmnMuLnWvonBvnnPs2dmwQdTt3lXNumHNuuXPu67hzRV6nMw/Evv/pzrlu0bW87BJc863OufzY9z3NOXd83HM3xK55jnPu2Ghaveucc22ccx84575xzs10zl0VO5+x33cx15zR37dzrrpzbrJz7qvYdQ+JnW/vnJsUu74XnXPVYud3iz2eF3u+3S43wntfqW5AFjAf6ABUA74C9o66XUm83oVA40Ln7gIGx+4PBv4ZdTvL4TqPALoBX+/sOoHjgXcBBxwCTIq6/eV4zbcC1xbx2r1j/9Z3A9rH/h/IivoaynjdLYBusft1gLmx68vY77uYa87o7zv2ndWO3c8GJsW+w5HAmbHzQ4HLYvcvB4bG7p8JvLirbaiMmeRBwDzv/QLv/WbgBaBfxG2qaP2Ap2L3nwJOirAt5cJ7/zHwU6HTia6zH/C0NxOB+s65FhXT0vKT4JoT6Qe84L3f5L3/DpiH/b+Qdrz3S733X8burwdmAa3I4O+7mGtOJCO+79h3tiH2MDt288DRwMux84W/6+DfwMvAMc7t2s7MlTFItgK+j3u8hOL/saU7D4x1zk1xzg2InWvmvV8au78MaBZN05Iu0XVm+r+BK2PdisPiutIz8ppj3WkHYBlGpfi+C10zZPj37ZzLcs5NA5YD47CseI33fmvsJfHX9r/rjj2/Fmi0K59fGYNkZXO4974b0Ae4wjl3RPyT3volMn6Kc2W5TuBhYHdgf2Ap8O9om5M8zrnawCvAIO/9uvjnMvX7LuKaM/779t5v897vD7TGsuFOFfn5lTFI5gNt4h63jp3LSN77/NhxOfAa9o/sx6C7KXZcHl0LkyrRdWbsvwHv/Y+xXyrbgccIu9gy6pqdc9lYsHjWe/9q7HRGf99FXXNl+b4BvPdrgA+AQ7Eu86qxp+Kv7X/XHXu+HrBqVz63MgbJL4COsdlR1bDB3VERtykpnHO1nHN1gvtAb+Br7HrPj73sfOCNaFqYdImucxTw+9isx0OAtXHddGmt0Fhbf+z7BrvmM2Oz/9oDHYHJFd2+8hAbY3oCmOW9vyfuqYz9vhNdc6Z/3865Js65+rH7NYBe2HjsB8CpsZcV/q6DfwOnAu/HehXKLurZS1HcsNluc7G+7b9G3Z4kXmcHbIbbV8DM4FqxPvrxwLfAe0DDqNtaDtf6PNbdtAUbo7g40XViM+YejH3/M4DcqNtfjtf8TOyapsd+YbSIe/1fY9c8B+gTdft34boPx7pSpwPTYrfjM/n7LuaaM/r7BroCU2PX9zVwS+x8ByzozwNeAnaLna8eezwv9nyHXW2DKu6IiIgkUBm7W0VEREpEQVJERCQBBUkREZEEFCRFREQSUJAUERFJQEFSJMU557bF7fIwzZXjzjXOuXbxu4iISEFVd/4SEYnYRm9luUSkgimTFElTzvYKvcvZfqGTnXN7xM63c869Hyt6Pd451zZ2vplz7rXY3nxfOee6x94qyzn3WGy/vrGxyiYigoKkSDqoUai79Yy459Z677sA/wXui537D/CU974r8CzwQOz8A8BH3vv9sH0oZ8bOdwQe9N7vA6wBTkny9YikDVXcEUlxzrkN3vvaRZxfCBztvV8QK369zHvfyDm3EitPtiV2fqn3vrFzbgXQ2nu/Ke492gHjvPcdY4+vB7K993ck/8pEUp8ySZH05hPcL41Ncfe3obkKIv+jICmS3s6IO06I3f8c290G4Bzgk9j98cBl8L+NbOtVVCNF0pX+YhRJfTViO7MHRnvvg2UgDZxz07Fs8KzYuT8CTzrnrgNWABfGzl8FPOqcuxjLGC/DdhERkQQ0JimSpmJjkrne+5VRt0UkU6m7VUREJAFlkiIiIgkokxQREUlAQVJERCQBBUkREZEEFCRFREQSUJAUERFJQEFSREQkgf8HNsRx2Y2Z6EcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.140772024790446 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  3\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 36.189, test_acc:38.333, F1:0.382\n",
            "[Epoch: 2 Batch:   106] loss: 1.085, acc: 38.239, test_acc:31.667, F1:0.298\n",
            "[Epoch: 3 Batch:   106] loss: 1.082, acc: 38.126, test_acc:39.167, F1:0.383\n",
            "[Epoch: 4 Batch:   106] loss: 1.081, acc: 37.623, test_acc:37.500, F1:0.363\n",
            "[Epoch: 5 Batch:   106] loss: 1.080, acc: 38.918, test_acc:34.167, F1:0.340\n",
            "[Epoch: 6 Batch:   106] loss: 1.079, acc: 38.101, test_acc:41.667, F1:0.416\n",
            "[Epoch: 7 Batch:   106] loss: 1.077, acc: 37.635, test_acc:38.333, F1:0.385\n",
            "[Epoch: 8 Batch:   106] loss: 1.076, acc: 38.377, test_acc:40.000, F1:0.406\n",
            "[Epoch: 9 Batch:   106] loss: 1.075, acc: 38.340, test_acc:41.667, F1:0.425\n",
            "[Epoch: 10 Batch:   106] loss: 1.074, acc: 39.371, test_acc:48.333, F1:0.484\n",
            "[Epoch: 11 Batch:   106] loss: 1.071, acc: 39.145, test_acc:42.500, F1:0.431\n",
            "[Epoch: 12 Batch:   106] loss: 1.072, acc: 37.849, test_acc:44.167, F1:0.461\n",
            "[Epoch: 13 Batch:   106] loss: 1.071, acc: 38.692, test_acc:38.333, F1:0.403\n",
            "[Epoch: 14 Batch:   106] loss: 1.067, acc: 39.509, test_acc:45.000, F1:0.454\n",
            "[Epoch: 15 Batch:   106] loss: 1.069, acc: 40.365, test_acc:40.833, F1:0.420\n",
            "[Epoch: 16 Batch:   106] loss: 1.066, acc: 41.119, test_acc:35.833, F1:0.389\n",
            "[Epoch: 17 Batch:   106] loss: 1.064, acc: 39.497, test_acc:44.167, F1:0.454\n",
            "[Epoch: 18 Batch:   106] loss: 1.064, acc: 41.384, test_acc:36.667, F1:0.387\n",
            "[Epoch: 19 Batch:   106] loss: 1.064, acc: 40.151, test_acc:36.667, F1:0.377\n",
            "[Epoch: 20 Batch:   106] loss: 1.061, acc: 40.642, test_acc:38.333, F1:0.404\n",
            "[Epoch: 21 Batch:   106] loss: 1.060, acc: 40.239, test_acc:41.667, F1:0.431\n",
            "[Epoch: 22 Batch:   106] loss: 1.059, acc: 40.818, test_acc:41.667, F1:0.424\n",
            "[Epoch: 23 Batch:   106] loss: 1.059, acc: 41.346, test_acc:41.667, F1:0.430\n",
            "[Epoch: 24 Batch:   106] loss: 1.055, acc: 41.849, test_acc:37.500, F1:0.392\n",
            "[Epoch: 25 Batch:   106] loss: 1.052, acc: 41.233, test_acc:36.667, F1:0.386\n",
            "[Epoch: 26 Batch:   106] loss: 1.051, acc: 41.899, test_acc:40.000, F1:0.414\n",
            "[Epoch: 27 Batch:   106] loss: 1.053, acc: 42.704, test_acc:36.667, F1:0.384\n",
            "[Epoch: 28 Batch:   106] loss: 1.048, acc: 43.396, test_acc:37.500, F1:0.398\n",
            "[Epoch: 29 Batch:   106] loss: 1.049, acc: 43.019, test_acc:32.500, F1:0.355\n",
            "[Epoch: 30 Batch:   106] loss: 1.051, acc: 43.421, test_acc:39.167, F1:0.411\n",
            "[Epoch: 31 Batch:   106] loss: 1.046, acc: 43.862, test_acc:40.833, F1:0.426\n",
            "[Epoch: 32 Batch:   106] loss: 1.043, acc: 43.321, test_acc:40.833, F1:0.431\n",
            "[Epoch: 33 Batch:   106] loss: 1.043, acc: 44.000, test_acc:40.000, F1:0.425\n",
            "[Epoch: 34 Batch:   106] loss: 1.043, acc: 44.654, test_acc:42.500, F1:0.453\n",
            "[Epoch: 35 Batch:   106] loss: 1.042, acc: 43.522, test_acc:42.500, F1:0.446\n",
            "[Epoch: 36 Batch:   106] loss: 1.034, acc: 45.195, test_acc:44.167, F1:0.460\n",
            "[Epoch: 37 Batch:   106] loss: 1.039, acc: 44.126, test_acc:38.333, F1:0.413\n",
            "[Epoch: 38 Batch:   106] loss: 1.032, acc: 44.931, test_acc:40.000, F1:0.432\n",
            "[Epoch: 39 Batch:   106] loss: 1.031, acc: 46.101, test_acc:43.333, F1:0.457\n",
            "[Epoch: 40 Batch:   106] loss: 1.034, acc: 46.126, test_acc:40.833, F1:0.432\n",
            "[Epoch: 41 Batch:   106] loss: 1.026, acc: 46.164, test_acc:42.500, F1:0.452\n",
            "[Epoch: 42 Batch:   106] loss: 1.028, acc: 46.201, test_acc:40.833, F1:0.435\n",
            "[Epoch: 43 Batch:   106] loss: 1.027, acc: 47.421, test_acc:43.333, F1:0.454\n",
            "[Epoch: 44 Batch:   106] loss: 1.019, acc: 47.962, test_acc:42.500, F1:0.445\n",
            "[Epoch: 45 Batch:   106] loss: 1.019, acc: 47.044, test_acc:40.000, F1:0.426\n",
            "[Epoch: 46 Batch:   106] loss: 1.017, acc: 49.371, test_acc:43.333, F1:0.454\n",
            "[Epoch: 47 Batch:   106] loss: 1.014, acc: 48.503, test_acc:40.000, F1:0.421\n",
            "[Epoch: 48 Batch:   106] loss: 1.007, acc: 49.421, test_acc:40.000, F1:0.425\n",
            "[Epoch: 49 Batch:   106] loss: 1.013, acc: 49.459, test_acc:40.833, F1:0.429\n",
            "[Epoch: 50 Batch:   106] loss: 1.004, acc: 50.088, test_acc:40.000, F1:0.422\n",
            "[Epoch: 51 Batch:   106] loss: 0.999, acc: 50.189, test_acc:39.167, F1:0.416\n",
            "[Epoch: 52 Batch:   106] loss: 1.001, acc: 49.912, test_acc:37.500, F1:0.391\n",
            "[Epoch: 53 Batch:   106] loss: 0.997, acc: 50.516, test_acc:37.500, F1:0.387\n",
            "[Epoch: 54 Batch:   106] loss: 0.998, acc: 50.767, test_acc:32.500, F1:0.352\n",
            "[Epoch: 55 Batch:   106] loss: 0.988, acc: 51.384, test_acc:37.500, F1:0.396\n",
            "[Epoch: 56 Batch:   106] loss: 0.988, acc: 51.094, test_acc:39.167, F1:0.417\n",
            "[Epoch: 57 Batch:   106] loss: 0.984, acc: 51.660, test_acc:32.500, F1:0.359\n",
            "[Epoch: 58 Batch:   106] loss: 0.988, acc: 52.126, test_acc:39.167, F1:0.396\n",
            "[Epoch: 59 Batch:   106] loss: 0.986, acc: 51.484, test_acc:41.667, F1:0.441\n",
            "[Epoch: 60 Batch:   106] loss: 0.982, acc: 53.610, test_acc:38.333, F1:0.402\n",
            "[Epoch: 61 Batch:   106] loss: 0.975, acc: 53.522, test_acc:32.500, F1:0.349\n",
            "[Epoch: 62 Batch:   106] loss: 0.971, acc: 53.811, test_acc:35.000, F1:0.371\n",
            "[Epoch: 63 Batch:   106] loss: 0.963, acc: 53.585, test_acc:39.167, F1:0.418\n",
            "[Epoch: 64 Batch:   106] loss: 0.960, acc: 54.126, test_acc:33.333, F1:0.353\n",
            "[Epoch: 65 Batch:   106] loss: 0.957, acc: 55.182, test_acc:33.333, F1:0.353\n",
            "[Epoch: 66 Batch:   106] loss: 0.955, acc: 54.943, test_acc:38.333, F1:0.395\n",
            "[Epoch: 67 Batch:   106] loss: 0.956, acc: 53.950, test_acc:30.833, F1:0.334\n",
            "[Epoch: 68 Batch:   106] loss: 0.941, acc: 55.031, test_acc:35.000, F1:0.372\n",
            "[Epoch: 69 Batch:   106] loss: 0.944, acc: 55.119, test_acc:39.167, F1:0.405\n",
            "[Epoch: 70 Batch:   106] loss: 0.940, acc: 55.145, test_acc:32.500, F1:0.334\n",
            "[Epoch: 71 Batch:   106] loss: 0.942, acc: 56.465, test_acc:37.500, F1:0.398\n",
            "[Epoch: 72 Batch:   106] loss: 0.929, acc: 57.472, test_acc:35.833, F1:0.371\n",
            "[Epoch: 73 Batch:   106] loss: 0.933, acc: 57.610, test_acc:33.333, F1:0.366\n",
            "[Epoch: 74 Batch:   106] loss: 0.927, acc: 56.403, test_acc:32.500, F1:0.341\n",
            "[Epoch: 75 Batch:   106] loss: 0.925, acc: 56.516, test_acc:37.500, F1:0.388\n",
            "[Epoch: 76 Batch:   106] loss: 0.915, acc: 58.667, test_acc:36.667, F1:0.384\n",
            "[Epoch: 77 Batch:   106] loss: 0.925, acc: 57.623, test_acc:30.833, F1:0.316\n",
            "[Epoch: 78 Batch:   106] loss: 0.918, acc: 57.308, test_acc:33.333, F1:0.336\n",
            "[Epoch: 79 Batch:   106] loss: 0.914, acc: 57.836, test_acc:34.167, F1:0.359\n",
            "[Epoch: 80 Batch:   106] loss: 0.906, acc: 58.981, test_acc:34.167, F1:0.363\n",
            "[Epoch: 81 Batch:   106] loss: 0.909, acc: 57.987, test_acc:40.833, F1:0.426\n",
            "[Epoch: 82 Batch:   106] loss: 0.903, acc: 58.918, test_acc:33.333, F1:0.352\n",
            "[Epoch: 83 Batch:   106] loss: 0.894, acc: 60.742, test_acc:38.333, F1:0.405\n",
            "[Epoch: 84 Batch:   106] loss: 0.892, acc: 59.170, test_acc:30.833, F1:0.319\n",
            "[Epoch: 85 Batch:   106] loss: 0.893, acc: 58.918, test_acc:37.500, F1:0.392\n",
            "[Epoch: 86 Batch:   106] loss: 0.886, acc: 59.799, test_acc:35.000, F1:0.371\n",
            "[Epoch: 87 Batch:   106] loss: 0.890, acc: 59.296, test_acc:39.167, F1:0.404\n",
            "[Epoch: 88 Batch:   106] loss: 0.882, acc: 59.283, test_acc:38.333, F1:0.400\n",
            "[Epoch: 89 Batch:   106] loss: 0.877, acc: 60.390, test_acc:41.667, F1:0.432\n",
            "[Epoch: 90 Batch:   106] loss: 0.877, acc: 60.956, test_acc:35.833, F1:0.371\n",
            "[Epoch: 91 Batch:   106] loss: 0.866, acc: 60.516, test_acc:36.667, F1:0.384\n",
            "[Epoch: 92 Batch:   106] loss: 0.868, acc: 60.541, test_acc:38.333, F1:0.402\n",
            "[Epoch: 93 Batch:   106] loss: 0.862, acc: 61.208, test_acc:41.667, F1:0.444\n",
            "[Epoch: 94 Batch:   106] loss: 0.863, acc: 61.836, test_acc:35.833, F1:0.377\n",
            "[Epoch: 95 Batch:   106] loss: 0.866, acc: 61.648, test_acc:36.667, F1:0.385\n",
            "[Epoch: 96 Batch:   106] loss: 0.862, acc: 61.824, test_acc:39.167, F1:0.408\n",
            "[Epoch: 97 Batch:   106] loss: 0.846, acc: 62.956, test_acc:37.500, F1:0.393\n",
            "[Epoch: 98 Batch:   106] loss: 0.854, acc: 60.855, test_acc:36.667, F1:0.387\n",
            "[Epoch: 99 Batch:   106] loss: 0.847, acc: 61.723, test_acc:38.333, F1:0.400\n",
            "[Epoch: 100 Batch:   106] loss: 0.835, acc: 63.031, test_acc:35.833, F1:0.377\n",
            "[Epoch: 101 Batch:   106] loss: 0.843, acc: 63.296, test_acc:37.500, F1:0.395\n",
            "[Epoch: 102 Batch:   106] loss: 0.834, acc: 63.673, test_acc:40.000, F1:0.426\n",
            "[Epoch: 103 Batch:   106] loss: 0.833, acc: 63.849, test_acc:39.167, F1:0.411\n",
            "[Epoch: 104 Batch:   106] loss: 0.823, acc: 63.723, test_acc:45.000, F1:0.469\n",
            "[Epoch: 105 Batch:   106] loss: 0.829, acc: 63.623, test_acc:40.000, F1:0.420\n",
            "[Epoch: 106 Batch:   106] loss: 0.826, acc: 64.088, test_acc:37.500, F1:0.391\n",
            "[Epoch: 107 Batch:   106] loss: 0.819, acc: 62.591, test_acc:40.000, F1:0.417\n",
            "[Epoch: 108 Batch:   106] loss: 0.804, acc: 65.094, test_acc:37.500, F1:0.400\n",
            "[Epoch: 109 Batch:   106] loss: 0.807, acc: 64.340, test_acc:40.000, F1:0.424\n",
            "[Epoch: 110 Batch:   106] loss: 0.805, acc: 63.421, test_acc:40.000, F1:0.427\n",
            "[Epoch: 111 Batch:   106] loss: 0.806, acc: 63.509, test_acc:40.833, F1:0.430\n",
            "[Epoch: 112 Batch:   106] loss: 0.801, acc: 65.258, test_acc:42.500, F1:0.450\n",
            "[Epoch: 113 Batch:   106] loss: 0.803, acc: 65.799, test_acc:44.167, F1:0.462\n",
            "[Epoch: 114 Batch:   106] loss: 0.810, acc: 64.252, test_acc:44.167, F1:0.458\n",
            "[Epoch: 115 Batch:   106] loss: 0.799, acc: 65.358, test_acc:35.833, F1:0.382\n",
            "[Epoch: 116 Batch:   106] loss: 0.813, acc: 65.635, test_acc:44.167, F1:0.457\n",
            "[Epoch: 117 Batch:   106] loss: 0.778, acc: 65.799, test_acc:44.167, F1:0.459\n",
            "[Epoch: 118 Batch:   106] loss: 0.787, acc: 66.755, test_acc:38.333, F1:0.412\n",
            "[Epoch: 119 Batch:   106] loss: 0.794, acc: 66.465, test_acc:41.667, F1:0.437\n",
            "[Epoch: 120 Batch:   106] loss: 0.771, acc: 67.874, test_acc:39.167, F1:0.407\n",
            "[Epoch: 121 Batch:   106] loss: 0.775, acc: 66.113, test_acc:38.333, F1:0.403\n",
            "[Epoch: 122 Batch:   106] loss: 0.768, acc: 66.717, test_acc:40.833, F1:0.433\n",
            "[Epoch: 123 Batch:   106] loss: 0.775, acc: 66.063, test_acc:40.000, F1:0.417\n",
            "[Epoch: 124 Batch:   106] loss: 0.760, acc: 66.893, test_acc:40.000, F1:0.427\n",
            "[Epoch: 125 Batch:   106] loss: 0.769, acc: 67.396, test_acc:40.833, F1:0.428\n",
            "[Epoch: 126 Batch:   106] loss: 0.768, acc: 65.950, test_acc:36.667, F1:0.384\n",
            "[Epoch: 127 Batch:   106] loss: 0.751, acc: 67.774, test_acc:41.667, F1:0.437\n",
            "[Epoch: 128 Batch:   106] loss: 0.750, acc: 67.824, test_acc:40.833, F1:0.434\n",
            "[Epoch: 129 Batch:   106] loss: 0.766, acc: 67.836, test_acc:40.000, F1:0.425\n",
            "[Epoch: 130 Batch:   106] loss: 0.739, acc: 68.176, test_acc:46.667, F1:0.485\n",
            "[Epoch: 131 Batch:   106] loss: 0.749, acc: 68.214, test_acc:40.833, F1:0.433\n",
            "[Epoch: 132 Batch:   106] loss: 0.748, acc: 67.233, test_acc:39.167, F1:0.407\n",
            "[Epoch: 133 Batch:   106] loss: 0.734, acc: 68.767, test_acc:38.333, F1:0.408\n",
            "[Epoch: 134 Batch:   106] loss: 0.730, acc: 68.189, test_acc:37.500, F1:0.400\n",
            "[Epoch: 135 Batch:   106] loss: 0.718, acc: 68.025, test_acc:39.167, F1:0.418\n",
            "[Epoch: 136 Batch:   106] loss: 0.728, acc: 68.931, test_acc:35.833, F1:0.373\n",
            "[Epoch: 137 Batch:   106] loss: 0.724, acc: 69.610, test_acc:40.000, F1:0.422\n",
            "[Epoch: 138 Batch:   106] loss: 0.726, acc: 68.906, test_acc:40.000, F1:0.424\n",
            "[Epoch: 139 Batch:   106] loss: 0.729, acc: 68.214, test_acc:36.667, F1:0.381\n",
            "[Epoch: 140 Batch:   106] loss: 0.719, acc: 69.786, test_acc:38.333, F1:0.408\n",
            "[Epoch: 141 Batch:   106] loss: 0.715, acc: 69.899, test_acc:40.833, F1:0.433\n",
            "[Epoch: 142 Batch:   106] loss: 0.702, acc: 69.585, test_acc:44.167, F1:0.466\n",
            "[Epoch: 143 Batch:   106] loss: 0.710, acc: 69.799, test_acc:40.833, F1:0.420\n",
            "[Epoch: 144 Batch:   106] loss: 0.695, acc: 70.780, test_acc:44.167, F1:0.464\n",
            "[Epoch: 145 Batch:   106] loss: 0.713, acc: 67.686, test_acc:45.833, F1:0.478\n",
            "[Epoch: 146 Batch:   106] loss: 0.691, acc: 69.346, test_acc:45.833, F1:0.472\n",
            "[Epoch: 147 Batch:   106] loss: 0.690, acc: 68.327, test_acc:41.667, F1:0.438\n",
            "[Epoch: 148 Batch:   106] loss: 0.682, acc: 71.006, test_acc:37.500, F1:0.405\n",
            "[Epoch: 149 Batch:   106] loss: 0.680, acc: 69.396, test_acc:40.000, F1:0.422\n",
            "[Epoch: 150 Batch:   106] loss: 0.681, acc: 70.616, test_acc:41.667, F1:0.436\n",
            "[Epoch: 151 Batch:   106] loss: 0.688, acc: 70.642, test_acc:43.333, F1:0.446\n",
            "[Epoch: 152 Batch:   106] loss: 0.664, acc: 70.566, test_acc:43.333, F1:0.449\n",
            "[Epoch: 153 Batch:   106] loss: 0.699, acc: 71.044, test_acc:41.667, F1:0.438\n",
            "[Epoch: 154 Batch:   106] loss: 0.670, acc: 71.270, test_acc:42.500, F1:0.446\n",
            "[Epoch: 155 Batch:   106] loss: 0.679, acc: 69.094, test_acc:37.500, F1:0.403\n",
            "[Epoch: 156 Batch:   106] loss: 0.669, acc: 70.956, test_acc:42.500, F1:0.446\n",
            "[Epoch: 157 Batch:   106] loss: 0.655, acc: 70.893, test_acc:35.833, F1:0.390\n",
            "[Epoch: 158 Batch:   106] loss: 0.680, acc: 70.566, test_acc:42.500, F1:0.443\n",
            "[Epoch: 159 Batch:   106] loss: 0.642, acc: 72.491, test_acc:32.500, F1:0.354\n",
            "[Epoch: 160 Batch:   106] loss: 0.667, acc: 70.893, test_acc:39.167, F1:0.413\n",
            "[Epoch: 161 Batch:   106] loss: 0.640, acc: 72.013, test_acc:42.500, F1:0.446\n",
            "[Epoch: 162 Batch:   106] loss: 0.636, acc: 71.987, test_acc:42.500, F1:0.446\n",
            "[Epoch: 163 Batch:   106] loss: 0.641, acc: 71.044, test_acc:37.500, F1:0.411\n",
            "[Epoch: 164 Batch:   106] loss: 0.656, acc: 70.050, test_acc:38.333, F1:0.408\n",
            "[Epoch: 165 Batch:   106] loss: 0.657, acc: 70.704, test_acc:40.833, F1:0.432\n",
            "[Epoch: 166 Batch:   106] loss: 0.675, acc: 71.723, test_acc:37.500, F1:0.407\n",
            "[Epoch: 167 Batch:   106] loss: 0.649, acc: 71.132, test_acc:39.167, F1:0.413\n",
            "[Epoch: 168 Batch:   106] loss: 0.642, acc: 71.484, test_acc:42.500, F1:0.449\n",
            "[Epoch: 169 Batch:   106] loss: 0.634, acc: 74.050, test_acc:45.000, F1:0.475\n",
            "[Epoch: 170 Batch:   106] loss: 0.619, acc: 72.478, test_acc:39.167, F1:0.420\n",
            "[Epoch: 171 Batch:   106] loss: 0.603, acc: 72.969, test_acc:40.000, F1:0.415\n",
            "[Epoch: 172 Batch:   106] loss: 0.610, acc: 72.440, test_acc:41.667, F1:0.436\n",
            "[Epoch: 173 Batch:   106] loss: 0.621, acc: 72.428, test_acc:38.333, F1:0.414\n",
            "[Epoch: 174 Batch:   106] loss: 0.606, acc: 73.698, test_acc:40.833, F1:0.433\n",
            "[Epoch: 175 Batch:   106] loss: 0.610, acc: 71.560, test_acc:40.000, F1:0.419\n",
            "[Epoch: 176 Batch:   106] loss: 0.645, acc: 69.849, test_acc:40.000, F1:0.415\n",
            "[Epoch: 177 Batch:   106] loss: 0.610, acc: 72.050, test_acc:44.167, F1:0.461\n",
            "[Epoch: 178 Batch:   106] loss: 0.622, acc: 72.805, test_acc:42.500, F1:0.447\n",
            "[Epoch: 179 Batch:   106] loss: 0.601, acc: 73.585, test_acc:44.167, F1:0.460\n",
            "[Epoch: 180 Batch:   106] loss: 0.605, acc: 72.969, test_acc:41.667, F1:0.441\n",
            "[Epoch: 181 Batch:   106] loss: 0.607, acc: 72.969, test_acc:40.000, F1:0.423\n",
            "[Epoch: 182 Batch:   106] loss: 0.633, acc: 72.050, test_acc:41.667, F1:0.444\n",
            "[Epoch: 183 Batch:   106] loss: 0.591, acc: 73.937, test_acc:43.333, F1:0.454\n",
            "[Epoch: 184 Batch:   106] loss: 0.600, acc: 72.503, test_acc:38.333, F1:0.407\n",
            "[Epoch: 185 Batch:   106] loss: 0.597, acc: 72.818, test_acc:36.667, F1:0.400\n",
            "[Epoch: 186 Batch:   106] loss: 0.601, acc: 72.767, test_acc:40.833, F1:0.435\n",
            "[Epoch: 187 Batch:   106] loss: 0.594, acc: 70.830, test_acc:35.833, F1:0.384\n",
            "[Epoch: 188 Batch:   106] loss: 0.590, acc: 70.667, test_acc:36.667, F1:0.391\n",
            "[Epoch: 189 Batch:   106] loss: 0.575, acc: 74.075, test_acc:38.333, F1:0.403\n",
            "[Epoch: 190 Batch:   106] loss: 0.583, acc: 70.755, test_acc:36.667, F1:0.390\n",
            "[Epoch: 191 Batch:   106] loss: 0.588, acc: 72.692, test_acc:40.000, F1:0.427\n",
            "[Epoch: 192 Batch:   106] loss: 0.562, acc: 74.126, test_acc:38.333, F1:0.400\n",
            "[Epoch: 193 Batch:   106] loss: 0.549, acc: 73.874, test_acc:37.500, F1:0.411\n",
            "[Epoch: 194 Batch:   106] loss: 0.582, acc: 72.855, test_acc:37.500, F1:0.400\n",
            "[Epoch: 195 Batch:   106] loss: 0.543, acc: 73.811, test_acc:40.000, F1:0.428\n",
            "[Epoch: 196 Batch:   106] loss: 0.569, acc: 71.711, test_acc:39.167, F1:0.417\n",
            "[Epoch: 197 Batch:   106] loss: 0.537, acc: 72.969, test_acc:40.000, F1:0.416\n",
            "[Epoch: 198 Batch:   106] loss: 0.590, acc: 73.145, test_acc:41.667, F1:0.455\n",
            "[Epoch: 199 Batch:   106] loss: 0.561, acc: 71.660, test_acc:39.167, F1:0.410\n",
            "[Epoch: 200 Batch:   106] loss: 0.546, acc: 73.208, test_acc:36.667, F1:0.399\n",
            "[Epoch: 201 Batch:   106] loss: 0.562, acc: 73.484, test_acc:41.667, F1:0.443\n",
            "[Epoch: 202 Batch:   106] loss: 0.541, acc: 74.063, test_acc:39.167, F1:0.415\n",
            "[Epoch: 203 Batch:   106] loss: 0.580, acc: 72.805, test_acc:42.500, F1:0.449\n",
            "[Epoch: 204 Batch:   106] loss: 0.546, acc: 75.434, test_acc:37.500, F1:0.395\n",
            "[Epoch: 205 Batch:   106] loss: 0.537, acc: 74.742, test_acc:44.167, F1:0.470\n",
            "[Epoch: 206 Batch:   106] loss: 0.584, acc: 74.403, test_acc:37.500, F1:0.407\n",
            "[Epoch: 207 Batch:   106] loss: 0.535, acc: 74.113, test_acc:37.500, F1:0.406\n",
            "[Epoch: 208 Batch:   106] loss: 0.517, acc: 74.189, test_acc:39.167, F1:0.418\n",
            "[Epoch: 209 Batch:   106] loss: 0.519, acc: 73.887, test_acc:39.167, F1:0.422\n",
            "[Epoch: 210 Batch:   106] loss: 0.518, acc: 72.742, test_acc:44.167, F1:0.469\n",
            "[Epoch: 211 Batch:   106] loss: 0.498, acc: 74.465, test_acc:37.500, F1:0.398\n",
            "[Epoch: 212 Batch:   106] loss: 0.508, acc: 74.478, test_acc:39.167, F1:0.413\n",
            "[Epoch: 213 Batch:   106] loss: 0.528, acc: 73.447, test_acc:40.833, F1:0.429\n",
            "[Epoch: 214 Batch:   106] loss: 0.541, acc: 73.358, test_acc:38.333, F1:0.410\n",
            "[Epoch: 215 Batch:   106] loss: 0.517, acc: 73.006, test_acc:40.833, F1:0.436\n",
            "[Epoch: 216 Batch:   106] loss: 0.491, acc: 75.509, test_acc:40.833, F1:0.433\n",
            "[Epoch: 217 Batch:   106] loss: 0.522, acc: 73.497, test_acc:37.500, F1:0.392\n",
            "[Epoch: 218 Batch:   106] loss: 0.523, acc: 73.547, test_acc:43.333, F1:0.445\n",
            "[Epoch: 219 Batch:   106] loss: 0.513, acc: 74.478, test_acc:40.000, F1:0.415\n",
            "[Epoch: 220 Batch:   106] loss: 0.481, acc: 74.881, test_acc:44.167, F1:0.468\n",
            "[Epoch: 221 Batch:   106] loss: 0.513, acc: 73.774, test_acc:36.667, F1:0.384\n",
            "[Epoch: 222 Batch:   106] loss: 0.491, acc: 73.686, test_acc:39.167, F1:0.418\n",
            "[Epoch: 223 Batch:   106] loss: 0.497, acc: 75.447, test_acc:36.667, F1:0.397\n",
            "[Epoch: 224 Batch:   106] loss: 0.476, acc: 74.013, test_acc:36.667, F1:0.372\n",
            "[Epoch: 225 Batch:   106] loss: 0.498, acc: 75.346, test_acc:40.833, F1:0.428\n",
            "[Epoch: 226 Batch:   106] loss: 0.463, acc: 74.377, test_acc:36.667, F1:0.397\n",
            "[Epoch: 227 Batch:   106] loss: 0.518, acc: 72.855, test_acc:35.000, F1:0.368\n",
            "[Epoch: 228 Batch:   106] loss: 0.520, acc: 72.164, test_acc:44.167, F1:0.468\n",
            "[Epoch: 229 Batch:   106] loss: 0.483, acc: 73.547, test_acc:38.333, F1:0.407\n",
            "[Epoch: 230 Batch:   106] loss: 0.468, acc: 75.044, test_acc:39.167, F1:0.413\n",
            "[Epoch: 231 Batch:   106] loss: 0.447, acc: 75.132, test_acc:37.500, F1:0.399\n",
            "[Epoch: 232 Batch:   106] loss: 0.481, acc: 73.346, test_acc:33.333, F1:0.344\n",
            "[Epoch: 233 Batch:   106] loss: 0.514, acc: 74.327, test_acc:43.333, F1:0.449\n",
            "[Epoch: 234 Batch:   106] loss: 0.482, acc: 74.302, test_acc:37.500, F1:0.401\n",
            "[Epoch: 235 Batch:   106] loss: 0.470, acc: 74.101, test_acc:35.833, F1:0.385\n",
            "[Epoch: 236 Batch:   106] loss: 0.489, acc: 75.748, test_acc:39.167, F1:0.415\n",
            "[Epoch: 237 Batch:   106] loss: 0.468, acc: 74.692, test_acc:38.333, F1:0.410\n",
            "[Epoch: 238 Batch:   106] loss: 0.474, acc: 75.094, test_acc:35.833, F1:0.381\n",
            "[Epoch: 239 Batch:   106] loss: 0.471, acc: 74.025, test_acc:36.667, F1:0.395\n",
            "[Epoch: 240 Batch:   106] loss: 0.479, acc: 75.094, test_acc:39.167, F1:0.420\n",
            "[Epoch: 241 Batch:   106] loss: 0.472, acc: 74.818, test_acc:38.333, F1:0.416\n",
            "[Epoch: 242 Batch:   106] loss: 0.444, acc: 74.604, test_acc:35.000, F1:0.371\n",
            "[Epoch: 243 Batch:   106] loss: 0.434, acc: 74.126, test_acc:40.833, F1:0.439\n",
            "[Epoch: 244 Batch:   106] loss: 0.469, acc: 75.472, test_acc:38.333, F1:0.412\n",
            "[Epoch: 245 Batch:   106] loss: 0.477, acc: 74.591, test_acc:33.333, F1:0.356\n",
            "[Epoch: 246 Batch:   106] loss: 0.440, acc: 73.899, test_acc:37.500, F1:0.403\n",
            "[Epoch: 247 Batch:   106] loss: 0.444, acc: 73.648, test_acc:40.000, F1:0.425\n",
            "[Epoch: 248 Batch:   106] loss: 0.430, acc: 75.987, test_acc:31.667, F1:0.342\n",
            "[Epoch: 249 Batch:   106] loss: 0.423, acc: 76.503, test_acc:35.833, F1:0.373\n",
            "[Epoch: 250 Batch:   106] loss: 0.462, acc: 73.836, test_acc:35.000, F1:0.380\n",
            "[Epoch: 251 Batch:   106] loss: 0.406, acc: 75.497, test_acc:38.333, F1:0.409\n",
            "[Epoch: 252 Batch:   106] loss: 0.480, acc: 73.346, test_acc:36.667, F1:0.359\n",
            "[Epoch: 253 Batch:   106] loss: 0.471, acc: 74.478, test_acc:37.500, F1:0.401\n",
            "[Epoch: 254 Batch:   106] loss: 0.521, acc: 71.912, test_acc:41.667, F1:0.441\n",
            "[Epoch: 255 Batch:   106] loss: 0.464, acc: 75.094, test_acc:36.667, F1:0.391\n",
            "[Epoch: 256 Batch:   106] loss: 0.446, acc: 74.931, test_acc:38.333, F1:0.420\n",
            "[Epoch: 257 Batch:   106] loss: 0.470, acc: 73.346, test_acc:38.333, F1:0.420\n",
            "[Epoch: 258 Batch:   106] loss: 0.439, acc: 74.591, test_acc:40.833, F1:0.429\n",
            "[Epoch: 259 Batch:   106] loss: 0.442, acc: 74.591, test_acc:33.333, F1:0.365\n",
            "[Epoch: 260 Batch:   106] loss: 0.500, acc: 74.302, test_acc:37.500, F1:0.390\n",
            "[Epoch: 261 Batch:   106] loss: 0.432, acc: 75.396, test_acc:36.667, F1:0.386\n",
            "[Epoch: 262 Batch:   106] loss: 0.422, acc: 75.258, test_acc:35.833, F1:0.376\n",
            "[Epoch: 263 Batch:   106] loss: 0.431, acc: 73.535, test_acc:34.167, F1:0.354\n",
            "[Epoch: 264 Batch:   106] loss: 0.461, acc: 73.560, test_acc:32.500, F1:0.336\n",
            "[Epoch: 265 Batch:   106] loss: 0.450, acc: 72.214, test_acc:32.500, F1:0.352\n",
            "[Epoch: 266 Batch:   106] loss: 0.426, acc: 76.063, test_acc:34.167, F1:0.377\n",
            "[Epoch: 267 Batch:   106] loss: 0.422, acc: 72.528, test_acc:33.333, F1:0.358\n",
            "[Epoch: 268 Batch:   106] loss: 0.443, acc: 73.723, test_acc:38.333, F1:0.408\n",
            "[Epoch: 269 Batch:   106] loss: 0.483, acc: 73.497, test_acc:34.167, F1:0.364\n",
            "[Epoch: 270 Batch:   106] loss: 0.473, acc: 72.843, test_acc:30.833, F1:0.331\n",
            "[Epoch: 271 Batch:   106] loss: 0.401, acc: 74.453, test_acc:30.000, F1:0.316\n",
            "[Epoch: 272 Batch:   106] loss: 0.417, acc: 73.975, test_acc:30.833, F1:0.341\n",
            "[Epoch: 273 Batch:   106] loss: 0.470, acc: 74.717, test_acc:33.333, F1:0.350\n",
            "[Epoch: 274 Batch:   106] loss: 0.401, acc: 74.981, test_acc:30.000, F1:0.312\n",
            "[Epoch: 275 Batch:   106] loss: 0.456, acc: 73.673, test_acc:35.000, F1:0.380\n",
            "[Epoch: 276 Batch:   106] loss: 0.415, acc: 73.057, test_acc:31.667, F1:0.327\n",
            "[Epoch: 277 Batch:   106] loss: 0.416, acc: 75.069, test_acc:29.167, F1:0.301\n",
            "[Epoch: 278 Batch:   106] loss: 0.481, acc: 74.138, test_acc:36.667, F1:0.394\n",
            "[Epoch: 279 Batch:   106] loss: 0.454, acc: 73.459, test_acc:31.667, F1:0.337\n",
            "[Epoch: 280 Batch:   106] loss: 0.449, acc: 72.516, test_acc:34.167, F1:0.357\n",
            "[Epoch: 281 Batch:   106] loss: 0.414, acc: 75.761, test_acc:30.833, F1:0.315\n",
            "[Epoch: 282 Batch:   106] loss: 0.436, acc: 75.145, test_acc:30.833, F1:0.323\n",
            "[Epoch: 283 Batch:   106] loss: 0.435, acc: 75.245, test_acc:35.833, F1:0.384\n",
            "[Epoch: 284 Batch:   106] loss: 0.489, acc: 73.597, test_acc:32.500, F1:0.345\n",
            "[Epoch: 285 Batch:   106] loss: 0.428, acc: 75.308, test_acc:32.500, F1:0.354\n",
            "[Epoch: 286 Batch:   106] loss: 0.402, acc: 75.899, test_acc:33.333, F1:0.344\n",
            "[Epoch: 287 Batch:   106] loss: 0.425, acc: 74.239, test_acc:34.167, F1:0.341\n",
            "[Epoch: 288 Batch:   106] loss: 0.419, acc: 73.094, test_acc:32.500, F1:0.343\n",
            "[Epoch: 289 Batch:   106] loss: 0.378, acc: 75.786, test_acc:30.833, F1:0.325\n",
            "[Epoch: 290 Batch:   106] loss: 0.385, acc: 74.767, test_acc:35.000, F1:0.381\n",
            "[Epoch: 291 Batch:   106] loss: 0.440, acc: 73.535, test_acc:30.833, F1:0.331\n",
            "[Epoch: 292 Batch:   106] loss: 0.392, acc: 74.403, test_acc:28.333, F1:0.294\n",
            "[Epoch: 293 Batch:   106] loss: 0.430, acc: 74.189, test_acc:31.667, F1:0.329\n",
            "[Epoch: 294 Batch:   106] loss: 0.413, acc: 72.679, test_acc:32.500, F1:0.348\n",
            "[Epoch: 295 Batch:   106] loss: 0.431, acc: 73.774, test_acc:31.667, F1:0.336\n",
            "[Epoch: 296 Batch:   106] loss: 0.422, acc: 73.472, test_acc:26.667, F1:0.283\n",
            "[Epoch: 297 Batch:   106] loss: 0.464, acc: 73.522, test_acc:31.667, F1:0.346\n",
            "[Epoch: 298 Batch:   106] loss: 0.451, acc: 73.270, test_acc:37.500, F1:0.407\n",
            "[Epoch: 299 Batch:   106] loss: 0.516, acc: 72.994, test_acc:38.333, F1:0.414\n",
            "[Epoch: 300 Batch:   106] loss: 0.452, acc: 74.440, test_acc:32.500, F1:0.336\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  32.5\n",
            "Test F1 Score : 0.33567723071118655\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.73      0.24        15\n",
            "         1.0       0.64      0.40      0.49        57\n",
            "         2.0       0.56      0.10      0.18        48\n",
            "\n",
            "    accuracy                           0.33       120\n",
            "   macro avg       0.45      0.41      0.30       120\n",
            "weighted avg       0.54      0.33      0.34       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[11  4  0]\n",
            " [30 23  4]\n",
            " [34  9  5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.102457888921102 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  4\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 33.283, test_acc:31.667, F1:0.328\n",
            "[Epoch: 2 Batch:   106] loss: 1.085, acc: 37.082, test_acc:31.667, F1:0.318\n",
            "[Epoch: 3 Batch:   106] loss: 1.084, acc: 37.472, test_acc:32.500, F1:0.318\n",
            "[Epoch: 4 Batch:   106] loss: 1.081, acc: 36.214, test_acc:32.500, F1:0.296\n",
            "[Epoch: 5 Batch:   106] loss: 1.078, acc: 36.327, test_acc:30.000, F1:0.275\n",
            "[Epoch: 6 Batch:   106] loss: 1.076, acc: 36.151, test_acc:30.000, F1:0.274\n",
            "[Epoch: 7 Batch:   106] loss: 1.074, acc: 36.616, test_acc:31.667, F1:0.308\n",
            "[Epoch: 8 Batch:   106] loss: 1.074, acc: 36.541, test_acc:31.667, F1:0.314\n",
            "[Epoch: 9 Batch:   106] loss: 1.070, acc: 37.447, test_acc:34.167, F1:0.339\n",
            "[Epoch: 10 Batch:   106] loss: 1.069, acc: 38.792, test_acc:34.167, F1:0.351\n",
            "[Epoch: 11 Batch:   106] loss: 1.070, acc: 37.396, test_acc:35.000, F1:0.364\n",
            "[Epoch: 12 Batch:   106] loss: 1.067, acc: 38.642, test_acc:32.500, F1:0.341\n",
            "[Epoch: 13 Batch:   106] loss: 1.065, acc: 39.447, test_acc:35.000, F1:0.373\n",
            "[Epoch: 14 Batch:   106] loss: 1.064, acc: 39.648, test_acc:35.000, F1:0.373\n",
            "[Epoch: 15 Batch:   106] loss: 1.062, acc: 40.541, test_acc:34.167, F1:0.362\n",
            "[Epoch: 16 Batch:   106] loss: 1.060, acc: 39.899, test_acc:34.167, F1:0.366\n",
            "[Epoch: 17 Batch:   106] loss: 1.062, acc: 39.069, test_acc:35.000, F1:0.374\n",
            "[Epoch: 18 Batch:   106] loss: 1.059, acc: 39.623, test_acc:38.333, F1:0.410\n",
            "[Epoch: 19 Batch:   106] loss: 1.060, acc: 40.302, test_acc:36.667, F1:0.384\n",
            "[Epoch: 20 Batch:   106] loss: 1.055, acc: 40.428, test_acc:34.167, F1:0.351\n",
            "[Epoch: 21 Batch:   106] loss: 1.057, acc: 41.635, test_acc:32.500, F1:0.334\n",
            "[Epoch: 22 Batch:   106] loss: 1.052, acc: 42.503, test_acc:35.833, F1:0.382\n",
            "[Epoch: 23 Batch:   106] loss: 1.052, acc: 43.069, test_acc:37.500, F1:0.397\n",
            "[Epoch: 24 Batch:   106] loss: 1.050, acc: 41.472, test_acc:36.667, F1:0.383\n",
            "[Epoch: 25 Batch:   106] loss: 1.051, acc: 41.396, test_acc:32.500, F1:0.342\n",
            "[Epoch: 26 Batch:   106] loss: 1.046, acc: 42.239, test_acc:35.000, F1:0.365\n",
            "[Epoch: 27 Batch:   106] loss: 1.050, acc: 42.314, test_acc:32.500, F1:0.320\n",
            "[Epoch: 28 Batch:   106] loss: 1.046, acc: 43.220, test_acc:30.833, F1:0.328\n",
            "[Epoch: 29 Batch:   106] loss: 1.045, acc: 43.409, test_acc:28.333, F1:0.292\n",
            "[Epoch: 30 Batch:   106] loss: 1.040, acc: 42.289, test_acc:35.000, F1:0.370\n",
            "[Epoch: 31 Batch:   106] loss: 1.038, acc: 43.182, test_acc:32.500, F1:0.340\n",
            "[Epoch: 32 Batch:   106] loss: 1.038, acc: 43.824, test_acc:30.833, F1:0.318\n",
            "[Epoch: 33 Batch:   106] loss: 1.038, acc: 43.899, test_acc:33.333, F1:0.337\n",
            "[Epoch: 34 Batch:   106] loss: 1.036, acc: 44.377, test_acc:30.833, F1:0.325\n",
            "[Epoch: 35 Batch:   106] loss: 1.030, acc: 45.308, test_acc:31.667, F1:0.330\n",
            "[Epoch: 36 Batch:   106] loss: 1.029, acc: 45.220, test_acc:30.833, F1:0.323\n",
            "[Epoch: 37 Batch:   106] loss: 1.029, acc: 45.912, test_acc:29.167, F1:0.312\n",
            "[Epoch: 38 Batch:   106] loss: 1.028, acc: 45.522, test_acc:27.500, F1:0.282\n",
            "[Epoch: 39 Batch:   106] loss: 1.027, acc: 46.050, test_acc:32.500, F1:0.346\n",
            "[Epoch: 40 Batch:   106] loss: 1.027, acc: 46.277, test_acc:30.000, F1:0.314\n",
            "[Epoch: 41 Batch:   106] loss: 1.018, acc: 46.390, test_acc:26.667, F1:0.272\n",
            "[Epoch: 42 Batch:   106] loss: 1.020, acc: 45.937, test_acc:27.500, F1:0.285\n",
            "[Epoch: 43 Batch:   106] loss: 1.014, acc: 46.918, test_acc:27.500, F1:0.283\n",
            "[Epoch: 44 Batch:   106] loss: 1.017, acc: 46.742, test_acc:28.333, F1:0.289\n",
            "[Epoch: 45 Batch:   106] loss: 1.015, acc: 47.660, test_acc:31.667, F1:0.329\n",
            "[Epoch: 46 Batch:   106] loss: 1.009, acc: 47.283, test_acc:31.667, F1:0.329\n",
            "[Epoch: 47 Batch:   106] loss: 1.007, acc: 48.604, test_acc:31.667, F1:0.324\n",
            "[Epoch: 48 Batch:   106] loss: 1.007, acc: 48.679, test_acc:30.000, F1:0.299\n",
            "[Epoch: 49 Batch:   106] loss: 1.001, acc: 48.591, test_acc:30.000, F1:0.304\n",
            "[Epoch: 50 Batch:   106] loss: 1.001, acc: 49.082, test_acc:31.667, F1:0.323\n",
            "[Epoch: 51 Batch:   106] loss: 0.997, acc: 49.673, test_acc:30.000, F1:0.308\n",
            "[Epoch: 52 Batch:   106] loss: 0.992, acc: 50.541, test_acc:31.667, F1:0.328\n",
            "[Epoch: 53 Batch:   106] loss: 0.991, acc: 50.692, test_acc:30.000, F1:0.302\n",
            "[Epoch: 54 Batch:   106] loss: 0.988, acc: 51.648, test_acc:29.167, F1:0.301\n",
            "[Epoch: 55 Batch:   106] loss: 0.991, acc: 51.421, test_acc:31.667, F1:0.326\n",
            "[Epoch: 56 Batch:   106] loss: 0.987, acc: 50.478, test_acc:31.667, F1:0.328\n",
            "[Epoch: 57 Batch:   106] loss: 0.984, acc: 52.893, test_acc:30.000, F1:0.306\n",
            "[Epoch: 58 Batch:   106] loss: 0.977, acc: 51.836, test_acc:33.333, F1:0.340\n",
            "[Epoch: 59 Batch:   106] loss: 0.977, acc: 52.063, test_acc:34.167, F1:0.346\n",
            "[Epoch: 60 Batch:   106] loss: 0.973, acc: 52.541, test_acc:33.333, F1:0.343\n",
            "[Epoch: 61 Batch:   106] loss: 0.975, acc: 52.994, test_acc:29.167, F1:0.294\n",
            "[Epoch: 62 Batch:   106] loss: 0.962, acc: 53.384, test_acc:28.333, F1:0.289\n",
            "[Epoch: 63 Batch:   106] loss: 0.963, acc: 54.025, test_acc:27.500, F1:0.284\n",
            "[Epoch: 64 Batch:   106] loss: 0.955, acc: 54.428, test_acc:34.167, F1:0.344\n",
            "[Epoch: 65 Batch:   106] loss: 0.950, acc: 54.893, test_acc:31.667, F1:0.324\n",
            "[Epoch: 66 Batch:   106] loss: 0.955, acc: 54.189, test_acc:33.333, F1:0.343\n",
            "[Epoch: 67 Batch:   106] loss: 0.947, acc: 55.736, test_acc:30.833, F1:0.313\n",
            "[Epoch: 68 Batch:   106] loss: 0.943, acc: 55.686, test_acc:30.000, F1:0.302\n",
            "[Epoch: 69 Batch:   106] loss: 0.940, acc: 56.352, test_acc:32.500, F1:0.327\n",
            "[Epoch: 70 Batch:   106] loss: 0.936, acc: 54.566, test_acc:35.833, F1:0.367\n",
            "[Epoch: 71 Batch:   106] loss: 0.928, acc: 56.629, test_acc:31.667, F1:0.326\n",
            "[Epoch: 72 Batch:   106] loss: 0.925, acc: 56.994, test_acc:30.833, F1:0.316\n",
            "[Epoch: 73 Batch:   106] loss: 0.928, acc: 57.170, test_acc:36.667, F1:0.376\n",
            "[Epoch: 74 Batch:   106] loss: 0.923, acc: 57.283, test_acc:30.833, F1:0.308\n",
            "[Epoch: 75 Batch:   106] loss: 0.930, acc: 57.887, test_acc:31.667, F1:0.315\n",
            "[Epoch: 76 Batch:   106] loss: 0.909, acc: 58.491, test_acc:32.500, F1:0.329\n",
            "[Epoch: 77 Batch:   106] loss: 0.904, acc: 58.843, test_acc:33.333, F1:0.338\n",
            "[Epoch: 78 Batch:   106] loss: 0.895, acc: 58.881, test_acc:35.000, F1:0.363\n",
            "[Epoch: 79 Batch:   106] loss: 0.894, acc: 59.396, test_acc:35.000, F1:0.358\n",
            "[Epoch: 80 Batch:   106] loss: 0.901, acc: 58.843, test_acc:35.000, F1:0.362\n",
            "[Epoch: 81 Batch:   106] loss: 0.885, acc: 59.862, test_acc:32.500, F1:0.330\n",
            "[Epoch: 82 Batch:   106] loss: 0.873, acc: 59.824, test_acc:35.833, F1:0.366\n",
            "[Epoch: 83 Batch:   106] loss: 0.878, acc: 61.572, test_acc:31.667, F1:0.326\n",
            "[Epoch: 84 Batch:   106] loss: 0.884, acc: 60.918, test_acc:36.667, F1:0.366\n",
            "[Epoch: 85 Batch:   106] loss: 0.873, acc: 59.233, test_acc:37.500, F1:0.377\n",
            "[Epoch: 86 Batch:   106] loss: 0.871, acc: 61.761, test_acc:36.667, F1:0.378\n",
            "[Epoch: 87 Batch:   106] loss: 0.866, acc: 60.818, test_acc:38.333, F1:0.395\n",
            "[Epoch: 88 Batch:   106] loss: 0.852, acc: 61.950, test_acc:38.333, F1:0.392\n",
            "[Epoch: 89 Batch:   106] loss: 0.855, acc: 61.912, test_acc:30.000, F1:0.308\n",
            "[Epoch: 90 Batch:   106] loss: 0.839, acc: 63.660, test_acc:35.000, F1:0.358\n",
            "[Epoch: 91 Batch:   106] loss: 0.836, acc: 63.182, test_acc:38.333, F1:0.392\n",
            "[Epoch: 92 Batch:   106] loss: 0.836, acc: 64.264, test_acc:33.333, F1:0.345\n",
            "[Epoch: 93 Batch:   106] loss: 0.841, acc: 63.950, test_acc:39.167, F1:0.400\n",
            "[Epoch: 94 Batch:   106] loss: 0.828, acc: 63.358, test_acc:37.500, F1:0.379\n",
            "[Epoch: 95 Batch:   106] loss: 0.822, acc: 64.101, test_acc:38.333, F1:0.390\n",
            "[Epoch: 96 Batch:   106] loss: 0.815, acc: 64.881, test_acc:39.167, F1:0.401\n",
            "[Epoch: 97 Batch:   106] loss: 0.816, acc: 63.786, test_acc:40.000, F1:0.412\n",
            "[Epoch: 98 Batch:   106] loss: 0.812, acc: 65.371, test_acc:36.667, F1:0.379\n",
            "[Epoch: 99 Batch:   106] loss: 0.793, acc: 66.730, test_acc:43.333, F1:0.443\n",
            "[Epoch: 100 Batch:   106] loss: 0.790, acc: 67.119, test_acc:37.500, F1:0.388\n",
            "[Epoch: 101 Batch:   106] loss: 0.795, acc: 66.755, test_acc:43.333, F1:0.444\n",
            "[Epoch: 102 Batch:   106] loss: 0.783, acc: 66.679, test_acc:37.500, F1:0.382\n",
            "[Epoch: 103 Batch:   106] loss: 0.798, acc: 66.491, test_acc:37.500, F1:0.386\n",
            "[Epoch: 104 Batch:   106] loss: 0.764, acc: 67.610, test_acc:40.833, F1:0.424\n",
            "[Epoch: 105 Batch:   106] loss: 0.770, acc: 66.906, test_acc:39.167, F1:0.399\n",
            "[Epoch: 106 Batch:   106] loss: 0.757, acc: 67.698, test_acc:40.833, F1:0.425\n",
            "[Epoch: 107 Batch:   106] loss: 0.771, acc: 65.748, test_acc:40.833, F1:0.412\n",
            "[Epoch: 108 Batch:   106] loss: 0.762, acc: 67.748, test_acc:38.333, F1:0.394\n",
            "[Epoch: 109 Batch:   106] loss: 0.750, acc: 68.164, test_acc:42.500, F1:0.440\n",
            "[Epoch: 110 Batch:   106] loss: 0.759, acc: 68.226, test_acc:41.667, F1:0.420\n",
            "[Epoch: 111 Batch:   106] loss: 0.747, acc: 68.717, test_acc:47.500, F1:0.489\n",
            "[Epoch: 112 Batch:   106] loss: 0.755, acc: 68.365, test_acc:39.167, F1:0.410\n",
            "[Epoch: 113 Batch:   106] loss: 0.735, acc: 69.346, test_acc:40.000, F1:0.408\n",
            "[Epoch: 114 Batch:   106] loss: 0.721, acc: 70.088, test_acc:41.667, F1:0.425\n",
            "[Epoch: 115 Batch:   106] loss: 0.727, acc: 68.704, test_acc:40.000, F1:0.411\n",
            "[Epoch: 116 Batch:   106] loss: 0.717, acc: 70.226, test_acc:38.333, F1:0.397\n",
            "[Epoch: 117 Batch:   106] loss: 0.724, acc: 68.440, test_acc:40.833, F1:0.424\n",
            "[Epoch: 118 Batch:   106] loss: 0.715, acc: 70.252, test_acc:36.667, F1:0.380\n",
            "[Epoch: 119 Batch:   106] loss: 0.698, acc: 70.013, test_acc:38.333, F1:0.395\n",
            "[Epoch: 120 Batch:   106] loss: 0.702, acc: 72.063, test_acc:40.000, F1:0.410\n",
            "[Epoch: 121 Batch:   106] loss: 0.689, acc: 70.881, test_acc:40.000, F1:0.410\n",
            "[Epoch: 122 Batch:   106] loss: 0.707, acc: 69.761, test_acc:40.833, F1:0.423\n",
            "[Epoch: 123 Batch:   106] loss: 0.692, acc: 71.447, test_acc:40.000, F1:0.408\n",
            "[Epoch: 124 Batch:   106] loss: 0.687, acc: 72.113, test_acc:41.667, F1:0.428\n",
            "[Epoch: 125 Batch:   106] loss: 0.677, acc: 71.547, test_acc:44.167, F1:0.445\n",
            "[Epoch: 126 Batch:   106] loss: 0.670, acc: 72.642, test_acc:41.667, F1:0.427\n",
            "[Epoch: 127 Batch:   106] loss: 0.665, acc: 72.843, test_acc:39.167, F1:0.403\n",
            "[Epoch: 128 Batch:   106] loss: 0.646, acc: 72.365, test_acc:39.167, F1:0.404\n",
            "[Epoch: 129 Batch:   106] loss: 0.657, acc: 71.233, test_acc:39.167, F1:0.399\n",
            "[Epoch: 130 Batch:   106] loss: 0.646, acc: 73.208, test_acc:36.667, F1:0.364\n",
            "[Epoch: 131 Batch:   106] loss: 0.656, acc: 73.069, test_acc:44.167, F1:0.446\n",
            "[Epoch: 132 Batch:   106] loss: 0.656, acc: 71.031, test_acc:42.500, F1:0.434\n",
            "[Epoch: 133 Batch:   106] loss: 0.639, acc: 73.409, test_acc:38.333, F1:0.392\n",
            "[Epoch: 134 Batch:   106] loss: 0.653, acc: 72.881, test_acc:40.000, F1:0.408\n",
            "[Epoch: 135 Batch:   106] loss: 0.631, acc: 73.019, test_acc:40.000, F1:0.414\n",
            "[Epoch: 136 Batch:   106] loss: 0.630, acc: 72.390, test_acc:33.333, F1:0.344\n",
            "[Epoch: 137 Batch:   106] loss: 0.623, acc: 72.868, test_acc:42.500, F1:0.434\n",
            "[Epoch: 138 Batch:   106] loss: 0.625, acc: 73.987, test_acc:36.667, F1:0.376\n",
            "[Epoch: 139 Batch:   106] loss: 0.599, acc: 75.145, test_acc:43.333, F1:0.439\n",
            "[Epoch: 140 Batch:   106] loss: 0.608, acc: 73.610, test_acc:40.833, F1:0.422\n",
            "[Epoch: 141 Batch:   106] loss: 0.627, acc: 73.522, test_acc:44.167, F1:0.447\n",
            "[Epoch: 142 Batch:   106] loss: 0.598, acc: 74.138, test_acc:41.667, F1:0.425\n",
            "[Epoch: 143 Batch:   106] loss: 0.597, acc: 75.258, test_acc:42.500, F1:0.432\n",
            "[Epoch: 144 Batch:   106] loss: 0.591, acc: 75.836, test_acc:38.333, F1:0.400\n",
            "[Epoch: 145 Batch:   106] loss: 0.594, acc: 73.711, test_acc:35.000, F1:0.354\n",
            "[Epoch: 146 Batch:   106] loss: 0.582, acc: 72.918, test_acc:35.000, F1:0.356\n",
            "[Epoch: 147 Batch:   106] loss: 0.572, acc: 74.956, test_acc:39.167, F1:0.403\n",
            "[Epoch: 148 Batch:   106] loss: 0.582, acc: 73.346, test_acc:36.667, F1:0.371\n",
            "[Epoch: 149 Batch:   106] loss: 0.579, acc: 74.667, test_acc:38.333, F1:0.394\n",
            "[Epoch: 150 Batch:   106] loss: 0.576, acc: 74.327, test_acc:38.333, F1:0.387\n",
            "[Epoch: 151 Batch:   106] loss: 0.553, acc: 76.415, test_acc:36.667, F1:0.379\n",
            "[Epoch: 152 Batch:   106] loss: 0.570, acc: 75.346, test_acc:38.333, F1:0.374\n",
            "[Epoch: 153 Batch:   106] loss: 0.582, acc: 75.245, test_acc:35.833, F1:0.344\n",
            "[Epoch: 154 Batch:   106] loss: 0.581, acc: 75.648, test_acc:39.167, F1:0.401\n",
            "[Epoch: 155 Batch:   106] loss: 0.562, acc: 74.050, test_acc:34.167, F1:0.341\n",
            "[Epoch: 156 Batch:   106] loss: 0.572, acc: 76.440, test_acc:36.667, F1:0.371\n",
            "[Epoch: 157 Batch:   106] loss: 0.543, acc: 76.415, test_acc:31.667, F1:0.324\n",
            "[Epoch: 158 Batch:   106] loss: 0.552, acc: 75.912, test_acc:35.833, F1:0.334\n",
            "[Epoch: 159 Batch:   106] loss: 0.516, acc: 77.434, test_acc:34.167, F1:0.332\n",
            "[Epoch: 160 Batch:   106] loss: 0.532, acc: 75.170, test_acc:38.333, F1:0.381\n",
            "[Epoch: 161 Batch:   106] loss: 0.521, acc: 75.472, test_acc:38.333, F1:0.371\n",
            "[Epoch: 162 Batch:   106] loss: 0.557, acc: 74.616, test_acc:33.333, F1:0.345\n",
            "[Epoch: 163 Batch:   106] loss: 0.551, acc: 75.170, test_acc:35.833, F1:0.366\n",
            "[Epoch: 164 Batch:   106] loss: 0.546, acc: 76.403, test_acc:39.167, F1:0.397\n",
            "[Epoch: 165 Batch:   106] loss: 0.526, acc: 75.824, test_acc:40.000, F1:0.402\n",
            "[Epoch: 166 Batch:   106] loss: 0.535, acc: 77.497, test_acc:34.167, F1:0.335\n",
            "[Epoch: 167 Batch:   106] loss: 0.512, acc: 76.843, test_acc:31.667, F1:0.300\n",
            "[Epoch: 168 Batch:   106] loss: 0.493, acc: 75.547, test_acc:31.667, F1:0.282\n",
            "[Epoch: 169 Batch:   106] loss: 0.494, acc: 76.604, test_acc:31.667, F1:0.306\n",
            "[Epoch: 170 Batch:   106] loss: 0.493, acc: 77.409, test_acc:32.500, F1:0.294\n",
            "[Epoch: 171 Batch:   106] loss: 0.497, acc: 74.855, test_acc:35.000, F1:0.336\n",
            "[Epoch: 172 Batch:   106] loss: 0.506, acc: 77.635, test_acc:32.500, F1:0.309\n",
            "[Epoch: 173 Batch:   106] loss: 0.491, acc: 76.981, test_acc:31.667, F1:0.296\n",
            "[Epoch: 174 Batch:   106] loss: 0.486, acc: 76.667, test_acc:35.833, F1:0.326\n",
            "[Epoch: 175 Batch:   106] loss: 0.510, acc: 76.151, test_acc:38.333, F1:0.368\n",
            "[Epoch: 176 Batch:   106] loss: 0.490, acc: 78.264, test_acc:35.833, F1:0.352\n",
            "[Epoch: 177 Batch:   106] loss: 0.462, acc: 78.591, test_acc:40.000, F1:0.380\n",
            "[Epoch: 178 Batch:   106] loss: 0.497, acc: 75.396, test_acc:35.833, F1:0.362\n",
            "[Epoch: 179 Batch:   106] loss: 0.481, acc: 78.038, test_acc:33.333, F1:0.328\n",
            "[Epoch: 180 Batch:   106] loss: 0.486, acc: 76.390, test_acc:36.667, F1:0.338\n",
            "[Epoch: 181 Batch:   106] loss: 0.509, acc: 76.767, test_acc:38.333, F1:0.385\n",
            "[Epoch: 182 Batch:   106] loss: 0.469, acc: 76.780, test_acc:32.500, F1:0.331\n",
            "[Epoch: 183 Batch:   106] loss: 0.477, acc: 77.849, test_acc:39.167, F1:0.402\n",
            "[Epoch: 184 Batch:   106] loss: 0.512, acc: 75.874, test_acc:36.667, F1:0.373\n",
            "[Epoch: 185 Batch:   106] loss: 0.468, acc: 77.560, test_acc:40.833, F1:0.415\n",
            "[Epoch: 186 Batch:   106] loss: 0.438, acc: 77.748, test_acc:35.833, F1:0.347\n",
            "[Epoch: 187 Batch:   106] loss: 0.491, acc: 75.912, test_acc:35.833, F1:0.331\n",
            "[Epoch: 188 Batch:   106] loss: 0.471, acc: 76.679, test_acc:34.167, F1:0.324\n",
            "[Epoch: 189 Batch:   106] loss: 0.444, acc: 78.352, test_acc:36.667, F1:0.332\n",
            "[Epoch: 190 Batch:   106] loss: 0.444, acc: 77.270, test_acc:39.167, F1:0.391\n",
            "[Epoch: 191 Batch:   106] loss: 0.442, acc: 77.673, test_acc:39.167, F1:0.368\n",
            "[Epoch: 192 Batch:   106] loss: 0.422, acc: 77.673, test_acc:30.833, F1:0.297\n",
            "[Epoch: 193 Batch:   106] loss: 0.463, acc: 77.585, test_acc:35.833, F1:0.351\n",
            "[Epoch: 194 Batch:   106] loss: 0.452, acc: 76.868, test_acc:37.500, F1:0.371\n",
            "[Epoch: 195 Batch:   106] loss: 0.439, acc: 77.597, test_acc:35.000, F1:0.350\n",
            "[Epoch: 196 Batch:   106] loss: 0.455, acc: 77.723, test_acc:36.667, F1:0.366\n",
            "[Epoch: 197 Batch:   106] loss: 0.441, acc: 77.283, test_acc:37.500, F1:0.363\n",
            "[Epoch: 198 Batch:   106] loss: 0.425, acc: 79.522, test_acc:36.667, F1:0.357\n",
            "[Epoch: 199 Batch:   106] loss: 0.455, acc: 77.736, test_acc:35.833, F1:0.351\n",
            "[Epoch: 200 Batch:   106] loss: 0.445, acc: 77.799, test_acc:36.667, F1:0.364\n",
            "[Epoch: 201 Batch:   106] loss: 0.445, acc: 78.604, test_acc:42.500, F1:0.417\n",
            "[Epoch: 202 Batch:   106] loss: 0.414, acc: 78.352, test_acc:34.167, F1:0.334\n",
            "[Epoch: 203 Batch:   106] loss: 0.390, acc: 79.006, test_acc:43.333, F1:0.414\n",
            "[Epoch: 204 Batch:   106] loss: 0.394, acc: 79.006, test_acc:37.500, F1:0.370\n",
            "[Epoch: 205 Batch:   106] loss: 0.435, acc: 77.748, test_acc:36.667, F1:0.326\n",
            "[Epoch: 206 Batch:   106] loss: 0.424, acc: 75.862, test_acc:32.500, F1:0.294\n",
            "[Epoch: 207 Batch:   106] loss: 0.384, acc: 79.761, test_acc:41.667, F1:0.417\n",
            "[Epoch: 208 Batch:   106] loss: 0.366, acc: 80.654, test_acc:35.833, F1:0.349\n",
            "[Epoch: 209 Batch:   106] loss: 0.400, acc: 77.270, test_acc:36.667, F1:0.338\n",
            "[Epoch: 210 Batch:   106] loss: 0.394, acc: 77.547, test_acc:39.167, F1:0.382\n",
            "[Epoch: 211 Batch:   106] loss: 0.418, acc: 78.277, test_acc:35.833, F1:0.356\n",
            "[Epoch: 212 Batch:   106] loss: 0.420, acc: 78.906, test_acc:34.167, F1:0.299\n",
            "[Epoch: 213 Batch:   106] loss: 0.395, acc: 78.931, test_acc:35.000, F1:0.304\n",
            "[Epoch: 214 Batch:   106] loss: 0.392, acc: 77.585, test_acc:38.333, F1:0.375\n",
            "[Epoch: 215 Batch:   106] loss: 0.404, acc: 76.340, test_acc:37.500, F1:0.368\n",
            "[Epoch: 216 Batch:   106] loss: 0.445, acc: 76.302, test_acc:35.000, F1:0.323\n",
            "[Epoch: 217 Batch:   106] loss: 0.449, acc: 76.994, test_acc:36.667, F1:0.308\n",
            "[Epoch: 218 Batch:   106] loss: 0.390, acc: 79.899, test_acc:37.500, F1:0.367\n",
            "[Epoch: 219 Batch:   106] loss: 0.374, acc: 79.409, test_acc:40.000, F1:0.389\n",
            "[Epoch: 220 Batch:   106] loss: 0.372, acc: 79.874, test_acc:46.667, F1:0.472\n",
            "[Epoch: 221 Batch:   106] loss: 0.445, acc: 75.925, test_acc:38.333, F1:0.381\n",
            "[Epoch: 222 Batch:   106] loss: 0.346, acc: 78.201, test_acc:40.000, F1:0.400\n",
            "[Epoch: 223 Batch:   106] loss: 0.413, acc: 76.428, test_acc:40.833, F1:0.379\n",
            "[Epoch: 224 Batch:   106] loss: 0.413, acc: 79.346, test_acc:45.000, F1:0.454\n",
            "[Epoch: 225 Batch:   106] loss: 0.366, acc: 76.101, test_acc:30.833, F1:0.281\n",
            "[Epoch: 226 Batch:   106] loss: 0.355, acc: 80.201, test_acc:38.333, F1:0.356\n",
            "[Epoch: 227 Batch:   106] loss: 0.374, acc: 77.509, test_acc:41.667, F1:0.410\n",
            "[Epoch: 228 Batch:   106] loss: 0.393, acc: 77.321, test_acc:35.000, F1:0.337\n",
            "[Epoch: 229 Batch:   106] loss: 0.359, acc: 79.434, test_acc:42.500, F1:0.433\n",
            "[Epoch: 230 Batch:   106] loss: 0.400, acc: 79.157, test_acc:39.167, F1:0.374\n",
            "[Epoch: 231 Batch:   106] loss: 0.417, acc: 78.767, test_acc:35.000, F1:0.328\n",
            "[Epoch: 232 Batch:   106] loss: 0.378, acc: 78.667, test_acc:35.833, F1:0.339\n",
            "[Epoch: 233 Batch:   106] loss: 0.374, acc: 80.465, test_acc:40.833, F1:0.397\n",
            "[Epoch: 234 Batch:   106] loss: 0.355, acc: 77.396, test_acc:43.333, F1:0.432\n",
            "[Epoch: 235 Batch:   106] loss: 0.358, acc: 77.786, test_acc:37.500, F1:0.337\n",
            "[Epoch: 236 Batch:   106] loss: 0.376, acc: 78.126, test_acc:32.500, F1:0.273\n",
            "[Epoch: 237 Batch:   106] loss: 0.358, acc: 78.327, test_acc:36.667, F1:0.340\n",
            "[Epoch: 238 Batch:   106] loss: 0.371, acc: 77.572, test_acc:38.333, F1:0.364\n",
            "[Epoch: 239 Batch:   106] loss: 0.377, acc: 79.245, test_acc:35.833, F1:0.321\n",
            "[Epoch: 240 Batch:   106] loss: 0.354, acc: 79.044, test_acc:36.667, F1:0.355\n",
            "[Epoch: 241 Batch:   106] loss: 0.353, acc: 78.755, test_acc:35.000, F1:0.335\n",
            "[Epoch: 242 Batch:   106] loss: 0.393, acc: 79.132, test_acc:31.667, F1:0.314\n",
            "[Epoch: 243 Batch:   106] loss: 0.425, acc: 78.264, test_acc:31.667, F1:0.291\n",
            "[Epoch: 244 Batch:   106] loss: 0.382, acc: 75.132, test_acc:36.667, F1:0.330\n",
            "[Epoch: 245 Batch:   106] loss: 0.351, acc: 78.428, test_acc:34.167, F1:0.325\n",
            "[Epoch: 246 Batch:   106] loss: 0.387, acc: 78.692, test_acc:40.000, F1:0.389\n",
            "[Epoch: 247 Batch:   106] loss: 0.343, acc: 80.252, test_acc:35.833, F1:0.337\n",
            "[Epoch: 248 Batch:   106] loss: 0.378, acc: 75.824, test_acc:37.500, F1:0.362\n",
            "[Epoch: 249 Batch:   106] loss: 0.478, acc: 76.038, test_acc:38.333, F1:0.368\n",
            "[Epoch: 250 Batch:   106] loss: 0.454, acc: 78.050, test_acc:35.000, F1:0.320\n",
            "[Epoch: 251 Batch:   106] loss: 0.382, acc: 79.560, test_acc:33.333, F1:0.314\n",
            "[Epoch: 252 Batch:   106] loss: 0.311, acc: 77.912, test_acc:40.000, F1:0.374\n",
            "[Epoch: 253 Batch:   106] loss: 0.333, acc: 78.566, test_acc:35.833, F1:0.327\n",
            "[Epoch: 254 Batch:   106] loss: 0.357, acc: 79.748, test_acc:36.667, F1:0.350\n",
            "[Epoch: 255 Batch:   106] loss: 0.380, acc: 78.805, test_acc:34.167, F1:0.333\n",
            "[Epoch: 256 Batch:   106] loss: 0.380, acc: 78.214, test_acc:35.000, F1:0.337\n",
            "[Epoch: 257 Batch:   106] loss: 0.341, acc: 80.742, test_acc:35.833, F1:0.338\n",
            "[Epoch: 258 Batch:   106] loss: 0.306, acc: 81.094, test_acc:40.000, F1:0.397\n",
            "[Epoch: 259 Batch:   106] loss: 0.410, acc: 79.333, test_acc:35.833, F1:0.337\n",
            "[Epoch: 260 Batch:   106] loss: 0.414, acc: 76.226, test_acc:35.000, F1:0.310\n",
            "[Epoch: 261 Batch:   106] loss: 0.348, acc: 79.497, test_acc:36.667, F1:0.339\n",
            "[Epoch: 262 Batch:   106] loss: 0.361, acc: 77.874, test_acc:34.167, F1:0.322\n",
            "[Epoch: 263 Batch:   106] loss: 0.346, acc: 79.623, test_acc:41.667, F1:0.398\n",
            "[Epoch: 264 Batch:   106] loss: 0.388, acc: 78.403, test_acc:37.500, F1:0.348\n",
            "[Epoch: 265 Batch:   106] loss: 0.341, acc: 77.874, test_acc:35.000, F1:0.306\n",
            "[Epoch: 266 Batch:   106] loss: 0.344, acc: 78.755, test_acc:35.833, F1:0.354\n",
            "[Epoch: 267 Batch:   106] loss: 0.344, acc: 78.969, test_acc:32.500, F1:0.297\n",
            "[Epoch: 268 Batch:   106] loss: 0.446, acc: 76.050, test_acc:35.833, F1:0.347\n",
            "[Epoch: 269 Batch:   106] loss: 0.384, acc: 77.698, test_acc:34.167, F1:0.314\n",
            "[Epoch: 270 Batch:   106] loss: 0.315, acc: 77.799, test_acc:30.000, F1:0.279\n",
            "[Epoch: 271 Batch:   106] loss: 0.330, acc: 81.170, test_acc:36.667, F1:0.339\n",
            "[Epoch: 272 Batch:   106] loss: 0.368, acc: 76.164, test_acc:39.167, F1:0.363\n",
            "[Epoch: 273 Batch:   106] loss: 0.390, acc: 76.667, test_acc:34.167, F1:0.295\n",
            "[Epoch: 274 Batch:   106] loss: 0.331, acc: 79.811, test_acc:35.833, F1:0.353\n",
            "[Epoch: 275 Batch:   106] loss: 0.388, acc: 78.000, test_acc:29.167, F1:0.226\n",
            "[Epoch: 276 Batch:   106] loss: 0.357, acc: 78.956, test_acc:35.000, F1:0.315\n",
            "[Epoch: 277 Batch:   106] loss: 0.371, acc: 78.931, test_acc:36.667, F1:0.335\n",
            "[Epoch: 278 Batch:   106] loss: 0.346, acc: 78.025, test_acc:31.667, F1:0.271\n",
            "[Epoch: 279 Batch:   106] loss: 0.425, acc: 78.994, test_acc:34.167, F1:0.331\n",
            "[Epoch: 280 Batch:   106] loss: 0.381, acc: 77.472, test_acc:35.000, F1:0.312\n",
            "[Epoch: 281 Batch:   106] loss: 0.383, acc: 79.585, test_acc:34.167, F1:0.318\n",
            "[Epoch: 282 Batch:   106] loss: 0.394, acc: 80.050, test_acc:40.833, F1:0.383\n",
            "[Epoch: 283 Batch:   106] loss: 0.426, acc: 78.893, test_acc:41.667, F1:0.416\n",
            "[Epoch: 284 Batch:   106] loss: 0.341, acc: 79.031, test_acc:39.167, F1:0.382\n",
            "[Epoch: 285 Batch:   106] loss: 0.301, acc: 78.755, test_acc:35.000, F1:0.322\n",
            "[Epoch: 286 Batch:   106] loss: 0.259, acc: 80.277, test_acc:37.500, F1:0.357\n",
            "[Epoch: 287 Batch:   106] loss: 0.313, acc: 79.736, test_acc:35.000, F1:0.326\n",
            "[Epoch: 288 Batch:   106] loss: 0.292, acc: 79.308, test_acc:38.333, F1:0.352\n",
            "[Epoch: 289 Batch:   106] loss: 0.347, acc: 78.642, test_acc:36.667, F1:0.360\n",
            "[Epoch: 290 Batch:   106] loss: 0.326, acc: 80.566, test_acc:36.667, F1:0.364\n",
            "[Epoch: 291 Batch:   106] loss: 0.385, acc: 78.792, test_acc:35.833, F1:0.322\n",
            "[Epoch: 292 Batch:   106] loss: 0.317, acc: 80.805, test_acc:35.833, F1:0.329\n",
            "[Epoch: 293 Batch:   106] loss: 0.316, acc: 78.704, test_acc:37.500, F1:0.353\n",
            "[Epoch: 294 Batch:   106] loss: 0.372, acc: 77.283, test_acc:35.833, F1:0.335\n",
            "[Epoch: 295 Batch:   106] loss: 0.392, acc: 77.824, test_acc:35.833, F1:0.334\n",
            "[Epoch: 296 Batch:   106] loss: 0.442, acc: 80.994, test_acc:44.167, F1:0.435\n",
            "[Epoch: 297 Batch:   106] loss: 0.432, acc: 79.283, test_acc:34.167, F1:0.294\n",
            "[Epoch: 298 Batch:   106] loss: 0.430, acc: 78.868, test_acc:32.500, F1:0.302\n",
            "[Epoch: 299 Batch:   106] loss: 0.423, acc: 76.239, test_acc:34.167, F1:0.315\n",
            "[Epoch: 300 Batch:   106] loss: 0.323, acc: 80.491, test_acc:35.000, F1:0.307\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  35.0\n",
            "Test F1 Score : 0.30737910349644604\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.17      0.26        60\n",
            "         1.0       0.22      0.17      0.19        24\n",
            "         2.0       0.33      0.78      0.46        36\n",
            "\n",
            "    accuracy                           0.35       120\n",
            "   macro avg       0.39      0.37      0.30       120\n",
            "weighted avg       0.45      0.35      0.31       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[10  9 41]\n",
            " [ 3  4 17]\n",
            " [ 3  5 28]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.148392534255981 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  5\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 34.264, test_acc:32.500, F1:0.329\n",
            "[Epoch: 2 Batch:   106] loss: 1.083, acc: 34.679, test_acc:36.667, F1:0.375\n",
            "[Epoch: 3 Batch:   106] loss: 1.082, acc: 35.119, test_acc:35.000, F1:0.359\n",
            "[Epoch: 4 Batch:   106] loss: 1.080, acc: 35.308, test_acc:36.667, F1:0.376\n",
            "[Epoch: 5 Batch:   106] loss: 1.076, acc: 36.277, test_acc:35.833, F1:0.366\n",
            "[Epoch: 6 Batch:   106] loss: 1.075, acc: 36.428, test_acc:31.667, F1:0.325\n",
            "[Epoch: 7 Batch:   106] loss: 1.073, acc: 37.421, test_acc:30.833, F1:0.322\n",
            "[Epoch: 8 Batch:   106] loss: 1.075, acc: 38.164, test_acc:25.833, F1:0.271\n",
            "[Epoch: 9 Batch:   106] loss: 1.073, acc: 38.679, test_acc:30.000, F1:0.317\n",
            "[Epoch: 10 Batch:   106] loss: 1.069, acc: 38.642, test_acc:30.000, F1:0.313\n",
            "[Epoch: 11 Batch:   106] loss: 1.068, acc: 38.553, test_acc:28.333, F1:0.303\n",
            "[Epoch: 12 Batch:   106] loss: 1.068, acc: 39.723, test_acc:29.167, F1:0.303\n",
            "[Epoch: 13 Batch:   106] loss: 1.065, acc: 40.025, test_acc:33.333, F1:0.347\n",
            "[Epoch: 14 Batch:   106] loss: 1.063, acc: 40.528, test_acc:29.167, F1:0.306\n",
            "[Epoch: 15 Batch:   106] loss: 1.062, acc: 40.239, test_acc:32.500, F1:0.340\n",
            "[Epoch: 16 Batch:   106] loss: 1.062, acc: 40.428, test_acc:30.833, F1:0.320\n",
            "[Epoch: 17 Batch:   106] loss: 1.061, acc: 40.604, test_acc:33.333, F1:0.345\n",
            "[Epoch: 18 Batch:   106] loss: 1.057, acc: 41.849, test_acc:35.833, F1:0.367\n",
            "[Epoch: 19 Batch:   106] loss: 1.056, acc: 41.987, test_acc:31.667, F1:0.328\n",
            "[Epoch: 20 Batch:   106] loss: 1.058, acc: 41.547, test_acc:29.167, F1:0.295\n",
            "[Epoch: 21 Batch:   106] loss: 1.055, acc: 41.107, test_acc:31.667, F1:0.329\n",
            "[Epoch: 22 Batch:   106] loss: 1.054, acc: 42.088, test_acc:32.500, F1:0.329\n",
            "[Epoch: 23 Batch:   106] loss: 1.049, acc: 41.962, test_acc:31.667, F1:0.311\n",
            "[Epoch: 24 Batch:   106] loss: 1.047, acc: 41.862, test_acc:32.500, F1:0.325\n",
            "[Epoch: 25 Batch:   106] loss: 1.049, acc: 43.057, test_acc:29.167, F1:0.299\n",
            "[Epoch: 26 Batch:   106] loss: 1.048, acc: 42.264, test_acc:30.833, F1:0.313\n",
            "[Epoch: 27 Batch:   106] loss: 1.045, acc: 44.088, test_acc:29.167, F1:0.296\n",
            "[Epoch: 28 Batch:   106] loss: 1.042, acc: 43.887, test_acc:30.000, F1:0.312\n",
            "[Epoch: 29 Batch:   106] loss: 1.043, acc: 42.855, test_acc:36.667, F1:0.368\n",
            "[Epoch: 30 Batch:   106] loss: 1.038, acc: 44.277, test_acc:33.333, F1:0.340\n",
            "[Epoch: 31 Batch:   106] loss: 1.037, acc: 45.748, test_acc:37.500, F1:0.369\n",
            "[Epoch: 32 Batch:   106] loss: 1.038, acc: 43.811, test_acc:36.667, F1:0.377\n",
            "[Epoch: 33 Batch:   106] loss: 1.033, acc: 45.069, test_acc:30.833, F1:0.307\n",
            "[Epoch: 34 Batch:   106] loss: 1.028, acc: 46.440, test_acc:31.667, F1:0.316\n",
            "[Epoch: 35 Batch:   106] loss: 1.032, acc: 47.132, test_acc:34.167, F1:0.344\n",
            "[Epoch: 36 Batch:   106] loss: 1.028, acc: 47.195, test_acc:35.000, F1:0.359\n",
            "[Epoch: 37 Batch:   106] loss: 1.029, acc: 46.654, test_acc:29.167, F1:0.287\n",
            "[Epoch: 38 Batch:   106] loss: 1.021, acc: 47.434, test_acc:26.667, F1:0.272\n",
            "[Epoch: 39 Batch:   106] loss: 1.020, acc: 47.698, test_acc:35.833, F1:0.368\n",
            "[Epoch: 40 Batch:   106] loss: 1.020, acc: 48.038, test_acc:25.000, F1:0.256\n",
            "[Epoch: 41 Batch:   106] loss: 1.021, acc: 47.623, test_acc:25.000, F1:0.255\n",
            "[Epoch: 42 Batch:   106] loss: 1.016, acc: 49.182, test_acc:30.000, F1:0.306\n",
            "[Epoch: 43 Batch:   106] loss: 1.011, acc: 48.792, test_acc:27.500, F1:0.277\n",
            "[Epoch: 44 Batch:   106] loss: 1.011, acc: 48.730, test_acc:29.167, F1:0.293\n",
            "[Epoch: 45 Batch:   106] loss: 1.004, acc: 49.132, test_acc:27.500, F1:0.282\n",
            "[Epoch: 46 Batch:   106] loss: 1.001, acc: 49.836, test_acc:25.000, F1:0.256\n",
            "[Epoch: 47 Batch:   106] loss: 0.997, acc: 50.994, test_acc:25.000, F1:0.256\n",
            "[Epoch: 48 Batch:   106] loss: 0.998, acc: 51.170, test_acc:32.500, F1:0.339\n",
            "[Epoch: 49 Batch:   106] loss: 0.987, acc: 51.836, test_acc:29.167, F1:0.301\n",
            "[Epoch: 50 Batch:   106] loss: 0.987, acc: 53.031, test_acc:26.667, F1:0.282\n",
            "[Epoch: 51 Batch:   106] loss: 0.990, acc: 50.692, test_acc:28.333, F1:0.285\n",
            "[Epoch: 52 Batch:   106] loss: 0.989, acc: 50.956, test_acc:35.000, F1:0.349\n",
            "[Epoch: 53 Batch:   106] loss: 0.980, acc: 53.308, test_acc:31.667, F1:0.325\n",
            "[Epoch: 54 Batch:   106] loss: 0.973, acc: 54.352, test_acc:28.333, F1:0.286\n",
            "[Epoch: 55 Batch:   106] loss: 0.971, acc: 53.170, test_acc:35.833, F1:0.362\n",
            "[Epoch: 56 Batch:   106] loss: 0.969, acc: 54.591, test_acc:35.000, F1:0.355\n",
            "[Epoch: 57 Batch:   106] loss: 0.959, acc: 52.918, test_acc:24.167, F1:0.246\n",
            "[Epoch: 58 Batch:   106] loss: 0.963, acc: 54.465, test_acc:32.500, F1:0.327\n",
            "[Epoch: 59 Batch:   106] loss: 0.965, acc: 54.352, test_acc:23.333, F1:0.236\n",
            "[Epoch: 60 Batch:   106] loss: 0.954, acc: 55.119, test_acc:34.167, F1:0.359\n",
            "[Epoch: 61 Batch:   106] loss: 0.960, acc: 54.818, test_acc:29.167, F1:0.297\n",
            "[Epoch: 62 Batch:   106] loss: 0.943, acc: 56.063, test_acc:28.333, F1:0.291\n",
            "[Epoch: 63 Batch:   106] loss: 0.950, acc: 55.459, test_acc:31.667, F1:0.322\n",
            "[Epoch: 64 Batch:   106] loss: 0.937, acc: 56.503, test_acc:34.167, F1:0.344\n",
            "[Epoch: 65 Batch:   106] loss: 0.931, acc: 56.151, test_acc:32.500, F1:0.323\n",
            "[Epoch: 66 Batch:   106] loss: 0.928, acc: 57.836, test_acc:30.000, F1:0.301\n",
            "[Epoch: 67 Batch:   106] loss: 0.931, acc: 57.308, test_acc:35.833, F1:0.364\n",
            "[Epoch: 68 Batch:   106] loss: 0.919, acc: 57.560, test_acc:31.667, F1:0.317\n",
            "[Epoch: 69 Batch:   106] loss: 0.916, acc: 57.774, test_acc:30.000, F1:0.308\n",
            "[Epoch: 70 Batch:   106] loss: 0.910, acc: 57.107, test_acc:32.500, F1:0.332\n",
            "[Epoch: 71 Batch:   106] loss: 0.908, acc: 59.384, test_acc:35.000, F1:0.350\n",
            "[Epoch: 72 Batch:   106] loss: 0.907, acc: 57.421, test_acc:27.500, F1:0.277\n",
            "[Epoch: 73 Batch:   106] loss: 0.894, acc: 59.509, test_acc:26.667, F1:0.274\n",
            "[Epoch: 74 Batch:   106] loss: 0.890, acc: 58.604, test_acc:33.333, F1:0.347\n",
            "[Epoch: 75 Batch:   106] loss: 0.890, acc: 59.899, test_acc:32.500, F1:0.327\n",
            "[Epoch: 76 Batch:   106] loss: 0.889, acc: 60.075, test_acc:27.500, F1:0.287\n",
            "[Epoch: 77 Batch:   106] loss: 0.877, acc: 61.044, test_acc:33.333, F1:0.334\n",
            "[Epoch: 78 Batch:   106] loss: 0.866, acc: 61.975, test_acc:34.167, F1:0.351\n",
            "[Epoch: 79 Batch:   106] loss: 0.868, acc: 60.881, test_acc:29.167, F1:0.283\n",
            "[Epoch: 80 Batch:   106] loss: 0.871, acc: 62.906, test_acc:35.000, F1:0.357\n",
            "[Epoch: 81 Batch:   106] loss: 0.876, acc: 60.780, test_acc:29.167, F1:0.292\n",
            "[Epoch: 82 Batch:   106] loss: 0.851, acc: 62.428, test_acc:30.833, F1:0.315\n",
            "[Epoch: 83 Batch:   106] loss: 0.854, acc: 62.679, test_acc:36.667, F1:0.372\n",
            "[Epoch: 84 Batch:   106] loss: 0.843, acc: 63.585, test_acc:35.000, F1:0.359\n",
            "[Epoch: 85 Batch:   106] loss: 0.843, acc: 64.340, test_acc:32.500, F1:0.327\n",
            "[Epoch: 86 Batch:   106] loss: 0.836, acc: 63.358, test_acc:31.667, F1:0.313\n",
            "[Epoch: 87 Batch:   106] loss: 0.828, acc: 64.365, test_acc:32.500, F1:0.331\n",
            "[Epoch: 88 Batch:   106] loss: 0.822, acc: 65.572, test_acc:31.667, F1:0.323\n",
            "[Epoch: 89 Batch:   106] loss: 0.812, acc: 65.962, test_acc:33.333, F1:0.338\n",
            "[Epoch: 90 Batch:   106] loss: 0.818, acc: 65.057, test_acc:29.167, F1:0.302\n",
            "[Epoch: 91 Batch:   106] loss: 0.802, acc: 64.918, test_acc:30.833, F1:0.310\n",
            "[Epoch: 92 Batch:   106] loss: 0.802, acc: 66.403, test_acc:30.833, F1:0.313\n",
            "[Epoch: 93 Batch:   106] loss: 0.822, acc: 65.031, test_acc:30.833, F1:0.316\n",
            "[Epoch: 94 Batch:   106] loss: 0.805, acc: 65.547, test_acc:30.000, F1:0.309\n",
            "[Epoch: 95 Batch:   106] loss: 0.780, acc: 66.742, test_acc:30.833, F1:0.316\n",
            "[Epoch: 96 Batch:   106] loss: 0.794, acc: 65.748, test_acc:30.833, F1:0.321\n",
            "[Epoch: 97 Batch:   106] loss: 0.763, acc: 67.145, test_acc:34.167, F1:0.339\n",
            "[Epoch: 98 Batch:   106] loss: 0.772, acc: 66.994, test_acc:29.167, F1:0.292\n",
            "[Epoch: 99 Batch:   106] loss: 0.762, acc: 67.484, test_acc:30.000, F1:0.313\n",
            "[Epoch: 100 Batch:   106] loss: 0.771, acc: 68.176, test_acc:30.000, F1:0.308\n",
            "[Epoch: 101 Batch:   106] loss: 0.764, acc: 67.799, test_acc:31.667, F1:0.322\n",
            "[Epoch: 102 Batch:   106] loss: 0.759, acc: 67.358, test_acc:31.667, F1:0.325\n",
            "[Epoch: 103 Batch:   106] loss: 0.748, acc: 68.541, test_acc:27.500, F1:0.287\n",
            "[Epoch: 104 Batch:   106] loss: 0.752, acc: 67.774, test_acc:25.833, F1:0.267\n",
            "[Epoch: 105 Batch:   106] loss: 0.752, acc: 66.918, test_acc:30.833, F1:0.316\n",
            "[Epoch: 106 Batch:   106] loss: 0.746, acc: 67.245, test_acc:33.333, F1:0.340\n",
            "[Epoch: 107 Batch:   106] loss: 0.726, acc: 69.648, test_acc:32.500, F1:0.338\n",
            "[Epoch: 108 Batch:   106] loss: 0.728, acc: 69.711, test_acc:29.167, F1:0.291\n",
            "[Epoch: 109 Batch:   106] loss: 0.731, acc: 69.409, test_acc:32.500, F1:0.333\n",
            "[Epoch: 110 Batch:   106] loss: 0.713, acc: 70.943, test_acc:32.500, F1:0.333\n",
            "[Epoch: 111 Batch:   106] loss: 0.729, acc: 70.855, test_acc:30.000, F1:0.307\n",
            "[Epoch: 112 Batch:   106] loss: 0.710, acc: 69.925, test_acc:31.667, F1:0.319\n",
            "[Epoch: 113 Batch:   106] loss: 0.686, acc: 69.610, test_acc:33.333, F1:0.340\n",
            "[Epoch: 114 Batch:   106] loss: 0.707, acc: 71.044, test_acc:31.667, F1:0.324\n",
            "[Epoch: 115 Batch:   106] loss: 0.703, acc: 70.478, test_acc:29.167, F1:0.298\n",
            "[Epoch: 116 Batch:   106] loss: 0.689, acc: 71.585, test_acc:31.667, F1:0.326\n",
            "[Epoch: 117 Batch:   106] loss: 0.689, acc: 71.975, test_acc:32.500, F1:0.339\n",
            "[Epoch: 118 Batch:   106] loss: 0.685, acc: 70.604, test_acc:32.500, F1:0.334\n",
            "[Epoch: 119 Batch:   106] loss: 0.696, acc: 70.755, test_acc:30.000, F1:0.309\n",
            "[Epoch: 120 Batch:   106] loss: 0.690, acc: 71.270, test_acc:27.500, F1:0.282\n",
            "[Epoch: 121 Batch:   106] loss: 0.684, acc: 71.459, test_acc:32.500, F1:0.336\n",
            "[Epoch: 122 Batch:   106] loss: 0.655, acc: 72.465, test_acc:29.167, F1:0.307\n",
            "[Epoch: 123 Batch:   106] loss: 0.646, acc: 72.025, test_acc:30.000, F1:0.303\n",
            "[Epoch: 124 Batch:   106] loss: 0.643, acc: 72.553, test_acc:31.667, F1:0.328\n",
            "[Epoch: 125 Batch:   106] loss: 0.673, acc: 72.692, test_acc:32.500, F1:0.334\n",
            "[Epoch: 126 Batch:   106] loss: 0.633, acc: 74.075, test_acc:33.333, F1:0.347\n",
            "[Epoch: 127 Batch:   106] loss: 0.652, acc: 71.874, test_acc:28.333, F1:0.291\n",
            "[Epoch: 128 Batch:   106] loss: 0.641, acc: 71.635, test_acc:30.833, F1:0.317\n",
            "[Epoch: 129 Batch:   106] loss: 0.626, acc: 73.799, test_acc:31.667, F1:0.325\n",
            "[Epoch: 130 Batch:   106] loss: 0.609, acc: 74.403, test_acc:26.667, F1:0.268\n",
            "[Epoch: 131 Batch:   106] loss: 0.607, acc: 73.950, test_acc:32.500, F1:0.342\n",
            "[Epoch: 132 Batch:   106] loss: 0.622, acc: 73.509, test_acc:32.500, F1:0.330\n",
            "[Epoch: 133 Batch:   106] loss: 0.617, acc: 74.403, test_acc:33.333, F1:0.339\n",
            "[Epoch: 134 Batch:   106] loss: 0.611, acc: 73.057, test_acc:35.833, F1:0.365\n",
            "[Epoch: 135 Batch:   106] loss: 0.631, acc: 73.648, test_acc:26.667, F1:0.277\n",
            "[Epoch: 136 Batch:   106] loss: 0.606, acc: 72.226, test_acc:30.000, F1:0.309\n",
            "[Epoch: 137 Batch:   106] loss: 0.613, acc: 74.038, test_acc:29.167, F1:0.300\n",
            "[Epoch: 138 Batch:   106] loss: 0.599, acc: 74.201, test_acc:36.667, F1:0.378\n",
            "[Epoch: 139 Batch:   106] loss: 0.603, acc: 73.736, test_acc:32.500, F1:0.337\n",
            "[Epoch: 140 Batch:   106] loss: 0.610, acc: 72.956, test_acc:30.000, F1:0.308\n",
            "[Epoch: 141 Batch:   106] loss: 0.599, acc: 74.465, test_acc:30.833, F1:0.329\n",
            "[Epoch: 142 Batch:   106] loss: 0.585, acc: 73.686, test_acc:30.000, F1:0.309\n",
            "[Epoch: 143 Batch:   106] loss: 0.565, acc: 74.830, test_acc:34.167, F1:0.349\n",
            "[Epoch: 144 Batch:   106] loss: 0.576, acc: 74.252, test_acc:37.500, F1:0.379\n",
            "[Epoch: 145 Batch:   106] loss: 0.567, acc: 75.057, test_acc:29.167, F1:0.303\n",
            "[Epoch: 146 Batch:   106] loss: 0.548, acc: 74.604, test_acc:30.000, F1:0.312\n",
            "[Epoch: 147 Batch:   106] loss: 0.557, acc: 74.830, test_acc:29.167, F1:0.297\n",
            "[Epoch: 148 Batch:   106] loss: 0.561, acc: 73.811, test_acc:31.667, F1:0.323\n",
            "[Epoch: 149 Batch:   106] loss: 0.517, acc: 76.126, test_acc:32.500, F1:0.335\n",
            "[Epoch: 150 Batch:   106] loss: 0.563, acc: 74.730, test_acc:32.500, F1:0.327\n",
            "[Epoch: 151 Batch:   106] loss: 0.529, acc: 75.119, test_acc:33.333, F1:0.346\n",
            "[Epoch: 152 Batch:   106] loss: 0.553, acc: 76.440, test_acc:30.000, F1:0.316\n",
            "[Epoch: 153 Batch:   106] loss: 0.541, acc: 76.528, test_acc:32.500, F1:0.344\n",
            "[Epoch: 154 Batch:   106] loss: 0.549, acc: 75.547, test_acc:34.167, F1:0.345\n",
            "[Epoch: 155 Batch:   106] loss: 0.513, acc: 76.214, test_acc:35.833, F1:0.365\n",
            "[Epoch: 156 Batch:   106] loss: 0.533, acc: 74.755, test_acc:35.000, F1:0.350\n",
            "[Epoch: 157 Batch:   106] loss: 0.515, acc: 77.107, test_acc:30.000, F1:0.319\n",
            "[Epoch: 158 Batch:   106] loss: 0.505, acc: 76.830, test_acc:25.833, F1:0.267\n",
            "[Epoch: 159 Batch:   106] loss: 0.567, acc: 75.333, test_acc:33.333, F1:0.345\n",
            "[Epoch: 160 Batch:   106] loss: 0.502, acc: 75.333, test_acc:28.333, F1:0.297\n",
            "[Epoch: 161 Batch:   106] loss: 0.522, acc: 75.434, test_acc:30.833, F1:0.311\n",
            "[Epoch: 162 Batch:   106] loss: 0.505, acc: 74.969, test_acc:32.500, F1:0.329\n",
            "[Epoch: 163 Batch:   106] loss: 0.526, acc: 75.094, test_acc:33.333, F1:0.336\n",
            "[Epoch: 164 Batch:   106] loss: 0.544, acc: 72.943, test_acc:34.167, F1:0.351\n",
            "[Epoch: 165 Batch:   106] loss: 0.507, acc: 76.340, test_acc:36.667, F1:0.380\n",
            "[Epoch: 166 Batch:   106] loss: 0.480, acc: 76.704, test_acc:35.000, F1:0.361\n",
            "[Epoch: 167 Batch:   106] loss: 0.471, acc: 75.094, test_acc:34.167, F1:0.356\n",
            "[Epoch: 168 Batch:   106] loss: 0.489, acc: 77.145, test_acc:38.333, F1:0.393\n",
            "[Epoch: 169 Batch:   106] loss: 0.504, acc: 75.409, test_acc:32.500, F1:0.334\n",
            "[Epoch: 170 Batch:   106] loss: 0.515, acc: 75.698, test_acc:39.167, F1:0.402\n",
            "[Epoch: 171 Batch:   106] loss: 0.465, acc: 74.491, test_acc:30.000, F1:0.320\n",
            "[Epoch: 172 Batch:   106] loss: 0.469, acc: 77.094, test_acc:32.500, F1:0.324\n",
            "[Epoch: 173 Batch:   106] loss: 0.478, acc: 76.604, test_acc:30.833, F1:0.321\n",
            "[Epoch: 174 Batch:   106] loss: 0.494, acc: 75.937, test_acc:31.667, F1:0.311\n",
            "[Epoch: 175 Batch:   106] loss: 0.437, acc: 78.994, test_acc:32.500, F1:0.339\n",
            "[Epoch: 176 Batch:   106] loss: 0.453, acc: 76.742, test_acc:33.333, F1:0.343\n",
            "[Epoch: 177 Batch:   106] loss: 0.443, acc: 75.698, test_acc:28.333, F1:0.304\n",
            "[Epoch: 178 Batch:   106] loss: 0.432, acc: 77.522, test_acc:30.833, F1:0.324\n",
            "[Epoch: 179 Batch:   106] loss: 0.431, acc: 77.119, test_acc:30.833, F1:0.311\n",
            "[Epoch: 180 Batch:   106] loss: 0.503, acc: 73.887, test_acc:37.500, F1:0.381\n",
            "[Epoch: 181 Batch:   106] loss: 0.479, acc: 76.327, test_acc:35.000, F1:0.353\n",
            "[Epoch: 182 Batch:   106] loss: 0.475, acc: 74.994, test_acc:30.833, F1:0.321\n",
            "[Epoch: 183 Batch:   106] loss: 0.480, acc: 77.044, test_acc:31.667, F1:0.323\n",
            "[Epoch: 184 Batch:   106] loss: 0.448, acc: 75.786, test_acc:33.333, F1:0.338\n",
            "[Epoch: 185 Batch:   106] loss: 0.466, acc: 75.069, test_acc:31.667, F1:0.330\n",
            "[Epoch: 186 Batch:   106] loss: 0.393, acc: 78.566, test_acc:34.167, F1:0.351\n",
            "[Epoch: 187 Batch:   106] loss: 0.408, acc: 78.566, test_acc:35.833, F1:0.359\n",
            "[Epoch: 188 Batch:   106] loss: 0.389, acc: 78.642, test_acc:35.000, F1:0.361\n",
            "[Epoch: 189 Batch:   106] loss: 0.409, acc: 76.881, test_acc:31.667, F1:0.327\n",
            "[Epoch: 190 Batch:   106] loss: 0.373, acc: 78.126, test_acc:32.500, F1:0.316\n",
            "[Epoch: 191 Batch:   106] loss: 0.427, acc: 76.541, test_acc:34.167, F1:0.333\n",
            "[Epoch: 192 Batch:   106] loss: 0.437, acc: 78.893, test_acc:36.667, F1:0.379\n",
            "[Epoch: 193 Batch:   106] loss: 0.382, acc: 77.723, test_acc:33.333, F1:0.341\n",
            "[Epoch: 194 Batch:   106] loss: 0.418, acc: 76.440, test_acc:32.500, F1:0.327\n",
            "[Epoch: 195 Batch:   106] loss: 0.420, acc: 77.233, test_acc:35.000, F1:0.359\n",
            "[Epoch: 196 Batch:   106] loss: 0.403, acc: 79.522, test_acc:29.167, F1:0.298\n",
            "[Epoch: 197 Batch:   106] loss: 0.418, acc: 77.849, test_acc:31.667, F1:0.328\n",
            "[Epoch: 198 Batch:   106] loss: 0.421, acc: 76.176, test_acc:37.500, F1:0.373\n",
            "[Epoch: 199 Batch:   106] loss: 0.421, acc: 74.994, test_acc:35.000, F1:0.350\n",
            "[Epoch: 200 Batch:   106] loss: 0.398, acc: 76.755, test_acc:32.500, F1:0.335\n",
            "[Epoch: 201 Batch:   106] loss: 0.424, acc: 78.113, test_acc:39.167, F1:0.405\n",
            "[Epoch: 202 Batch:   106] loss: 0.452, acc: 76.025, test_acc:37.500, F1:0.386\n",
            "[Epoch: 203 Batch:   106] loss: 0.460, acc: 73.899, test_acc:35.000, F1:0.348\n",
            "[Epoch: 204 Batch:   106] loss: 0.461, acc: 75.258, test_acc:30.833, F1:0.313\n",
            "[Epoch: 205 Batch:   106] loss: 0.400, acc: 78.314, test_acc:29.167, F1:0.298\n",
            "[Epoch: 206 Batch:   106] loss: 0.448, acc: 78.075, test_acc:33.333, F1:0.344\n",
            "[Epoch: 207 Batch:   106] loss: 0.446, acc: 76.679, test_acc:30.833, F1:0.316\n",
            "[Epoch: 208 Batch:   106] loss: 0.399, acc: 77.270, test_acc:30.833, F1:0.314\n",
            "[Epoch: 209 Batch:   106] loss: 0.430, acc: 75.761, test_acc:27.500, F1:0.278\n",
            "[Epoch: 210 Batch:   106] loss: 0.381, acc: 77.786, test_acc:35.000, F1:0.359\n",
            "[Epoch: 211 Batch:   106] loss: 0.386, acc: 76.289, test_acc:30.000, F1:0.316\n",
            "[Epoch: 212 Batch:   106] loss: 0.376, acc: 76.704, test_acc:30.000, F1:0.314\n",
            "[Epoch: 213 Batch:   106] loss: 0.385, acc: 76.591, test_acc:31.667, F1:0.324\n",
            "[Epoch: 214 Batch:   106] loss: 0.399, acc: 75.698, test_acc:30.833, F1:0.316\n",
            "[Epoch: 215 Batch:   106] loss: 0.381, acc: 77.950, test_acc:33.333, F1:0.344\n",
            "[Epoch: 216 Batch:   106] loss: 0.405, acc: 76.931, test_acc:30.833, F1:0.324\n",
            "[Epoch: 217 Batch:   106] loss: 0.390, acc: 76.792, test_acc:33.333, F1:0.341\n",
            "[Epoch: 218 Batch:   106] loss: 0.323, acc: 77.748, test_acc:31.667, F1:0.327\n",
            "[Epoch: 219 Batch:   106] loss: 0.392, acc: 78.503, test_acc:29.167, F1:0.301\n",
            "[Epoch: 220 Batch:   106] loss: 0.383, acc: 76.692, test_acc:31.667, F1:0.327\n",
            "[Epoch: 221 Batch:   106] loss: 0.384, acc: 77.975, test_acc:40.000, F1:0.414\n",
            "[Epoch: 222 Batch:   106] loss: 0.354, acc: 76.679, test_acc:30.000, F1:0.307\n",
            "[Epoch: 223 Batch:   106] loss: 0.397, acc: 74.516, test_acc:39.167, F1:0.399\n",
            "[Epoch: 224 Batch:   106] loss: 0.434, acc: 77.069, test_acc:33.333, F1:0.339\n",
            "[Epoch: 225 Batch:   106] loss: 0.460, acc: 77.384, test_acc:23.333, F1:0.247\n",
            "[Epoch: 226 Batch:   106] loss: 0.424, acc: 76.528, test_acc:31.667, F1:0.326\n",
            "[Epoch: 227 Batch:   106] loss: 0.402, acc: 77.811, test_acc:29.167, F1:0.302\n",
            "[Epoch: 228 Batch:   106] loss: 0.329, acc: 79.258, test_acc:38.333, F1:0.394\n",
            "[Epoch: 229 Batch:   106] loss: 0.410, acc: 78.403, test_acc:42.500, F1:0.428\n",
            "[Epoch: 230 Batch:   106] loss: 0.455, acc: 75.635, test_acc:30.833, F1:0.319\n",
            "[Epoch: 231 Batch:   106] loss: 0.367, acc: 78.214, test_acc:33.333, F1:0.346\n",
            "[Epoch: 232 Batch:   106] loss: 0.380, acc: 77.119, test_acc:33.333, F1:0.343\n",
            "[Epoch: 233 Batch:   106] loss: 0.358, acc: 76.818, test_acc:31.667, F1:0.330\n",
            "[Epoch: 234 Batch:   106] loss: 0.360, acc: 78.579, test_acc:28.333, F1:0.296\n",
            "[Epoch: 235 Batch:   106] loss: 0.357, acc: 78.428, test_acc:27.500, F1:0.268\n",
            "[Epoch: 236 Batch:   106] loss: 0.373, acc: 78.767, test_acc:35.000, F1:0.359\n",
            "[Epoch: 237 Batch:   106] loss: 0.388, acc: 77.270, test_acc:35.000, F1:0.361\n",
            "[Epoch: 238 Batch:   106] loss: 0.418, acc: 77.208, test_acc:32.500, F1:0.323\n",
            "[Epoch: 239 Batch:   106] loss: 0.406, acc: 74.528, test_acc:33.333, F1:0.337\n",
            "[Epoch: 240 Batch:   106] loss: 0.349, acc: 76.918, test_acc:30.000, F1:0.309\n",
            "[Epoch: 241 Batch:   106] loss: 0.313, acc: 81.937, test_acc:27.500, F1:0.280\n",
            "[Epoch: 242 Batch:   106] loss: 0.298, acc: 78.805, test_acc:35.833, F1:0.363\n",
            "[Epoch: 243 Batch:   106] loss: 0.352, acc: 78.101, test_acc:28.333, F1:0.292\n",
            "[Epoch: 244 Batch:   106] loss: 0.349, acc: 76.604, test_acc:35.000, F1:0.360\n",
            "[Epoch: 245 Batch:   106] loss: 0.400, acc: 76.491, test_acc:30.833, F1:0.318\n",
            "[Epoch: 246 Batch:   106] loss: 0.449, acc: 77.132, test_acc:29.167, F1:0.300\n",
            "[Epoch: 247 Batch:   106] loss: 0.402, acc: 76.214, test_acc:27.500, F1:0.287\n",
            "[Epoch: 248 Batch:   106] loss: 0.494, acc: 77.019, test_acc:32.500, F1:0.333\n",
            "[Epoch: 249 Batch:   106] loss: 0.378, acc: 76.327, test_acc:33.333, F1:0.344\n",
            "[Epoch: 250 Batch:   106] loss: 0.430, acc: 77.522, test_acc:34.167, F1:0.353\n",
            "[Epoch: 251 Batch:   106] loss: 0.353, acc: 77.245, test_acc:35.833, F1:0.366\n",
            "[Epoch: 252 Batch:   106] loss: 0.351, acc: 77.786, test_acc:30.000, F1:0.304\n",
            "[Epoch: 253 Batch:   106] loss: 0.330, acc: 78.302, test_acc:36.667, F1:0.369\n",
            "[Epoch: 254 Batch:   106] loss: 0.374, acc: 76.277, test_acc:32.500, F1:0.335\n",
            "[Epoch: 255 Batch:   106] loss: 0.384, acc: 76.881, test_acc:35.000, F1:0.361\n",
            "[Epoch: 256 Batch:   106] loss: 0.445, acc: 75.547, test_acc:35.833, F1:0.366\n",
            "[Epoch: 257 Batch:   106] loss: 0.428, acc: 77.887, test_acc:29.167, F1:0.305\n",
            "[Epoch: 258 Batch:   106] loss: 0.393, acc: 76.239, test_acc:33.333, F1:0.342\n",
            "[Epoch: 259 Batch:   106] loss: 0.357, acc: 76.528, test_acc:38.333, F1:0.385\n",
            "[Epoch: 260 Batch:   106] loss: 0.371, acc: 76.767, test_acc:29.167, F1:0.283\n",
            "[Epoch: 261 Batch:   106] loss: 0.387, acc: 75.597, test_acc:33.333, F1:0.335\n",
            "[Epoch: 262 Batch:   106] loss: 0.397, acc: 76.830, test_acc:35.000, F1:0.363\n",
            "[Epoch: 263 Batch:   106] loss: 0.387, acc: 78.013, test_acc:45.000, F1:0.441\n",
            "[Epoch: 264 Batch:   106] loss: 0.421, acc: 76.981, test_acc:35.833, F1:0.359\n",
            "[Epoch: 265 Batch:   106] loss: 0.419, acc: 75.975, test_acc:37.500, F1:0.358\n",
            "[Epoch: 266 Batch:   106] loss: 0.481, acc: 77.170, test_acc:31.667, F1:0.325\n",
            "[Epoch: 267 Batch:   106] loss: 0.409, acc: 76.164, test_acc:37.500, F1:0.381\n",
            "[Epoch: 268 Batch:   106] loss: 0.407, acc: 76.453, test_acc:35.833, F1:0.366\n",
            "[Epoch: 269 Batch:   106] loss: 0.367, acc: 75.057, test_acc:32.500, F1:0.319\n",
            "[Epoch: 270 Batch:   106] loss: 0.346, acc: 77.774, test_acc:40.000, F1:0.401\n",
            "[Epoch: 271 Batch:   106] loss: 0.373, acc: 80.101, test_acc:35.000, F1:0.359\n",
            "[Epoch: 272 Batch:   106] loss: 0.414, acc: 77.006, test_acc:29.167, F1:0.303\n",
            "[Epoch: 273 Batch:   106] loss: 0.417, acc: 75.119, test_acc:36.667, F1:0.369\n",
            "[Epoch: 274 Batch:   106] loss: 0.445, acc: 77.069, test_acc:35.833, F1:0.361\n",
            "[Epoch: 275 Batch:   106] loss: 0.445, acc: 75.723, test_acc:39.167, F1:0.403\n",
            "[Epoch: 276 Batch:   106] loss: 0.425, acc: 76.755, test_acc:33.333, F1:0.339\n",
            "[Epoch: 277 Batch:   106] loss: 0.350, acc: 77.748, test_acc:39.167, F1:0.384\n",
            "[Epoch: 278 Batch:   106] loss: 0.478, acc: 72.528, test_acc:43.333, F1:0.446\n",
            "[Epoch: 279 Batch:   106] loss: 0.407, acc: 75.585, test_acc:38.333, F1:0.391\n",
            "[Epoch: 280 Batch:   106] loss: 0.481, acc: 74.264, test_acc:37.500, F1:0.372\n",
            "[Epoch: 281 Batch:   106] loss: 0.337, acc: 78.969, test_acc:35.000, F1:0.359\n",
            "[Epoch: 282 Batch:   106] loss: 0.388, acc: 77.887, test_acc:33.333, F1:0.323\n",
            "[Epoch: 283 Batch:   106] loss: 0.452, acc: 77.484, test_acc:31.667, F1:0.322\n",
            "[Epoch: 284 Batch:   106] loss: 0.409, acc: 76.805, test_acc:42.500, F1:0.428\n",
            "[Epoch: 285 Batch:   106] loss: 0.383, acc: 76.792, test_acc:35.833, F1:0.368\n",
            "[Epoch: 286 Batch:   106] loss: 0.447, acc: 74.906, test_acc:38.333, F1:0.387\n",
            "[Epoch: 287 Batch:   106] loss: 0.387, acc: 77.031, test_acc:37.500, F1:0.370\n",
            "[Epoch: 288 Batch:   106] loss: 0.380, acc: 76.126, test_acc:36.667, F1:0.374\n",
            "[Epoch: 289 Batch:   106] loss: 0.363, acc: 75.824, test_acc:30.833, F1:0.319\n",
            "[Epoch: 290 Batch:   106] loss: 0.426, acc: 77.635, test_acc:29.167, F1:0.296\n",
            "[Epoch: 291 Batch:   106] loss: 0.361, acc: 77.283, test_acc:35.833, F1:0.360\n",
            "[Epoch: 292 Batch:   106] loss: 0.313, acc: 77.673, test_acc:32.500, F1:0.326\n",
            "[Epoch: 293 Batch:   106] loss: 0.288, acc: 77.711, test_acc:34.167, F1:0.345\n",
            "[Epoch: 294 Batch:   106] loss: 0.320, acc: 77.258, test_acc:43.333, F1:0.428\n",
            "[Epoch: 295 Batch:   106] loss: 0.318, acc: 77.522, test_acc:36.667, F1:0.375\n",
            "[Epoch: 296 Batch:   106] loss: 0.359, acc: 78.000, test_acc:31.667, F1:0.313\n",
            "[Epoch: 297 Batch:   106] loss: 0.436, acc: 75.711, test_acc:38.333, F1:0.391\n",
            "[Epoch: 298 Batch:   106] loss: 0.445, acc: 77.270, test_acc:40.833, F1:0.404\n",
            "[Epoch: 299 Batch:   106] loss: 0.418, acc: 77.748, test_acc:30.833, F1:0.316\n",
            "[Epoch: 300 Batch:   106] loss: 0.501, acc: 76.365, test_acc:40.000, F1:0.407\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  40.0\n",
            "Test F1 Score : 0.4071890789342208\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.32      0.52      0.40        33\n",
            "         1.0       0.23      0.22      0.23        27\n",
            "         2.0       0.61      0.42      0.50        60\n",
            "\n",
            "    accuracy                           0.40       120\n",
            "   macro avg       0.39      0.38      0.37       120\n",
            "weighted avg       0.45      0.40      0.41       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[17  8  8]\n",
            " [13  6  8]\n",
            " [23 12 25]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.159528533617656 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  6\n",
            "[Epoch: 1 Batch:   106] loss: 1.091, acc: 35.308, test_acc:38.333, F1:0.402\n",
            "[Epoch: 2 Batch:   106] loss: 1.088, acc: 37.358, test_acc:39.167, F1:0.411\n",
            "[Epoch: 3 Batch:   106] loss: 1.086, acc: 36.415, test_acc:42.500, F1:0.454\n",
            "[Epoch: 4 Batch:   106] loss: 1.082, acc: 35.245, test_acc:42.500, F1:0.447\n",
            "[Epoch: 5 Batch:   106] loss: 1.083, acc: 36.126, test_acc:41.667, F1:0.446\n",
            "[Epoch: 6 Batch:   106] loss: 1.081, acc: 36.755, test_acc:42.500, F1:0.444\n",
            "[Epoch: 7 Batch:   106] loss: 1.080, acc: 36.340, test_acc:40.833, F1:0.428\n",
            "[Epoch: 8 Batch:   106] loss: 1.079, acc: 37.811, test_acc:35.833, F1:0.385\n",
            "[Epoch: 9 Batch:   106] loss: 1.076, acc: 36.969, test_acc:40.833, F1:0.425\n",
            "[Epoch: 10 Batch:   106] loss: 1.076, acc: 37.082, test_acc:40.000, F1:0.424\n",
            "[Epoch: 11 Batch:   106] loss: 1.074, acc: 38.491, test_acc:35.833, F1:0.384\n",
            "[Epoch: 12 Batch:   106] loss: 1.075, acc: 37.597, test_acc:34.167, F1:0.361\n",
            "[Epoch: 13 Batch:   106] loss: 1.073, acc: 38.667, test_acc:34.167, F1:0.349\n",
            "[Epoch: 14 Batch:   106] loss: 1.073, acc: 39.874, test_acc:30.833, F1:0.288\n",
            "[Epoch: 15 Batch:   106] loss: 1.070, acc: 38.340, test_acc:35.000, F1:0.360\n",
            "[Epoch: 16 Batch:   106] loss: 1.069, acc: 38.553, test_acc:33.333, F1:0.352\n",
            "[Epoch: 17 Batch:   106] loss: 1.070, acc: 39.170, test_acc:32.500, F1:0.334\n",
            "[Epoch: 18 Batch:   106] loss: 1.064, acc: 40.428, test_acc:32.500, F1:0.333\n",
            "[Epoch: 19 Batch:   106] loss: 1.065, acc: 40.000, test_acc:35.000, F1:0.357\n",
            "[Epoch: 20 Batch:   106] loss: 1.065, acc: 40.013, test_acc:35.000, F1:0.365\n",
            "[Epoch: 21 Batch:   106] loss: 1.063, acc: 40.327, test_acc:29.167, F1:0.307\n",
            "[Epoch: 22 Batch:   106] loss: 1.061, acc: 40.516, test_acc:35.833, F1:0.370\n",
            "[Epoch: 23 Batch:   106] loss: 1.060, acc: 40.994, test_acc:30.000, F1:0.306\n",
            "[Epoch: 24 Batch:   106] loss: 1.058, acc: 41.057, test_acc:34.167, F1:0.338\n",
            "[Epoch: 25 Batch:   106] loss: 1.056, acc: 42.201, test_acc:32.500, F1:0.312\n",
            "[Epoch: 26 Batch:   106] loss: 1.053, acc: 41.686, test_acc:32.500, F1:0.339\n",
            "[Epoch: 27 Batch:   106] loss: 1.051, acc: 42.277, test_acc:30.833, F1:0.307\n",
            "[Epoch: 28 Batch:   106] loss: 1.052, acc: 42.352, test_acc:35.000, F1:0.351\n",
            "[Epoch: 29 Batch:   106] loss: 1.048, acc: 43.836, test_acc:35.833, F1:0.355\n",
            "[Epoch: 30 Batch:   106] loss: 1.046, acc: 43.736, test_acc:33.333, F1:0.324\n",
            "[Epoch: 31 Batch:   106] loss: 1.049, acc: 43.409, test_acc:34.167, F1:0.334\n",
            "[Epoch: 32 Batch:   106] loss: 1.044, acc: 44.566, test_acc:32.500, F1:0.327\n",
            "[Epoch: 33 Batch:   106] loss: 1.042, acc: 43.597, test_acc:30.833, F1:0.319\n",
            "[Epoch: 34 Batch:   106] loss: 1.038, acc: 43.774, test_acc:29.167, F1:0.309\n",
            "[Epoch: 35 Batch:   106] loss: 1.039, acc: 46.063, test_acc:30.833, F1:0.310\n",
            "[Epoch: 36 Batch:   106] loss: 1.037, acc: 46.101, test_acc:29.167, F1:0.297\n",
            "[Epoch: 37 Batch:   106] loss: 1.035, acc: 46.642, test_acc:30.000, F1:0.296\n",
            "[Epoch: 38 Batch:   106] loss: 1.032, acc: 45.962, test_acc:34.167, F1:0.345\n",
            "[Epoch: 39 Batch:   106] loss: 1.030, acc: 45.623, test_acc:30.000, F1:0.303\n",
            "[Epoch: 40 Batch:   106] loss: 1.029, acc: 46.642, test_acc:35.000, F1:0.353\n",
            "[Epoch: 41 Batch:   106] loss: 1.028, acc: 46.327, test_acc:33.333, F1:0.337\n",
            "[Epoch: 42 Batch:   106] loss: 1.021, acc: 48.050, test_acc:32.500, F1:0.323\n",
            "[Epoch: 43 Batch:   106] loss: 1.020, acc: 48.164, test_acc:29.167, F1:0.298\n",
            "[Epoch: 44 Batch:   106] loss: 1.019, acc: 48.604, test_acc:30.000, F1:0.309\n",
            "[Epoch: 45 Batch:   106] loss: 1.015, acc: 49.799, test_acc:33.333, F1:0.339\n",
            "[Epoch: 46 Batch:   106] loss: 1.015, acc: 49.258, test_acc:30.833, F1:0.306\n",
            "[Epoch: 47 Batch:   106] loss: 1.010, acc: 50.277, test_acc:36.667, F1:0.379\n",
            "[Epoch: 48 Batch:   106] loss: 1.010, acc: 49.887, test_acc:26.667, F1:0.262\n",
            "[Epoch: 49 Batch:   106] loss: 1.004, acc: 51.421, test_acc:37.500, F1:0.389\n",
            "[Epoch: 50 Batch:   106] loss: 1.008, acc: 49.824, test_acc:32.500, F1:0.324\n",
            "[Epoch: 51 Batch:   106] loss: 0.994, acc: 51.145, test_acc:31.667, F1:0.322\n",
            "[Epoch: 52 Batch:   106] loss: 0.994, acc: 52.189, test_acc:34.167, F1:0.353\n",
            "[Epoch: 53 Batch:   106] loss: 0.992, acc: 52.654, test_acc:30.000, F1:0.305\n",
            "[Epoch: 54 Batch:   106] loss: 0.988, acc: 52.516, test_acc:36.667, F1:0.374\n",
            "[Epoch: 55 Batch:   106] loss: 0.986, acc: 52.629, test_acc:35.000, F1:0.357\n",
            "[Epoch: 56 Batch:   106] loss: 0.988, acc: 53.057, test_acc:35.833, F1:0.377\n",
            "[Epoch: 57 Batch:   106] loss: 0.981, acc: 53.673, test_acc:37.500, F1:0.389\n",
            "[Epoch: 58 Batch:   106] loss: 0.977, acc: 53.434, test_acc:35.833, F1:0.370\n",
            "[Epoch: 59 Batch:   106] loss: 0.975, acc: 52.881, test_acc:34.167, F1:0.352\n",
            "[Epoch: 60 Batch:   106] loss: 0.973, acc: 55.044, test_acc:36.667, F1:0.375\n",
            "[Epoch: 61 Batch:   106] loss: 0.967, acc: 54.830, test_acc:30.000, F1:0.314\n",
            "[Epoch: 62 Batch:   106] loss: 0.960, acc: 54.855, test_acc:37.500, F1:0.394\n",
            "[Epoch: 63 Batch:   106] loss: 0.963, acc: 53.711, test_acc:32.500, F1:0.335\n",
            "[Epoch: 64 Batch:   106] loss: 0.959, acc: 55.371, test_acc:38.333, F1:0.399\n",
            "[Epoch: 65 Batch:   106] loss: 0.957, acc: 55.044, test_acc:35.833, F1:0.371\n",
            "[Epoch: 66 Batch:   106] loss: 0.952, acc: 55.308, test_acc:38.333, F1:0.397\n",
            "[Epoch: 67 Batch:   106] loss: 0.946, acc: 55.836, test_acc:33.333, F1:0.347\n",
            "[Epoch: 68 Batch:   106] loss: 0.937, acc: 56.453, test_acc:34.167, F1:0.360\n",
            "[Epoch: 69 Batch:   106] loss: 0.943, acc: 57.472, test_acc:33.333, F1:0.347\n",
            "[Epoch: 70 Batch:   106] loss: 0.939, acc: 57.761, test_acc:41.667, F1:0.430\n",
            "[Epoch: 71 Batch:   106] loss: 0.944, acc: 56.969, test_acc:37.500, F1:0.390\n",
            "[Epoch: 72 Batch:   106] loss: 0.933, acc: 57.044, test_acc:32.500, F1:0.337\n",
            "[Epoch: 73 Batch:   106] loss: 0.923, acc: 57.937, test_acc:36.667, F1:0.378\n",
            "[Epoch: 74 Batch:   106] loss: 0.929, acc: 56.918, test_acc:41.667, F1:0.427\n",
            "[Epoch: 75 Batch:   106] loss: 0.926, acc: 57.862, test_acc:35.833, F1:0.379\n",
            "[Epoch: 76 Batch:   106] loss: 0.908, acc: 59.610, test_acc:38.333, F1:0.398\n",
            "[Epoch: 77 Batch:   106] loss: 0.913, acc: 58.164, test_acc:33.333, F1:0.353\n",
            "[Epoch: 78 Batch:   106] loss: 0.902, acc: 59.849, test_acc:36.667, F1:0.382\n",
            "[Epoch: 79 Batch:   106] loss: 0.896, acc: 59.774, test_acc:38.333, F1:0.387\n",
            "[Epoch: 80 Batch:   106] loss: 0.907, acc: 60.302, test_acc:35.833, F1:0.379\n",
            "[Epoch: 81 Batch:   106] loss: 0.900, acc: 59.434, test_acc:32.500, F1:0.333\n",
            "[Epoch: 82 Batch:   106] loss: 0.888, acc: 60.528, test_acc:34.167, F1:0.366\n",
            "[Epoch: 83 Batch:   106] loss: 0.893, acc: 61.233, test_acc:34.167, F1:0.355\n",
            "[Epoch: 84 Batch:   106] loss: 0.885, acc: 62.126, test_acc:39.167, F1:0.403\n",
            "[Epoch: 85 Batch:   106] loss: 0.883, acc: 62.189, test_acc:36.667, F1:0.383\n",
            "[Epoch: 86 Batch:   106] loss: 0.875, acc: 62.226, test_acc:38.333, F1:0.401\n",
            "[Epoch: 87 Batch:   106] loss: 0.873, acc: 63.786, test_acc:40.000, F1:0.416\n",
            "[Epoch: 88 Batch:   106] loss: 0.869, acc: 63.321, test_acc:39.167, F1:0.408\n",
            "[Epoch: 89 Batch:   106] loss: 0.861, acc: 62.981, test_acc:35.000, F1:0.366\n",
            "[Epoch: 90 Batch:   106] loss: 0.852, acc: 63.824, test_acc:36.667, F1:0.381\n",
            "[Epoch: 91 Batch:   106] loss: 0.865, acc: 62.239, test_acc:35.833, F1:0.372\n",
            "[Epoch: 92 Batch:   106] loss: 0.860, acc: 64.113, test_acc:38.333, F1:0.402\n",
            "[Epoch: 93 Batch:   106] loss: 0.834, acc: 64.289, test_acc:38.333, F1:0.396\n",
            "[Epoch: 94 Batch:   106] loss: 0.836, acc: 63.560, test_acc:36.667, F1:0.374\n",
            "[Epoch: 95 Batch:   106] loss: 0.831, acc: 65.421, test_acc:41.667, F1:0.435\n",
            "[Epoch: 96 Batch:   106] loss: 0.827, acc: 64.805, test_acc:38.333, F1:0.403\n",
            "[Epoch: 97 Batch:   106] loss: 0.835, acc: 65.321, test_acc:43.333, F1:0.452\n",
            "[Epoch: 98 Batch:   106] loss: 0.819, acc: 65.346, test_acc:41.667, F1:0.436\n",
            "[Epoch: 99 Batch:   106] loss: 0.819, acc: 65.333, test_acc:40.833, F1:0.419\n",
            "[Epoch: 100 Batch:   106] loss: 0.819, acc: 66.151, test_acc:36.667, F1:0.383\n",
            "[Epoch: 101 Batch:   106] loss: 0.807, acc: 66.667, test_acc:37.500, F1:0.386\n",
            "[Epoch: 102 Batch:   106] loss: 0.805, acc: 66.277, test_acc:43.333, F1:0.445\n",
            "[Epoch: 103 Batch:   106] loss: 0.803, acc: 66.717, test_acc:36.667, F1:0.387\n",
            "[Epoch: 104 Batch:   106] loss: 0.795, acc: 67.409, test_acc:39.167, F1:0.406\n",
            "[Epoch: 105 Batch:   106] loss: 0.800, acc: 67.082, test_acc:43.333, F1:0.451\n",
            "[Epoch: 106 Batch:   106] loss: 0.790, acc: 66.981, test_acc:40.000, F1:0.416\n",
            "[Epoch: 107 Batch:   106] loss: 0.794, acc: 67.321, test_acc:42.500, F1:0.445\n",
            "[Epoch: 108 Batch:   106] loss: 0.789, acc: 68.025, test_acc:44.167, F1:0.455\n",
            "[Epoch: 109 Batch:   106] loss: 0.774, acc: 68.440, test_acc:40.000, F1:0.410\n",
            "[Epoch: 110 Batch:   106] loss: 0.781, acc: 67.396, test_acc:45.833, F1:0.467\n",
            "[Epoch: 111 Batch:   106] loss: 0.778, acc: 69.333, test_acc:41.667, F1:0.437\n",
            "[Epoch: 112 Batch:   106] loss: 0.762, acc: 68.981, test_acc:40.000, F1:0.415\n",
            "[Epoch: 113 Batch:   106] loss: 0.756, acc: 69.585, test_acc:36.667, F1:0.386\n",
            "[Epoch: 114 Batch:   106] loss: 0.751, acc: 70.403, test_acc:35.833, F1:0.370\n",
            "[Epoch: 115 Batch:   106] loss: 0.752, acc: 69.057, test_acc:39.167, F1:0.415\n",
            "[Epoch: 116 Batch:   106] loss: 0.737, acc: 71.484, test_acc:35.833, F1:0.376\n",
            "[Epoch: 117 Batch:   106] loss: 0.751, acc: 69.673, test_acc:34.167, F1:0.348\n",
            "[Epoch: 118 Batch:   106] loss: 0.728, acc: 70.453, test_acc:42.500, F1:0.439\n",
            "[Epoch: 119 Batch:   106] loss: 0.736, acc: 70.164, test_acc:38.333, F1:0.397\n",
            "[Epoch: 120 Batch:   106] loss: 0.739, acc: 70.566, test_acc:34.167, F1:0.357\n",
            "[Epoch: 121 Batch:   106] loss: 0.728, acc: 71.044, test_acc:40.000, F1:0.414\n",
            "[Epoch: 122 Batch:   106] loss: 0.724, acc: 72.101, test_acc:39.167, F1:0.411\n",
            "[Epoch: 123 Batch:   106] loss: 0.711, acc: 72.126, test_acc:35.000, F1:0.363\n",
            "[Epoch: 124 Batch:   106] loss: 0.715, acc: 72.138, test_acc:33.333, F1:0.352\n",
            "[Epoch: 125 Batch:   106] loss: 0.709, acc: 71.107, test_acc:39.167, F1:0.411\n",
            "[Epoch: 126 Batch:   106] loss: 0.700, acc: 70.151, test_acc:38.333, F1:0.401\n",
            "[Epoch: 127 Batch:   106] loss: 0.704, acc: 72.088, test_acc:33.333, F1:0.346\n",
            "[Epoch: 128 Batch:   106] loss: 0.682, acc: 72.616, test_acc:39.167, F1:0.407\n",
            "[Epoch: 129 Batch:   106] loss: 0.707, acc: 71.686, test_acc:34.167, F1:0.362\n",
            "[Epoch: 130 Batch:   106] loss: 0.699, acc: 72.453, test_acc:37.500, F1:0.373\n",
            "[Epoch: 131 Batch:   106] loss: 0.682, acc: 73.182, test_acc:35.000, F1:0.366\n",
            "[Epoch: 132 Batch:   106] loss: 0.688, acc: 73.421, test_acc:38.333, F1:0.407\n",
            "[Epoch: 133 Batch:   106] loss: 0.677, acc: 73.811, test_acc:35.833, F1:0.378\n",
            "[Epoch: 134 Batch:   106] loss: 0.674, acc: 72.755, test_acc:37.500, F1:0.386\n",
            "[Epoch: 135 Batch:   106] loss: 0.674, acc: 75.119, test_acc:40.000, F1:0.419\n",
            "[Epoch: 136 Batch:   106] loss: 0.653, acc: 75.006, test_acc:37.500, F1:0.384\n",
            "[Epoch: 137 Batch:   106] loss: 0.671, acc: 73.509, test_acc:43.333, F1:0.446\n",
            "[Epoch: 138 Batch:   106] loss: 0.665, acc: 73.748, test_acc:43.333, F1:0.444\n",
            "[Epoch: 139 Batch:   106] loss: 0.662, acc: 75.082, test_acc:39.167, F1:0.403\n",
            "[Epoch: 140 Batch:   106] loss: 0.669, acc: 72.767, test_acc:39.167, F1:0.409\n",
            "[Epoch: 141 Batch:   106] loss: 0.644, acc: 74.717, test_acc:36.667, F1:0.383\n",
            "[Epoch: 142 Batch:   106] loss: 0.655, acc: 73.296, test_acc:36.667, F1:0.380\n",
            "[Epoch: 143 Batch:   106] loss: 0.663, acc: 72.881, test_acc:30.833, F1:0.313\n",
            "[Epoch: 144 Batch:   106] loss: 0.648, acc: 74.667, test_acc:40.000, F1:0.409\n",
            "[Epoch: 145 Batch:   106] loss: 0.646, acc: 73.836, test_acc:39.167, F1:0.390\n",
            "[Epoch: 146 Batch:   106] loss: 0.656, acc: 73.912, test_acc:40.000, F1:0.412\n",
            "[Epoch: 147 Batch:   106] loss: 0.635, acc: 75.270, test_acc:39.167, F1:0.399\n",
            "[Epoch: 148 Batch:   106] loss: 0.627, acc: 75.182, test_acc:38.333, F1:0.393\n",
            "[Epoch: 149 Batch:   106] loss: 0.626, acc: 76.906, test_acc:35.833, F1:0.373\n",
            "[Epoch: 150 Batch:   106] loss: 0.637, acc: 74.792, test_acc:32.500, F1:0.341\n",
            "[Epoch: 151 Batch:   106] loss: 0.626, acc: 76.365, test_acc:40.833, F1:0.422\n",
            "[Epoch: 152 Batch:   106] loss: 0.629, acc: 73.987, test_acc:41.667, F1:0.432\n",
            "[Epoch: 153 Batch:   106] loss: 0.640, acc: 76.541, test_acc:40.000, F1:0.417\n",
            "[Epoch: 154 Batch:   106] loss: 0.628, acc: 75.170, test_acc:40.833, F1:0.424\n",
            "[Epoch: 155 Batch:   106] loss: 0.628, acc: 76.465, test_acc:39.167, F1:0.413\n",
            "[Epoch: 156 Batch:   106] loss: 0.665, acc: 73.396, test_acc:37.500, F1:0.388\n",
            "[Epoch: 157 Batch:   106] loss: 0.599, acc: 76.126, test_acc:31.667, F1:0.325\n",
            "[Epoch: 158 Batch:   106] loss: 0.625, acc: 76.566, test_acc:37.500, F1:0.386\n",
            "[Epoch: 159 Batch:   106] loss: 0.603, acc: 77.119, test_acc:32.500, F1:0.347\n",
            "[Epoch: 160 Batch:   106] loss: 0.601, acc: 75.346, test_acc:35.000, F1:0.361\n",
            "[Epoch: 161 Batch:   106] loss: 0.586, acc: 76.516, test_acc:37.500, F1:0.394\n",
            "[Epoch: 162 Batch:   106] loss: 0.589, acc: 76.918, test_acc:41.667, F1:0.431\n",
            "[Epoch: 163 Batch:   106] loss: 0.584, acc: 76.956, test_acc:39.167, F1:0.412\n",
            "[Epoch: 164 Batch:   106] loss: 0.604, acc: 76.415, test_acc:36.667, F1:0.380\n",
            "[Epoch: 165 Batch:   106] loss: 0.565, acc: 76.818, test_acc:35.833, F1:0.377\n",
            "[Epoch: 166 Batch:   106] loss: 0.580, acc: 76.478, test_acc:36.667, F1:0.384\n",
            "[Epoch: 167 Batch:   106] loss: 0.596, acc: 75.849, test_acc:32.500, F1:0.334\n",
            "[Epoch: 168 Batch:   106] loss: 0.599, acc: 76.289, test_acc:35.833, F1:0.366\n",
            "[Epoch: 169 Batch:   106] loss: 0.578, acc: 76.503, test_acc:37.500, F1:0.390\n",
            "[Epoch: 170 Batch:   106] loss: 0.593, acc: 77.132, test_acc:44.167, F1:0.456\n",
            "[Epoch: 171 Batch:   106] loss: 0.567, acc: 76.465, test_acc:36.667, F1:0.381\n",
            "[Epoch: 172 Batch:   106] loss: 0.547, acc: 78.000, test_acc:37.500, F1:0.384\n",
            "[Epoch: 173 Batch:   106] loss: 0.536, acc: 78.164, test_acc:42.500, F1:0.441\n",
            "[Epoch: 174 Batch:   106] loss: 0.551, acc: 78.365, test_acc:34.167, F1:0.358\n",
            "[Epoch: 175 Batch:   106] loss: 0.566, acc: 78.943, test_acc:38.333, F1:0.398\n",
            "[Epoch: 176 Batch:   106] loss: 0.567, acc: 77.019, test_acc:37.500, F1:0.387\n",
            "[Epoch: 177 Batch:   106] loss: 0.559, acc: 77.547, test_acc:35.000, F1:0.361\n",
            "[Epoch: 178 Batch:   106] loss: 0.547, acc: 77.824, test_acc:38.333, F1:0.387\n",
            "[Epoch: 179 Batch:   106] loss: 0.559, acc: 77.270, test_acc:38.333, F1:0.400\n",
            "[Epoch: 180 Batch:   106] loss: 0.533, acc: 76.654, test_acc:37.500, F1:0.388\n",
            "[Epoch: 181 Batch:   106] loss: 0.559, acc: 77.119, test_acc:39.167, F1:0.403\n",
            "[Epoch: 182 Batch:   106] loss: 0.540, acc: 77.597, test_acc:37.500, F1:0.379\n",
            "[Epoch: 183 Batch:   106] loss: 0.550, acc: 76.943, test_acc:39.167, F1:0.401\n",
            "[Epoch: 184 Batch:   106] loss: 0.542, acc: 77.786, test_acc:34.167, F1:0.357\n",
            "[Epoch: 185 Batch:   106] loss: 0.551, acc: 78.553, test_acc:30.000, F1:0.304\n",
            "[Epoch: 186 Batch:   106] loss: 0.547, acc: 76.855, test_acc:39.167, F1:0.401\n",
            "[Epoch: 187 Batch:   106] loss: 0.541, acc: 78.126, test_acc:37.500, F1:0.381\n",
            "[Epoch: 188 Batch:   106] loss: 0.560, acc: 78.138, test_acc:35.000, F1:0.354\n",
            "[Epoch: 189 Batch:   106] loss: 0.538, acc: 76.277, test_acc:38.333, F1:0.397\n",
            "[Epoch: 190 Batch:   106] loss: 0.540, acc: 76.843, test_acc:37.500, F1:0.384\n",
            "[Epoch: 191 Batch:   106] loss: 0.526, acc: 79.975, test_acc:35.000, F1:0.358\n",
            "[Epoch: 192 Batch:   106] loss: 0.515, acc: 78.994, test_acc:34.167, F1:0.355\n",
            "[Epoch: 193 Batch:   106] loss: 0.524, acc: 77.874, test_acc:35.833, F1:0.372\n",
            "[Epoch: 194 Batch:   106] loss: 0.515, acc: 78.604, test_acc:39.167, F1:0.404\n",
            "[Epoch: 195 Batch:   106] loss: 0.528, acc: 77.522, test_acc:37.500, F1:0.384\n",
            "[Epoch: 196 Batch:   106] loss: 0.498, acc: 78.113, test_acc:38.333, F1:0.404\n",
            "[Epoch: 197 Batch:   106] loss: 0.494, acc: 78.478, test_acc:35.833, F1:0.376\n",
            "[Epoch: 198 Batch:   106] loss: 0.496, acc: 78.868, test_acc:35.000, F1:0.362\n",
            "[Epoch: 199 Batch:   106] loss: 0.505, acc: 76.994, test_acc:34.167, F1:0.359\n",
            "[Epoch: 200 Batch:   106] loss: 0.518, acc: 79.094, test_acc:40.833, F1:0.418\n",
            "[Epoch: 201 Batch:   106] loss: 0.496, acc: 78.327, test_acc:35.000, F1:0.368\n",
            "[Epoch: 202 Batch:   106] loss: 0.479, acc: 80.126, test_acc:34.167, F1:0.353\n",
            "[Epoch: 203 Batch:   106] loss: 0.482, acc: 81.157, test_acc:36.667, F1:0.378\n",
            "[Epoch: 204 Batch:   106] loss: 0.521, acc: 76.918, test_acc:40.833, F1:0.422\n",
            "[Epoch: 205 Batch:   106] loss: 0.512, acc: 79.170, test_acc:40.833, F1:0.420\n",
            "[Epoch: 206 Batch:   106] loss: 0.516, acc: 78.579, test_acc:33.333, F1:0.352\n",
            "[Epoch: 207 Batch:   106] loss: 0.491, acc: 78.000, test_acc:34.167, F1:0.352\n",
            "[Epoch: 208 Batch:   106] loss: 0.461, acc: 78.579, test_acc:37.500, F1:0.390\n",
            "[Epoch: 209 Batch:   106] loss: 0.477, acc: 78.931, test_acc:40.833, F1:0.419\n",
            "[Epoch: 210 Batch:   106] loss: 0.493, acc: 78.101, test_acc:36.667, F1:0.378\n",
            "[Epoch: 211 Batch:   106] loss: 0.512, acc: 77.912, test_acc:40.000, F1:0.417\n",
            "[Epoch: 212 Batch:   106] loss: 0.555, acc: 77.799, test_acc:36.667, F1:0.378\n",
            "[Epoch: 213 Batch:   106] loss: 0.509, acc: 79.006, test_acc:44.167, F1:0.461\n",
            "[Epoch: 214 Batch:   106] loss: 0.491, acc: 76.767, test_acc:40.000, F1:0.415\n",
            "[Epoch: 215 Batch:   106] loss: 0.468, acc: 80.138, test_acc:39.167, F1:0.414\n",
            "[Epoch: 216 Batch:   106] loss: 0.467, acc: 78.969, test_acc:37.500, F1:0.394\n",
            "[Epoch: 217 Batch:   106] loss: 0.471, acc: 79.346, test_acc:38.333, F1:0.394\n",
            "[Epoch: 218 Batch:   106] loss: 0.502, acc: 79.333, test_acc:37.500, F1:0.391\n",
            "[Epoch: 219 Batch:   106] loss: 0.470, acc: 80.289, test_acc:36.667, F1:0.376\n",
            "[Epoch: 220 Batch:   106] loss: 0.453, acc: 79.031, test_acc:38.333, F1:0.397\n",
            "[Epoch: 221 Batch:   106] loss: 0.444, acc: 77.799, test_acc:37.500, F1:0.391\n",
            "[Epoch: 222 Batch:   106] loss: 0.437, acc: 79.057, test_acc:39.167, F1:0.398\n",
            "[Epoch: 223 Batch:   106] loss: 0.490, acc: 79.031, test_acc:40.833, F1:0.426\n",
            "[Epoch: 224 Batch:   106] loss: 0.458, acc: 79.258, test_acc:37.500, F1:0.389\n",
            "[Epoch: 225 Batch:   106] loss: 0.465, acc: 78.541, test_acc:35.833, F1:0.377\n",
            "[Epoch: 226 Batch:   106] loss: 0.451, acc: 77.962, test_acc:37.500, F1:0.386\n",
            "[Epoch: 227 Batch:   106] loss: 0.451, acc: 78.654, test_acc:33.333, F1:0.348\n",
            "[Epoch: 228 Batch:   106] loss: 0.446, acc: 80.302, test_acc:31.667, F1:0.325\n",
            "[Epoch: 229 Batch:   106] loss: 0.459, acc: 80.453, test_acc:36.667, F1:0.389\n",
            "[Epoch: 230 Batch:   106] loss: 0.470, acc: 79.358, test_acc:38.333, F1:0.396\n",
            "[Epoch: 231 Batch:   106] loss: 0.453, acc: 79.132, test_acc:36.667, F1:0.380\n",
            "[Epoch: 232 Batch:   106] loss: 0.431, acc: 78.616, test_acc:38.333, F1:0.398\n",
            "[Epoch: 233 Batch:   106] loss: 0.455, acc: 79.962, test_acc:43.333, F1:0.413\n",
            "[Epoch: 234 Batch:   106] loss: 0.430, acc: 78.742, test_acc:34.167, F1:0.356\n",
            "[Epoch: 235 Batch:   106] loss: 0.434, acc: 80.314, test_acc:30.833, F1:0.328\n",
            "[Epoch: 236 Batch:   106] loss: 0.453, acc: 78.893, test_acc:37.500, F1:0.395\n",
            "[Epoch: 237 Batch:   106] loss: 0.454, acc: 78.931, test_acc:35.833, F1:0.365\n",
            "[Epoch: 238 Batch:   106] loss: 0.415, acc: 81.736, test_acc:40.000, F1:0.409\n",
            "[Epoch: 239 Batch:   106] loss: 0.455, acc: 79.145, test_acc:38.333, F1:0.396\n",
            "[Epoch: 240 Batch:   106] loss: 0.430, acc: 79.761, test_acc:35.833, F1:0.372\n",
            "[Epoch: 241 Batch:   106] loss: 0.439, acc: 78.088, test_acc:30.000, F1:0.310\n",
            "[Epoch: 242 Batch:   106] loss: 0.430, acc: 81.371, test_acc:37.500, F1:0.390\n",
            "[Epoch: 243 Batch:   106] loss: 0.415, acc: 80.566, test_acc:40.833, F1:0.413\n",
            "[Epoch: 244 Batch:   106] loss: 0.422, acc: 79.119, test_acc:35.000, F1:0.368\n",
            "[Epoch: 245 Batch:   106] loss: 0.422, acc: 79.094, test_acc:35.000, F1:0.361\n",
            "[Epoch: 246 Batch:   106] loss: 0.426, acc: 78.201, test_acc:39.167, F1:0.399\n",
            "[Epoch: 247 Batch:   106] loss: 0.423, acc: 81.623, test_acc:35.000, F1:0.359\n",
            "[Epoch: 248 Batch:   106] loss: 0.426, acc: 79.057, test_acc:35.000, F1:0.354\n",
            "[Epoch: 249 Batch:   106] loss: 0.419, acc: 80.264, test_acc:39.167, F1:0.407\n",
            "[Epoch: 250 Batch:   106] loss: 0.437, acc: 79.107, test_acc:33.333, F1:0.349\n",
            "[Epoch: 251 Batch:   106] loss: 0.424, acc: 78.667, test_acc:37.500, F1:0.384\n",
            "[Epoch: 252 Batch:   106] loss: 0.392, acc: 80.742, test_acc:34.167, F1:0.353\n",
            "[Epoch: 253 Batch:   106] loss: 0.427, acc: 78.881, test_acc:34.167, F1:0.363\n",
            "[Epoch: 254 Batch:   106] loss: 0.390, acc: 81.748, test_acc:38.333, F1:0.392\n",
            "[Epoch: 255 Batch:   106] loss: 0.455, acc: 77.434, test_acc:29.167, F1:0.301\n",
            "[Epoch: 256 Batch:   106] loss: 0.381, acc: 81.597, test_acc:35.833, F1:0.364\n",
            "[Epoch: 257 Batch:   106] loss: 0.452, acc: 78.327, test_acc:38.333, F1:0.394\n",
            "[Epoch: 258 Batch:   106] loss: 0.411, acc: 80.264, test_acc:40.000, F1:0.413\n",
            "[Epoch: 259 Batch:   106] loss: 0.431, acc: 79.220, test_acc:36.667, F1:0.376\n",
            "[Epoch: 260 Batch:   106] loss: 0.443, acc: 80.189, test_acc:35.000, F1:0.368\n",
            "[Epoch: 261 Batch:   106] loss: 0.464, acc: 80.151, test_acc:35.833, F1:0.379\n",
            "[Epoch: 262 Batch:   106] loss: 0.423, acc: 78.050, test_acc:36.667, F1:0.375\n",
            "[Epoch: 263 Batch:   106] loss: 0.457, acc: 79.799, test_acc:32.500, F1:0.328\n",
            "[Epoch: 264 Batch:   106] loss: 0.446, acc: 79.409, test_acc:39.167, F1:0.400\n",
            "[Epoch: 265 Batch:   106] loss: 0.454, acc: 77.484, test_acc:39.167, F1:0.405\n",
            "[Epoch: 266 Batch:   106] loss: 0.423, acc: 80.340, test_acc:35.833, F1:0.369\n",
            "[Epoch: 267 Batch:   106] loss: 0.484, acc: 79.119, test_acc:39.167, F1:0.404\n",
            "[Epoch: 268 Batch:   106] loss: 0.467, acc: 77.384, test_acc:36.667, F1:0.383\n",
            "[Epoch: 269 Batch:   106] loss: 0.401, acc: 79.233, test_acc:39.167, F1:0.405\n",
            "[Epoch: 270 Batch:   106] loss: 0.388, acc: 80.704, test_acc:35.833, F1:0.379\n",
            "[Epoch: 271 Batch:   106] loss: 0.429, acc: 80.239, test_acc:35.833, F1:0.368\n",
            "[Epoch: 272 Batch:   106] loss: 0.435, acc: 79.333, test_acc:36.667, F1:0.380\n",
            "[Epoch: 273 Batch:   106] loss: 0.448, acc: 81.660, test_acc:35.833, F1:0.370\n",
            "[Epoch: 274 Batch:   106] loss: 0.409, acc: 80.453, test_acc:32.500, F1:0.342\n",
            "[Epoch: 275 Batch:   106] loss: 0.427, acc: 78.553, test_acc:37.500, F1:0.389\n",
            "[Epoch: 276 Batch:   106] loss: 0.392, acc: 82.679, test_acc:36.667, F1:0.379\n",
            "[Epoch: 277 Batch:   106] loss: 0.470, acc: 79.182, test_acc:35.833, F1:0.379\n",
            "[Epoch: 278 Batch:   106] loss: 0.447, acc: 79.547, test_acc:33.333, F1:0.335\n",
            "[Epoch: 279 Batch:   106] loss: 0.476, acc: 78.704, test_acc:35.833, F1:0.371\n",
            "[Epoch: 280 Batch:   106] loss: 0.463, acc: 78.327, test_acc:36.667, F1:0.386\n",
            "[Epoch: 281 Batch:   106] loss: 0.412, acc: 80.591, test_acc:38.333, F1:0.387\n",
            "[Epoch: 282 Batch:   106] loss: 0.420, acc: 79.308, test_acc:34.167, F1:0.363\n",
            "[Epoch: 283 Batch:   106] loss: 0.421, acc: 80.314, test_acc:36.667, F1:0.379\n",
            "[Epoch: 284 Batch:   106] loss: 0.403, acc: 81.560, test_acc:37.500, F1:0.381\n",
            "[Epoch: 285 Batch:   106] loss: 0.451, acc: 80.579, test_acc:38.333, F1:0.394\n",
            "[Epoch: 286 Batch:   106] loss: 0.455, acc: 80.352, test_acc:32.500, F1:0.340\n",
            "[Epoch: 287 Batch:   106] loss: 0.413, acc: 79.912, test_acc:30.833, F1:0.319\n",
            "[Epoch: 288 Batch:   106] loss: 0.413, acc: 80.075, test_acc:35.833, F1:0.372\n",
            "[Epoch: 289 Batch:   106] loss: 0.369, acc: 79.522, test_acc:38.333, F1:0.394\n",
            "[Epoch: 290 Batch:   106] loss: 0.426, acc: 78.805, test_acc:32.500, F1:0.332\n",
            "[Epoch: 291 Batch:   106] loss: 0.454, acc: 78.591, test_acc:37.500, F1:0.385\n",
            "[Epoch: 292 Batch:   106] loss: 0.502, acc: 76.994, test_acc:44.167, F1:0.405\n",
            "[Epoch: 293 Batch:   106] loss: 0.441, acc: 78.453, test_acc:30.833, F1:0.317\n",
            "[Epoch: 294 Batch:   106] loss: 0.396, acc: 77.346, test_acc:35.000, F1:0.359\n",
            "[Epoch: 295 Batch:   106] loss: 0.493, acc: 76.428, test_acc:32.500, F1:0.329\n",
            "[Epoch: 296 Batch:   106] loss: 0.429, acc: 78.805, test_acc:33.333, F1:0.343\n",
            "[Epoch: 297 Batch:   106] loss: 0.520, acc: 76.881, test_acc:35.833, F1:0.364\n",
            "[Epoch: 298 Batch:   106] loss: 0.438, acc: 78.352, test_acc:33.333, F1:0.345\n",
            "[Epoch: 299 Batch:   106] loss: 0.465, acc: 77.006, test_acc:39.167, F1:0.400\n",
            "[Epoch: 300 Batch:   106] loss: 0.374, acc: 80.415, test_acc:27.500, F1:0.287\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  27.500000000000004\n",
            "Test F1 Score : 0.2868429324435418\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.53      0.26        15\n",
            "         1.0       0.15      0.15      0.15        33\n",
            "         2.0       0.49      0.28      0.35        72\n",
            "\n",
            "    accuracy                           0.28       120\n",
            "   macro avg       0.27      0.32      0.26       120\n",
            "weighted avg       0.36      0.28      0.29       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[ 8  4  3]\n",
            " [10  5 18]\n",
            " [28 24 20]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAADbCAYAAAAGVmpVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU9dXH8c/ZpUkXqVKkCCpGIbgiINiDYMOuWBML0aioj+WBaIxBjSXqEwt2scWoRE2CKLEgxq4sCggouIIoKNIRUYr4e/449zqzyw4ssLNT9vt+vfY1M/fenTmXQQ+/dn4WQkBEREQ2VJDpAERERLKVkqSIiEgKSpIiIiIpKEmKiIikoCQpIiKSgpKkiIhICjUyHcDmatq0aWjfvn2mwxARkTwxadKkxSGEZuWdy7kk2b59e4qLizMdhoiI5Akzm5vqXNq6W81slJktNLNpKc7vbGbvmNkaM7s0XXGIiIhsqXSOST4MDNjI+aXAUODmNMYgIiKyxdKWJEMIr+OJMNX5hSGEicC6dMUgIiKyNTS7VUREJIWcSJJmNsTMis2seNGiRZXzpgsXVs77iIhI3sqJJBlCuC+EUBRCKGrWrNxZuptn7lzo2BHOPBO++mrr309ERPJSTiTJStekCfzud/Doo9CuHZxwAkyeDJ9+Cj/9lOnoREQkS1i69pM0syeA/YCmwDfAH4GaACGEe8ysJVAMNAR+Ar4DuoYQvt3Y+xYVFYVKWyf52Wdwzz1w992wapUfa9sWiopgxx3hkENg333BrHI+T0REso6ZTQohFJV7Ltc2Xa7UJBn7+msYNw5+/BHGjoXZs71VuXatd8u2agUHHQS9esH69bDPPtCgQeXGICIiGaEkuSVWrYJnn4XRo2HJEnjnndLn69aF/v3hmGNg++1hm208iarVKSKSU5QkK8Onn8KCBbBuHbz9trc+R4+GxYsT11x3HZx+Onz+uY977rJL1ccpIiKbRUkyXdatg1mzYNEiuP9++PvfS58/4AA46ihPlj17qotWRCQLbSxJ5lyB86xSsybsuqs/33tv6NfPu1t32AGmTPHEecEFfr5+fTjlFDj3XNh998zFLCIiFaaWZDqF4GsyZ83yVuZTT8Hq1dC7N1xyiS836dwZunfPdKQiItWWuluzxdKl8MgjcOedPoMWoLAQhg2D3XaD556Ds8/2ZSciIlIllCSzzY8/wn/+A40awR13wD/+4ccLCqBGDRg+HI47LtGVKyIiaaMkme2++spbll26wGmnwYsverK89FJYvtzXaB55pLc6RUSkUilJ5ppvvoEzzoAXXoDatWHNGmjRAk46CS6+2KsCiYhIpdhYkqyetVuzXYsWPj755Zfw3Xde1KBvX7j9dujUyddi3nOPd9muWJHpaEVE8pZakrlk7ly45RYYNSpRa7ZzZyguhoYNMxubiEiOUksyX+ywg7cmv/0W5s3zJSWzZ8MRR8ANN8D48T4pSEREKoWKCeSiggJo3RqOP96r/QwfDv/9r5/r3t3XYO61l7cyRURki6WtJWlmo8xsoZlNS3HezOx2Mysxs6lm1iNdseS1887zluWyZfD44z7p59RTffnIAw/Au+/6ziUiIrLZ0tnd+jAwYCPnBwKdo58hwN1pjCX/NW7ss1/nzIGpU31HkrPP9uo+J5/srcvzz890lCIiOSVt3a0hhNfNrP1GLhkEPBp85tC7ZtbYzFqFEL5OV0zVQu3aXr3npZdgwgR48034858T5887T7uTiIhUUCYn7rQGvkx6PS86JpWhTh0YOBCuvdbL4D30kBdkv/feTEcmIpIzcmLijpkNwbtkadeuXYajyTFm3noEX1f5wAM+M3a//bx7tkmTjIYnIpLNMtmSnA8kl45pEx3bQAjhvhBCUQihqFmzZlUSXF664grf0uvDD30Lr65d4W9/86IFL76oCT4iImVkMkmOAU6LZrn2AlZoPDLNdtvNk+Fnn8HEidCqlc+EbdcOBgyAiy7KdIQiIlklbd2tZvYEsB/Q1MzmAX8EagKEEO4BXgAOAUqA74HfpCsWKUdREUyaBK+8Ah99BJ9+6mOXBQVw/fVQt26mIxQRybh0zm4dvInzATgvXZ8vFVBQAP37+8/69T6x5/bbvZLPkCFwzjmw/faZjlJEJGNUlk5cYaHvbfn6697KvPZa6NABxo3LdGQiIhmjJCml9esHY8d69+svfgHHHAPvvOPncqwYvojI1lKSlPJ16uStyDZt4NBDfVZsly4wZUqmIxMRqTJKkpJa8+ZeuaduXS939/330LMnDBoEH3+c6ehERNJOSVI2rn17+OQTT5KTJnlhgrfe8pqwr7+e6ehERNJKSVI2rX59rwnbsiXceqsny1at4PDDffmIiEieUpKUzbfDDt4NW7++d73OmweXXQYzZsCNN8LIkZmOUESkUljIsRmLRUVFobi4ONNhCPhGz/vtB40awYoVvu7yp598Ocm0abDzzpmOUERkk8xsUgihqLxzaknKltt3XzjjDE+Qt94KRx7p23LVrQvDhmU6OhGRrZYTu4BIFrv7bq/5uttucPHFfiwEL6b++uueQHfayZePiIjkGLUkZevUquUJMtlFF0Hr1j5eecQRniSvvTYz8YmIbAUlSal8det6kfTly+F3v4MDD4TbbtNWXCKSc5QkJT1OPdW35LrzTjj7bFi8GN59N9NRiYhslrQmSTMbYGYzzazEzDaYyWFmO5jZeDObamavmVmbdMYjVaxjRzDzvSpr1IChQ73cXUlJpiMTEamQtCVJMysERgIDga7AYDPrWuaym4FHQwi7AyOA69MVj2RQo0a+VOSDD2D2bLj6aj8+bpyvq8yxZUgiUn2kc3ZrT6AkhDAbwMyeBAYBM5Ku6Qr8T/R8AvCvNMYjmTRihBdJ//Zb+Otf4cILffnIggXQpIl3yYqIZJl0dre2Br5Mej0vOpZsCnB09PwooIGZbZfGmCRTevf2FuTvfw/bbedrLBcs8IIDQ4fC3LmZjlBEZAOZnrhzKbCvmX0I7AvMBzaYAmlmQ8ys2MyKFy1aVNUxSmVq2hT+/W+vzLP33l7ebv16uO46eOIJmDkz0xGKiPwsbWXpzKw3cHUI4eDo9XCAEEK5445mVh/4JISw0ck7KkuXJ2bO9IS53Xa+TOTuu/14x44weTI0aJDZ+ESk2shUWbqJQGcz62BmtYATgTFlAmtqZnEMw4FRaYxHsslOO3mCBK/O07OnV+z5/HMvQDB2bEbDExGBNCbJEMKPwPnAi8DHwOgQwnQzG2FmR0SX7QfMNLNZQAvgunTFI1msdWt47z2v/3rbbTB9um/DpUQpIhmmXUAk+6xZA3vuCQsXeuWeY46Bhg0zHZWI5CntAiK5pXZt+NvffMutM86AX/7SxylFRKqYkqRkp913hy+/hAkTYO1aOOQQWLbMz731VuK5iEgaKUlK9ioo8Eo9//63d71efLFX7enbF/bay6v3iIikkZKkZL8ePWD4cHjkETjtNKhfP5E0RUTSSElScsMf/uD7Vk6f7iXsjjnGu11zbOKZiOQWJUnJDbVqwWOP+djkJZdAr16wZIlvxyUikiZKkpI7unWD55/3dZW9evkx7VEpImmkJCm5qWtXH5t8801N4BGRtFGSlNxUWOgFB+691zdyvvNOP37FFT65R0SkEqRzP0mR9DrzTKgR/RW+4AL473/h6af99YgR0L59xkITkfyglqTkrpNP9q22xo6Fc8/1BLnjjn7uySczG5uI5AW1JCX31aoFd90Fv/0ttGoFgwbBQw9BvXqwciUceyx06ZLpKEUkBylJSv7o1s0ff/1rOOccGDrUX7/yCrz6asbCEpHcldbuVjMbYGYzzazEzIaVc76dmU0wsw/NbKqZHZLOeKSaGDIEvvgCFi2CG27w+q/vv5/pqEQkB6UtSZpZITASGAh0BQabWdcyl12J7zP5S3xT5rvSFY9UI2bQti00bepjlY0a+W4iDz0E69ZlOjoRySHpbEn2BEpCCLNDCGuBJ4FBZa4JQLxRYCPgqzTGI9VRw4Zw//2+k8gZZ8Auu8CsWT5WuWpVpqMTkSyXziTZGvgy6fW86Fiyq4FTzGwe8AJwQRrjkerquONg5kyv1rNiBRx6KHToAAccAD/9lOnoRCSLZXoJyGDg4RBCG+AQ4DEz2yAmMxtiZsVmVrxo0aIqD1LygJnXfR09GubMgZo1fZzyyCO9zN1zz2U6QhHJQulMkvOBtkmv20THkp0JjAYIIbwD1AGaln2jEMJ9IYSiEEJRs2bN0hSuVAv77++tys8+gz59PDmuWwdHHQXjx2c6OhHJMulMkhOBzmbWwcxq4RNzxpS55gvgQAAz2wVPkmoqSnp16gR163rxgXHjPGG2aAG33prpyEQky6QtSYYQfgTOB14EPsZnsU43sxFmdkR02SXA2WY2BXgC+HUI2iBQqkirVjBgADRo4Gsr//MfOOkkL57+xBOZjk5EsoDlWk4qKioKxcXFmQ5D8k1JCXTu7M/btfN1lsXFsMcemY1LRNLOzCaFEIrKO5fpiTsi2WHHHeHCC+FPf4LJkxObPItItVahlqSZ1QN+CCH8ZGZdgJ2BcSGEKl+ZrZakVIljjvG9KufPT+w0IiJ5qTJakq8DdcysNfAScCrwcOWEJ5KFTjkFFi6Exx/PdCQikkEVTZIWQvgeOBq4K4RwHLBr+sISybDDDoO99/Y6sC+/nOloRCRDKpwkzaw3cDLwfHSsMD0hiWSBmjV9DeVOO3nCHDoUrrjCK/Q8+CB88kmmIxSRKlDRwZaLgOHAP6NlHB2BCekLSyQLbLstvPYaHH003HknhADNm8NFF8Fpp8Ejj2Q6QhFJs81eAhKVjasfQvg2PSFtnCbuSEasWuVLQ1asgPXrYYcd4PPPMx2ViFSCrZ64Y2Z/N7OG0SzXacAMM7usMoMUyWr16nnrcf16fz53rpe3u/JKaN8epk3LdIQikgYVHZPsGrUcjwTGAR3wGa4i1cfvfuf7VN52m7/ef3+47jr46iv44x8zG5uIpEVFk2RNM6uJJ8kx0frI3CrVI7K1Onf2Sjy/+Y2PV379NfzlL/D738Ozz/quIiKSVyqaJO8FPgfqAa+b2Q5ARsYkRTKuoADOPBNOPRUuucQn8rRs6S3LZ5/NdHQiUom2uHarmdWIiphXKU3ckaz01Ve+VOSbb3xCT82amY5IRCqoMibuNDKzW+ONj83sFrxVKSIA228P11zjyfLKK+GMM0AbhIvkvIp2t44CVgLHRz/fAg9t6pfMbICZzTSzEjMbVs75/zOzydHPLDNbvjnBi2SVAQOgY0e46SZ46CE4/njf0FlEclZFk2SnEMIfQwizo58/AR039gtmVgiMBAYCXYHBZtY1+ZoQwsUhhO4hhO7AHYAGdCR3FRbCzTf7WOWdd3ohghEjYOVKrwO7YgUcfjh88EGmIxWRCqpoxZ0fzKxvCOFNADPbG/hhE7/TEygJIcyOfudJYBAwI8X1gwHNo5fcdtRR/gM+2/WGG7yMXb16cOONMHYszJgBH34IDRtmNlYR2aSKtiTPAUaa2edm9jlwJ/DbTfxOa+DLpNfzomMbiGbLdgBeTXF+SDweukjjPJIrbr0VmjaFpUt9U+eHH/YJPXPn+viliGS9CiXJEMKUEEI3YHdg9xDCL4EDKjGOE4GnQwjrU3z+fSGEohBCUbNmzSrxY0XSaLvtYPr0xPrJ556DvfaCgQNh9GivBSsiWa2iLUkAQgjfJtVs/Z9NXD4faJv0uk10rDwnAk9sTiwiOaFJE9htN2gddaLsvbdv6PzFF3DHHTBsmJe6E5GstFlJsgzbxPmJQGcz62BmtfBEOGaDNzHbGdgWeGcrYhHJXmZwQNTxsvfecMQRUKMGXHihj1P+/e+ZjU9EUtqaJLnRvqKo0MD5wIvAx8DoaJutEWZ2RNKlJwJPhi2taiCSC447Dlq0gL59vXV56KG+tnLXXb3u6+rVmY5QRMqx0Yo7ZraS8pOhAduEECo6O7bSqOKO5IXvv/cW5uuv+/rKLl1gv/18ichhh2U6OpFqZYsr7oQQGoQQGpbz0yATCVIkb9StC9tsAwcfDOPG+fPHHoOLL/Z1lB06wIsv+rUzZsALL2Q2XpFqamu6W0WkMgwYAJMn+/hkSQlcdZXXfz3qKF9Gsu++3l0bV+9ZvBjWrNnyz7v3XnjppUoJXSTfKUmKZIv+/f3x+ec9MXbr5ruMLFni3bNTp8KcObDjjnD22Vv2GSH4jNq77qq8uEXymJKkSLbo0sU3dQbfs/Ltt+HllxPdrm+8ASef7OXtnnrKk+eSJXD66TA/1eqqMhYtguXLVXxdpIKUJEWyhZmPURYW+uQdMzjoIPjVr3yd5Z//DO+8A5dfDmvXwuOPwxVXwKOP+vOKmDnTHxcuTN99iOQRJUmRbHLNNfDKK16tJ1mfPt76+8Uv4PrrYc89fUuu++7z86+8UrH3nzXLH5UkRSpESVIkm7Rs6UtByurTxx+vuAIKCnwm7KBB0Lu3d7e+8UbqtZY//ADz5vnzuCX57bdamylSAUqSIrngjDPggQd8livATjt5onzrLT+2erU/B1i2DC67zMceAc46y4sWLF2aSJKgcUmRClCSFMkFDRvCmWf6eGVZ++7ru4s8+KC/vuEG39fypptgyhQve/ftt77H5cyZUKeOX6cuV5FNUkEAkVxXvz4MH+4bPO+0E4wc6cn0jjt8ZmyjRtCjB/zf/8F333n92P/+V0lSpALUkhTJB1dd5bNgr77a11Q+8QSsWuXrKh94AG67zWfINmoEJ57ovzN2rLdCV67MaOgi2WyjtVuzkWq3iqTw00/w4YeeHPfZx6v4tGvnBdWTrVzp3bd16vhY5nPPqV6sVGsbq92q7laRfFFQAHvskXjdvXv519Wvn0iQABMmKEmKpJDW7lYzG2BmM82sxMyGpbjmeDObYWbTzUwb64mkmxk0b554PWFC5mIRyXJpS5JmVgiMBAYCXYHBZta1zDWdgeHA3iGEXYGL0hWPiCSJk+Tuu3u37NKlG17zzTde2UekGktnS7InUBJCmB1CWAs8CQwqc83ZwMgQwjKAEIKm24lUhWbN/HH4cC96ftBBXis2tmqVz5S95ZbSv/fJJ4ndSESqgXQmydbAl0mv50XHknUBupjZW2b2rpkNKO+NzGyImRWbWfEiLYAW2Xo77gidOsEJJ8Dtt8OCBb6XZWz8eC+k/uGH/nr1ajj1VNhlF/jrXzMTs0gGZHoJSA2gM7AfMBi438wal70ohHBfCKEohFDULP4XsIhsuRtu8GLpZnDBBV6h5/33Ydo0b1mOHevXxbVeH3wQ/vY3X0IybhyMHg3nn5+5+EWqSDqT5HygbdLrNtGxZPOAMSGEdSGEOcAsPGmKSDrVrZvocgU45RSoUcM3gG7VCp55xo9/+qknzUce8fHLs87y8nfDh3vRgvLGMkXySDqT5ESgs5l1MLNawInAmDLX/AtvRWJmTfHu19lpjElEytOsGZx0EqxZA40be/Lr2dMLE4wfDxMneiH1Aw/0yTyzo/9M338/s3GLpFna1kmGEH40s/OBF4FCYFQIYbqZjQCKQwhjonP9zWwGsB64LISwJF0xichGPPSQP/7wA4wZA9tuCwMH+s4jhYW+4XO9et7irFXLxynffddbnyJ5ShV3RKR8X3wBO+zgzw87zCvzgO9I0qqVj1u2bOn1YUVymCruiMjma9MmUZnn9NMTx0eN8sclS+DJJ70cXkHSyM3333vpuxYtqjZekTTI9OxWEclWBQW+VGTbbeHwwzc836uXLxOZPj1x7JlnoEEDb2FqqYjkASVJEUntqqvgrrugdu0Nzx14oD++/HLi2B13eFH1gw/2ZSXvvgvz53uLE3x3ki+/3PC9Yp984mOfP/xQefcgshWUJEUkteOOS2ytVVbbtl5cIB6TnD3b96k86yxPii1aeKIcOhQGD/YNoE86Ca65JvXn3XuvbxL92muVfisbNW4cvPRS1X6m5AQlSRHZcv37w+uve8vv0Ue9OMFpp/kykssugzffhGef9WvvuMMfx43zCj/jx3v5u1NPhcce8/WYzz/v11R10fVhw+DKK6v2MyUnKEmKyJY7+GCf2DNhAjz8sNeAbRvVEDnrLN/Lsk4dXzby+ON+fN486NfPrx00yCv5nHYaHHmkFy8wq9okGYJvTj13btV9puQMJUkR2XL77efdqkOGeJL59a8T5+rV87WXDz7o1XpWr4bWUfnmkhIvcTd+vP/O5Zf72kzw6j8ffOBl8779Nv33sHSpz8ZduNBn5ook0RIQEdly22zjk3vOOw8aNvTWYLIjjvDHN9/0xHfooV6954cf4N//9tJ2f/yjz6AtKPAW3W9+492vffr4eOgTT6T3HubMSTyfO9fHWUUiSpIisnXOPhvuucfHJ+vWLf+avfaCu+/2x6uu8go+LVvCbbclrrn+en/88UcYMcJnxj7zjLfwkjeJrmyzkyphKklKGUqSIrJ1atb0matmqa857DBf2nH44aULq5enRg34wx/g44+ha1cf67z88sT5sWN9HLG8tZtbIrkl+fnnlfOekjc0JikiW29jCRJgu+18gs7mbHW3yy4+weeuu+Crr+Dcc71wwWmnwSWXVOw9QvCW6cbMmePdvTVravKObEBJUkSy17Bhnrj69PEu3b33hmXLfBbsypWlr50/35ejlP393XbzpSZr1pT/GXPm+AbU7dqpJZnNhgyBBx6o8o9VkhSR7DVwoI9jzp3rjytWJMY9p0wpfe2ZZ/qSlORqPW+/7VV8DjjAZ9u+8sqGnzFnDnTs6MXc1ZLMXs88k5GCD2lNkmY2wMxmmlmJmQ0r5/yvzWyRmU2Ofs5KZzwikmPMfMLPuef62sm//AX+8Q8/9+GHieumTvXKP6tX+6bQsVmzvBv1/fdh/Xp44YXS7796tSfGDh2gfXu1JLNVCP4PpAxs8p22JGlmhcBIYCDQFRhsZl3LufSpEEL36Kfq29Iikt1++Usfl9xmG7j0Um9dNmtWOknecou3MGvUgFdf9WMrVvjM2Kuu8jWXfft6yzLZa6/5JtL77uuThL7+2rcIk+yyapX/I2fZsir/6HS2JHsCJSGE2SGEtcCTwKA0fp6IVAdmnjjjJDlpkq+rPOcc6NnTCxSAj1sC7Lqr71iy996+VjO5O3bsWE+u++/vM3AhsW9m7I03fP/MRYvSe18C69b5ZK3kovkAy5f7Yz61JIHWQHK5/3nRsbKOMbOpZva0mbUt743MbIiZFZtZ8SL9RRWRnj29i/X6632dZrNm3mI88EAoLvb/qc6a5dd26eKPffr4/4QnTfLXIXiSPOggL523005+bVz5J/bSS15rduLEqru/6uqLL7zwRNkC93GSzLOWZEU8B7QPIewOvAw8Ut5FIYT7QghFIYSiZpszhVxE8tMll8CvfgW//71PzLnrLi9zd/DBvgn0uHGJOrCdOvnv9O7tj/GY5Ucf+Xhk3IIEryU7YYJ31camTk1cX9Y77/jnSeWIu7q/+cYf334bmjZN9AqsWLHpJT2VLJ1Jcj6Q3DJsEx37WQhhSQghnpf9ALBHGuMRkXzRuLHvGPL++z7ueMwxfrx3b+8affppb0m2a+etRPDWZocOiZbkU0955Z+4dB542bx163zLr1g8i7Zskpw2zVun//pXeu4xk1avrvJkBCSS5IIF/vjRR7BkifcOxOJWZRVJZ5KcCHQ2sw5mVgs4ESjVj2FmrZJeHgF8nMZ4RCSfFBbCnntC/fqJYwUFcPTR3pKcODHR1Rrr1s2TXgi+b+VBB3mB9thee0GtWon1litWJJaFTJtW+r0++8wf46SbT3r18klSVS3+s45bknGB+7jrHKq8yzVtSTKE8CNwPvAinvxGhxCmm9kIM4v/6TbUzKab2RRgKPDrdMUjItXEscf65JzPPvPNnpN16+Zdd6++6ss9yp6vU8cTZZwk49bjrrt6mbx16xLXzp9f+pp88dNPMGOG/yNi/frN//23305duGFTyrYk427v5CRZxZN30jomGUJ4IYTQJYTQKYRwXXTsqhDCmOj58BDCriGEbiGE/UMIn6QzHhGpBvbZB269Fd57z3cUSdatm7cir7gCateGo47a8Pf33ddnwa5cmehqPflkXypSUpK4bt48f4zHLPPFsmX+j4FFizZcMrMpX3zhs4ivuWbLPjt5TDJeGwmJMck4viqU6Yk7IiKVq6AALr4Yioo2PNetmz++954XSG/YcMNr9tnHW1DDhsENN/huJQMG+LnJkxPXxS3JuXNT73t5443Qo0duTe6JuzoB/vnPiv3OyJG+LCceO7znntJLbSoqTpLr1nkyjJNk8nvlU0tSRCSrtG8PDRr485NOKv+a3r19a6677vIkOmaM139t2tT3wIzNm5co7H7qqXDllaXfZ8EC3/Lrww83v0WWbsuX+z6ea9dueC7u6mzUaMP1iqlMmuT/gHjySX+9ZMnm7wMagifJeGPuBQtK/+OjZk1/HD3aCz9sSRLeAkqSIlJ9FBTA7rt7Ahg4sPxr6tf3VuLSpT7euOeeXsnn2GO90MCqVX7d/PmwRzQhf8wYX7P5ZdLS8Ouu87G5WrV8tm02eeQRT+BvvOExJo+1xi3JHj28AlFFLFnij88+6+O3HTpsWAJwUxYv9sS3557+esGC0ktx2rXzxzFjfHy4orFtJSVJEalebrjBt+2Kl4aUp0YN3z6rIOl/kSeeCN9/n9jPct48H39r1cpnyYYA993n1y5bBg8+CKef7l21zzzjXa7XXlu6hTVmjCeradM8IV900ZZNlinPm2/Cf/5T/rm4UPhnn3nsgwf7so9XX020JHff3ZNfRZaCxF2g69d7t+uOOybGbMv77Guu8T+vZHFXa8+e/vjNN6WTZPPm/g+Y+PeqaCmINl0Wkeqlb98t/722beHmm72QwapV0KaNFzOoXx+OPNLPjR8PO+/sraILLvCJPWPG+Djotdd68hk82MfvBkWVOmfN8l1IbrsNzjjDr9laV1/tiaZrV5+M9NJL0LmztxzjijYzZ3pc69b5tW++6etGa9VKLJ9ZvNjHZZOFUHoP0bglCd4C/eij8nfsuOceL1YPPl9V4sYAAA6oSURBVKmqTZvEuXgGa58+/li2Jdm4sf/D5bvv/HUVJUm1JEVEKqKwEG66yZNbPP7YurWPWxYUeHfr4MHeDfvQQ/4/++7dPaGCF2Ffs8bHKH/4wbtuCwoSy1LimbPvvls58X7zjSe4qVN9uUtcaeitt7xFDL5zStzV+uab/vjKK752NF4/unBh6fe9/XbvTk1uYS5d6rOFwVuSbdp4d2jZVugTT/ifIyTWmcYmTfL36NPHk3TZJNmoETRpknitJCkikmVOOAH69/ftuyAxyQR8LG7UKC9icPLJ3q0L3h27884+XgeeOIqLvWJQr17+k5wk33nHk0PZ7sjNFSfJuN51nJT++U+fBLPPPjB9uh+74goYOtST0/ffe8uxeXM/l5wkf/jBx1rnzk10j4bgLcmzzvKlN/36+Z/LTz8lum5j8b6gyfHEiov9HxU1a3qCjifubLutn49bkrHkBJpGSpIiIhVl5pNeWkXFwpK7C2PNm/uYZ79+iWP77efJpGlTf/3ss95yOuww7wJdtixR0efll30W7jnnVCym88+H++8vfWz9ek+QP/4Is2f7sZIST2ajRnmLt3v3xPXDh3tX7y9+4a9btCg/ST76aOJ1vHZx5Ur/nPbtfelNYWHizyV5XHL9en/dt69fE8cFnlA/+CAxEWr77T3edev8zwc8STZp4okc1JIUEclKLVt6V+nQoT6OWBH77++PBx/sk1pGjvTXcZIEX46x/fbeXbt8uU8Ciiv/pPLVV/5ev/+9T7yJLV6caIl+EtVoKSmBO+/0luLllycKv7dvD/Xq+fN4HWnLll7rFhJJceZMT6ZxvHGSjCftbLdd4vPLS5Jff+2JslMn/3NLbkl++qkn2zhJtm+fKNIQj402buxJeNQo/8eKkqSISJbaYw9vecXja5uy//4+uWfAAJ9NWlDgCWu33RJJB3y9JXgyat9+w/qp8+Z5Yly71pPf2LF+fPFi+Mc/PDGOHl16KUpyknzkEU/Uu+6aSJJduyaujVuXLVp4UqpRI5Ekjz7aX48b5/fy6af++fH7J48Xlpck47qs7dr5Zycnybj+bVwAokOHxASdnXbyx2239VboySf7OLBmt4qI5IlmzbwlVa+eJ5sRIxIttY4dvWUUgs/47N/fZ6O2bAkXXugTat5911tyDz/sv9OkiSevli09odSq5TNHd97Zx01PPz3x2fGs0eXL/eeyy/x1nCR33TVxbXJLsqDAY1y40LuDZ8zwCkKdOnlr+OWXfRJPvGQjuSXZpIkvsZk3z39/zhz/AW9FduzoST320Uc+Fhkn7PbtE+e6d/eJUEcemTjWuLGSpIhIXol3K6lb139itWt76+rLLz3hxS2nU07xbtGDD/Yu0jp1vKXZuLG3ypYv93WNF13kCeavf/WZs1B60+K1az3hxaXx4hJ7O+4Ixx/vRRJiPXv6etD+/f118+ae5OJWX9zq7dLFW6yQaAUmtyTNvDX52GM+mScE2GUXPxe3JJcu9Xto3Nhbx61aeUsVSifJRo1K7/kJVZok09rdamYDzGymmZWY2bCNXHeMmQUzK6fYoohInttpJ08M8aQU8KRz9NGeIO++22eWjhrlSeeZZ7xE3vDh8D//4+sq161LlM2LuzZju+2W+JwOHfx5jRq+p2bcEgTYZhtfphGPA5ZNknHrM7mLOC5+kNySBE+SCxd6F2m7dl4lZ7vtvDUdv8/NN/vs2zhJxuIYwZNkWY0b5/7sVjMrBEYCA4GuwGAz61rOdQ2AC4H30hWLiEhWu/FGr9BT1m23+SSh8ma61q8Pf/6zFziIk2DyAv4aNRJjpj17egI+5JDNi6tskuzY0R/jJBnXwYXSyzPAE2G9ej4jNm6txqXl9tzT3/u66zzpf/21T1qKxddB+UmyUaO8aEn2BEpCCLNDCGuBJ4FB5Vx3DXAjsLqccyIi+a97d18mUlazZht2NZZn5509ISYv3m/ePNG6a9PGxzavvnrz4kpOki1aJLqM+/Xz7tPLL/fXDRqUbgWDF1eYNMlbyPGWZHHya9vW10F26eITisq2JOvUSbxO1ZLMgyTZGkiaYsW86NjPzKwH0DaE8Hwa4xARyW+1ayfGMuPWXnKSbNbMW2/lbQ22Mc2be/m9yZMTXaTxZ8yY4SXsoPR4ZKxZs0RMvXv77/fokThv5t2qn3ziE4OSkyQkxiWTW6uxPEmSG2VmBcCtwCUVuHaImRWbWfGiuHqEiIgkxPVejz7aH5s3TxQviB83V1xH9YMPSifJWJcuPimo7HhkWYWFXt3nD38ofbxDh0TVn7JJskMHT5DlLbNp3Nir8VTBPp3pTJLzgbZJr9tEx2INgF8Ar5nZ50AvYEx5k3dCCPeFEIpCCEXN4mnTIiKSEI9Lxl2bLVokkuOW/n+zX7/E+5aXJOvU8Vmym0qS4K3d5KLo4IkwLnqQPCYJPg77pz+V/16NG/vvpdrsuhKlcwnIRKCzmXXAk+OJwM+7nIYQVgA///PGzF4DLg0hFKcxJhGR/HTGGT47tXdv38Krd29vAcKWtyTNvOzdb39bfpIErwyUvKRlcyTPYi3bkuzXr3Rpv2SNG/vjihWJ52mStiQZQvjRzM4HXgQKgVEhhOlmNgIoDiGMSddni4hUOy1betk2SOzoMXy4P25ND9zpp/uY4aDy5l3ihQ+2VDx+ChsmyY2JE+Py5RUvDbiF0lpMIITwAvBCmWNXpbh2v3TGIiJS7fTt6y3KinSHplK7Nvzv/1ZeTMnilmRh4eYl8njGaxVM3lHtVhGRfHXoofD224lKNtlm2219xm1cBq+ikluSaZalf3IiIpL34mUgNWtu3u+1a+eFCOIlJmmkJCkiIpkzYsSGs143pWlT3x6sCihJiohI5sQFCbKUxiRFRERSUJIUERFJQUlSREQkBSVJERGRFJQkRUREUlCSFBERScFCXIE9R5jZImBuJb1dU2BxJb1XrqiO9wy67+qkOt4z6L63xg4hhHLr4uVckqxMZlYcQthga658Vh3vGXTfmY6jKlXHewbdd7reX92tIiIiKShJioiIpFDdk+R9mQ4gA6rjPYPuuzqpjvcMuu+0qNZjkiIiIhtT3VuSIiIiKVXLJGlmA8xsppmVmNmwTMeTTmb2uZl9ZGaTzaw4OtbEzF42s0+jx20zHefWMrNRZrbQzKYlHSv3Ps3dHn3/U82sR+Yi33Ip7vlqM5sffd+TzeyQpHPDo3ueaWYHZybqrWdmbc1sgpnNMLPpZnZhdDxvv++N3HNef99mVsfM3jezKdF9/yk63sHM3ovu7ykzqxUdrx29LonOt9/qIEII1eoHKAQ+AzoCtYApQNdMx5XG+/0caFrm2E3AsOj5MODGTMdZCfe5D9ADmLap+wQOAcYBBvQC3st0/JV4z1cDl5Zzbdfo73ptoEP030Bhpu9hC++7FdAjet4AmBXdX95+3xu557z+vqPvrH70vCbwXvQdjgZOjI7fA5wbPf8dcE/0/ETgqa2NoTq2JHsCJSGE2SGEtcCTwKAMx1TVBgGPRM8fAY7MYCyVIoTwOrC0zOFU9zkIeDS4d4HGZtaqaiKtPCnuOZVBwJMhhDUhhDlACf7fQs4JIXwdQvgger4S+BhoTR5/3xu551Ty4vuOvrPvopc1o58AHAA8HR0v+13HfweeBg4029wdnUurjkmyNfBl0ut5bPwvW64LwEtmNsnMhkTHWoQQvo6eLwBaZCa0tEt1n/n+d+D8qFtxVFJXel7ec9Sd9ku8hVEtvu8y9wx5/n2bWaGZTQYWAi/jreLlIYQfo0uS7+3n+47OrwC225rPr45JsrrpG0LoAQwEzjOzfZJPBu+XyPspztXlPoG7gU5Ad+Br4JbMhpM+ZlYfeAa4KITwbfK5fP2+y7nnvP++QwjrQwjdgTZ4a3jnqvz86pgk5wNtk163iY7lpRDC/OhxIfBP/C/ZN3F3U/S4MHMRplWq+8zbvwMhhG+i/6n8BNxPoostr+7ZzGriyeLxEMKz0eG8/r7Lu+fq8n0DhBCWAxOA3niXeY3oVPK9/Xzf0flGwJKt+dzqmCQnAp2j2VG18MHdMRmOKS3MrJ6ZNYifA/2Bafj9nh5ddjrw78xEmHap7nMMcFo067EXsCKpmy6nlRlrOwr/vsHv+cRo9l8HoDPwflXHVxmiMaYHgY9DCLcmncrb7zvVPef7921mzcyscfR8G+BX+HjsBODY6LKy33X8d+BY4NWoV2HLZXr2UiZ+8Nlus/C+7SsyHU8a77MjPsNtCjA9vle8j3488CnwCtAk07FWwr0+gXc3rcPHKM5MdZ/4jLmR0ff/EVCU6fgr8Z4fi+5pavQ/jFZJ118R3fNMYGCm49+K++6Ld6VOBSZHP4fk8/e9kXvO6+8b2B34MLq/acBV0fGOeNIvAf4B1I6O14lel0TnO25tDKq4IyIikkJ17G4VERGpECVJERGRFJQkRUREUlCSFBERSUFJUkREJAUlSZEsZ2brk3Z5mGyVuHONmbVP3kVEREqrselLRCTDfghelktEqphakiI5ynyv0JvM9wt938x2jI63N7NXo6LX482sXXS8hZn9M9qbb4qZ9YneqtDM7o/263spqmwiIihJiuSCbcp0t56QdG5FCGE34E7gr9GxO4BHQgi7A48Dt0fHbwf+G0Lohu9DOT063hkYGULYFVgOHJPm+xHJGaq4I5LlzOy7EEL9co5/DhwQQpgdFb9eEELYzswW4+XJ1kXHvw4hNDWzRUCbEMKapPdoD7wcQugcvf5foGYI4dr035lI9lNLUiS3hRTPN8eapOfr0VwFkZ8pSYrkthOSHt+Jnr+N724DcDLwRvR8PHAu/LyRbaOqClIkV+lfjCLZb5toZ/bYf0II8TKQbc1sKt4aHBwduwB4yMwuAxYBv4mOXwjcZ2Zn4i3Gc/FdREQkBY1JiuSoaEyyKISwONOxiOQrdbeKiIikoJakiIhICmpJioiIpKAkKSIikoKSpIiISApKkiIiIikoSYqIiKSgJCkiIpLC/wN7v6prrmKrpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.102179841200511 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  7\n",
            "[Epoch: 1 Batch:   106] loss: 1.091, acc: 34.780, test_acc:30.833, F1:0.322\n",
            "[Epoch: 2 Batch:   106] loss: 1.086, acc: 34.805, test_acc:37.500, F1:0.397\n",
            "[Epoch: 3 Batch:   106] loss: 1.083, acc: 34.792, test_acc:35.000, F1:0.363\n",
            "[Epoch: 4 Batch:   106] loss: 1.080, acc: 36.239, test_acc:33.333, F1:0.351\n",
            "[Epoch: 5 Batch:   106] loss: 1.078, acc: 35.887, test_acc:34.167, F1:0.360\n",
            "[Epoch: 6 Batch:   106] loss: 1.079, acc: 36.704, test_acc:30.833, F1:0.322\n",
            "[Epoch: 7 Batch:   106] loss: 1.077, acc: 37.107, test_acc:30.833, F1:0.312\n",
            "[Epoch: 8 Batch:   106] loss: 1.074, acc: 37.623, test_acc:29.167, F1:0.298\n",
            "[Epoch: 9 Batch:   106] loss: 1.076, acc: 37.673, test_acc:28.333, F1:0.261\n",
            "[Epoch: 10 Batch:   106] loss: 1.072, acc: 38.025, test_acc:30.833, F1:0.306\n",
            "[Epoch: 11 Batch:   106] loss: 1.071, acc: 38.088, test_acc:30.833, F1:0.320\n",
            "[Epoch: 12 Batch:   106] loss: 1.069, acc: 38.616, test_acc:26.667, F1:0.272\n",
            "[Epoch: 13 Batch:   106] loss: 1.069, acc: 39.736, test_acc:31.667, F1:0.330\n",
            "[Epoch: 14 Batch:   106] loss: 1.066, acc: 39.874, test_acc:25.833, F1:0.248\n",
            "[Epoch: 15 Batch:   106] loss: 1.067, acc: 39.635, test_acc:30.833, F1:0.310\n",
            "[Epoch: 16 Batch:   106] loss: 1.064, acc: 39.736, test_acc:28.333, F1:0.280\n",
            "[Epoch: 17 Batch:   106] loss: 1.063, acc: 39.711, test_acc:30.000, F1:0.308\n",
            "[Epoch: 18 Batch:   106] loss: 1.063, acc: 39.937, test_acc:34.167, F1:0.353\n",
            "[Epoch: 19 Batch:   106] loss: 1.062, acc: 41.384, test_acc:28.333, F1:0.299\n",
            "[Epoch: 20 Batch:   106] loss: 1.062, acc: 41.031, test_acc:25.000, F1:0.233\n",
            "[Epoch: 21 Batch:   106] loss: 1.062, acc: 40.428, test_acc:32.500, F1:0.317\n",
            "[Epoch: 22 Batch:   106] loss: 1.058, acc: 40.579, test_acc:25.000, F1:0.240\n",
            "[Epoch: 23 Batch:   106] loss: 1.054, acc: 41.145, test_acc:26.667, F1:0.250\n",
            "[Epoch: 24 Batch:   106] loss: 1.055, acc: 42.201, test_acc:29.167, F1:0.289\n",
            "[Epoch: 25 Batch:   106] loss: 1.056, acc: 41.233, test_acc:35.000, F1:0.359\n",
            "[Epoch: 26 Batch:   106] loss: 1.050, acc: 41.862, test_acc:34.167, F1:0.329\n",
            "[Epoch: 27 Batch:   106] loss: 1.051, acc: 43.610, test_acc:29.167, F1:0.267\n",
            "[Epoch: 28 Batch:   106] loss: 1.051, acc: 41.799, test_acc:35.000, F1:0.356\n",
            "[Epoch: 29 Batch:   106] loss: 1.047, acc: 42.855, test_acc:30.000, F1:0.290\n",
            "[Epoch: 30 Batch:   106] loss: 1.047, acc: 41.874, test_acc:35.833, F1:0.359\n",
            "[Epoch: 31 Batch:   106] loss: 1.046, acc: 43.673, test_acc:33.333, F1:0.319\n",
            "[Epoch: 32 Batch:   106] loss: 1.050, acc: 44.994, test_acc:35.833, F1:0.356\n",
            "[Epoch: 33 Batch:   106] loss: 1.044, acc: 44.340, test_acc:37.500, F1:0.362\n",
            "[Epoch: 34 Batch:   106] loss: 1.041, acc: 44.415, test_acc:28.333, F1:0.284\n",
            "[Epoch: 35 Batch:   106] loss: 1.039, acc: 43.698, test_acc:35.833, F1:0.361\n",
            "[Epoch: 36 Batch:   106] loss: 1.038, acc: 45.447, test_acc:34.167, F1:0.338\n",
            "[Epoch: 37 Batch:   106] loss: 1.036, acc: 45.019, test_acc:34.167, F1:0.346\n",
            "[Epoch: 38 Batch:   106] loss: 1.033, acc: 45.119, test_acc:34.167, F1:0.362\n",
            "[Epoch: 39 Batch:   106] loss: 1.031, acc: 44.138, test_acc:34.167, F1:0.357\n",
            "[Epoch: 40 Batch:   106] loss: 1.030, acc: 45.270, test_acc:38.333, F1:0.385\n",
            "[Epoch: 41 Batch:   106] loss: 1.030, acc: 45.748, test_acc:35.000, F1:0.364\n",
            "[Epoch: 42 Batch:   106] loss: 1.027, acc: 46.767, test_acc:36.667, F1:0.368\n",
            "[Epoch: 43 Batch:   106] loss: 1.023, acc: 47.660, test_acc:28.333, F1:0.285\n",
            "[Epoch: 44 Batch:   106] loss: 1.025, acc: 47.648, test_acc:38.333, F1:0.377\n",
            "[Epoch: 45 Batch:   106] loss: 1.019, acc: 46.654, test_acc:37.500, F1:0.381\n",
            "[Epoch: 46 Batch:   106] loss: 1.022, acc: 48.767, test_acc:33.333, F1:0.338\n",
            "[Epoch: 47 Batch:   106] loss: 1.014, acc: 48.717, test_acc:37.500, F1:0.374\n",
            "[Epoch: 48 Batch:   106] loss: 1.011, acc: 48.453, test_acc:32.500, F1:0.328\n",
            "[Epoch: 49 Batch:   106] loss: 1.005, acc: 49.031, test_acc:42.500, F1:0.426\n",
            "[Epoch: 50 Batch:   106] loss: 1.006, acc: 49.811, test_acc:42.500, F1:0.423\n",
            "[Epoch: 51 Batch:   106] loss: 1.008, acc: 49.912, test_acc:32.500, F1:0.336\n",
            "[Epoch: 52 Batch:   106] loss: 0.998, acc: 49.233, test_acc:38.333, F1:0.395\n",
            "[Epoch: 53 Batch:   106] loss: 1.002, acc: 51.157, test_acc:40.000, F1:0.400\n",
            "[Epoch: 54 Batch:   106] loss: 0.997, acc: 50.428, test_acc:36.667, F1:0.365\n",
            "[Epoch: 55 Batch:   106] loss: 0.996, acc: 50.855, test_acc:39.167, F1:0.399\n",
            "[Epoch: 56 Batch:   106] loss: 0.985, acc: 52.239, test_acc:40.833, F1:0.415\n",
            "[Epoch: 57 Batch:   106] loss: 0.990, acc: 52.390, test_acc:37.500, F1:0.379\n",
            "[Epoch: 58 Batch:   106] loss: 0.984, acc: 52.226, test_acc:42.500, F1:0.436\n",
            "[Epoch: 59 Batch:   106] loss: 0.975, acc: 53.610, test_acc:40.833, F1:0.411\n",
            "[Epoch: 60 Batch:   106] loss: 0.981, acc: 53.836, test_acc:40.833, F1:0.411\n",
            "[Epoch: 61 Batch:   106] loss: 0.975, acc: 52.528, test_acc:41.667, F1:0.432\n",
            "[Epoch: 62 Batch:   106] loss: 0.966, acc: 54.075, test_acc:34.167, F1:0.348\n",
            "[Epoch: 63 Batch:   106] loss: 0.964, acc: 55.233, test_acc:40.000, F1:0.410\n",
            "[Epoch: 64 Batch:   106] loss: 0.969, acc: 54.365, test_acc:36.667, F1:0.382\n",
            "[Epoch: 65 Batch:   106] loss: 0.957, acc: 54.792, test_acc:40.000, F1:0.420\n",
            "[Epoch: 66 Batch:   106] loss: 0.957, acc: 55.811, test_acc:35.833, F1:0.364\n",
            "[Epoch: 67 Batch:   106] loss: 0.957, acc: 55.522, test_acc:38.333, F1:0.398\n",
            "[Epoch: 68 Batch:   106] loss: 0.954, acc: 54.855, test_acc:40.833, F1:0.415\n",
            "[Epoch: 69 Batch:   106] loss: 0.953, acc: 54.327, test_acc:44.167, F1:0.445\n",
            "[Epoch: 70 Batch:   106] loss: 0.936, acc: 55.635, test_acc:36.667, F1:0.369\n",
            "[Epoch: 71 Batch:   106] loss: 0.943, acc: 56.239, test_acc:40.833, F1:0.424\n",
            "[Epoch: 72 Batch:   106] loss: 0.931, acc: 56.151, test_acc:40.000, F1:0.406\n",
            "[Epoch: 73 Batch:   106] loss: 0.919, acc: 57.484, test_acc:38.333, F1:0.386\n",
            "[Epoch: 74 Batch:   106] loss: 0.930, acc: 56.956, test_acc:37.500, F1:0.392\n",
            "[Epoch: 75 Batch:   106] loss: 0.923, acc: 57.799, test_acc:38.333, F1:0.400\n",
            "[Epoch: 76 Batch:   106] loss: 0.913, acc: 59.346, test_acc:35.000, F1:0.365\n",
            "[Epoch: 77 Batch:   106] loss: 0.912, acc: 57.950, test_acc:35.833, F1:0.363\n",
            "[Epoch: 78 Batch:   106] loss: 0.903, acc: 57.925, test_acc:35.833, F1:0.375\n",
            "[Epoch: 79 Batch:   106] loss: 0.903, acc: 59.509, test_acc:40.000, F1:0.411\n",
            "[Epoch: 80 Batch:   106] loss: 0.888, acc: 61.459, test_acc:39.167, F1:0.410\n",
            "[Epoch: 81 Batch:   106] loss: 0.887, acc: 60.579, test_acc:39.167, F1:0.397\n",
            "[Epoch: 82 Batch:   106] loss: 0.889, acc: 60.050, test_acc:35.833, F1:0.362\n",
            "[Epoch: 83 Batch:   106] loss: 0.885, acc: 61.899, test_acc:40.000, F1:0.411\n",
            "[Epoch: 84 Batch:   106] loss: 0.877, acc: 61.836, test_acc:39.167, F1:0.405\n",
            "[Epoch: 85 Batch:   106] loss: 0.868, acc: 61.069, test_acc:37.500, F1:0.387\n",
            "[Epoch: 86 Batch:   106] loss: 0.861, acc: 61.774, test_acc:35.833, F1:0.376\n",
            "[Epoch: 87 Batch:   106] loss: 0.865, acc: 62.176, test_acc:40.833, F1:0.421\n",
            "[Epoch: 88 Batch:   106] loss: 0.849, acc: 63.535, test_acc:40.000, F1:0.423\n",
            "[Epoch: 89 Batch:   106] loss: 0.850, acc: 62.969, test_acc:38.333, F1:0.399\n",
            "[Epoch: 90 Batch:   106] loss: 0.831, acc: 62.969, test_acc:35.000, F1:0.353\n",
            "[Epoch: 91 Batch:   106] loss: 0.836, acc: 63.660, test_acc:36.667, F1:0.383\n",
            "[Epoch: 92 Batch:   106] loss: 0.831, acc: 63.208, test_acc:40.000, F1:0.407\n",
            "[Epoch: 93 Batch:   106] loss: 0.832, acc: 63.258, test_acc:43.333, F1:0.440\n",
            "[Epoch: 94 Batch:   106] loss: 0.815, acc: 64.377, test_acc:37.500, F1:0.391\n",
            "[Epoch: 95 Batch:   106] loss: 0.812, acc: 65.472, test_acc:35.000, F1:0.364\n",
            "[Epoch: 96 Batch:   106] loss: 0.800, acc: 66.730, test_acc:38.333, F1:0.393\n",
            "[Epoch: 97 Batch:   106] loss: 0.805, acc: 65.459, test_acc:43.333, F1:0.438\n",
            "[Epoch: 98 Batch:   106] loss: 0.786, acc: 66.465, test_acc:40.833, F1:0.426\n",
            "[Epoch: 99 Batch:   106] loss: 0.791, acc: 64.969, test_acc:41.667, F1:0.435\n",
            "[Epoch: 100 Batch:   106] loss: 0.780, acc: 67.522, test_acc:38.333, F1:0.399\n",
            "[Epoch: 101 Batch:   106] loss: 0.788, acc: 66.264, test_acc:34.167, F1:0.364\n",
            "[Epoch: 102 Batch:   106] loss: 0.775, acc: 65.874, test_acc:31.667, F1:0.332\n",
            "[Epoch: 103 Batch:   106] loss: 0.769, acc: 66.981, test_acc:30.833, F1:0.313\n",
            "[Epoch: 104 Batch:   106] loss: 0.774, acc: 65.975, test_acc:34.167, F1:0.364\n",
            "[Epoch: 105 Batch:   106] loss: 0.763, acc: 65.208, test_acc:38.333, F1:0.401\n",
            "[Epoch: 106 Batch:   106] loss: 0.755, acc: 66.893, test_acc:27.500, F1:0.293\n",
            "[Epoch: 107 Batch:   106] loss: 0.738, acc: 66.415, test_acc:32.500, F1:0.348\n",
            "[Epoch: 108 Batch:   106] loss: 0.739, acc: 68.189, test_acc:38.333, F1:0.394\n",
            "[Epoch: 109 Batch:   106] loss: 0.744, acc: 68.252, test_acc:34.167, F1:0.361\n",
            "[Epoch: 110 Batch:   106] loss: 0.732, acc: 68.453, test_acc:30.000, F1:0.327\n",
            "[Epoch: 111 Batch:   106] loss: 0.734, acc: 68.176, test_acc:36.667, F1:0.384\n",
            "[Epoch: 112 Batch:   106] loss: 0.730, acc: 67.950, test_acc:32.500, F1:0.348\n",
            "[Epoch: 113 Batch:   106] loss: 0.718, acc: 69.094, test_acc:37.500, F1:0.401\n",
            "[Epoch: 114 Batch:   106] loss: 0.725, acc: 68.767, test_acc:33.333, F1:0.349\n",
            "[Epoch: 115 Batch:   106] loss: 0.718, acc: 68.868, test_acc:35.000, F1:0.374\n",
            "[Epoch: 116 Batch:   106] loss: 0.708, acc: 69.069, test_acc:32.500, F1:0.345\n",
            "[Epoch: 117 Batch:   106] loss: 0.696, acc: 69.195, test_acc:29.167, F1:0.306\n",
            "[Epoch: 118 Batch:   106] loss: 0.699, acc: 70.566, test_acc:27.500, F1:0.290\n",
            "[Epoch: 119 Batch:   106] loss: 0.694, acc: 70.000, test_acc:35.000, F1:0.370\n",
            "[Epoch: 120 Batch:   106] loss: 0.686, acc: 69.384, test_acc:32.500, F1:0.345\n",
            "[Epoch: 121 Batch:   106] loss: 0.680, acc: 69.711, test_acc:31.667, F1:0.331\n",
            "[Epoch: 122 Batch:   106] loss: 0.672, acc: 71.761, test_acc:30.833, F1:0.331\n",
            "[Epoch: 123 Batch:   106] loss: 0.683, acc: 71.170, test_acc:29.167, F1:0.309\n",
            "[Epoch: 124 Batch:   106] loss: 0.677, acc: 70.654, test_acc:30.000, F1:0.299\n",
            "[Epoch: 125 Batch:   106] loss: 0.678, acc: 69.057, test_acc:32.500, F1:0.341\n",
            "[Epoch: 126 Batch:   106] loss: 0.657, acc: 72.176, test_acc:40.833, F1:0.431\n",
            "[Epoch: 127 Batch:   106] loss: 0.672, acc: 69.950, test_acc:34.167, F1:0.357\n",
            "[Epoch: 128 Batch:   106] loss: 0.657, acc: 70.516, test_acc:29.167, F1:0.317\n",
            "[Epoch: 129 Batch:   106] loss: 0.649, acc: 70.465, test_acc:30.833, F1:0.327\n",
            "[Epoch: 130 Batch:   106] loss: 0.655, acc: 70.553, test_acc:34.167, F1:0.354\n",
            "[Epoch: 131 Batch:   106] loss: 0.627, acc: 71.233, test_acc:30.833, F1:0.338\n",
            "[Epoch: 132 Batch:   106] loss: 0.625, acc: 71.258, test_acc:31.667, F1:0.344\n",
            "[Epoch: 133 Batch:   106] loss: 0.622, acc: 72.881, test_acc:29.167, F1:0.309\n",
            "[Epoch: 134 Batch:   106] loss: 0.605, acc: 71.283, test_acc:34.167, F1:0.364\n",
            "[Epoch: 135 Batch:   106] loss: 0.616, acc: 72.314, test_acc:34.167, F1:0.361\n",
            "[Epoch: 136 Batch:   106] loss: 0.630, acc: 71.434, test_acc:30.833, F1:0.333\n",
            "[Epoch: 137 Batch:   106] loss: 0.606, acc: 72.277, test_acc:28.333, F1:0.305\n",
            "[Epoch: 138 Batch:   106] loss: 0.623, acc: 71.270, test_acc:36.667, F1:0.386\n",
            "[Epoch: 139 Batch:   106] loss: 0.595, acc: 72.516, test_acc:31.667, F1:0.338\n",
            "[Epoch: 140 Batch:   106] loss: 0.602, acc: 73.346, test_acc:35.000, F1:0.359\n",
            "[Epoch: 141 Batch:   106] loss: 0.588, acc: 72.252, test_acc:35.833, F1:0.369\n",
            "[Epoch: 142 Batch:   106] loss: 0.594, acc: 72.277, test_acc:29.167, F1:0.310\n",
            "[Epoch: 143 Batch:   106] loss: 0.583, acc: 73.623, test_acc:33.333, F1:0.354\n",
            "[Epoch: 144 Batch:   106] loss: 0.602, acc: 72.730, test_acc:36.667, F1:0.391\n",
            "[Epoch: 145 Batch:   106] loss: 0.583, acc: 70.667, test_acc:30.833, F1:0.327\n",
            "[Epoch: 146 Batch:   106] loss: 0.583, acc: 72.164, test_acc:35.000, F1:0.368\n",
            "[Epoch: 147 Batch:   106] loss: 0.565, acc: 73.660, test_acc:35.000, F1:0.369\n",
            "[Epoch: 148 Batch:   106] loss: 0.566, acc: 70.918, test_acc:35.833, F1:0.369\n",
            "[Epoch: 149 Batch:   106] loss: 0.587, acc: 71.874, test_acc:41.667, F1:0.426\n",
            "[Epoch: 150 Batch:   106] loss: 0.564, acc: 71.371, test_acc:37.500, F1:0.395\n",
            "[Epoch: 151 Batch:   106] loss: 0.570, acc: 73.648, test_acc:40.000, F1:0.423\n",
            "[Epoch: 152 Batch:   106] loss: 0.541, acc: 72.277, test_acc:35.000, F1:0.360\n",
            "[Epoch: 153 Batch:   106] loss: 0.542, acc: 74.365, test_acc:35.000, F1:0.368\n",
            "[Epoch: 154 Batch:   106] loss: 0.545, acc: 71.686, test_acc:34.167, F1:0.362\n",
            "[Epoch: 155 Batch:   106] loss: 0.526, acc: 73.421, test_acc:31.667, F1:0.332\n",
            "[Epoch: 156 Batch:   106] loss: 0.544, acc: 73.937, test_acc:35.833, F1:0.381\n",
            "[Epoch: 157 Batch:   106] loss: 0.534, acc: 73.421, test_acc:34.167, F1:0.367\n",
            "[Epoch: 158 Batch:   106] loss: 0.528, acc: 73.396, test_acc:25.000, F1:0.269\n",
            "[Epoch: 159 Batch:   106] loss: 0.563, acc: 72.730, test_acc:41.667, F1:0.437\n",
            "[Epoch: 160 Batch:   106] loss: 0.525, acc: 74.403, test_acc:43.333, F1:0.436\n",
            "[Epoch: 161 Batch:   106] loss: 0.571, acc: 74.428, test_acc:32.500, F1:0.344\n",
            "[Epoch: 162 Batch:   106] loss: 0.574, acc: 72.616, test_acc:34.167, F1:0.359\n",
            "[Epoch: 163 Batch:   106] loss: 0.534, acc: 72.176, test_acc:30.000, F1:0.319\n",
            "[Epoch: 164 Batch:   106] loss: 0.531, acc: 74.189, test_acc:32.500, F1:0.343\n",
            "[Epoch: 165 Batch:   106] loss: 0.496, acc: 73.472, test_acc:33.333, F1:0.353\n",
            "[Epoch: 166 Batch:   106] loss: 0.539, acc: 76.126, test_acc:42.500, F1:0.437\n",
            "[Epoch: 167 Batch:   106] loss: 0.517, acc: 73.333, test_acc:37.500, F1:0.400\n",
            "[Epoch: 168 Batch:   106] loss: 0.556, acc: 72.868, test_acc:38.333, F1:0.398\n",
            "[Epoch: 169 Batch:   106] loss: 0.523, acc: 74.428, test_acc:35.833, F1:0.383\n",
            "[Epoch: 170 Batch:   106] loss: 0.520, acc: 72.855, test_acc:35.833, F1:0.369\n",
            "[Epoch: 171 Batch:   106] loss: 0.541, acc: 72.767, test_acc:30.833, F1:0.330\n",
            "[Epoch: 172 Batch:   106] loss: 0.505, acc: 73.761, test_acc:33.333, F1:0.351\n",
            "[Epoch: 173 Batch:   106] loss: 0.500, acc: 75.283, test_acc:33.333, F1:0.348\n",
            "[Epoch: 174 Batch:   106] loss: 0.479, acc: 73.560, test_acc:37.500, F1:0.399\n",
            "[Epoch: 175 Batch:   106] loss: 0.474, acc: 76.277, test_acc:33.333, F1:0.355\n",
            "[Epoch: 176 Batch:   106] loss: 0.493, acc: 72.906, test_acc:36.667, F1:0.387\n",
            "[Epoch: 177 Batch:   106] loss: 0.501, acc: 74.604, test_acc:35.000, F1:0.369\n",
            "[Epoch: 178 Batch:   106] loss: 0.474, acc: 75.308, test_acc:42.500, F1:0.451\n",
            "[Epoch: 179 Batch:   106] loss: 0.473, acc: 75.321, test_acc:32.500, F1:0.348\n",
            "[Epoch: 180 Batch:   106] loss: 0.488, acc: 75.950, test_acc:36.667, F1:0.393\n",
            "[Epoch: 181 Batch:   106] loss: 0.483, acc: 75.421, test_acc:35.833, F1:0.387\n",
            "[Epoch: 182 Batch:   106] loss: 0.481, acc: 75.107, test_acc:30.833, F1:0.335\n",
            "[Epoch: 183 Batch:   106] loss: 0.472, acc: 75.044, test_acc:37.500, F1:0.389\n",
            "[Epoch: 184 Batch:   106] loss: 0.485, acc: 73.962, test_acc:34.167, F1:0.364\n",
            "[Epoch: 185 Batch:   106] loss: 0.504, acc: 71.975, test_acc:29.167, F1:0.321\n",
            "[Epoch: 186 Batch:   106] loss: 0.529, acc: 75.031, test_acc:30.833, F1:0.317\n",
            "[Epoch: 187 Batch:   106] loss: 0.468, acc: 73.711, test_acc:36.667, F1:0.385\n",
            "[Epoch: 188 Batch:   106] loss: 0.495, acc: 75.283, test_acc:28.333, F1:0.310\n",
            "[Epoch: 189 Batch:   106] loss: 0.473, acc: 75.396, test_acc:36.667, F1:0.390\n",
            "[Epoch: 190 Batch:   106] loss: 0.500, acc: 75.107, test_acc:35.000, F1:0.373\n",
            "[Epoch: 191 Batch:   106] loss: 0.443, acc: 74.692, test_acc:39.167, F1:0.414\n",
            "[Epoch: 192 Batch:   106] loss: 0.432, acc: 74.189, test_acc:35.833, F1:0.357\n",
            "[Epoch: 193 Batch:   106] loss: 0.456, acc: 75.572, test_acc:30.833, F1:0.312\n",
            "[Epoch: 194 Batch:   106] loss: 0.415, acc: 77.044, test_acc:38.333, F1:0.412\n",
            "[Epoch: 195 Batch:   106] loss: 0.454, acc: 74.264, test_acc:34.167, F1:0.373\n",
            "[Epoch: 196 Batch:   106] loss: 0.499, acc: 73.396, test_acc:38.333, F1:0.404\n",
            "[Epoch: 197 Batch:   106] loss: 0.453, acc: 76.264, test_acc:38.333, F1:0.403\n",
            "[Epoch: 198 Batch:   106] loss: 0.447, acc: 76.742, test_acc:31.667, F1:0.335\n",
            "[Epoch: 199 Batch:   106] loss: 0.411, acc: 74.616, test_acc:35.000, F1:0.366\n",
            "[Epoch: 200 Batch:   106] loss: 0.411, acc: 74.704, test_acc:37.500, F1:0.394\n",
            "[Epoch: 201 Batch:   106] loss: 0.453, acc: 77.107, test_acc:29.167, F1:0.305\n",
            "[Epoch: 202 Batch:   106] loss: 0.468, acc: 76.767, test_acc:23.333, F1:0.266\n",
            "[Epoch: 203 Batch:   106] loss: 0.465, acc: 74.692, test_acc:35.000, F1:0.379\n",
            "[Epoch: 204 Batch:   106] loss: 0.424, acc: 76.088, test_acc:38.333, F1:0.415\n",
            "[Epoch: 205 Batch:   106] loss: 0.397, acc: 74.704, test_acc:42.500, F1:0.443\n",
            "[Epoch: 206 Batch:   106] loss: 0.395, acc: 75.660, test_acc:35.000, F1:0.376\n",
            "[Epoch: 207 Batch:   106] loss: 0.443, acc: 74.692, test_acc:32.500, F1:0.327\n",
            "[Epoch: 208 Batch:   106] loss: 0.424, acc: 75.560, test_acc:31.667, F1:0.340\n",
            "[Epoch: 209 Batch:   106] loss: 0.464, acc: 76.214, test_acc:35.833, F1:0.374\n",
            "[Epoch: 210 Batch:   106] loss: 0.429, acc: 75.975, test_acc:35.000, F1:0.372\n",
            "[Epoch: 211 Batch:   106] loss: 0.507, acc: 73.698, test_acc:37.500, F1:0.399\n",
            "[Epoch: 212 Batch:   106] loss: 0.453, acc: 75.975, test_acc:36.667, F1:0.381\n",
            "[Epoch: 213 Batch:   106] loss: 0.405, acc: 75.245, test_acc:37.500, F1:0.405\n",
            "[Epoch: 214 Batch:   106] loss: 0.380, acc: 78.113, test_acc:35.000, F1:0.375\n",
            "[Epoch: 215 Batch:   106] loss: 0.398, acc: 76.176, test_acc:32.500, F1:0.343\n",
            "[Epoch: 216 Batch:   106] loss: 0.432, acc: 77.660, test_acc:35.833, F1:0.377\n",
            "[Epoch: 217 Batch:   106] loss: 0.484, acc: 74.503, test_acc:35.000, F1:0.378\n",
            "[Epoch: 218 Batch:   106] loss: 0.462, acc: 74.767, test_acc:41.667, F1:0.436\n",
            "[Epoch: 219 Batch:   106] loss: 0.430, acc: 74.969, test_acc:33.333, F1:0.359\n",
            "[Epoch: 220 Batch:   106] loss: 0.414, acc: 75.283, test_acc:26.667, F1:0.287\n",
            "[Epoch: 221 Batch:   106] loss: 0.426, acc: 75.044, test_acc:33.333, F1:0.349\n",
            "[Epoch: 222 Batch:   106] loss: 0.414, acc: 76.667, test_acc:36.667, F1:0.387\n",
            "[Epoch: 223 Batch:   106] loss: 0.435, acc: 74.151, test_acc:33.333, F1:0.355\n",
            "[Epoch: 224 Batch:   106] loss: 0.397, acc: 76.579, test_acc:35.000, F1:0.376\n",
            "[Epoch: 225 Batch:   106] loss: 0.384, acc: 75.082, test_acc:37.500, F1:0.402\n",
            "[Epoch: 226 Batch:   106] loss: 0.396, acc: 75.799, test_acc:33.333, F1:0.348\n",
            "[Epoch: 227 Batch:   106] loss: 0.399, acc: 76.969, test_acc:34.167, F1:0.354\n",
            "[Epoch: 228 Batch:   106] loss: 0.439, acc: 75.208, test_acc:38.333, F1:0.412\n",
            "[Epoch: 229 Batch:   106] loss: 0.432, acc: 77.799, test_acc:36.667, F1:0.382\n",
            "[Epoch: 230 Batch:   106] loss: 0.422, acc: 75.522, test_acc:35.000, F1:0.371\n",
            "[Epoch: 231 Batch:   106] loss: 0.373, acc: 74.377, test_acc:40.000, F1:0.423\n",
            "[Epoch: 232 Batch:   106] loss: 0.339, acc: 77.044, test_acc:33.333, F1:0.353\n",
            "[Epoch: 233 Batch:   106] loss: 0.390, acc: 77.019, test_acc:40.000, F1:0.417\n",
            "[Epoch: 234 Batch:   106] loss: 0.389, acc: 75.182, test_acc:40.000, F1:0.416\n",
            "[Epoch: 235 Batch:   106] loss: 0.369, acc: 75.962, test_acc:42.500, F1:0.439\n",
            "[Epoch: 236 Batch:   106] loss: 0.371, acc: 75.635, test_acc:34.167, F1:0.353\n",
            "[Epoch: 237 Batch:   106] loss: 0.351, acc: 75.484, test_acc:45.833, F1:0.477\n",
            "[Epoch: 238 Batch:   106] loss: 0.382, acc: 75.006, test_acc:32.500, F1:0.346\n",
            "[Epoch: 239 Batch:   106] loss: 0.438, acc: 77.082, test_acc:38.333, F1:0.405\n",
            "[Epoch: 240 Batch:   106] loss: 0.389, acc: 75.761, test_acc:40.833, F1:0.422\n",
            "[Epoch: 241 Batch:   106] loss: 0.400, acc: 75.560, test_acc:42.500, F1:0.450\n",
            "[Epoch: 242 Batch:   106] loss: 0.388, acc: 75.975, test_acc:35.000, F1:0.371\n",
            "[Epoch: 243 Batch:   106] loss: 0.358, acc: 76.692, test_acc:35.833, F1:0.383\n",
            "[Epoch: 244 Batch:   106] loss: 0.392, acc: 75.409, test_acc:30.833, F1:0.338\n",
            "[Epoch: 245 Batch:   106] loss: 0.405, acc: 76.239, test_acc:35.000, F1:0.372\n",
            "[Epoch: 246 Batch:   106] loss: 0.379, acc: 76.541, test_acc:35.833, F1:0.379\n",
            "[Epoch: 247 Batch:   106] loss: 0.380, acc: 74.994, test_acc:35.000, F1:0.373\n",
            "[Epoch: 248 Batch:   106] loss: 0.393, acc: 75.761, test_acc:43.333, F1:0.453\n",
            "[Epoch: 249 Batch:   106] loss: 0.367, acc: 75.937, test_acc:31.667, F1:0.335\n",
            "[Epoch: 250 Batch:   106] loss: 0.363, acc: 75.447, test_acc:38.333, F1:0.408\n",
            "[Epoch: 251 Batch:   106] loss: 0.397, acc: 75.069, test_acc:35.833, F1:0.372\n",
            "[Epoch: 252 Batch:   106] loss: 0.376, acc: 76.528, test_acc:35.000, F1:0.380\n",
            "[Epoch: 253 Batch:   106] loss: 0.319, acc: 76.667, test_acc:30.833, F1:0.324\n",
            "[Epoch: 254 Batch:   106] loss: 0.333, acc: 74.981, test_acc:35.833, F1:0.374\n",
            "[Epoch: 255 Batch:   106] loss: 0.366, acc: 75.421, test_acc:30.833, F1:0.320\n",
            "[Epoch: 256 Batch:   106] loss: 0.347, acc: 76.440, test_acc:35.833, F1:0.379\n",
            "[Epoch: 257 Batch:   106] loss: 0.483, acc: 75.220, test_acc:37.500, F1:0.396\n",
            "[Epoch: 258 Batch:   106] loss: 0.439, acc: 76.730, test_acc:40.833, F1:0.430\n",
            "[Epoch: 259 Batch:   106] loss: 0.411, acc: 74.101, test_acc:35.833, F1:0.382\n",
            "[Epoch: 260 Batch:   106] loss: 0.388, acc: 75.346, test_acc:35.000, F1:0.380\n",
            "[Epoch: 261 Batch:   106] loss: 0.426, acc: 75.258, test_acc:35.833, F1:0.366\n",
            "[Epoch: 262 Batch:   106] loss: 0.359, acc: 75.849, test_acc:37.500, F1:0.396\n",
            "[Epoch: 263 Batch:   106] loss: 0.398, acc: 76.000, test_acc:38.333, F1:0.399\n",
            "[Epoch: 264 Batch:   106] loss: 0.451, acc: 75.874, test_acc:35.000, F1:0.369\n",
            "[Epoch: 265 Batch:   106] loss: 0.412, acc: 74.818, test_acc:33.333, F1:0.354\n",
            "[Epoch: 266 Batch:   106] loss: 0.465, acc: 74.314, test_acc:30.000, F1:0.325\n",
            "[Epoch: 267 Batch:   106] loss: 0.449, acc: 74.704, test_acc:36.667, F1:0.379\n",
            "[Epoch: 268 Batch:   106] loss: 0.341, acc: 74.214, test_acc:36.667, F1:0.395\n",
            "[Epoch: 269 Batch:   106] loss: 0.346, acc: 72.214, test_acc:48.333, F1:0.488\n",
            "[Epoch: 270 Batch:   106] loss: 0.375, acc: 75.509, test_acc:37.500, F1:0.387\n",
            "[Epoch: 271 Batch:   106] loss: 0.386, acc: 76.579, test_acc:41.667, F1:0.425\n",
            "[Epoch: 272 Batch:   106] loss: 0.332, acc: 76.478, test_acc:38.333, F1:0.404\n",
            "[Epoch: 273 Batch:   106] loss: 0.325, acc: 75.371, test_acc:39.167, F1:0.423\n",
            "[Epoch: 274 Batch:   106] loss: 0.404, acc: 74.792, test_acc:40.000, F1:0.423\n",
            "[Epoch: 275 Batch:   106] loss: 0.406, acc: 72.742, test_acc:40.000, F1:0.394\n",
            "[Epoch: 276 Batch:   106] loss: 0.356, acc: 75.887, test_acc:37.500, F1:0.391\n",
            "[Epoch: 277 Batch:   106] loss: 0.343, acc: 75.119, test_acc:35.000, F1:0.376\n",
            "[Epoch: 278 Batch:   106] loss: 0.346, acc: 74.692, test_acc:42.500, F1:0.436\n",
            "[Epoch: 279 Batch:   106] loss: 0.363, acc: 74.214, test_acc:39.167, F1:0.420\n",
            "[Epoch: 280 Batch:   106] loss: 0.363, acc: 73.975, test_acc:44.167, F1:0.462\n",
            "[Epoch: 281 Batch:   106] loss: 0.374, acc: 75.987, test_acc:39.167, F1:0.407\n",
            "[Epoch: 282 Batch:   106] loss: 0.358, acc: 76.553, test_acc:33.333, F1:0.344\n",
            "[Epoch: 283 Batch:   106] loss: 0.362, acc: 76.138, test_acc:41.667, F1:0.426\n",
            "[Epoch: 284 Batch:   106] loss: 0.383, acc: 76.440, test_acc:37.500, F1:0.372\n",
            "[Epoch: 285 Batch:   106] loss: 0.387, acc: 74.956, test_acc:37.500, F1:0.401\n",
            "[Epoch: 286 Batch:   106] loss: 0.407, acc: 73.447, test_acc:45.833, F1:0.471\n",
            "[Epoch: 287 Batch:   106] loss: 0.389, acc: 74.465, test_acc:40.000, F1:0.419\n",
            "[Epoch: 288 Batch:   106] loss: 0.452, acc: 74.126, test_acc:39.167, F1:0.399\n",
            "[Epoch: 289 Batch:   106] loss: 0.408, acc: 71.899, test_acc:45.000, F1:0.469\n",
            "[Epoch: 290 Batch:   106] loss: 0.441, acc: 76.503, test_acc:31.667, F1:0.322\n",
            "[Epoch: 291 Batch:   106] loss: 0.436, acc: 74.629, test_acc:42.500, F1:0.440\n",
            "[Epoch: 292 Batch:   106] loss: 0.395, acc: 75.170, test_acc:38.333, F1:0.381\n",
            "[Epoch: 293 Batch:   106] loss: 0.442, acc: 75.321, test_acc:30.000, F1:0.298\n",
            "[Epoch: 294 Batch:   106] loss: 0.369, acc: 75.434, test_acc:45.833, F1:0.471\n",
            "[Epoch: 295 Batch:   106] loss: 0.375, acc: 75.585, test_acc:31.667, F1:0.332\n",
            "[Epoch: 296 Batch:   106] loss: 0.303, acc: 76.478, test_acc:41.667, F1:0.433\n",
            "[Epoch: 297 Batch:   106] loss: 0.350, acc: 74.176, test_acc:41.667, F1:0.431\n",
            "[Epoch: 298 Batch:   106] loss: 0.346, acc: 74.050, test_acc:40.000, F1:0.418\n",
            "[Epoch: 299 Batch:   106] loss: 0.383, acc: 76.038, test_acc:30.833, F1:0.334\n",
            "[Epoch: 300 Batch:   106] loss: 0.337, acc: 76.214, test_acc:40.833, F1:0.418\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  40.833333333333336\n",
            "Test F1 Score : 0.4180454108289361\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.24      0.41      0.30        27\n",
            "         1.0       0.15      0.11      0.13        18\n",
            "         2.0       0.59      0.48      0.53        75\n",
            "\n",
            "    accuracy                           0.41       120\n",
            "   macro avg       0.33      0.33      0.32       120\n",
            "weighted avg       0.45      0.41      0.42       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[11  2 14]\n",
            " [ 5  2 11]\n",
            " [30  9 36]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.1019950866699215 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  8\n",
            "[Epoch: 1 Batch:   106] loss: 1.087, acc: 34.843, test_acc:41.667, F1:0.422\n",
            "[Epoch: 2 Batch:   106] loss: 1.083, acc: 35.497, test_acc:36.667, F1:0.374\n",
            "[Epoch: 3 Batch:   106] loss: 1.078, acc: 34.277, test_acc:35.000, F1:0.356\n",
            "[Epoch: 4 Batch:   106] loss: 1.077, acc: 35.296, test_acc:34.167, F1:0.340\n",
            "[Epoch: 5 Batch:   106] loss: 1.076, acc: 36.428, test_acc:33.333, F1:0.328\n",
            "[Epoch: 6 Batch:   106] loss: 1.074, acc: 36.730, test_acc:40.000, F1:0.391\n",
            "[Epoch: 7 Batch:   106] loss: 1.071, acc: 37.849, test_acc:30.833, F1:0.299\n",
            "[Epoch: 8 Batch:   106] loss: 1.069, acc: 37.182, test_acc:35.833, F1:0.353\n",
            "[Epoch: 9 Batch:   106] loss: 1.068, acc: 38.264, test_acc:36.667, F1:0.365\n",
            "[Epoch: 10 Batch:   106] loss: 1.067, acc: 39.484, test_acc:38.333, F1:0.387\n",
            "[Epoch: 11 Batch:   106] loss: 1.064, acc: 39.044, test_acc:38.333, F1:0.387\n",
            "[Epoch: 12 Batch:   106] loss: 1.062, acc: 39.912, test_acc:37.500, F1:0.373\n",
            "[Epoch: 13 Batch:   106] loss: 1.064, acc: 40.365, test_acc:32.500, F1:0.329\n",
            "[Epoch: 14 Batch:   106] loss: 1.062, acc: 40.075, test_acc:33.333, F1:0.330\n",
            "[Epoch: 15 Batch:   106] loss: 1.058, acc: 41.447, test_acc:39.167, F1:0.390\n",
            "[Epoch: 16 Batch:   106] loss: 1.055, acc: 40.918, test_acc:30.000, F1:0.305\n",
            "[Epoch: 17 Batch:   106] loss: 1.053, acc: 41.811, test_acc:30.833, F1:0.314\n",
            "[Epoch: 18 Batch:   106] loss: 1.053, acc: 41.572, test_acc:40.833, F1:0.418\n",
            "[Epoch: 19 Batch:   106] loss: 1.056, acc: 40.717, test_acc:35.000, F1:0.359\n",
            "[Epoch: 20 Batch:   106] loss: 1.048, acc: 43.522, test_acc:35.833, F1:0.362\n",
            "[Epoch: 21 Batch:   106] loss: 1.047, acc: 44.126, test_acc:34.167, F1:0.345\n",
            "[Epoch: 22 Batch:   106] loss: 1.046, acc: 44.075, test_acc:31.667, F1:0.332\n",
            "[Epoch: 23 Batch:   106] loss: 1.043, acc: 44.000, test_acc:38.333, F1:0.387\n",
            "[Epoch: 24 Batch:   106] loss: 1.042, acc: 45.094, test_acc:30.000, F1:0.307\n",
            "[Epoch: 25 Batch:   106] loss: 1.040, acc: 44.981, test_acc:30.833, F1:0.323\n",
            "[Epoch: 26 Batch:   106] loss: 1.036, acc: 45.459, test_acc:36.667, F1:0.373\n",
            "[Epoch: 27 Batch:   106] loss: 1.033, acc: 45.811, test_acc:36.667, F1:0.375\n",
            "[Epoch: 28 Batch:   106] loss: 1.038, acc: 44.553, test_acc:36.667, F1:0.373\n",
            "[Epoch: 29 Batch:   106] loss: 1.032, acc: 45.572, test_acc:33.333, F1:0.339\n",
            "[Epoch: 30 Batch:   106] loss: 1.033, acc: 46.289, test_acc:35.833, F1:0.356\n",
            "[Epoch: 31 Batch:   106] loss: 1.028, acc: 46.692, test_acc:39.167, F1:0.399\n",
            "[Epoch: 32 Batch:   106] loss: 1.026, acc: 47.006, test_acc:33.333, F1:0.337\n",
            "[Epoch: 33 Batch:   106] loss: 1.028, acc: 46.868, test_acc:30.833, F1:0.320\n",
            "[Epoch: 34 Batch:   106] loss: 1.022, acc: 47.509, test_acc:32.500, F1:0.328\n",
            "[Epoch: 35 Batch:   106] loss: 1.018, acc: 47.321, test_acc:31.667, F1:0.324\n",
            "[Epoch: 36 Batch:   106] loss: 1.017, acc: 47.472, test_acc:33.333, F1:0.342\n",
            "[Epoch: 37 Batch:   106] loss: 1.013, acc: 49.019, test_acc:36.667, F1:0.371\n",
            "[Epoch: 38 Batch:   106] loss: 1.014, acc: 48.818, test_acc:34.167, F1:0.352\n",
            "[Epoch: 39 Batch:   106] loss: 1.008, acc: 49.547, test_acc:33.333, F1:0.344\n",
            "[Epoch: 40 Batch:   106] loss: 1.003, acc: 49.597, test_acc:35.833, F1:0.365\n",
            "[Epoch: 41 Batch:   106] loss: 1.006, acc: 49.421, test_acc:35.833, F1:0.363\n",
            "[Epoch: 42 Batch:   106] loss: 1.008, acc: 48.805, test_acc:32.500, F1:0.334\n",
            "[Epoch: 43 Batch:   106] loss: 1.003, acc: 49.597, test_acc:35.833, F1:0.361\n",
            "[Epoch: 44 Batch:   106] loss: 0.996, acc: 50.176, test_acc:35.833, F1:0.357\n",
            "[Epoch: 45 Batch:   106] loss: 0.991, acc: 51.182, test_acc:35.000, F1:0.353\n",
            "[Epoch: 46 Batch:   106] loss: 0.991, acc: 51.006, test_acc:35.833, F1:0.368\n",
            "[Epoch: 47 Batch:   106] loss: 0.987, acc: 52.440, test_acc:31.667, F1:0.321\n",
            "[Epoch: 48 Batch:   106] loss: 0.987, acc: 52.314, test_acc:34.167, F1:0.348\n",
            "[Epoch: 49 Batch:   106] loss: 0.981, acc: 50.906, test_acc:39.167, F1:0.396\n",
            "[Epoch: 50 Batch:   106] loss: 0.986, acc: 52.176, test_acc:35.833, F1:0.371\n",
            "[Epoch: 51 Batch:   106] loss: 0.976, acc: 51.962, test_acc:30.000, F1:0.308\n",
            "[Epoch: 52 Batch:   106] loss: 0.970, acc: 52.969, test_acc:35.000, F1:0.355\n",
            "[Epoch: 53 Batch:   106] loss: 0.967, acc: 52.667, test_acc:37.500, F1:0.381\n",
            "[Epoch: 54 Batch:   106] loss: 0.961, acc: 53.560, test_acc:32.500, F1:0.337\n",
            "[Epoch: 55 Batch:   106] loss: 0.960, acc: 53.572, test_acc:35.833, F1:0.367\n",
            "[Epoch: 56 Batch:   106] loss: 0.957, acc: 54.164, test_acc:26.667, F1:0.272\n",
            "[Epoch: 57 Batch:   106] loss: 0.949, acc: 55.396, test_acc:31.667, F1:0.327\n",
            "[Epoch: 58 Batch:   106] loss: 0.943, acc: 56.553, test_acc:38.333, F1:0.398\n",
            "[Epoch: 59 Batch:   106] loss: 0.946, acc: 54.692, test_acc:25.833, F1:0.270\n",
            "[Epoch: 60 Batch:   106] loss: 0.938, acc: 54.969, test_acc:34.167, F1:0.354\n",
            "[Epoch: 61 Batch:   106] loss: 0.932, acc: 56.780, test_acc:31.667, F1:0.322\n",
            "[Epoch: 62 Batch:   106] loss: 0.929, acc: 56.327, test_acc:31.667, F1:0.322\n",
            "[Epoch: 63 Batch:   106] loss: 0.924, acc: 56.868, test_acc:35.833, F1:0.364\n",
            "[Epoch: 64 Batch:   106] loss: 0.905, acc: 57.711, test_acc:39.167, F1:0.400\n",
            "[Epoch: 65 Batch:   106] loss: 0.906, acc: 57.333, test_acc:32.500, F1:0.339\n",
            "[Epoch: 66 Batch:   106] loss: 0.907, acc: 57.396, test_acc:30.833, F1:0.319\n",
            "[Epoch: 67 Batch:   106] loss: 0.905, acc: 58.226, test_acc:34.167, F1:0.357\n",
            "[Epoch: 68 Batch:   106] loss: 0.895, acc: 59.094, test_acc:30.833, F1:0.320\n",
            "[Epoch: 69 Batch:   106] loss: 0.890, acc: 59.899, test_acc:29.167, F1:0.306\n",
            "[Epoch: 70 Batch:   106] loss: 0.884, acc: 59.421, test_acc:31.667, F1:0.326\n",
            "[Epoch: 71 Batch:   106] loss: 0.885, acc: 59.585, test_acc:38.333, F1:0.397\n",
            "[Epoch: 72 Batch:   106] loss: 0.885, acc: 59.484, test_acc:39.167, F1:0.410\n",
            "[Epoch: 73 Batch:   106] loss: 0.866, acc: 60.629, test_acc:31.667, F1:0.330\n",
            "[Epoch: 74 Batch:   106] loss: 0.860, acc: 61.711, test_acc:34.167, F1:0.356\n",
            "[Epoch: 75 Batch:   106] loss: 0.852, acc: 62.893, test_acc:32.500, F1:0.334\n",
            "[Epoch: 76 Batch:   106] loss: 0.846, acc: 62.063, test_acc:29.167, F1:0.300\n",
            "[Epoch: 77 Batch:   106] loss: 0.858, acc: 62.214, test_acc:38.333, F1:0.393\n",
            "[Epoch: 78 Batch:   106] loss: 0.846, acc: 62.604, test_acc:30.833, F1:0.319\n",
            "[Epoch: 79 Batch:   106] loss: 0.842, acc: 63.774, test_acc:35.833, F1:0.367\n",
            "[Epoch: 80 Batch:   106] loss: 0.828, acc: 63.119, test_acc:30.000, F1:0.304\n",
            "[Epoch: 81 Batch:   106] loss: 0.824, acc: 63.648, test_acc:35.000, F1:0.355\n",
            "[Epoch: 82 Batch:   106] loss: 0.830, acc: 64.906, test_acc:24.167, F1:0.249\n",
            "[Epoch: 83 Batch:   106] loss: 0.826, acc: 64.327, test_acc:35.000, F1:0.356\n",
            "[Epoch: 84 Batch:   106] loss: 0.815, acc: 66.101, test_acc:32.500, F1:0.337\n",
            "[Epoch: 85 Batch:   106] loss: 0.792, acc: 66.717, test_acc:35.833, F1:0.365\n",
            "[Epoch: 86 Batch:   106] loss: 0.800, acc: 66.717, test_acc:30.833, F1:0.315\n",
            "[Epoch: 87 Batch:   106] loss: 0.791, acc: 65.799, test_acc:35.833, F1:0.364\n",
            "[Epoch: 88 Batch:   106] loss: 0.801, acc: 66.352, test_acc:35.000, F1:0.359\n",
            "[Epoch: 89 Batch:   106] loss: 0.802, acc: 66.755, test_acc:30.000, F1:0.300\n",
            "[Epoch: 90 Batch:   106] loss: 0.775, acc: 65.887, test_acc:39.167, F1:0.397\n",
            "[Epoch: 91 Batch:   106] loss: 0.779, acc: 66.654, test_acc:35.833, F1:0.364\n",
            "[Epoch: 92 Batch:   106] loss: 0.763, acc: 67.535, test_acc:32.500, F1:0.329\n",
            "[Epoch: 93 Batch:   106] loss: 0.752, acc: 67.723, test_acc:34.167, F1:0.354\n",
            "[Epoch: 94 Batch:   106] loss: 0.754, acc: 69.346, test_acc:32.500, F1:0.328\n",
            "[Epoch: 95 Batch:   106] loss: 0.758, acc: 68.516, test_acc:39.167, F1:0.394\n",
            "[Epoch: 96 Batch:   106] loss: 0.759, acc: 68.025, test_acc:37.500, F1:0.377\n",
            "[Epoch: 97 Batch:   106] loss: 0.744, acc: 67.836, test_acc:32.500, F1:0.333\n",
            "[Epoch: 98 Batch:   106] loss: 0.722, acc: 69.132, test_acc:37.500, F1:0.379\n",
            "[Epoch: 99 Batch:   106] loss: 0.735, acc: 67.786, test_acc:31.667, F1:0.325\n",
            "[Epoch: 100 Batch:   106] loss: 0.722, acc: 68.566, test_acc:35.833, F1:0.366\n",
            "[Epoch: 101 Batch:   106] loss: 0.739, acc: 69.019, test_acc:30.833, F1:0.313\n",
            "[Epoch: 102 Batch:   106] loss: 0.735, acc: 68.931, test_acc:32.500, F1:0.332\n",
            "[Epoch: 103 Batch:   106] loss: 0.720, acc: 70.176, test_acc:32.500, F1:0.333\n",
            "[Epoch: 104 Batch:   106] loss: 0.717, acc: 69.811, test_acc:29.167, F1:0.298\n",
            "[Epoch: 105 Batch:   106] loss: 0.714, acc: 69.912, test_acc:35.000, F1:0.358\n",
            "[Epoch: 106 Batch:   106] loss: 0.720, acc: 68.025, test_acc:30.000, F1:0.302\n",
            "[Epoch: 107 Batch:   106] loss: 0.686, acc: 70.403, test_acc:36.667, F1:0.365\n",
            "[Epoch: 108 Batch:   106] loss: 0.688, acc: 71.585, test_acc:32.500, F1:0.330\n",
            "[Epoch: 109 Batch:   106] loss: 0.693, acc: 70.327, test_acc:34.167, F1:0.349\n",
            "[Epoch: 110 Batch:   106] loss: 0.681, acc: 71.811, test_acc:35.000, F1:0.357\n",
            "[Epoch: 111 Batch:   106] loss: 0.678, acc: 71.484, test_acc:35.833, F1:0.359\n",
            "[Epoch: 112 Batch:   106] loss: 0.664, acc: 71.258, test_acc:31.667, F1:0.321\n",
            "[Epoch: 113 Batch:   106] loss: 0.669, acc: 72.239, test_acc:35.000, F1:0.357\n",
            "[Epoch: 114 Batch:   106] loss: 0.664, acc: 69.887, test_acc:28.333, F1:0.293\n",
            "[Epoch: 115 Batch:   106] loss: 0.689, acc: 71.472, test_acc:30.000, F1:0.298\n",
            "[Epoch: 116 Batch:   106] loss: 0.657, acc: 72.377, test_acc:34.167, F1:0.345\n",
            "[Epoch: 117 Batch:   106] loss: 0.654, acc: 71.862, test_acc:38.333, F1:0.390\n",
            "[Epoch: 118 Batch:   106] loss: 0.651, acc: 71.447, test_acc:31.667, F1:0.322\n",
            "[Epoch: 119 Batch:   106] loss: 0.636, acc: 72.302, test_acc:33.333, F1:0.340\n",
            "[Epoch: 120 Batch:   106] loss: 0.623, acc: 73.447, test_acc:34.167, F1:0.344\n",
            "[Epoch: 121 Batch:   106] loss: 0.649, acc: 72.365, test_acc:29.167, F1:0.299\n",
            "[Epoch: 122 Batch:   106] loss: 0.635, acc: 72.352, test_acc:35.833, F1:0.356\n",
            "[Epoch: 123 Batch:   106] loss: 0.620, acc: 73.874, test_acc:30.000, F1:0.308\n",
            "[Epoch: 124 Batch:   106] loss: 0.631, acc: 71.321, test_acc:33.333, F1:0.338\n",
            "[Epoch: 125 Batch:   106] loss: 0.637, acc: 72.088, test_acc:38.333, F1:0.384\n",
            "[Epoch: 126 Batch:   106] loss: 0.606, acc: 72.616, test_acc:28.333, F1:0.288\n",
            "[Epoch: 127 Batch:   106] loss: 0.601, acc: 72.541, test_acc:34.167, F1:0.345\n",
            "[Epoch: 128 Batch:   106] loss: 0.592, acc: 73.811, test_acc:31.667, F1:0.325\n",
            "[Epoch: 129 Batch:   106] loss: 0.597, acc: 74.025, test_acc:32.500, F1:0.329\n",
            "[Epoch: 130 Batch:   106] loss: 0.605, acc: 73.547, test_acc:29.167, F1:0.298\n",
            "[Epoch: 131 Batch:   106] loss: 0.602, acc: 74.440, test_acc:34.167, F1:0.351\n",
            "[Epoch: 132 Batch:   106] loss: 0.584, acc: 73.874, test_acc:33.333, F1:0.338\n",
            "[Epoch: 133 Batch:   106] loss: 0.597, acc: 73.447, test_acc:36.667, F1:0.370\n",
            "[Epoch: 134 Batch:   106] loss: 0.560, acc: 74.101, test_acc:37.500, F1:0.375\n",
            "[Epoch: 135 Batch:   106] loss: 0.567, acc: 74.792, test_acc:35.000, F1:0.353\n",
            "[Epoch: 136 Batch:   106] loss: 0.576, acc: 74.440, test_acc:37.500, F1:0.378\n",
            "[Epoch: 137 Batch:   106] loss: 0.585, acc: 74.943, test_acc:30.833, F1:0.311\n",
            "[Epoch: 138 Batch:   106] loss: 0.572, acc: 74.629, test_acc:31.667, F1:0.321\n",
            "[Epoch: 139 Batch:   106] loss: 0.601, acc: 74.893, test_acc:36.667, F1:0.368\n",
            "[Epoch: 140 Batch:   106] loss: 0.565, acc: 74.151, test_acc:30.833, F1:0.316\n",
            "[Epoch: 141 Batch:   106] loss: 0.568, acc: 73.975, test_acc:35.000, F1:0.353\n",
            "[Epoch: 142 Batch:   106] loss: 0.560, acc: 74.327, test_acc:35.833, F1:0.354\n",
            "[Epoch: 143 Batch:   106] loss: 0.549, acc: 73.849, test_acc:34.167, F1:0.348\n",
            "[Epoch: 144 Batch:   106] loss: 0.532, acc: 75.849, test_acc:30.833, F1:0.303\n",
            "[Epoch: 145 Batch:   106] loss: 0.576, acc: 73.623, test_acc:35.833, F1:0.362\n",
            "[Epoch: 146 Batch:   106] loss: 0.552, acc: 74.717, test_acc:35.000, F1:0.355\n",
            "[Epoch: 147 Batch:   106] loss: 0.537, acc: 74.050, test_acc:28.333, F1:0.285\n",
            "[Epoch: 148 Batch:   106] loss: 0.511, acc: 74.579, test_acc:30.833, F1:0.312\n",
            "[Epoch: 149 Batch:   106] loss: 0.554, acc: 75.358, test_acc:30.833, F1:0.315\n",
            "[Epoch: 150 Batch:   106] loss: 0.529, acc: 74.893, test_acc:28.333, F1:0.285\n",
            "[Epoch: 151 Batch:   106] loss: 0.543, acc: 75.673, test_acc:31.667, F1:0.323\n",
            "[Epoch: 152 Batch:   106] loss: 0.522, acc: 75.006, test_acc:37.500, F1:0.385\n",
            "[Epoch: 153 Batch:   106] loss: 0.592, acc: 72.692, test_acc:27.500, F1:0.281\n",
            "[Epoch: 154 Batch:   106] loss: 0.540, acc: 72.956, test_acc:29.167, F1:0.296\n",
            "[Epoch: 155 Batch:   106] loss: 0.506, acc: 75.396, test_acc:31.667, F1:0.317\n",
            "[Epoch: 156 Batch:   106] loss: 0.530, acc: 75.824, test_acc:30.833, F1:0.310\n",
            "[Epoch: 157 Batch:   106] loss: 0.539, acc: 73.145, test_acc:30.833, F1:0.316\n",
            "[Epoch: 158 Batch:   106] loss: 0.493, acc: 72.893, test_acc:32.500, F1:0.332\n",
            "[Epoch: 159 Batch:   106] loss: 0.501, acc: 75.308, test_acc:27.500, F1:0.279\n",
            "[Epoch: 160 Batch:   106] loss: 0.491, acc: 75.862, test_acc:30.000, F1:0.310\n",
            "[Epoch: 161 Batch:   106] loss: 0.500, acc: 76.365, test_acc:31.667, F1:0.325\n",
            "[Epoch: 162 Batch:   106] loss: 0.516, acc: 73.761, test_acc:30.000, F1:0.303\n",
            "[Epoch: 163 Batch:   106] loss: 0.495, acc: 75.509, test_acc:25.000, F1:0.261\n",
            "[Epoch: 164 Batch:   106] loss: 0.477, acc: 75.560, test_acc:29.167, F1:0.294\n",
            "[Epoch: 165 Batch:   106] loss: 0.497, acc: 75.899, test_acc:31.667, F1:0.320\n",
            "[Epoch: 166 Batch:   106] loss: 0.473, acc: 74.113, test_acc:34.167, F1:0.335\n",
            "[Epoch: 167 Batch:   106] loss: 0.443, acc: 76.000, test_acc:33.333, F1:0.321\n",
            "[Epoch: 168 Batch:   106] loss: 0.513, acc: 75.409, test_acc:29.167, F1:0.291\n",
            "[Epoch: 169 Batch:   106] loss: 0.504, acc: 73.799, test_acc:33.333, F1:0.339\n",
            "[Epoch: 170 Batch:   106] loss: 0.485, acc: 75.208, test_acc:33.333, F1:0.335\n",
            "[Epoch: 171 Batch:   106] loss: 0.459, acc: 76.730, test_acc:35.000, F1:0.337\n",
            "[Epoch: 172 Batch:   106] loss: 0.449, acc: 76.113, test_acc:33.333, F1:0.343\n",
            "[Epoch: 173 Batch:   106] loss: 0.502, acc: 73.887, test_acc:30.833, F1:0.320\n",
            "[Epoch: 174 Batch:   106] loss: 0.475, acc: 75.484, test_acc:34.167, F1:0.338\n",
            "[Epoch: 175 Batch:   106] loss: 0.446, acc: 74.780, test_acc:34.167, F1:0.341\n",
            "[Epoch: 176 Batch:   106] loss: 0.435, acc: 75.421, test_acc:32.500, F1:0.330\n",
            "[Epoch: 177 Batch:   106] loss: 0.476, acc: 75.836, test_acc:30.833, F1:0.306\n",
            "[Epoch: 178 Batch:   106] loss: 0.443, acc: 77.774, test_acc:31.667, F1:0.323\n",
            "[Epoch: 179 Batch:   106] loss: 0.428, acc: 77.748, test_acc:30.000, F1:0.304\n",
            "[Epoch: 180 Batch:   106] loss: 0.424, acc: 76.126, test_acc:31.667, F1:0.322\n",
            "[Epoch: 181 Batch:   106] loss: 0.432, acc: 75.145, test_acc:30.833, F1:0.310\n",
            "[Epoch: 182 Batch:   106] loss: 0.448, acc: 73.723, test_acc:30.000, F1:0.302\n",
            "[Epoch: 183 Batch:   106] loss: 0.494, acc: 75.623, test_acc:29.167, F1:0.295\n",
            "[Epoch: 184 Batch:   106] loss: 0.423, acc: 77.409, test_acc:31.667, F1:0.312\n",
            "[Epoch: 185 Batch:   106] loss: 0.406, acc: 75.019, test_acc:27.500, F1:0.281\n",
            "[Epoch: 186 Batch:   106] loss: 0.431, acc: 75.208, test_acc:28.333, F1:0.289\n",
            "[Epoch: 187 Batch:   106] loss: 0.441, acc: 74.566, test_acc:30.000, F1:0.303\n",
            "[Epoch: 188 Batch:   106] loss: 0.459, acc: 76.566, test_acc:30.833, F1:0.310\n",
            "[Epoch: 189 Batch:   106] loss: 0.462, acc: 75.698, test_acc:26.667, F1:0.270\n",
            "[Epoch: 190 Batch:   106] loss: 0.442, acc: 74.264, test_acc:28.333, F1:0.281\n",
            "[Epoch: 191 Batch:   106] loss: 0.409, acc: 77.220, test_acc:30.833, F1:0.318\n",
            "[Epoch: 192 Batch:   106] loss: 0.406, acc: 77.006, test_acc:34.167, F1:0.345\n",
            "[Epoch: 193 Batch:   106] loss: 0.444, acc: 77.308, test_acc:34.167, F1:0.346\n",
            "[Epoch: 194 Batch:   106] loss: 0.469, acc: 75.082, test_acc:36.667, F1:0.369\n",
            "[Epoch: 195 Batch:   106] loss: 0.435, acc: 76.503, test_acc:28.333, F1:0.279\n",
            "[Epoch: 196 Batch:   106] loss: 0.429, acc: 75.686, test_acc:33.333, F1:0.334\n",
            "[Epoch: 197 Batch:   106] loss: 0.421, acc: 75.484, test_acc:31.667, F1:0.311\n",
            "[Epoch: 198 Batch:   106] loss: 0.439, acc: 73.308, test_acc:34.167, F1:0.348\n",
            "[Epoch: 199 Batch:   106] loss: 0.434, acc: 77.182, test_acc:29.167, F1:0.286\n",
            "[Epoch: 200 Batch:   106] loss: 0.410, acc: 73.962, test_acc:28.333, F1:0.269\n",
            "[Epoch: 201 Batch:   106] loss: 0.441, acc: 76.063, test_acc:24.167, F1:0.254\n",
            "[Epoch: 202 Batch:   106] loss: 0.454, acc: 75.220, test_acc:30.833, F1:0.303\n",
            "[Epoch: 203 Batch:   106] loss: 0.413, acc: 76.616, test_acc:30.833, F1:0.310\n",
            "[Epoch: 204 Batch:   106] loss: 0.410, acc: 76.478, test_acc:29.167, F1:0.281\n",
            "[Epoch: 205 Batch:   106] loss: 0.427, acc: 75.484, test_acc:31.667, F1:0.325\n",
            "[Epoch: 206 Batch:   106] loss: 0.391, acc: 76.289, test_acc:31.667, F1:0.324\n",
            "[Epoch: 207 Batch:   106] loss: 0.407, acc: 76.101, test_acc:25.833, F1:0.275\n",
            "[Epoch: 208 Batch:   106] loss: 0.405, acc: 75.560, test_acc:30.000, F1:0.294\n",
            "[Epoch: 209 Batch:   106] loss: 0.422, acc: 78.314, test_acc:30.833, F1:0.325\n",
            "[Epoch: 210 Batch:   106] loss: 0.441, acc: 75.849, test_acc:34.167, F1:0.345\n",
            "[Epoch: 211 Batch:   106] loss: 0.415, acc: 75.623, test_acc:31.667, F1:0.309\n",
            "[Epoch: 212 Batch:   106] loss: 0.363, acc: 76.780, test_acc:30.000, F1:0.296\n",
            "[Epoch: 213 Batch:   106] loss: 0.378, acc: 76.692, test_acc:34.167, F1:0.308\n",
            "[Epoch: 214 Batch:   106] loss: 0.393, acc: 76.956, test_acc:30.000, F1:0.303\n",
            "[Epoch: 215 Batch:   106] loss: 0.407, acc: 77.057, test_acc:31.667, F1:0.316\n",
            "[Epoch: 216 Batch:   106] loss: 0.381, acc: 76.780, test_acc:26.667, F1:0.277\n",
            "[Epoch: 217 Batch:   106] loss: 0.363, acc: 76.654, test_acc:31.667, F1:0.313\n",
            "[Epoch: 218 Batch:   106] loss: 0.407, acc: 77.811, test_acc:33.333, F1:0.330\n",
            "[Epoch: 219 Batch:   106] loss: 0.377, acc: 77.660, test_acc:30.000, F1:0.307\n",
            "[Epoch: 220 Batch:   106] loss: 0.379, acc: 76.164, test_acc:30.000, F1:0.296\n",
            "[Epoch: 221 Batch:   106] loss: 0.409, acc: 76.943, test_acc:33.333, F1:0.339\n",
            "[Epoch: 222 Batch:   106] loss: 0.398, acc: 79.195, test_acc:30.833, F1:0.315\n",
            "[Epoch: 223 Batch:   106] loss: 0.413, acc: 75.384, test_acc:32.500, F1:0.322\n",
            "[Epoch: 224 Batch:   106] loss: 0.340, acc: 76.667, test_acc:31.667, F1:0.299\n",
            "[Epoch: 225 Batch:   106] loss: 0.312, acc: 76.969, test_acc:30.000, F1:0.303\n",
            "[Epoch: 226 Batch:   106] loss: 0.416, acc: 75.245, test_acc:30.000, F1:0.307\n",
            "[Epoch: 227 Batch:   106] loss: 0.353, acc: 78.377, test_acc:32.500, F1:0.307\n",
            "[Epoch: 228 Batch:   106] loss: 0.419, acc: 76.352, test_acc:31.667, F1:0.318\n",
            "[Epoch: 229 Batch:   106] loss: 0.360, acc: 77.497, test_acc:30.833, F1:0.319\n",
            "[Epoch: 230 Batch:   106] loss: 0.441, acc: 76.226, test_acc:30.833, F1:0.316\n",
            "[Epoch: 231 Batch:   106] loss: 0.345, acc: 77.434, test_acc:30.833, F1:0.290\n",
            "[Epoch: 232 Batch:   106] loss: 0.344, acc: 78.201, test_acc:34.167, F1:0.313\n",
            "[Epoch: 233 Batch:   106] loss: 0.340, acc: 77.321, test_acc:26.667, F1:0.271\n",
            "[Epoch: 234 Batch:   106] loss: 0.331, acc: 76.528, test_acc:27.500, F1:0.277\n",
            "[Epoch: 235 Batch:   106] loss: 0.343, acc: 78.956, test_acc:30.833, F1:0.300\n",
            "[Epoch: 236 Batch:   106] loss: 0.347, acc: 78.050, test_acc:31.667, F1:0.325\n",
            "[Epoch: 237 Batch:   106] loss: 0.400, acc: 75.006, test_acc:30.000, F1:0.297\n",
            "[Epoch: 238 Batch:   106] loss: 0.390, acc: 76.516, test_acc:25.833, F1:0.265\n",
            "[Epoch: 239 Batch:   106] loss: 0.359, acc: 75.711, test_acc:24.167, F1:0.243\n",
            "[Epoch: 240 Batch:   106] loss: 0.388, acc: 78.465, test_acc:27.500, F1:0.274\n",
            "[Epoch: 241 Batch:   106] loss: 0.420, acc: 75.560, test_acc:32.500, F1:0.312\n",
            "[Epoch: 242 Batch:   106] loss: 0.428, acc: 75.937, test_acc:30.000, F1:0.303\n",
            "[Epoch: 243 Batch:   106] loss: 0.409, acc: 77.421, test_acc:32.500, F1:0.309\n",
            "[Epoch: 244 Batch:   106] loss: 0.411, acc: 75.170, test_acc:31.667, F1:0.296\n",
            "[Epoch: 245 Batch:   106] loss: 0.484, acc: 74.365, test_acc:31.667, F1:0.252\n",
            "[Epoch: 246 Batch:   106] loss: 0.419, acc: 77.698, test_acc:28.333, F1:0.268\n",
            "[Epoch: 247 Batch:   106] loss: 0.354, acc: 77.786, test_acc:32.500, F1:0.297\n",
            "[Epoch: 248 Batch:   106] loss: 0.402, acc: 76.428, test_acc:20.000, F1:0.206\n",
            "[Epoch: 249 Batch:   106] loss: 0.416, acc: 78.855, test_acc:29.167, F1:0.273\n",
            "[Epoch: 250 Batch:   106] loss: 0.415, acc: 78.390, test_acc:30.833, F1:0.304\n",
            "[Epoch: 251 Batch:   106] loss: 0.379, acc: 76.453, test_acc:31.667, F1:0.316\n",
            "[Epoch: 252 Batch:   106] loss: 0.442, acc: 75.547, test_acc:28.333, F1:0.282\n",
            "[Epoch: 253 Batch:   106] loss: 0.430, acc: 75.031, test_acc:29.167, F1:0.301\n",
            "[Epoch: 254 Batch:   106] loss: 0.364, acc: 79.547, test_acc:29.167, F1:0.301\n",
            "[Epoch: 255 Batch:   106] loss: 0.375, acc: 76.730, test_acc:28.333, F1:0.294\n",
            "[Epoch: 256 Batch:   106] loss: 0.418, acc: 75.585, test_acc:32.500, F1:0.336\n",
            "[Epoch: 257 Batch:   106] loss: 0.320, acc: 78.063, test_acc:34.167, F1:0.338\n",
            "[Epoch: 258 Batch:   106] loss: 0.407, acc: 78.491, test_acc:34.167, F1:0.314\n",
            "[Epoch: 259 Batch:   106] loss: 0.428, acc: 76.616, test_acc:31.667, F1:0.307\n",
            "[Epoch: 260 Batch:   106] loss: 0.376, acc: 77.245, test_acc:30.000, F1:0.278\n",
            "[Epoch: 261 Batch:   106] loss: 0.542, acc: 75.623, test_acc:29.167, F1:0.284\n",
            "[Epoch: 262 Batch:   106] loss: 0.432, acc: 77.094, test_acc:34.167, F1:0.326\n",
            "[Epoch: 263 Batch:   106] loss: 0.406, acc: 75.245, test_acc:31.667, F1:0.300\n",
            "[Epoch: 264 Batch:   106] loss: 0.361, acc: 76.088, test_acc:35.833, F1:0.352\n",
            "[Epoch: 265 Batch:   106] loss: 0.328, acc: 76.679, test_acc:28.333, F1:0.269\n",
            "[Epoch: 266 Batch:   106] loss: 0.395, acc: 77.258, test_acc:28.333, F1:0.297\n",
            "[Epoch: 267 Batch:   106] loss: 0.355, acc: 75.799, test_acc:34.167, F1:0.307\n",
            "[Epoch: 268 Batch:   106] loss: 0.325, acc: 79.472, test_acc:27.500, F1:0.258\n",
            "[Epoch: 269 Batch:   106] loss: 0.361, acc: 77.031, test_acc:25.833, F1:0.263\n",
            "[Epoch: 270 Batch:   106] loss: 0.359, acc: 78.981, test_acc:30.000, F1:0.273\n",
            "[Epoch: 271 Batch:   106] loss: 0.328, acc: 78.503, test_acc:35.000, F1:0.307\n",
            "[Epoch: 272 Batch:   106] loss: 0.305, acc: 78.855, test_acc:31.667, F1:0.320\n",
            "[Epoch: 273 Batch:   106] loss: 0.446, acc: 73.572, test_acc:38.333, F1:0.373\n",
            "[Epoch: 274 Batch:   106] loss: 0.363, acc: 75.874, test_acc:33.333, F1:0.288\n",
            "[Epoch: 275 Batch:   106] loss: 0.343, acc: 79.975, test_acc:27.500, F1:0.267\n",
            "[Epoch: 276 Batch:   106] loss: 0.440, acc: 78.956, test_acc:26.667, F1:0.269\n",
            "[Epoch: 277 Batch:   106] loss: 0.429, acc: 75.572, test_acc:32.500, F1:0.324\n",
            "[Epoch: 278 Batch:   106] loss: 0.366, acc: 78.377, test_acc:34.167, F1:0.354\n",
            "[Epoch: 279 Batch:   106] loss: 0.392, acc: 76.113, test_acc:30.833, F1:0.279\n",
            "[Epoch: 280 Batch:   106] loss: 0.394, acc: 76.226, test_acc:30.000, F1:0.284\n",
            "[Epoch: 281 Batch:   106] loss: 0.360, acc: 79.094, test_acc:33.333, F1:0.263\n",
            "[Epoch: 282 Batch:   106] loss: 0.397, acc: 77.912, test_acc:30.000, F1:0.315\n",
            "[Epoch: 283 Batch:   106] loss: 0.428, acc: 77.736, test_acc:34.167, F1:0.326\n",
            "[Epoch: 284 Batch:   106] loss: 0.417, acc: 77.560, test_acc:23.333, F1:0.218\n",
            "[Epoch: 285 Batch:   106] loss: 0.375, acc: 74.730, test_acc:25.833, F1:0.248\n",
            "[Epoch: 286 Batch:   106] loss: 0.384, acc: 78.730, test_acc:30.000, F1:0.304\n",
            "[Epoch: 287 Batch:   106] loss: 0.324, acc: 77.321, test_acc:30.833, F1:0.308\n",
            "[Epoch: 288 Batch:   106] loss: 0.316, acc: 76.994, test_acc:28.333, F1:0.280\n",
            "[Epoch: 289 Batch:   106] loss: 0.393, acc: 76.302, test_acc:35.000, F1:0.351\n",
            "[Epoch: 290 Batch:   106] loss: 0.382, acc: 77.270, test_acc:33.333, F1:0.277\n",
            "[Epoch: 291 Batch:   106] loss: 0.345, acc: 77.786, test_acc:33.333, F1:0.345\n",
            "[Epoch: 292 Batch:   106] loss: 0.431, acc: 75.975, test_acc:31.667, F1:0.283\n",
            "[Epoch: 293 Batch:   106] loss: 0.373, acc: 75.874, test_acc:27.500, F1:0.283\n",
            "[Epoch: 294 Batch:   106] loss: 0.355, acc: 77.748, test_acc:32.500, F1:0.277\n",
            "[Epoch: 295 Batch:   106] loss: 0.378, acc: 77.484, test_acc:28.333, F1:0.246\n",
            "[Epoch: 296 Batch:   106] loss: 0.426, acc: 77.648, test_acc:30.000, F1:0.294\n",
            "[Epoch: 297 Batch:   106] loss: 0.445, acc: 76.465, test_acc:35.000, F1:0.266\n",
            "[Epoch: 298 Batch:   106] loss: 0.415, acc: 76.226, test_acc:32.500, F1:0.294\n",
            "[Epoch: 299 Batch:   106] loss: 0.369, acc: 77.245, test_acc:34.167, F1:0.308\n",
            "[Epoch: 300 Batch:   106] loss: 0.387, acc: 76.579, test_acc:34.167, F1:0.294\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  34.166666666666664\n",
            "Test F1 Score : 0.29412066752246463\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.19      0.29      0.23        24\n",
            "         1.0       0.44      0.63      0.52        51\n",
            "         2.0       0.17      0.04      0.07        45\n",
            "\n",
            "    accuracy                           0.34       120\n",
            "   macro avg       0.27      0.32      0.27       120\n",
            "weighted avg       0.29      0.34      0.29       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[ 7 12  5]\n",
            " [14 32  5]\n",
            " [15 28  2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.118823556105296 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  9\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 37.547, test_acc:30.000, F1:0.304\n",
            "[Epoch: 2 Batch:   106] loss: 1.084, acc: 39.346, test_acc:32.500, F1:0.324\n",
            "[Epoch: 3 Batch:   106] loss: 1.079, acc: 38.604, test_acc:34.167, F1:0.345\n",
            "[Epoch: 4 Batch:   106] loss: 1.074, acc: 38.239, test_acc:39.167, F1:0.392\n",
            "[Epoch: 5 Batch:   106] loss: 1.073, acc: 38.616, test_acc:35.000, F1:0.354\n",
            "[Epoch: 6 Batch:   106] loss: 1.071, acc: 39.925, test_acc:35.833, F1:0.364\n",
            "[Epoch: 7 Batch:   106] loss: 1.068, acc: 38.629, test_acc:36.667, F1:0.369\n",
            "[Epoch: 8 Batch:   106] loss: 1.068, acc: 38.453, test_acc:37.500, F1:0.377\n",
            "[Epoch: 9 Batch:   106] loss: 1.067, acc: 38.314, test_acc:33.333, F1:0.337\n",
            "[Epoch: 10 Batch:   106] loss: 1.066, acc: 40.277, test_acc:35.833, F1:0.356\n",
            "[Epoch: 11 Batch:   106] loss: 1.065, acc: 40.314, test_acc:32.500, F1:0.325\n",
            "[Epoch: 12 Batch:   106] loss: 1.063, acc: 38.830, test_acc:35.000, F1:0.351\n",
            "[Epoch: 13 Batch:   106] loss: 1.059, acc: 41.283, test_acc:30.833, F1:0.306\n",
            "[Epoch: 14 Batch:   106] loss: 1.063, acc: 39.623, test_acc:33.333, F1:0.336\n",
            "[Epoch: 15 Batch:   106] loss: 1.058, acc: 40.314, test_acc:30.833, F1:0.308\n",
            "[Epoch: 16 Batch:   106] loss: 1.057, acc: 40.164, test_acc:33.333, F1:0.333\n",
            "[Epoch: 17 Batch:   106] loss: 1.058, acc: 40.566, test_acc:31.667, F1:0.316\n",
            "[Epoch: 18 Batch:   106] loss: 1.053, acc: 42.201, test_acc:31.667, F1:0.318\n",
            "[Epoch: 19 Batch:   106] loss: 1.052, acc: 41.321, test_acc:32.500, F1:0.321\n",
            "[Epoch: 20 Batch:   106] loss: 1.054, acc: 41.660, test_acc:30.833, F1:0.305\n",
            "[Epoch: 21 Batch:   106] loss: 1.051, acc: 42.717, test_acc:33.333, F1:0.333\n",
            "[Epoch: 22 Batch:   106] loss: 1.048, acc: 43.358, test_acc:30.000, F1:0.296\n",
            "[Epoch: 23 Batch:   106] loss: 1.046, acc: 43.170, test_acc:30.000, F1:0.291\n",
            "[Epoch: 24 Batch:   106] loss: 1.047, acc: 42.528, test_acc:30.000, F1:0.294\n",
            "[Epoch: 25 Batch:   106] loss: 1.039, acc: 43.094, test_acc:35.000, F1:0.347\n",
            "[Epoch: 26 Batch:   106] loss: 1.043, acc: 45.019, test_acc:33.333, F1:0.327\n",
            "[Epoch: 27 Batch:   106] loss: 1.039, acc: 44.792, test_acc:35.833, F1:0.341\n",
            "[Epoch: 28 Batch:   106] loss: 1.039, acc: 44.730, test_acc:35.000, F1:0.347\n",
            "[Epoch: 29 Batch:   106] loss: 1.031, acc: 45.132, test_acc:29.167, F1:0.295\n",
            "[Epoch: 30 Batch:   106] loss: 1.034, acc: 46.440, test_acc:35.000, F1:0.344\n",
            "[Epoch: 31 Batch:   106] loss: 1.034, acc: 45.623, test_acc:33.333, F1:0.329\n",
            "[Epoch: 32 Batch:   106] loss: 1.033, acc: 46.453, test_acc:41.667, F1:0.396\n",
            "[Epoch: 33 Batch:   106] loss: 1.030, acc: 44.981, test_acc:30.833, F1:0.303\n",
            "[Epoch: 34 Batch:   106] loss: 1.025, acc: 47.019, test_acc:35.833, F1:0.360\n",
            "[Epoch: 35 Batch:   106] loss: 1.025, acc: 46.704, test_acc:35.833, F1:0.351\n",
            "[Epoch: 36 Batch:   106] loss: 1.020, acc: 48.327, test_acc:36.667, F1:0.368\n",
            "[Epoch: 37 Batch:   106] loss: 1.016, acc: 48.465, test_acc:39.167, F1:0.390\n",
            "[Epoch: 38 Batch:   106] loss: 1.020, acc: 46.579, test_acc:40.000, F1:0.392\n",
            "[Epoch: 39 Batch:   106] loss: 1.017, acc: 47.132, test_acc:29.167, F1:0.285\n",
            "[Epoch: 40 Batch:   106] loss: 1.016, acc: 48.365, test_acc:38.333, F1:0.381\n",
            "[Epoch: 41 Batch:   106] loss: 1.011, acc: 48.755, test_acc:43.333, F1:0.425\n",
            "[Epoch: 42 Batch:   106] loss: 1.007, acc: 48.239, test_acc:40.000, F1:0.398\n",
            "[Epoch: 43 Batch:   106] loss: 1.007, acc: 49.283, test_acc:37.500, F1:0.376\n",
            "[Epoch: 44 Batch:   106] loss: 1.010, acc: 49.975, test_acc:31.667, F1:0.313\n",
            "[Epoch: 45 Batch:   106] loss: 1.001, acc: 49.887, test_acc:40.000, F1:0.393\n",
            "[Epoch: 46 Batch:   106] loss: 1.003, acc: 49.761, test_acc:36.667, F1:0.367\n",
            "[Epoch: 47 Batch:   106] loss: 0.999, acc: 50.189, test_acc:39.167, F1:0.389\n",
            "[Epoch: 48 Batch:   106] loss: 0.997, acc: 50.566, test_acc:35.000, F1:0.351\n",
            "[Epoch: 49 Batch:   106] loss: 0.986, acc: 52.201, test_acc:40.833, F1:0.400\n",
            "[Epoch: 50 Batch:   106] loss: 0.983, acc: 51.535, test_acc:36.667, F1:0.365\n",
            "[Epoch: 51 Batch:   106] loss: 0.988, acc: 52.113, test_acc:38.333, F1:0.381\n",
            "[Epoch: 52 Batch:   106] loss: 0.980, acc: 51.975, test_acc:35.833, F1:0.359\n",
            "[Epoch: 53 Batch:   106] loss: 0.982, acc: 53.170, test_acc:44.167, F1:0.439\n",
            "[Epoch: 54 Batch:   106] loss: 0.976, acc: 53.195, test_acc:44.167, F1:0.441\n",
            "[Epoch: 55 Batch:   106] loss: 0.973, acc: 53.409, test_acc:36.667, F1:0.363\n",
            "[Epoch: 56 Batch:   106] loss: 0.966, acc: 53.824, test_acc:37.500, F1:0.369\n",
            "[Epoch: 57 Batch:   106] loss: 0.977, acc: 52.994, test_acc:38.333, F1:0.382\n",
            "[Epoch: 58 Batch:   106] loss: 0.964, acc: 53.849, test_acc:40.833, F1:0.405\n",
            "[Epoch: 59 Batch:   106] loss: 0.960, acc: 54.025, test_acc:37.500, F1:0.375\n",
            "[Epoch: 60 Batch:   106] loss: 0.954, acc: 54.805, test_acc:38.333, F1:0.382\n",
            "[Epoch: 61 Batch:   106] loss: 0.950, acc: 55.987, test_acc:45.000, F1:0.450\n",
            "[Epoch: 62 Batch:   106] loss: 0.951, acc: 56.491, test_acc:38.333, F1:0.382\n",
            "[Epoch: 63 Batch:   106] loss: 0.942, acc: 55.509, test_acc:33.333, F1:0.327\n",
            "[Epoch: 64 Batch:   106] loss: 0.940, acc: 56.013, test_acc:40.000, F1:0.396\n",
            "[Epoch: 65 Batch:   106] loss: 0.940, acc: 56.616, test_acc:38.333, F1:0.380\n",
            "[Epoch: 66 Batch:   106] loss: 0.938, acc: 56.164, test_acc:42.500, F1:0.418\n",
            "[Epoch: 67 Batch:   106] loss: 0.938, acc: 56.415, test_acc:37.500, F1:0.377\n",
            "[Epoch: 68 Batch:   106] loss: 0.920, acc: 56.717, test_acc:43.333, F1:0.432\n",
            "[Epoch: 69 Batch:   106] loss: 0.922, acc: 58.164, test_acc:36.667, F1:0.361\n",
            "[Epoch: 70 Batch:   106] loss: 0.913, acc: 57.836, test_acc:46.667, F1:0.466\n",
            "[Epoch: 71 Batch:   106] loss: 0.922, acc: 57.698, test_acc:38.333, F1:0.379\n",
            "[Epoch: 72 Batch:   106] loss: 0.907, acc: 58.704, test_acc:45.000, F1:0.451\n",
            "[Epoch: 73 Batch:   106] loss: 0.904, acc: 58.201, test_acc:41.667, F1:0.419\n",
            "[Epoch: 74 Batch:   106] loss: 0.893, acc: 59.761, test_acc:33.333, F1:0.332\n",
            "[Epoch: 75 Batch:   106] loss: 0.892, acc: 59.132, test_acc:39.167, F1:0.386\n",
            "[Epoch: 76 Batch:   106] loss: 0.881, acc: 61.308, test_acc:35.833, F1:0.357\n",
            "[Epoch: 77 Batch:   106] loss: 0.886, acc: 59.912, test_acc:43.333, F1:0.434\n",
            "[Epoch: 78 Batch:   106] loss: 0.886, acc: 60.050, test_acc:43.333, F1:0.432\n",
            "[Epoch: 79 Batch:   106] loss: 0.874, acc: 60.755, test_acc:38.333, F1:0.380\n",
            "[Epoch: 80 Batch:   106] loss: 0.879, acc: 61.346, test_acc:40.833, F1:0.408\n",
            "[Epoch: 81 Batch:   106] loss: 0.873, acc: 61.597, test_acc:44.167, F1:0.439\n",
            "[Epoch: 82 Batch:   106] loss: 0.869, acc: 62.013, test_acc:43.333, F1:0.429\n",
            "[Epoch: 83 Batch:   106] loss: 0.858, acc: 62.465, test_acc:40.000, F1:0.396\n",
            "[Epoch: 84 Batch:   106] loss: 0.870, acc: 62.151, test_acc:41.667, F1:0.409\n",
            "[Epoch: 85 Batch:   106] loss: 0.846, acc: 62.931, test_acc:46.667, F1:0.469\n",
            "[Epoch: 86 Batch:   106] loss: 0.845, acc: 64.201, test_acc:51.667, F1:0.517\n",
            "[Epoch: 87 Batch:   106] loss: 0.829, acc: 65.195, test_acc:40.000, F1:0.397\n",
            "[Epoch: 88 Batch:   106] loss: 0.839, acc: 63.597, test_acc:42.500, F1:0.425\n",
            "[Epoch: 89 Batch:   106] loss: 0.821, acc: 65.358, test_acc:48.333, F1:0.486\n",
            "[Epoch: 90 Batch:   106] loss: 0.825, acc: 65.107, test_acc:44.167, F1:0.433\n",
            "[Epoch: 91 Batch:   106] loss: 0.820, acc: 64.780, test_acc:45.833, F1:0.458\n",
            "[Epoch: 92 Batch:   106] loss: 0.813, acc: 65.635, test_acc:40.833, F1:0.405\n",
            "[Epoch: 93 Batch:   106] loss: 0.817, acc: 66.000, test_acc:43.333, F1:0.433\n",
            "[Epoch: 94 Batch:   106] loss: 0.792, acc: 65.912, test_acc:44.167, F1:0.442\n",
            "[Epoch: 95 Batch:   106] loss: 0.802, acc: 66.226, test_acc:44.167, F1:0.442\n",
            "[Epoch: 96 Batch:   106] loss: 0.794, acc: 67.094, test_acc:42.500, F1:0.425\n",
            "[Epoch: 97 Batch:   106] loss: 0.800, acc: 66.038, test_acc:41.667, F1:0.414\n",
            "[Epoch: 98 Batch:   106] loss: 0.778, acc: 68.214, test_acc:43.333, F1:0.433\n",
            "[Epoch: 99 Batch:   106] loss: 0.789, acc: 67.560, test_acc:45.000, F1:0.448\n",
            "[Epoch: 100 Batch:   106] loss: 0.788, acc: 67.899, test_acc:44.167, F1:0.442\n",
            "[Epoch: 101 Batch:   106] loss: 0.767, acc: 68.616, test_acc:50.000, F1:0.500\n",
            "[Epoch: 102 Batch:   106] loss: 0.768, acc: 66.277, test_acc:47.500, F1:0.475\n",
            "[Epoch: 103 Batch:   106] loss: 0.765, acc: 68.541, test_acc:43.333, F1:0.433\n",
            "[Epoch: 104 Batch:   106] loss: 0.749, acc: 69.623, test_acc:46.667, F1:0.468\n",
            "[Epoch: 105 Batch:   106] loss: 0.754, acc: 69.912, test_acc:45.833, F1:0.461\n",
            "[Epoch: 106 Batch:   106] loss: 0.744, acc: 69.673, test_acc:46.667, F1:0.465\n",
            "[Epoch: 107 Batch:   106] loss: 0.741, acc: 70.164, test_acc:40.833, F1:0.403\n",
            "[Epoch: 108 Batch:   106] loss: 0.738, acc: 69.925, test_acc:40.000, F1:0.401\n",
            "[Epoch: 109 Batch:   106] loss: 0.744, acc: 68.730, test_acc:48.333, F1:0.481\n",
            "[Epoch: 110 Batch:   106] loss: 0.711, acc: 71.258, test_acc:43.333, F1:0.434\n",
            "[Epoch: 111 Batch:   106] loss: 0.729, acc: 70.352, test_acc:47.500, F1:0.475\n",
            "[Epoch: 112 Batch:   106] loss: 0.708, acc: 72.365, test_acc:41.667, F1:0.416\n",
            "[Epoch: 113 Batch:   106] loss: 0.708, acc: 71.321, test_acc:46.667, F1:0.463\n",
            "[Epoch: 114 Batch:   106] loss: 0.696, acc: 71.698, test_acc:42.500, F1:0.424\n",
            "[Epoch: 115 Batch:   106] loss: 0.679, acc: 72.151, test_acc:48.333, F1:0.484\n",
            "[Epoch: 116 Batch:   106] loss: 0.698, acc: 71.597, test_acc:45.833, F1:0.462\n",
            "[Epoch: 117 Batch:   106] loss: 0.691, acc: 72.881, test_acc:47.500, F1:0.477\n",
            "[Epoch: 118 Batch:   106] loss: 0.689, acc: 72.088, test_acc:47.500, F1:0.475\n",
            "[Epoch: 119 Batch:   106] loss: 0.687, acc: 72.403, test_acc:49.167, F1:0.492\n",
            "[Epoch: 120 Batch:   106] loss: 0.677, acc: 73.799, test_acc:47.500, F1:0.476\n",
            "[Epoch: 121 Batch:   106] loss: 0.666, acc: 73.031, test_acc:45.833, F1:0.458\n",
            "[Epoch: 122 Batch:   106] loss: 0.673, acc: 72.528, test_acc:43.333, F1:0.433\n",
            "[Epoch: 123 Batch:   106] loss: 0.669, acc: 73.006, test_acc:45.000, F1:0.451\n",
            "[Epoch: 124 Batch:   106] loss: 0.660, acc: 75.031, test_acc:46.667, F1:0.467\n",
            "[Epoch: 125 Batch:   106] loss: 0.656, acc: 74.679, test_acc:45.000, F1:0.446\n",
            "[Epoch: 126 Batch:   106] loss: 0.654, acc: 72.138, test_acc:45.000, F1:0.452\n",
            "[Epoch: 127 Batch:   106] loss: 0.637, acc: 74.981, test_acc:45.833, F1:0.458\n",
            "[Epoch: 128 Batch:   106] loss: 0.629, acc: 73.660, test_acc:49.167, F1:0.493\n",
            "[Epoch: 129 Batch:   106] loss: 0.644, acc: 73.836, test_acc:46.667, F1:0.467\n",
            "[Epoch: 130 Batch:   106] loss: 0.618, acc: 75.308, test_acc:45.000, F1:0.454\n",
            "[Epoch: 131 Batch:   106] loss: 0.601, acc: 74.390, test_acc:49.167, F1:0.492\n",
            "[Epoch: 132 Batch:   106] loss: 0.625, acc: 75.660, test_acc:42.500, F1:0.428\n",
            "[Epoch: 133 Batch:   106] loss: 0.627, acc: 73.610, test_acc:45.833, F1:0.457\n",
            "[Epoch: 134 Batch:   106] loss: 0.627, acc: 75.623, test_acc:50.833, F1:0.510\n",
            "[Epoch: 135 Batch:   106] loss: 0.625, acc: 74.428, test_acc:49.167, F1:0.494\n",
            "[Epoch: 136 Batch:   106] loss: 0.602, acc: 74.994, test_acc:45.000, F1:0.449\n",
            "[Epoch: 137 Batch:   106] loss: 0.591, acc: 75.522, test_acc:47.500, F1:0.477\n",
            "[Epoch: 138 Batch:   106] loss: 0.593, acc: 76.390, test_acc:49.167, F1:0.494\n",
            "[Epoch: 139 Batch:   106] loss: 0.572, acc: 75.585, test_acc:52.500, F1:0.531\n",
            "[Epoch: 140 Batch:   106] loss: 0.585, acc: 75.333, test_acc:49.167, F1:0.498\n",
            "[Epoch: 141 Batch:   106] loss: 0.578, acc: 76.893, test_acc:45.833, F1:0.457\n",
            "[Epoch: 142 Batch:   106] loss: 0.555, acc: 77.610, test_acc:37.500, F1:0.373\n",
            "[Epoch: 143 Batch:   106] loss: 0.562, acc: 76.981, test_acc:48.333, F1:0.480\n",
            "[Epoch: 144 Batch:   106] loss: 0.526, acc: 77.799, test_acc:49.167, F1:0.489\n",
            "[Epoch: 145 Batch:   106] loss: 0.553, acc: 76.855, test_acc:46.667, F1:0.467\n",
            "[Epoch: 146 Batch:   106] loss: 0.551, acc: 77.057, test_acc:45.833, F1:0.461\n",
            "[Epoch: 147 Batch:   106] loss: 0.537, acc: 77.585, test_acc:48.333, F1:0.484\n",
            "[Epoch: 148 Batch:   106] loss: 0.538, acc: 77.962, test_acc:48.333, F1:0.484\n",
            "[Epoch: 149 Batch:   106] loss: 0.545, acc: 76.151, test_acc:46.667, F1:0.467\n",
            "[Epoch: 150 Batch:   106] loss: 0.541, acc: 77.434, test_acc:48.333, F1:0.482\n",
            "[Epoch: 151 Batch:   106] loss: 0.552, acc: 76.428, test_acc:47.500, F1:0.476\n",
            "[Epoch: 152 Batch:   106] loss: 0.573, acc: 77.044, test_acc:48.333, F1:0.482\n",
            "[Epoch: 153 Batch:   106] loss: 0.524, acc: 78.780, test_acc:47.500, F1:0.475\n",
            "[Epoch: 154 Batch:   106] loss: 0.570, acc: 76.730, test_acc:49.167, F1:0.492\n",
            "[Epoch: 155 Batch:   106] loss: 0.513, acc: 76.994, test_acc:50.000, F1:0.504\n",
            "[Epoch: 156 Batch:   106] loss: 0.489, acc: 79.082, test_acc:46.667, F1:0.458\n",
            "[Epoch: 157 Batch:   106] loss: 0.531, acc: 77.937, test_acc:44.167, F1:0.440\n",
            "[Epoch: 158 Batch:   106] loss: 0.499, acc: 78.038, test_acc:45.000, F1:0.452\n",
            "[Epoch: 159 Batch:   106] loss: 0.501, acc: 77.799, test_acc:42.500, F1:0.421\n",
            "[Epoch: 160 Batch:   106] loss: 0.501, acc: 78.453, test_acc:41.667, F1:0.415\n",
            "[Epoch: 161 Batch:   106] loss: 0.502, acc: 79.484, test_acc:42.500, F1:0.423\n",
            "[Epoch: 162 Batch:   106] loss: 0.487, acc: 78.679, test_acc:43.333, F1:0.432\n",
            "[Epoch: 163 Batch:   106] loss: 0.504, acc: 77.723, test_acc:49.167, F1:0.486\n",
            "[Epoch: 164 Batch:   106] loss: 0.466, acc: 80.440, test_acc:51.667, F1:0.519\n",
            "[Epoch: 165 Batch:   106] loss: 0.476, acc: 76.063, test_acc:49.167, F1:0.495\n",
            "[Epoch: 166 Batch:   106] loss: 0.459, acc: 80.302, test_acc:44.167, F1:0.441\n",
            "[Epoch: 167 Batch:   106] loss: 0.489, acc: 77.862, test_acc:49.167, F1:0.495\n",
            "[Epoch: 168 Batch:   106] loss: 0.452, acc: 79.748, test_acc:50.833, F1:0.507\n",
            "[Epoch: 169 Batch:   106] loss: 0.468, acc: 77.950, test_acc:45.000, F1:0.445\n",
            "[Epoch: 170 Batch:   106] loss: 0.421, acc: 80.327, test_acc:45.000, F1:0.449\n",
            "[Epoch: 171 Batch:   106] loss: 0.468, acc: 80.226, test_acc:42.500, F1:0.426\n",
            "[Epoch: 172 Batch:   106] loss: 0.442, acc: 79.132, test_acc:37.500, F1:0.374\n",
            "[Epoch: 173 Batch:   106] loss: 0.438, acc: 78.893, test_acc:44.167, F1:0.447\n",
            "[Epoch: 174 Batch:   106] loss: 0.454, acc: 78.667, test_acc:39.167, F1:0.384\n",
            "[Epoch: 175 Batch:   106] loss: 0.430, acc: 80.239, test_acc:43.333, F1:0.434\n",
            "[Epoch: 176 Batch:   106] loss: 0.448, acc: 78.654, test_acc:45.000, F1:0.452\n",
            "[Epoch: 177 Batch:   106] loss: 0.474, acc: 78.264, test_acc:37.500, F1:0.367\n",
            "[Epoch: 178 Batch:   106] loss: 0.459, acc: 79.623, test_acc:40.000, F1:0.400\n",
            "[Epoch: 179 Batch:   106] loss: 0.449, acc: 77.899, test_acc:48.333, F1:0.475\n",
            "[Epoch: 180 Batch:   106] loss: 0.437, acc: 79.950, test_acc:46.667, F1:0.464\n",
            "[Epoch: 181 Batch:   106] loss: 0.421, acc: 78.767, test_acc:43.333, F1:0.422\n",
            "[Epoch: 182 Batch:   106] loss: 0.455, acc: 77.019, test_acc:45.833, F1:0.460\n",
            "[Epoch: 183 Batch:   106] loss: 0.432, acc: 79.950, test_acc:45.000, F1:0.452\n",
            "[Epoch: 184 Batch:   106] loss: 0.412, acc: 80.038, test_acc:44.167, F1:0.442\n",
            "[Epoch: 185 Batch:   106] loss: 0.429, acc: 78.239, test_acc:49.167, F1:0.492\n",
            "[Epoch: 186 Batch:   106] loss: 0.445, acc: 79.384, test_acc:44.167, F1:0.443\n",
            "[Epoch: 187 Batch:   106] loss: 0.384, acc: 80.906, test_acc:43.333, F1:0.436\n",
            "[Epoch: 188 Batch:   106] loss: 0.407, acc: 79.006, test_acc:50.000, F1:0.502\n",
            "[Epoch: 189 Batch:   106] loss: 0.444, acc: 80.868, test_acc:42.500, F1:0.418\n",
            "[Epoch: 190 Batch:   106] loss: 0.438, acc: 77.447, test_acc:43.333, F1:0.437\n",
            "[Epoch: 191 Batch:   106] loss: 0.421, acc: 80.868, test_acc:43.333, F1:0.431\n",
            "[Epoch: 192 Batch:   106] loss: 0.379, acc: 81.057, test_acc:46.667, F1:0.470\n",
            "[Epoch: 193 Batch:   106] loss: 0.379, acc: 78.767, test_acc:45.833, F1:0.447\n",
            "[Epoch: 194 Batch:   106] loss: 0.408, acc: 80.151, test_acc:46.667, F1:0.465\n",
            "[Epoch: 195 Batch:   106] loss: 0.390, acc: 78.943, test_acc:45.000, F1:0.452\n",
            "[Epoch: 196 Batch:   106] loss: 0.398, acc: 80.239, test_acc:50.000, F1:0.498\n",
            "[Epoch: 197 Batch:   106] loss: 0.344, acc: 79.774, test_acc:48.333, F1:0.482\n",
            "[Epoch: 198 Batch:   106] loss: 0.343, acc: 80.642, test_acc:47.500, F1:0.476\n",
            "[Epoch: 199 Batch:   106] loss: 0.408, acc: 82.440, test_acc:45.833, F1:0.462\n",
            "[Epoch: 200 Batch:   106] loss: 0.421, acc: 80.403, test_acc:48.333, F1:0.483\n",
            "[Epoch: 201 Batch:   106] loss: 0.344, acc: 81.233, test_acc:45.000, F1:0.450\n",
            "[Epoch: 202 Batch:   106] loss: 0.374, acc: 79.711, test_acc:47.500, F1:0.472\n",
            "[Epoch: 203 Batch:   106] loss: 0.384, acc: 80.340, test_acc:48.333, F1:0.484\n",
            "[Epoch: 204 Batch:   106] loss: 0.370, acc: 78.302, test_acc:50.000, F1:0.496\n",
            "[Epoch: 205 Batch:   106] loss: 0.404, acc: 80.277, test_acc:46.667, F1:0.461\n",
            "[Epoch: 206 Batch:   106] loss: 0.363, acc: 78.189, test_acc:47.500, F1:0.459\n",
            "[Epoch: 207 Batch:   106] loss: 0.415, acc: 79.786, test_acc:45.833, F1:0.455\n",
            "[Epoch: 208 Batch:   106] loss: 0.372, acc: 80.491, test_acc:43.333, F1:0.422\n",
            "[Epoch: 209 Batch:   106] loss: 0.373, acc: 80.818, test_acc:44.167, F1:0.441\n",
            "[Epoch: 210 Batch:   106] loss: 0.363, acc: 80.616, test_acc:43.333, F1:0.429\n",
            "[Epoch: 211 Batch:   106] loss: 0.373, acc: 76.855, test_acc:43.333, F1:0.423\n",
            "[Epoch: 212 Batch:   106] loss: 0.346, acc: 80.667, test_acc:48.333, F1:0.480\n",
            "[Epoch: 213 Batch:   106] loss: 0.393, acc: 78.101, test_acc:46.667, F1:0.468\n",
            "[Epoch: 214 Batch:   106] loss: 0.416, acc: 78.314, test_acc:40.000, F1:0.395\n",
            "[Epoch: 215 Batch:   106] loss: 0.377, acc: 79.270, test_acc:42.500, F1:0.409\n",
            "[Epoch: 216 Batch:   106] loss: 0.318, acc: 79.597, test_acc:42.500, F1:0.430\n",
            "[Epoch: 217 Batch:   106] loss: 0.444, acc: 79.673, test_acc:49.167, F1:0.495\n",
            "[Epoch: 218 Batch:   106] loss: 0.428, acc: 77.082, test_acc:45.833, F1:0.448\n",
            "[Epoch: 219 Batch:   106] loss: 0.374, acc: 80.214, test_acc:45.000, F1:0.421\n",
            "[Epoch: 220 Batch:   106] loss: 0.367, acc: 80.403, test_acc:42.500, F1:0.423\n",
            "[Epoch: 221 Batch:   106] loss: 0.363, acc: 78.717, test_acc:44.167, F1:0.437\n",
            "[Epoch: 222 Batch:   106] loss: 0.384, acc: 80.252, test_acc:45.000, F1:0.434\n",
            "[Epoch: 223 Batch:   106] loss: 0.387, acc: 80.013, test_acc:43.333, F1:0.434\n",
            "[Epoch: 224 Batch:   106] loss: 0.371, acc: 80.642, test_acc:44.167, F1:0.430\n",
            "[Epoch: 225 Batch:   106] loss: 0.322, acc: 81.421, test_acc:45.833, F1:0.418\n",
            "[Epoch: 226 Batch:   106] loss: 0.364, acc: 80.755, test_acc:45.000, F1:0.448\n",
            "[Epoch: 227 Batch:   106] loss: 0.371, acc: 80.164, test_acc:43.333, F1:0.437\n",
            "[Epoch: 228 Batch:   106] loss: 0.425, acc: 78.377, test_acc:41.667, F1:0.415\n",
            "[Epoch: 229 Batch:   106] loss: 0.380, acc: 79.623, test_acc:49.167, F1:0.493\n",
            "[Epoch: 230 Batch:   106] loss: 0.330, acc: 77.635, test_acc:41.667, F1:0.409\n",
            "[Epoch: 231 Batch:   106] loss: 0.335, acc: 80.340, test_acc:45.000, F1:0.448\n",
            "[Epoch: 232 Batch:   106] loss: 0.336, acc: 80.189, test_acc:39.167, F1:0.382\n",
            "[Epoch: 233 Batch:   106] loss: 0.308, acc: 81.836, test_acc:46.667, F1:0.470\n",
            "[Epoch: 234 Batch:   106] loss: 0.317, acc: 82.553, test_acc:41.667, F1:0.415\n",
            "[Epoch: 235 Batch:   106] loss: 0.383, acc: 78.931, test_acc:43.333, F1:0.434\n",
            "[Epoch: 236 Batch:   106] loss: 0.374, acc: 79.987, test_acc:48.333, F1:0.483\n",
            "[Epoch: 237 Batch:   106] loss: 0.388, acc: 77.673, test_acc:45.833, F1:0.438\n",
            "[Epoch: 238 Batch:   106] loss: 0.408, acc: 77.987, test_acc:50.833, F1:0.489\n",
            "[Epoch: 239 Batch:   106] loss: 0.423, acc: 79.208, test_acc:39.167, F1:0.370\n",
            "[Epoch: 240 Batch:   106] loss: 0.293, acc: 79.358, test_acc:48.333, F1:0.483\n",
            "[Epoch: 241 Batch:   106] loss: 0.349, acc: 79.623, test_acc:45.000, F1:0.444\n",
            "[Epoch: 242 Batch:   106] loss: 0.284, acc: 80.767, test_acc:49.167, F1:0.483\n",
            "[Epoch: 243 Batch:   106] loss: 0.322, acc: 77.937, test_acc:40.833, F1:0.404\n",
            "[Epoch: 244 Batch:   106] loss: 0.344, acc: 79.484, test_acc:40.833, F1:0.400\n",
            "[Epoch: 245 Batch:   106] loss: 0.349, acc: 82.855, test_acc:45.000, F1:0.436\n",
            "[Epoch: 246 Batch:   106] loss: 0.386, acc: 80.604, test_acc:41.667, F1:0.423\n",
            "[Epoch: 247 Batch:   106] loss: 0.333, acc: 80.579, test_acc:45.833, F1:0.457\n",
            "[Epoch: 248 Batch:   106] loss: 0.364, acc: 79.748, test_acc:50.000, F1:0.491\n",
            "[Epoch: 249 Batch:   106] loss: 0.368, acc: 78.843, test_acc:50.833, F1:0.506\n",
            "[Epoch: 250 Batch:   106] loss: 0.338, acc: 80.818, test_acc:42.500, F1:0.417\n",
            "[Epoch: 251 Batch:   106] loss: 0.390, acc: 81.522, test_acc:47.500, F1:0.474\n",
            "[Epoch: 252 Batch:   106] loss: 0.323, acc: 81.358, test_acc:46.667, F1:0.467\n",
            "[Epoch: 253 Batch:   106] loss: 0.316, acc: 80.226, test_acc:44.167, F1:0.407\n",
            "[Epoch: 254 Batch:   106] loss: 0.311, acc: 81.811, test_acc:44.167, F1:0.436\n",
            "[Epoch: 255 Batch:   106] loss: 0.286, acc: 81.572, test_acc:41.667, F1:0.420\n",
            "[Epoch: 256 Batch:   106] loss: 0.271, acc: 81.623, test_acc:48.333, F1:0.471\n",
            "[Epoch: 257 Batch:   106] loss: 0.284, acc: 81.245, test_acc:48.333, F1:0.490\n",
            "[Epoch: 258 Batch:   106] loss: 0.370, acc: 79.585, test_acc:49.167, F1:0.492\n",
            "[Epoch: 259 Batch:   106] loss: 0.409, acc: 79.434, test_acc:52.500, F1:0.519\n",
            "[Epoch: 260 Batch:   106] loss: 0.366, acc: 80.151, test_acc:40.833, F1:0.399\n",
            "[Epoch: 261 Batch:   106] loss: 0.398, acc: 79.484, test_acc:44.167, F1:0.432\n",
            "[Epoch: 262 Batch:   106] loss: 0.372, acc: 80.390, test_acc:45.000, F1:0.442\n",
            "[Epoch: 263 Batch:   106] loss: 0.383, acc: 80.453, test_acc:46.667, F1:0.473\n",
            "[Epoch: 264 Batch:   106] loss: 0.345, acc: 80.189, test_acc:43.333, F1:0.422\n",
            "[Epoch: 265 Batch:   106] loss: 0.407, acc: 80.226, test_acc:43.333, F1:0.435\n",
            "[Epoch: 266 Batch:   106] loss: 0.423, acc: 76.717, test_acc:45.000, F1:0.428\n",
            "[Epoch: 267 Batch:   106] loss: 0.523, acc: 76.553, test_acc:41.667, F1:0.425\n",
            "[Epoch: 268 Batch:   106] loss: 0.521, acc: 79.245, test_acc:45.000, F1:0.447\n",
            "[Epoch: 269 Batch:   106] loss: 0.468, acc: 80.000, test_acc:46.667, F1:0.457\n",
            "[Epoch: 270 Batch:   106] loss: 0.373, acc: 78.214, test_acc:43.333, F1:0.431\n",
            "[Epoch: 271 Batch:   106] loss: 0.388, acc: 79.157, test_acc:41.667, F1:0.378\n",
            "[Epoch: 272 Batch:   106] loss: 0.457, acc: 76.918, test_acc:45.000, F1:0.444\n",
            "[Epoch: 273 Batch:   106] loss: 0.355, acc: 80.440, test_acc:41.667, F1:0.417\n",
            "[Epoch: 274 Batch:   106] loss: 0.420, acc: 79.132, test_acc:47.500, F1:0.458\n",
            "[Epoch: 275 Batch:   106] loss: 0.326, acc: 80.843, test_acc:45.000, F1:0.446\n",
            "[Epoch: 276 Batch:   106] loss: 0.307, acc: 80.264, test_acc:46.667, F1:0.449\n",
            "[Epoch: 277 Batch:   106] loss: 0.272, acc: 81.371, test_acc:45.000, F1:0.454\n",
            "[Epoch: 278 Batch:   106] loss: 0.293, acc: 81.182, test_acc:40.833, F1:0.389\n",
            "[Epoch: 279 Batch:   106] loss: 0.264, acc: 81.094, test_acc:44.167, F1:0.434\n",
            "[Epoch: 280 Batch:   106] loss: 0.349, acc: 80.478, test_acc:48.333, F1:0.466\n",
            "[Epoch: 281 Batch:   106] loss: 0.309, acc: 82.176, test_acc:44.167, F1:0.438\n",
            "[Epoch: 282 Batch:   106] loss: 0.352, acc: 80.541, test_acc:45.000, F1:0.435\n",
            "[Epoch: 283 Batch:   106] loss: 0.402, acc: 79.849, test_acc:46.667, F1:0.459\n",
            "[Epoch: 284 Batch:   106] loss: 0.455, acc: 79.660, test_acc:40.833, F1:0.407\n",
            "[Epoch: 285 Batch:   106] loss: 0.403, acc: 80.277, test_acc:37.500, F1:0.363\n",
            "[Epoch: 286 Batch:   106] loss: 0.455, acc: 79.308, test_acc:43.333, F1:0.421\n",
            "[Epoch: 287 Batch:   106] loss: 0.359, acc: 80.063, test_acc:37.500, F1:0.376\n",
            "[Epoch: 288 Batch:   106] loss: 0.429, acc: 76.478, test_acc:48.333, F1:0.471\n",
            "[Epoch: 289 Batch:   106] loss: 0.336, acc: 79.937, test_acc:44.167, F1:0.396\n",
            "[Epoch: 290 Batch:   106] loss: 0.305, acc: 81.107, test_acc:49.167, F1:0.459\n",
            "[Epoch: 291 Batch:   106] loss: 0.314, acc: 80.642, test_acc:43.333, F1:0.390\n",
            "[Epoch: 292 Batch:   106] loss: 0.331, acc: 81.434, test_acc:32.500, F1:0.302\n",
            "[Epoch: 293 Batch:   106] loss: 0.502, acc: 78.138, test_acc:41.667, F1:0.401\n",
            "[Epoch: 294 Batch:   106] loss: 0.431, acc: 79.220, test_acc:40.000, F1:0.388\n",
            "[Epoch: 295 Batch:   106] loss: 0.404, acc: 80.138, test_acc:40.000, F1:0.399\n",
            "[Epoch: 296 Batch:   106] loss: 0.389, acc: 80.742, test_acc:34.167, F1:0.332\n",
            "[Epoch: 297 Batch:   106] loss: 0.358, acc: 79.874, test_acc:40.833, F1:0.411\n",
            "[Epoch: 298 Batch:   106] loss: 0.402, acc: 80.943, test_acc:44.167, F1:0.440\n",
            "[Epoch: 299 Batch:   106] loss: 0.403, acc: 78.956, test_acc:42.500, F1:0.424\n",
            "[Epoch: 300 Batch:   106] loss: 0.471, acc: 80.063, test_acc:38.333, F1:0.369\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  38.333333333333336\n",
            "Test F1 Score : 0.3694564808943376\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.56      0.48        36\n",
            "         1.0       0.44      0.22      0.29        51\n",
            "         2.0       0.31      0.45      0.37        33\n",
            "\n",
            "    accuracy                           0.38       120\n",
            "   macro avg       0.39      0.41      0.38       120\n",
            "weighted avg       0.40      0.38      0.37       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[20  7  9]\n",
            " [16 11 24]\n",
            " [11  7 15]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.057715598742167 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  10\n",
            "[Epoch: 1 Batch:   106] loss: 1.087, acc: 35.396, test_acc:35.833, F1:0.351\n",
            "[Epoch: 2 Batch:   106] loss: 1.081, acc: 34.616, test_acc:30.833, F1:0.302\n",
            "[Epoch: 3 Batch:   106] loss: 1.077, acc: 36.692, test_acc:31.667, F1:0.312\n",
            "[Epoch: 4 Batch:   106] loss: 1.076, acc: 36.491, test_acc:29.167, F1:0.284\n",
            "[Epoch: 5 Batch:   106] loss: 1.075, acc: 37.648, test_acc:22.500, F1:0.220\n",
            "[Epoch: 6 Batch:   106] loss: 1.073, acc: 37.283, test_acc:24.167, F1:0.238\n",
            "[Epoch: 7 Batch:   106] loss: 1.073, acc: 37.786, test_acc:25.000, F1:0.250\n",
            "[Epoch: 8 Batch:   106] loss: 1.071, acc: 37.572, test_acc:27.500, F1:0.272\n",
            "[Epoch: 9 Batch:   106] loss: 1.071, acc: 38.981, test_acc:30.000, F1:0.299\n",
            "[Epoch: 10 Batch:   106] loss: 1.069, acc: 38.516, test_acc:30.833, F1:0.308\n",
            "[Epoch: 11 Batch:   106] loss: 1.070, acc: 37.987, test_acc:30.833, F1:0.308\n",
            "[Epoch: 12 Batch:   106] loss: 1.067, acc: 39.119, test_acc:25.833, F1:0.256\n",
            "[Epoch: 13 Batch:   106] loss: 1.066, acc: 39.572, test_acc:27.500, F1:0.274\n",
            "[Epoch: 14 Batch:   106] loss: 1.069, acc: 39.044, test_acc:29.167, F1:0.290\n",
            "[Epoch: 15 Batch:   106] loss: 1.067, acc: 40.050, test_acc:29.167, F1:0.291\n",
            "[Epoch: 16 Batch:   106] loss: 1.065, acc: 39.912, test_acc:27.500, F1:0.275\n",
            "[Epoch: 17 Batch:   106] loss: 1.062, acc: 39.182, test_acc:30.833, F1:0.307\n",
            "[Epoch: 18 Batch:   106] loss: 1.061, acc: 41.421, test_acc:34.167, F1:0.343\n",
            "[Epoch: 19 Batch:   106] loss: 1.063, acc: 40.478, test_acc:26.667, F1:0.268\n",
            "[Epoch: 20 Batch:   106] loss: 1.059, acc: 40.981, test_acc:29.167, F1:0.292\n",
            "[Epoch: 21 Batch:   106] loss: 1.060, acc: 40.679, test_acc:30.833, F1:0.310\n",
            "[Epoch: 22 Batch:   106] loss: 1.056, acc: 42.113, test_acc:30.833, F1:0.311\n",
            "[Epoch: 23 Batch:   106] loss: 1.053, acc: 41.887, test_acc:33.333, F1:0.334\n",
            "[Epoch: 24 Batch:   106] loss: 1.056, acc: 42.579, test_acc:40.000, F1:0.400\n",
            "[Epoch: 25 Batch:   106] loss: 1.053, acc: 41.220, test_acc:27.500, F1:0.274\n",
            "[Epoch: 26 Batch:   106] loss: 1.056, acc: 43.019, test_acc:34.167, F1:0.343\n",
            "[Epoch: 27 Batch:   106] loss: 1.053, acc: 42.943, test_acc:30.000, F1:0.300\n",
            "[Epoch: 28 Batch:   106] loss: 1.048, acc: 42.704, test_acc:37.500, F1:0.375\n",
            "[Epoch: 29 Batch:   106] loss: 1.048, acc: 42.780, test_acc:34.167, F1:0.342\n",
            "[Epoch: 30 Batch:   106] loss: 1.042, acc: 44.604, test_acc:37.500, F1:0.376\n",
            "[Epoch: 31 Batch:   106] loss: 1.044, acc: 45.535, test_acc:40.833, F1:0.408\n",
            "[Epoch: 32 Batch:   106] loss: 1.041, acc: 45.107, test_acc:34.167, F1:0.344\n",
            "[Epoch: 33 Batch:   106] loss: 1.042, acc: 44.956, test_acc:36.667, F1:0.367\n",
            "[Epoch: 34 Batch:   106] loss: 1.035, acc: 45.610, test_acc:32.500, F1:0.324\n",
            "[Epoch: 35 Batch:   106] loss: 1.036, acc: 45.321, test_acc:32.500, F1:0.326\n",
            "[Epoch: 36 Batch:   106] loss: 1.035, acc: 45.031, test_acc:35.833, F1:0.357\n",
            "[Epoch: 37 Batch:   106] loss: 1.029, acc: 45.786, test_acc:37.500, F1:0.377\n",
            "[Epoch: 38 Batch:   106] loss: 1.029, acc: 45.748, test_acc:35.000, F1:0.354\n",
            "[Epoch: 39 Batch:   106] loss: 1.020, acc: 47.333, test_acc:31.667, F1:0.318\n",
            "[Epoch: 40 Batch:   106] loss: 1.026, acc: 47.623, test_acc:35.833, F1:0.361\n",
            "[Epoch: 41 Batch:   106] loss: 1.014, acc: 47.270, test_acc:37.500, F1:0.378\n",
            "[Epoch: 42 Batch:   106] loss: 1.019, acc: 48.000, test_acc:34.167, F1:0.344\n",
            "[Epoch: 43 Batch:   106] loss: 1.015, acc: 46.906, test_acc:35.833, F1:0.358\n",
            "[Epoch: 44 Batch:   106] loss: 1.006, acc: 49.761, test_acc:45.000, F1:0.451\n",
            "[Epoch: 45 Batch:   106] loss: 1.007, acc: 49.623, test_acc:30.000, F1:0.297\n",
            "[Epoch: 46 Batch:   106] loss: 1.006, acc: 48.931, test_acc:27.500, F1:0.275\n",
            "[Epoch: 47 Batch:   106] loss: 1.005, acc: 49.610, test_acc:33.333, F1:0.332\n",
            "[Epoch: 48 Batch:   106] loss: 1.000, acc: 50.403, test_acc:35.000, F1:0.350\n",
            "[Epoch: 49 Batch:   106] loss: 1.000, acc: 50.126, test_acc:45.833, F1:0.458\n",
            "[Epoch: 50 Batch:   106] loss: 0.989, acc: 49.824, test_acc:37.500, F1:0.380\n",
            "[Epoch: 51 Batch:   106] loss: 0.982, acc: 51.660, test_acc:38.333, F1:0.386\n",
            "[Epoch: 52 Batch:   106] loss: 0.987, acc: 52.075, test_acc:37.500, F1:0.378\n",
            "[Epoch: 53 Batch:   106] loss: 0.980, acc: 51.195, test_acc:35.000, F1:0.346\n",
            "[Epoch: 54 Batch:   106] loss: 0.978, acc: 52.780, test_acc:30.833, F1:0.302\n",
            "[Epoch: 55 Batch:   106] loss: 0.971, acc: 53.962, test_acc:36.667, F1:0.363\n",
            "[Epoch: 56 Batch:   106] loss: 0.966, acc: 53.358, test_acc:36.667, F1:0.368\n",
            "[Epoch: 57 Batch:   106] loss: 0.971, acc: 53.698, test_acc:30.833, F1:0.306\n",
            "[Epoch: 58 Batch:   106] loss: 0.966, acc: 53.497, test_acc:37.500, F1:0.374\n",
            "[Epoch: 59 Batch:   106] loss: 0.961, acc: 54.164, test_acc:39.167, F1:0.389\n",
            "[Epoch: 60 Batch:   106] loss: 0.957, acc: 54.755, test_acc:31.667, F1:0.313\n",
            "[Epoch: 61 Batch:   106] loss: 0.946, acc: 55.270, test_acc:34.167, F1:0.344\n",
            "[Epoch: 62 Batch:   106] loss: 0.943, acc: 55.384, test_acc:35.000, F1:0.350\n",
            "[Epoch: 63 Batch:   106] loss: 0.941, acc: 56.126, test_acc:31.667, F1:0.316\n",
            "[Epoch: 64 Batch:   106] loss: 0.941, acc: 56.453, test_acc:35.000, F1:0.352\n",
            "[Epoch: 65 Batch:   106] loss: 0.934, acc: 55.836, test_acc:33.333, F1:0.335\n",
            "[Epoch: 66 Batch:   106] loss: 0.936, acc: 55.635, test_acc:35.833, F1:0.358\n",
            "[Epoch: 67 Batch:   106] loss: 0.923, acc: 56.264, test_acc:39.167, F1:0.393\n",
            "[Epoch: 68 Batch:   106] loss: 0.925, acc: 57.786, test_acc:39.167, F1:0.396\n",
            "[Epoch: 69 Batch:   106] loss: 0.922, acc: 57.019, test_acc:41.667, F1:0.416\n",
            "[Epoch: 70 Batch:   106] loss: 0.911, acc: 57.912, test_acc:27.500, F1:0.272\n",
            "[Epoch: 71 Batch:   106] loss: 0.912, acc: 58.239, test_acc:33.333, F1:0.331\n",
            "[Epoch: 72 Batch:   106] loss: 0.911, acc: 58.730, test_acc:39.167, F1:0.395\n",
            "[Epoch: 73 Batch:   106] loss: 0.903, acc: 58.252, test_acc:37.500, F1:0.375\n",
            "[Epoch: 74 Batch:   106] loss: 0.902, acc: 58.478, test_acc:32.500, F1:0.326\n",
            "[Epoch: 75 Batch:   106] loss: 0.902, acc: 59.535, test_acc:29.167, F1:0.289\n",
            "[Epoch: 76 Batch:   106] loss: 0.893, acc: 60.491, test_acc:35.000, F1:0.346\n",
            "[Epoch: 77 Batch:   106] loss: 0.894, acc: 60.377, test_acc:34.167, F1:0.342\n",
            "[Epoch: 78 Batch:   106] loss: 0.881, acc: 59.849, test_acc:35.833, F1:0.359\n",
            "[Epoch: 79 Batch:   106] loss: 0.886, acc: 61.195, test_acc:37.500, F1:0.373\n",
            "[Epoch: 80 Batch:   106] loss: 0.874, acc: 61.006, test_acc:29.167, F1:0.288\n",
            "[Epoch: 81 Batch:   106] loss: 0.860, acc: 61.824, test_acc:27.500, F1:0.270\n",
            "[Epoch: 82 Batch:   106] loss: 0.868, acc: 60.805, test_acc:34.167, F1:0.340\n",
            "[Epoch: 83 Batch:   106] loss: 0.863, acc: 62.164, test_acc:41.667, F1:0.417\n",
            "[Epoch: 84 Batch:   106] loss: 0.868, acc: 60.654, test_acc:36.667, F1:0.367\n",
            "[Epoch: 85 Batch:   106] loss: 0.853, acc: 63.296, test_acc:30.833, F1:0.305\n",
            "[Epoch: 86 Batch:   106] loss: 0.839, acc: 62.403, test_acc:35.833, F1:0.357\n",
            "[Epoch: 87 Batch:   106] loss: 0.863, acc: 62.692, test_acc:36.667, F1:0.357\n",
            "[Epoch: 88 Batch:   106] loss: 0.839, acc: 63.635, test_acc:29.167, F1:0.289\n",
            "[Epoch: 89 Batch:   106] loss: 0.847, acc: 62.792, test_acc:28.333, F1:0.274\n",
            "[Epoch: 90 Batch:   106] loss: 0.840, acc: 63.686, test_acc:30.833, F1:0.305\n",
            "[Epoch: 91 Batch:   106] loss: 0.843, acc: 63.119, test_acc:35.000, F1:0.351\n",
            "[Epoch: 92 Batch:   106] loss: 0.828, acc: 63.170, test_acc:31.667, F1:0.312\n",
            "[Epoch: 93 Batch:   106] loss: 0.819, acc: 64.805, test_acc:32.500, F1:0.324\n",
            "[Epoch: 94 Batch:   106] loss: 0.837, acc: 63.836, test_acc:35.000, F1:0.349\n",
            "[Epoch: 95 Batch:   106] loss: 0.812, acc: 64.981, test_acc:35.000, F1:0.347\n",
            "[Epoch: 96 Batch:   106] loss: 0.816, acc: 65.358, test_acc:33.333, F1:0.329\n",
            "[Epoch: 97 Batch:   106] loss: 0.804, acc: 65.560, test_acc:33.333, F1:0.328\n",
            "[Epoch: 98 Batch:   106] loss: 0.811, acc: 65.811, test_acc:29.167, F1:0.292\n",
            "[Epoch: 99 Batch:   106] loss: 0.807, acc: 65.283, test_acc:32.500, F1:0.324\n",
            "[Epoch: 100 Batch:   106] loss: 0.793, acc: 65.836, test_acc:31.667, F1:0.316\n",
            "[Epoch: 101 Batch:   106] loss: 0.799, acc: 65.560, test_acc:33.333, F1:0.331\n",
            "[Epoch: 102 Batch:   106] loss: 0.785, acc: 66.377, test_acc:26.667, F1:0.261\n",
            "[Epoch: 103 Batch:   106] loss: 0.792, acc: 66.428, test_acc:32.500, F1:0.322\n",
            "[Epoch: 104 Batch:   106] loss: 0.785, acc: 68.201, test_acc:30.000, F1:0.300\n",
            "[Epoch: 105 Batch:   106] loss: 0.782, acc: 67.811, test_acc:28.333, F1:0.284\n",
            "[Epoch: 106 Batch:   106] loss: 0.765, acc: 68.151, test_acc:30.833, F1:0.308\n",
            "[Epoch: 107 Batch:   106] loss: 0.768, acc: 66.767, test_acc:35.833, F1:0.358\n",
            "[Epoch: 108 Batch:   106] loss: 0.762, acc: 67.509, test_acc:29.167, F1:0.290\n",
            "[Epoch: 109 Batch:   106] loss: 0.770, acc: 67.245, test_acc:24.167, F1:0.243\n",
            "[Epoch: 110 Batch:   106] loss: 0.770, acc: 68.792, test_acc:28.333, F1:0.281\n",
            "[Epoch: 111 Batch:   106] loss: 0.761, acc: 67.836, test_acc:27.500, F1:0.274\n",
            "[Epoch: 112 Batch:   106] loss: 0.750, acc: 68.063, test_acc:30.833, F1:0.305\n",
            "[Epoch: 113 Batch:   106] loss: 0.757, acc: 68.969, test_acc:31.667, F1:0.316\n",
            "[Epoch: 114 Batch:   106] loss: 0.751, acc: 68.616, test_acc:27.500, F1:0.274\n",
            "[Epoch: 115 Batch:   106] loss: 0.748, acc: 69.157, test_acc:31.667, F1:0.312\n",
            "[Epoch: 116 Batch:   106] loss: 0.745, acc: 69.157, test_acc:33.333, F1:0.331\n",
            "[Epoch: 117 Batch:   106] loss: 0.745, acc: 69.585, test_acc:31.667, F1:0.308\n",
            "[Epoch: 118 Batch:   106] loss: 0.724, acc: 69.987, test_acc:25.833, F1:0.258\n",
            "[Epoch: 119 Batch:   106] loss: 0.724, acc: 69.409, test_acc:34.167, F1:0.339\n",
            "[Epoch: 120 Batch:   106] loss: 0.731, acc: 69.535, test_acc:35.000, F1:0.348\n",
            "[Epoch: 121 Batch:   106] loss: 0.724, acc: 69.497, test_acc:30.000, F1:0.299\n",
            "[Epoch: 122 Batch:   106] loss: 0.719, acc: 70.717, test_acc:32.500, F1:0.325\n",
            "[Epoch: 123 Batch:   106] loss: 0.717, acc: 69.585, test_acc:29.167, F1:0.291\n",
            "[Epoch: 124 Batch:   106] loss: 0.721, acc: 69.472, test_acc:30.833, F1:0.308\n",
            "[Epoch: 125 Batch:   106] loss: 0.710, acc: 71.321, test_acc:30.000, F1:0.298\n",
            "[Epoch: 126 Batch:   106] loss: 0.718, acc: 69.874, test_acc:32.500, F1:0.326\n",
            "[Epoch: 127 Batch:   106] loss: 0.709, acc: 71.094, test_acc:34.167, F1:0.341\n",
            "[Epoch: 128 Batch:   106] loss: 0.694, acc: 69.962, test_acc:27.500, F1:0.274\n",
            "[Epoch: 129 Batch:   106] loss: 0.681, acc: 71.447, test_acc:27.500, F1:0.276\n",
            "[Epoch: 130 Batch:   106] loss: 0.686, acc: 71.031, test_acc:28.333, F1:0.284\n",
            "[Epoch: 131 Batch:   106] loss: 0.696, acc: 70.956, test_acc:33.333, F1:0.334\n",
            "[Epoch: 132 Batch:   106] loss: 0.708, acc: 70.377, test_acc:38.333, F1:0.383\n",
            "[Epoch: 133 Batch:   106] loss: 0.701, acc: 69.698, test_acc:32.500, F1:0.324\n",
            "[Epoch: 134 Batch:   106] loss: 0.691, acc: 69.296, test_acc:34.167, F1:0.341\n",
            "[Epoch: 135 Batch:   106] loss: 0.691, acc: 70.440, test_acc:33.333, F1:0.334\n",
            "[Epoch: 136 Batch:   106] loss: 0.687, acc: 70.755, test_acc:38.333, F1:0.384\n",
            "[Epoch: 137 Batch:   106] loss: 0.695, acc: 71.447, test_acc:36.667, F1:0.367\n",
            "[Epoch: 138 Batch:   106] loss: 0.670, acc: 72.377, test_acc:39.167, F1:0.392\n",
            "[Epoch: 139 Batch:   106] loss: 0.656, acc: 72.063, test_acc:35.000, F1:0.348\n",
            "[Epoch: 140 Batch:   106] loss: 0.676, acc: 72.302, test_acc:35.000, F1:0.351\n",
            "[Epoch: 141 Batch:   106] loss: 0.666, acc: 72.063, test_acc:35.833, F1:0.356\n",
            "[Epoch: 142 Batch:   106] loss: 0.661, acc: 73.522, test_acc:33.333, F1:0.334\n",
            "[Epoch: 143 Batch:   106] loss: 0.683, acc: 70.591, test_acc:34.167, F1:0.341\n",
            "[Epoch: 144 Batch:   106] loss: 0.658, acc: 70.931, test_acc:31.667, F1:0.316\n",
            "[Epoch: 145 Batch:   106] loss: 0.675, acc: 71.585, test_acc:30.833, F1:0.308\n",
            "[Epoch: 146 Batch:   106] loss: 0.642, acc: 74.151, test_acc:35.000, F1:0.350\n",
            "[Epoch: 147 Batch:   106] loss: 0.638, acc: 73.258, test_acc:29.167, F1:0.291\n",
            "[Epoch: 148 Batch:   106] loss: 0.662, acc: 71.132, test_acc:36.667, F1:0.367\n",
            "[Epoch: 149 Batch:   106] loss: 0.618, acc: 74.969, test_acc:38.333, F1:0.382\n",
            "[Epoch: 150 Batch:   106] loss: 0.633, acc: 74.616, test_acc:34.167, F1:0.342\n",
            "[Epoch: 151 Batch:   106] loss: 0.638, acc: 73.535, test_acc:36.667, F1:0.367\n",
            "[Epoch: 152 Batch:   106] loss: 0.626, acc: 72.881, test_acc:30.833, F1:0.307\n",
            "[Epoch: 153 Batch:   106] loss: 0.616, acc: 74.881, test_acc:34.167, F1:0.342\n",
            "[Epoch: 154 Batch:   106] loss: 0.632, acc: 73.434, test_acc:33.333, F1:0.335\n",
            "[Epoch: 155 Batch:   106] loss: 0.617, acc: 73.019, test_acc:35.833, F1:0.360\n",
            "[Epoch: 156 Batch:   106] loss: 0.606, acc: 74.000, test_acc:31.667, F1:0.315\n",
            "[Epoch: 157 Batch:   106] loss: 0.624, acc: 72.931, test_acc:34.167, F1:0.342\n",
            "[Epoch: 158 Batch:   106] loss: 0.616, acc: 75.673, test_acc:37.500, F1:0.375\n",
            "[Epoch: 159 Batch:   106] loss: 0.627, acc: 72.767, test_acc:33.333, F1:0.333\n",
            "[Epoch: 160 Batch:   106] loss: 0.607, acc: 73.434, test_acc:33.333, F1:0.332\n",
            "[Epoch: 161 Batch:   106] loss: 0.601, acc: 74.667, test_acc:35.000, F1:0.351\n",
            "[Epoch: 162 Batch:   106] loss: 0.602, acc: 74.717, test_acc:29.167, F1:0.291\n",
            "[Epoch: 163 Batch:   106] loss: 0.593, acc: 74.755, test_acc:35.833, F1:0.358\n",
            "[Epoch: 164 Batch:   106] loss: 0.579, acc: 75.774, test_acc:35.000, F1:0.353\n",
            "[Epoch: 165 Batch:   106] loss: 0.580, acc: 74.893, test_acc:34.167, F1:0.335\n",
            "[Epoch: 166 Batch:   106] loss: 0.624, acc: 73.635, test_acc:35.833, F1:0.353\n",
            "[Epoch: 167 Batch:   106] loss: 0.612, acc: 74.679, test_acc:30.833, F1:0.308\n",
            "[Epoch: 168 Batch:   106] loss: 0.616, acc: 73.182, test_acc:37.500, F1:0.373\n",
            "[Epoch: 169 Batch:   106] loss: 0.573, acc: 73.937, test_acc:36.667, F1:0.367\n",
            "[Epoch: 170 Batch:   106] loss: 0.579, acc: 74.013, test_acc:36.667, F1:0.368\n",
            "[Epoch: 171 Batch:   106] loss: 0.574, acc: 74.566, test_acc:37.500, F1:0.376\n",
            "[Epoch: 172 Batch:   106] loss: 0.589, acc: 74.906, test_acc:33.333, F1:0.333\n",
            "[Epoch: 173 Batch:   106] loss: 0.570, acc: 75.748, test_acc:35.000, F1:0.351\n",
            "[Epoch: 174 Batch:   106] loss: 0.559, acc: 74.075, test_acc:35.833, F1:0.354\n",
            "[Epoch: 175 Batch:   106] loss: 0.569, acc: 75.535, test_acc:31.667, F1:0.317\n",
            "[Epoch: 176 Batch:   106] loss: 0.560, acc: 76.541, test_acc:35.833, F1:0.356\n",
            "[Epoch: 177 Batch:   106] loss: 0.577, acc: 75.962, test_acc:40.000, F1:0.400\n",
            "[Epoch: 178 Batch:   106] loss: 0.542, acc: 74.415, test_acc:35.000, F1:0.339\n",
            "[Epoch: 179 Batch:   106] loss: 0.556, acc: 75.509, test_acc:38.333, F1:0.381\n",
            "[Epoch: 180 Batch:   106] loss: 0.567, acc: 74.792, test_acc:35.000, F1:0.347\n",
            "[Epoch: 181 Batch:   106] loss: 0.567, acc: 76.038, test_acc:37.500, F1:0.377\n",
            "[Epoch: 182 Batch:   106] loss: 0.561, acc: 75.660, test_acc:29.167, F1:0.291\n",
            "[Epoch: 183 Batch:   106] loss: 0.546, acc: 77.220, test_acc:30.833, F1:0.309\n",
            "[Epoch: 184 Batch:   106] loss: 0.554, acc: 74.943, test_acc:35.000, F1:0.349\n",
            "[Epoch: 185 Batch:   106] loss: 0.549, acc: 75.308, test_acc:37.500, F1:0.374\n",
            "[Epoch: 186 Batch:   106] loss: 0.525, acc: 77.421, test_acc:30.833, F1:0.303\n",
            "[Epoch: 187 Batch:   106] loss: 0.528, acc: 74.428, test_acc:36.667, F1:0.368\n",
            "[Epoch: 188 Batch:   106] loss: 0.522, acc: 76.327, test_acc:32.500, F1:0.322\n",
            "[Epoch: 189 Batch:   106] loss: 0.536, acc: 75.296, test_acc:35.000, F1:0.349\n",
            "[Epoch: 190 Batch:   106] loss: 0.508, acc: 75.811, test_acc:33.333, F1:0.332\n",
            "[Epoch: 191 Batch:   106] loss: 0.504, acc: 77.396, test_acc:35.833, F1:0.358\n",
            "[Epoch: 192 Batch:   106] loss: 0.494, acc: 77.233, test_acc:33.333, F1:0.335\n",
            "[Epoch: 193 Batch:   106] loss: 0.528, acc: 76.214, test_acc:39.167, F1:0.389\n",
            "[Epoch: 194 Batch:   106] loss: 0.528, acc: 75.233, test_acc:38.333, F1:0.384\n",
            "[Epoch: 195 Batch:   106] loss: 0.480, acc: 77.723, test_acc:35.833, F1:0.359\n",
            "[Epoch: 196 Batch:   106] loss: 0.491, acc: 76.956, test_acc:32.500, F1:0.325\n",
            "[Epoch: 197 Batch:   106] loss: 0.502, acc: 78.025, test_acc:37.500, F1:0.376\n",
            "[Epoch: 198 Batch:   106] loss: 0.530, acc: 74.805, test_acc:34.167, F1:0.334\n",
            "[Epoch: 199 Batch:   106] loss: 0.561, acc: 75.421, test_acc:31.667, F1:0.314\n",
            "[Epoch: 200 Batch:   106] loss: 0.508, acc: 76.805, test_acc:36.667, F1:0.361\n",
            "[Epoch: 201 Batch:   106] loss: 0.502, acc: 77.069, test_acc:38.333, F1:0.384\n",
            "[Epoch: 202 Batch:   106] loss: 0.485, acc: 76.528, test_acc:33.333, F1:0.334\n",
            "[Epoch: 203 Batch:   106] loss: 0.508, acc: 77.132, test_acc:38.333, F1:0.380\n",
            "[Epoch: 204 Batch:   106] loss: 0.511, acc: 75.799, test_acc:35.833, F1:0.348\n",
            "[Epoch: 205 Batch:   106] loss: 0.496, acc: 76.591, test_acc:35.833, F1:0.359\n",
            "[Epoch: 206 Batch:   106] loss: 0.464, acc: 77.472, test_acc:34.167, F1:0.343\n",
            "[Epoch: 207 Batch:   106] loss: 0.507, acc: 75.208, test_acc:34.167, F1:0.337\n",
            "[Epoch: 208 Batch:   106] loss: 0.458, acc: 77.635, test_acc:35.000, F1:0.347\n",
            "[Epoch: 209 Batch:   106] loss: 0.493, acc: 76.679, test_acc:36.667, F1:0.366\n",
            "[Epoch: 210 Batch:   106] loss: 0.494, acc: 75.887, test_acc:38.333, F1:0.382\n",
            "[Epoch: 211 Batch:   106] loss: 0.488, acc: 75.560, test_acc:35.000, F1:0.340\n",
            "[Epoch: 212 Batch:   106] loss: 0.490, acc: 75.560, test_acc:37.500, F1:0.373\n",
            "[Epoch: 213 Batch:   106] loss: 0.465, acc: 78.176, test_acc:33.333, F1:0.332\n",
            "[Epoch: 214 Batch:   106] loss: 0.490, acc: 76.969, test_acc:36.667, F1:0.356\n",
            "[Epoch: 215 Batch:   106] loss: 0.480, acc: 76.516, test_acc:35.833, F1:0.355\n",
            "[Epoch: 216 Batch:   106] loss: 0.482, acc: 77.673, test_acc:36.667, F1:0.361\n",
            "[Epoch: 217 Batch:   106] loss: 0.465, acc: 78.101, test_acc:35.833, F1:0.353\n",
            "[Epoch: 218 Batch:   106] loss: 0.507, acc: 75.937, test_acc:34.167, F1:0.340\n",
            "[Epoch: 219 Batch:   106] loss: 0.456, acc: 78.843, test_acc:34.167, F1:0.340\n",
            "[Epoch: 220 Batch:   106] loss: 0.452, acc: 77.736, test_acc:37.500, F1:0.377\n",
            "[Epoch: 221 Batch:   106] loss: 0.433, acc: 77.233, test_acc:35.833, F1:0.353\n",
            "[Epoch: 222 Batch:   106] loss: 0.462, acc: 76.252, test_acc:37.500, F1:0.374\n",
            "[Epoch: 223 Batch:   106] loss: 0.487, acc: 78.075, test_acc:37.500, F1:0.363\n",
            "[Epoch: 224 Batch:   106] loss: 0.430, acc: 78.956, test_acc:31.667, F1:0.316\n",
            "[Epoch: 225 Batch:   106] loss: 0.428, acc: 76.491, test_acc:35.833, F1:0.357\n",
            "[Epoch: 226 Batch:   106] loss: 0.490, acc: 77.019, test_acc:38.333, F1:0.383\n",
            "[Epoch: 227 Batch:   106] loss: 0.442, acc: 79.396, test_acc:35.833, F1:0.355\n",
            "[Epoch: 228 Batch:   106] loss: 0.439, acc: 78.642, test_acc:35.833, F1:0.356\n",
            "[Epoch: 229 Batch:   106] loss: 0.447, acc: 77.648, test_acc:29.167, F1:0.292\n",
            "[Epoch: 230 Batch:   106] loss: 0.534, acc: 75.824, test_acc:35.833, F1:0.353\n",
            "[Epoch: 231 Batch:   106] loss: 0.441, acc: 76.918, test_acc:37.500, F1:0.376\n",
            "[Epoch: 232 Batch:   106] loss: 0.457, acc: 77.925, test_acc:35.000, F1:0.348\n",
            "[Epoch: 233 Batch:   106] loss: 0.451, acc: 78.226, test_acc:33.333, F1:0.333\n",
            "[Epoch: 234 Batch:   106] loss: 0.444, acc: 78.000, test_acc:31.667, F1:0.315\n",
            "[Epoch: 235 Batch:   106] loss: 0.448, acc: 78.465, test_acc:34.167, F1:0.339\n",
            "[Epoch: 236 Batch:   106] loss: 0.459, acc: 75.384, test_acc:33.333, F1:0.332\n",
            "[Epoch: 237 Batch:   106] loss: 0.437, acc: 77.031, test_acc:35.000, F1:0.349\n",
            "[Epoch: 238 Batch:   106] loss: 0.389, acc: 78.692, test_acc:28.333, F1:0.269\n",
            "[Epoch: 239 Batch:   106] loss: 0.421, acc: 77.610, test_acc:33.333, F1:0.328\n",
            "[Epoch: 240 Batch:   106] loss: 0.402, acc: 78.063, test_acc:32.500, F1:0.322\n",
            "[Epoch: 241 Batch:   106] loss: 0.460, acc: 79.107, test_acc:35.833, F1:0.358\n",
            "[Epoch: 242 Batch:   106] loss: 0.459, acc: 77.862, test_acc:34.167, F1:0.341\n",
            "[Epoch: 243 Batch:   106] loss: 0.506, acc: 76.453, test_acc:33.333, F1:0.321\n",
            "[Epoch: 244 Batch:   106] loss: 0.459, acc: 76.491, test_acc:35.000, F1:0.347\n",
            "[Epoch: 245 Batch:   106] loss: 0.433, acc: 77.031, test_acc:35.833, F1:0.354\n",
            "[Epoch: 246 Batch:   106] loss: 0.460, acc: 76.969, test_acc:30.000, F1:0.300\n",
            "[Epoch: 247 Batch:   106] loss: 0.461, acc: 76.503, test_acc:31.667, F1:0.316\n",
            "[Epoch: 248 Batch:   106] loss: 0.403, acc: 77.799, test_acc:32.500, F1:0.319\n",
            "[Epoch: 249 Batch:   106] loss: 0.367, acc: 79.447, test_acc:35.000, F1:0.337\n",
            "[Epoch: 250 Batch:   106] loss: 0.477, acc: 75.799, test_acc:38.333, F1:0.383\n",
            "[Epoch: 251 Batch:   106] loss: 0.422, acc: 77.635, test_acc:33.333, F1:0.323\n",
            "[Epoch: 252 Batch:   106] loss: 0.400, acc: 75.862, test_acc:30.000, F1:0.299\n",
            "[Epoch: 253 Batch:   106] loss: 0.395, acc: 78.390, test_acc:39.167, F1:0.392\n",
            "[Epoch: 254 Batch:   106] loss: 0.416, acc: 77.547, test_acc:35.000, F1:0.350\n",
            "[Epoch: 255 Batch:   106] loss: 0.434, acc: 78.050, test_acc:33.333, F1:0.314\n",
            "[Epoch: 256 Batch:   106] loss: 0.447, acc: 77.308, test_acc:32.500, F1:0.321\n",
            "[Epoch: 257 Batch:   106] loss: 0.439, acc: 79.145, test_acc:36.667, F1:0.366\n",
            "[Epoch: 258 Batch:   106] loss: 0.422, acc: 77.069, test_acc:35.000, F1:0.350\n",
            "[Epoch: 259 Batch:   106] loss: 0.407, acc: 79.057, test_acc:39.167, F1:0.389\n",
            "[Epoch: 260 Batch:   106] loss: 0.463, acc: 77.208, test_acc:34.167, F1:0.339\n",
            "[Epoch: 261 Batch:   106] loss: 0.466, acc: 77.899, test_acc:40.000, F1:0.401\n",
            "[Epoch: 262 Batch:   106] loss: 0.393, acc: 77.673, test_acc:32.500, F1:0.323\n",
            "[Epoch: 263 Batch:   106] loss: 0.387, acc: 80.151, test_acc:29.167, F1:0.290\n",
            "[Epoch: 264 Batch:   106] loss: 0.433, acc: 76.176, test_acc:35.833, F1:0.356\n",
            "[Epoch: 265 Batch:   106] loss: 0.405, acc: 79.748, test_acc:36.667, F1:0.365\n",
            "[Epoch: 266 Batch:   106] loss: 0.414, acc: 79.472, test_acc:35.833, F1:0.356\n",
            "[Epoch: 267 Batch:   106] loss: 0.430, acc: 77.484, test_acc:34.167, F1:0.342\n",
            "[Epoch: 268 Batch:   106] loss: 0.411, acc: 79.547, test_acc:32.500, F1:0.326\n",
            "[Epoch: 269 Batch:   106] loss: 0.473, acc: 77.132, test_acc:33.333, F1:0.331\n",
            "[Epoch: 270 Batch:   106] loss: 0.441, acc: 78.830, test_acc:37.500, F1:0.373\n",
            "[Epoch: 271 Batch:   106] loss: 0.441, acc: 79.233, test_acc:35.833, F1:0.352\n",
            "[Epoch: 272 Batch:   106] loss: 0.404, acc: 79.572, test_acc:33.333, F1:0.330\n",
            "[Epoch: 273 Batch:   106] loss: 0.380, acc: 78.013, test_acc:35.833, F1:0.358\n",
            "[Epoch: 274 Batch:   106] loss: 0.373, acc: 75.836, test_acc:35.833, F1:0.352\n",
            "[Epoch: 275 Batch:   106] loss: 0.398, acc: 78.654, test_acc:38.333, F1:0.379\n",
            "[Epoch: 276 Batch:   106] loss: 0.376, acc: 80.491, test_acc:33.333, F1:0.333\n",
            "[Epoch: 277 Batch:   106] loss: 0.417, acc: 75.824, test_acc:34.167, F1:0.341\n",
            "[Epoch: 278 Batch:   106] loss: 0.454, acc: 79.862, test_acc:40.000, F1:0.399\n",
            "[Epoch: 279 Batch:   106] loss: 0.498, acc: 78.013, test_acc:35.000, F1:0.335\n",
            "[Epoch: 280 Batch:   106] loss: 0.411, acc: 78.126, test_acc:35.000, F1:0.350\n",
            "[Epoch: 281 Batch:   106] loss: 0.434, acc: 78.591, test_acc:38.333, F1:0.381\n",
            "[Epoch: 282 Batch:   106] loss: 0.357, acc: 78.943, test_acc:35.833, F1:0.356\n",
            "[Epoch: 283 Batch:   106] loss: 0.404, acc: 77.899, test_acc:40.000, F1:0.396\n",
            "[Epoch: 284 Batch:   106] loss: 0.358, acc: 79.572, test_acc:36.667, F1:0.360\n",
            "[Epoch: 285 Batch:   106] loss: 0.396, acc: 77.698, test_acc:36.667, F1:0.366\n",
            "[Epoch: 286 Batch:   106] loss: 0.451, acc: 77.082, test_acc:35.833, F1:0.355\n",
            "[Epoch: 287 Batch:   106] loss: 0.388, acc: 76.981, test_acc:36.667, F1:0.363\n",
            "[Epoch: 288 Batch:   106] loss: 0.346, acc: 78.893, test_acc:36.667, F1:0.367\n",
            "[Epoch: 289 Batch:   106] loss: 0.366, acc: 77.862, test_acc:33.333, F1:0.327\n",
            "[Epoch: 290 Batch:   106] loss: 0.381, acc: 78.365, test_acc:35.000, F1:0.349\n",
            "[Epoch: 291 Batch:   106] loss: 0.405, acc: 78.101, test_acc:35.833, F1:0.353\n",
            "[Epoch: 292 Batch:   106] loss: 0.443, acc: 76.918, test_acc:36.667, F1:0.367\n",
            "[Epoch: 293 Batch:   106] loss: 0.390, acc: 79.145, test_acc:40.000, F1:0.397\n",
            "[Epoch: 294 Batch:   106] loss: 0.486, acc: 77.748, test_acc:36.667, F1:0.364\n",
            "[Epoch: 295 Batch:   106] loss: 0.502, acc: 76.289, test_acc:35.000, F1:0.344\n",
            "[Epoch: 296 Batch:   106] loss: 0.405, acc: 77.937, test_acc:31.667, F1:0.309\n",
            "[Epoch: 297 Batch:   106] loss: 0.439, acc: 79.824, test_acc:35.833, F1:0.351\n",
            "[Epoch: 298 Batch:   106] loss: 0.409, acc: 78.742, test_acc:31.667, F1:0.317\n",
            "[Epoch: 299 Batch:   106] loss: 0.377, acc: 79.421, test_acc:36.667, F1:0.367\n",
            "[Epoch: 300 Batch:   106] loss: 0.424, acc: 78.126, test_acc:31.667, F1:0.309\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  31.666666666666664\n",
            "Test F1 Score : 0.30913978494623656\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.46      0.39        39\n",
            "         1.0       0.33      0.22      0.27        45\n",
            "         2.0       0.28      0.28      0.28        36\n",
            "\n",
            "    accuracy                           0.32       120\n",
            "   macro avg       0.31      0.32      0.31       120\n",
            "weighted avg       0.32      0.32      0.31       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[18 11 10]\n",
            " [19 10 16]\n",
            " [17  9 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.1687079787254335 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  11\n",
            "[Epoch: 1 Batch:   106] loss: 1.090, acc: 36.239, test_acc:33.333, F1:0.311\n",
            "[Epoch: 2 Batch:   106] loss: 1.081, acc: 34.138, test_acc:30.833, F1:0.272\n",
            "[Epoch: 3 Batch:   106] loss: 1.080, acc: 35.170, test_acc:31.667, F1:0.303\n",
            "[Epoch: 4 Batch:   106] loss: 1.077, acc: 34.742, test_acc:38.333, F1:0.375\n",
            "[Epoch: 5 Batch:   106] loss: 1.075, acc: 35.962, test_acc:37.500, F1:0.366\n",
            "[Epoch: 6 Batch:   106] loss: 1.074, acc: 36.403, test_acc:33.333, F1:0.327\n",
            "[Epoch: 7 Batch:   106] loss: 1.073, acc: 38.679, test_acc:36.667, F1:0.348\n",
            "[Epoch: 8 Batch:   106] loss: 1.073, acc: 38.201, test_acc:34.167, F1:0.343\n",
            "[Epoch: 9 Batch:   106] loss: 1.068, acc: 39.585, test_acc:31.667, F1:0.319\n",
            "[Epoch: 10 Batch:   106] loss: 1.069, acc: 40.491, test_acc:30.833, F1:0.304\n",
            "[Epoch: 11 Batch:   106] loss: 1.065, acc: 41.925, test_acc:33.333, F1:0.332\n",
            "[Epoch: 12 Batch:   106] loss: 1.063, acc: 40.780, test_acc:36.667, F1:0.355\n",
            "[Epoch: 13 Batch:   106] loss: 1.063, acc: 39.560, test_acc:28.333, F1:0.277\n",
            "[Epoch: 14 Batch:   106] loss: 1.061, acc: 40.943, test_acc:31.667, F1:0.312\n",
            "[Epoch: 15 Batch:   106] loss: 1.060, acc: 39.535, test_acc:32.500, F1:0.324\n",
            "[Epoch: 16 Batch:   106] loss: 1.057, acc: 41.006, test_acc:30.833, F1:0.303\n",
            "[Epoch: 17 Batch:   106] loss: 1.057, acc: 42.528, test_acc:32.500, F1:0.318\n",
            "[Epoch: 18 Batch:   106] loss: 1.056, acc: 41.673, test_acc:34.167, F1:0.335\n",
            "[Epoch: 19 Batch:   106] loss: 1.052, acc: 42.239, test_acc:33.333, F1:0.325\n",
            "[Epoch: 20 Batch:   106] loss: 1.052, acc: 42.541, test_acc:35.833, F1:0.352\n",
            "[Epoch: 21 Batch:   106] loss: 1.050, acc: 42.591, test_acc:35.000, F1:0.348\n",
            "[Epoch: 22 Batch:   106] loss: 1.052, acc: 42.868, test_acc:27.500, F1:0.276\n",
            "[Epoch: 23 Batch:   106] loss: 1.048, acc: 42.591, test_acc:35.833, F1:0.350\n",
            "[Epoch: 24 Batch:   106] loss: 1.047, acc: 43.270, test_acc:29.167, F1:0.285\n",
            "[Epoch: 25 Batch:   106] loss: 1.045, acc: 43.296, test_acc:34.167, F1:0.337\n",
            "[Epoch: 26 Batch:   106] loss: 1.045, acc: 44.730, test_acc:31.667, F1:0.313\n",
            "[Epoch: 27 Batch:   106] loss: 1.041, acc: 43.774, test_acc:28.333, F1:0.283\n",
            "[Epoch: 28 Batch:   106] loss: 1.040, acc: 44.906, test_acc:29.167, F1:0.288\n",
            "[Epoch: 29 Batch:   106] loss: 1.038, acc: 44.377, test_acc:28.333, F1:0.279\n",
            "[Epoch: 30 Batch:   106] loss: 1.035, acc: 44.931, test_acc:31.667, F1:0.312\n",
            "[Epoch: 31 Batch:   106] loss: 1.038, acc: 44.302, test_acc:32.500, F1:0.318\n",
            "[Epoch: 32 Batch:   106] loss: 1.034, acc: 44.969, test_acc:36.667, F1:0.363\n",
            "[Epoch: 33 Batch:   106] loss: 1.027, acc: 46.994, test_acc:25.000, F1:0.250\n",
            "[Epoch: 34 Batch:   106] loss: 1.027, acc: 44.792, test_acc:29.167, F1:0.289\n",
            "[Epoch: 35 Batch:   106] loss: 1.021, acc: 46.742, test_acc:30.000, F1:0.295\n",
            "[Epoch: 36 Batch:   106] loss: 1.023, acc: 46.855, test_acc:30.000, F1:0.296\n",
            "[Epoch: 37 Batch:   106] loss: 1.023, acc: 48.088, test_acc:21.667, F1:0.215\n",
            "[Epoch: 38 Batch:   106] loss: 1.018, acc: 48.126, test_acc:32.500, F1:0.319\n",
            "[Epoch: 39 Batch:   106] loss: 1.012, acc: 48.277, test_acc:33.333, F1:0.328\n",
            "[Epoch: 40 Batch:   106] loss: 1.009, acc: 47.384, test_acc:32.500, F1:0.323\n",
            "[Epoch: 41 Batch:   106] loss: 1.008, acc: 48.704, test_acc:26.667, F1:0.261\n",
            "[Epoch: 42 Batch:   106] loss: 1.003, acc: 49.094, test_acc:30.833, F1:0.307\n",
            "[Epoch: 43 Batch:   106] loss: 1.001, acc: 48.780, test_acc:25.833, F1:0.257\n",
            "[Epoch: 44 Batch:   106] loss: 1.003, acc: 49.333, test_acc:23.333, F1:0.233\n",
            "[Epoch: 45 Batch:   106] loss: 0.992, acc: 50.465, test_acc:33.333, F1:0.332\n",
            "[Epoch: 46 Batch:   106] loss: 0.997, acc: 50.264, test_acc:28.333, F1:0.283\n",
            "[Epoch: 47 Batch:   106] loss: 0.994, acc: 50.717, test_acc:28.333, F1:0.283\n",
            "[Epoch: 48 Batch:   106] loss: 0.980, acc: 52.000, test_acc:30.833, F1:0.306\n",
            "[Epoch: 49 Batch:   106] loss: 0.987, acc: 51.006, test_acc:31.667, F1:0.310\n",
            "[Epoch: 50 Batch:   106] loss: 0.974, acc: 51.887, test_acc:33.333, F1:0.330\n",
            "[Epoch: 51 Batch:   106] loss: 0.978, acc: 52.881, test_acc:28.333, F1:0.282\n",
            "[Epoch: 52 Batch:   106] loss: 0.977, acc: 52.403, test_acc:33.333, F1:0.331\n",
            "[Epoch: 53 Batch:   106] loss: 0.974, acc: 52.792, test_acc:27.500, F1:0.274\n",
            "[Epoch: 54 Batch:   106] loss: 0.961, acc: 53.862, test_acc:28.333, F1:0.283\n",
            "[Epoch: 55 Batch:   106] loss: 0.961, acc: 53.497, test_acc:27.500, F1:0.275\n",
            "[Epoch: 56 Batch:   106] loss: 0.960, acc: 54.956, test_acc:29.167, F1:0.286\n",
            "[Epoch: 57 Batch:   106] loss: 0.958, acc: 53.925, test_acc:32.500, F1:0.320\n",
            "[Epoch: 58 Batch:   106] loss: 0.955, acc: 54.566, test_acc:28.333, F1:0.284\n",
            "[Epoch: 59 Batch:   106] loss: 0.941, acc: 54.843, test_acc:28.333, F1:0.284\n",
            "[Epoch: 60 Batch:   106] loss: 0.941, acc: 56.314, test_acc:28.333, F1:0.278\n",
            "[Epoch: 61 Batch:   106] loss: 0.946, acc: 55.899, test_acc:32.500, F1:0.322\n",
            "[Epoch: 62 Batch:   106] loss: 0.939, acc: 56.239, test_acc:25.000, F1:0.246\n",
            "[Epoch: 63 Batch:   106] loss: 0.931, acc: 55.786, test_acc:25.833, F1:0.257\n",
            "[Epoch: 64 Batch:   106] loss: 0.923, acc: 57.711, test_acc:25.833, F1:0.256\n",
            "[Epoch: 65 Batch:   106] loss: 0.925, acc: 58.679, test_acc:24.167, F1:0.236\n",
            "[Epoch: 66 Batch:   106] loss: 0.918, acc: 57.409, test_acc:29.167, F1:0.290\n",
            "[Epoch: 67 Batch:   106] loss: 0.917, acc: 58.289, test_acc:34.167, F1:0.336\n",
            "[Epoch: 68 Batch:   106] loss: 0.908, acc: 59.019, test_acc:27.500, F1:0.273\n",
            "[Epoch: 69 Batch:   106] loss: 0.911, acc: 59.333, test_acc:30.000, F1:0.300\n",
            "[Epoch: 70 Batch:   106] loss: 0.903, acc: 59.182, test_acc:28.333, F1:0.284\n",
            "[Epoch: 71 Batch:   106] loss: 0.890, acc: 60.063, test_acc:31.667, F1:0.319\n",
            "[Epoch: 72 Batch:   106] loss: 0.893, acc: 60.138, test_acc:30.000, F1:0.299\n",
            "[Epoch: 73 Batch:   106] loss: 0.891, acc: 60.503, test_acc:32.500, F1:0.322\n",
            "[Epoch: 74 Batch:   106] loss: 0.893, acc: 61.899, test_acc:30.833, F1:0.308\n",
            "[Epoch: 75 Batch:   106] loss: 0.873, acc: 61.748, test_acc:25.833, F1:0.254\n",
            "[Epoch: 76 Batch:   106] loss: 0.882, acc: 61.371, test_acc:32.500, F1:0.320\n",
            "[Epoch: 77 Batch:   106] loss: 0.879, acc: 61.057, test_acc:30.000, F1:0.300\n",
            "[Epoch: 78 Batch:   106] loss: 0.873, acc: 62.553, test_acc:30.000, F1:0.299\n",
            "[Epoch: 79 Batch:   106] loss: 0.871, acc: 61.296, test_acc:26.667, F1:0.265\n",
            "[Epoch: 80 Batch:   106] loss: 0.862, acc: 63.031, test_acc:26.667, F1:0.263\n",
            "[Epoch: 81 Batch:   106] loss: 0.859, acc: 61.912, test_acc:25.833, F1:0.258\n",
            "[Epoch: 82 Batch:   106] loss: 0.863, acc: 61.409, test_acc:25.000, F1:0.248\n",
            "[Epoch: 83 Batch:   106] loss: 0.846, acc: 63.396, test_acc:28.333, F1:0.282\n",
            "[Epoch: 84 Batch:   106] loss: 0.851, acc: 64.113, test_acc:32.500, F1:0.323\n",
            "[Epoch: 85 Batch:   106] loss: 0.840, acc: 64.553, test_acc:26.667, F1:0.269\n",
            "[Epoch: 86 Batch:   106] loss: 0.826, acc: 65.283, test_acc:30.833, F1:0.306\n",
            "[Epoch: 87 Batch:   106] loss: 0.837, acc: 63.283, test_acc:30.000, F1:0.301\n",
            "[Epoch: 88 Batch:   106] loss: 0.813, acc: 65.434, test_acc:27.500, F1:0.273\n",
            "[Epoch: 89 Batch:   106] loss: 0.831, acc: 64.566, test_acc:30.833, F1:0.304\n",
            "[Epoch: 90 Batch:   106] loss: 0.817, acc: 65.208, test_acc:29.167, F1:0.287\n",
            "[Epoch: 91 Batch:   106] loss: 0.815, acc: 65.975, test_acc:28.333, F1:0.282\n",
            "[Epoch: 92 Batch:   106] loss: 0.812, acc: 65.849, test_acc:32.500, F1:0.326\n",
            "[Epoch: 93 Batch:   106] loss: 0.808, acc: 66.767, test_acc:29.167, F1:0.292\n",
            "[Epoch: 94 Batch:   106] loss: 0.808, acc: 66.151, test_acc:30.833, F1:0.307\n",
            "[Epoch: 95 Batch:   106] loss: 0.797, acc: 65.836, test_acc:35.833, F1:0.357\n",
            "[Epoch: 96 Batch:   106] loss: 0.793, acc: 66.302, test_acc:29.167, F1:0.293\n",
            "[Epoch: 97 Batch:   106] loss: 0.797, acc: 65.975, test_acc:30.833, F1:0.307\n",
            "[Epoch: 98 Batch:   106] loss: 0.767, acc: 67.975, test_acc:30.000, F1:0.299\n",
            "[Epoch: 99 Batch:   106] loss: 0.769, acc: 67.333, test_acc:32.500, F1:0.318\n",
            "[Epoch: 100 Batch:   106] loss: 0.785, acc: 67.107, test_acc:28.333, F1:0.280\n",
            "[Epoch: 101 Batch:   106] loss: 0.786, acc: 67.811, test_acc:33.333, F1:0.331\n",
            "[Epoch: 102 Batch:   106] loss: 0.787, acc: 66.943, test_acc:31.667, F1:0.315\n",
            "[Epoch: 103 Batch:   106] loss: 0.756, acc: 68.352, test_acc:30.000, F1:0.300\n",
            "[Epoch: 104 Batch:   106] loss: 0.766, acc: 68.730, test_acc:26.667, F1:0.264\n",
            "[Epoch: 105 Batch:   106] loss: 0.735, acc: 69.522, test_acc:30.000, F1:0.297\n",
            "[Epoch: 106 Batch:   106] loss: 0.747, acc: 70.302, test_acc:31.667, F1:0.317\n",
            "[Epoch: 107 Batch:   106] loss: 0.751, acc: 68.189, test_acc:28.333, F1:0.284\n",
            "[Epoch: 108 Batch:   106] loss: 0.730, acc: 70.063, test_acc:29.167, F1:0.284\n",
            "[Epoch: 109 Batch:   106] loss: 0.722, acc: 70.742, test_acc:33.333, F1:0.330\n",
            "[Epoch: 110 Batch:   106] loss: 0.720, acc: 71.006, test_acc:29.167, F1:0.288\n",
            "[Epoch: 111 Batch:   106] loss: 0.716, acc: 70.717, test_acc:30.833, F1:0.306\n",
            "[Epoch: 112 Batch:   106] loss: 0.714, acc: 71.371, test_acc:32.500, F1:0.321\n",
            "[Epoch: 113 Batch:   106] loss: 0.694, acc: 71.195, test_acc:33.333, F1:0.328\n",
            "[Epoch: 114 Batch:   106] loss: 0.705, acc: 71.170, test_acc:29.167, F1:0.289\n",
            "[Epoch: 115 Batch:   106] loss: 0.692, acc: 71.535, test_acc:26.667, F1:0.263\n",
            "[Epoch: 116 Batch:   106] loss: 0.707, acc: 71.447, test_acc:28.333, F1:0.285\n",
            "[Epoch: 117 Batch:   106] loss: 0.687, acc: 71.308, test_acc:23.333, F1:0.226\n",
            "[Epoch: 118 Batch:   106] loss: 0.663, acc: 74.415, test_acc:30.833, F1:0.305\n",
            "[Epoch: 119 Batch:   106] loss: 0.671, acc: 73.610, test_acc:30.000, F1:0.300\n",
            "[Epoch: 120 Batch:   106] loss: 0.692, acc: 72.742, test_acc:30.833, F1:0.308\n",
            "[Epoch: 121 Batch:   106] loss: 0.669, acc: 74.428, test_acc:27.500, F1:0.272\n",
            "[Epoch: 122 Batch:   106] loss: 0.673, acc: 75.057, test_acc:28.333, F1:0.283\n",
            "[Epoch: 123 Batch:   106] loss: 0.661, acc: 72.969, test_acc:25.000, F1:0.250\n",
            "[Epoch: 124 Batch:   106] loss: 0.645, acc: 73.233, test_acc:29.167, F1:0.294\n",
            "[Epoch: 125 Batch:   106] loss: 0.645, acc: 74.340, test_acc:30.833, F1:0.306\n",
            "[Epoch: 126 Batch:   106] loss: 0.652, acc: 73.421, test_acc:25.000, F1:0.246\n",
            "[Epoch: 127 Batch:   106] loss: 0.643, acc: 74.503, test_acc:26.667, F1:0.264\n",
            "[Epoch: 128 Batch:   106] loss: 0.628, acc: 74.843, test_acc:29.167, F1:0.294\n",
            "[Epoch: 129 Batch:   106] loss: 0.640, acc: 74.164, test_acc:29.167, F1:0.287\n",
            "[Epoch: 130 Batch:   106] loss: 0.622, acc: 74.704, test_acc:24.167, F1:0.239\n",
            "[Epoch: 131 Batch:   106] loss: 0.629, acc: 74.868, test_acc:30.833, F1:0.305\n",
            "[Epoch: 132 Batch:   106] loss: 0.606, acc: 74.314, test_acc:31.667, F1:0.309\n",
            "[Epoch: 133 Batch:   106] loss: 0.628, acc: 72.956, test_acc:27.500, F1:0.275\n",
            "[Epoch: 134 Batch:   106] loss: 0.617, acc: 73.522, test_acc:25.833, F1:0.257\n",
            "[Epoch: 135 Batch:   106] loss: 0.596, acc: 75.560, test_acc:28.333, F1:0.275\n",
            "[Epoch: 136 Batch:   106] loss: 0.603, acc: 74.239, test_acc:25.833, F1:0.259\n",
            "[Epoch: 137 Batch:   106] loss: 0.602, acc: 74.264, test_acc:25.833, F1:0.256\n",
            "[Epoch: 138 Batch:   106] loss: 0.586, acc: 75.597, test_acc:31.667, F1:0.316\n",
            "[Epoch: 139 Batch:   106] loss: 0.615, acc: 74.025, test_acc:30.833, F1:0.307\n",
            "[Epoch: 140 Batch:   106] loss: 0.585, acc: 75.258, test_acc:36.667, F1:0.362\n",
            "[Epoch: 141 Batch:   106] loss: 0.573, acc: 75.836, test_acc:30.000, F1:0.295\n",
            "[Epoch: 142 Batch:   106] loss: 0.585, acc: 76.616, test_acc:27.500, F1:0.275\n",
            "[Epoch: 143 Batch:   106] loss: 0.551, acc: 76.101, test_acc:30.000, F1:0.296\n",
            "[Epoch: 144 Batch:   106] loss: 0.578, acc: 76.201, test_acc:30.000, F1:0.297\n",
            "[Epoch: 145 Batch:   106] loss: 0.562, acc: 74.843, test_acc:30.000, F1:0.300\n",
            "[Epoch: 146 Batch:   106] loss: 0.553, acc: 75.912, test_acc:34.167, F1:0.340\n",
            "[Epoch: 147 Batch:   106] loss: 0.544, acc: 77.698, test_acc:28.333, F1:0.277\n",
            "[Epoch: 148 Batch:   106] loss: 0.551, acc: 76.302, test_acc:25.000, F1:0.249\n",
            "[Epoch: 149 Batch:   106] loss: 0.537, acc: 77.761, test_acc:28.333, F1:0.283\n",
            "[Epoch: 150 Batch:   106] loss: 0.554, acc: 75.698, test_acc:25.833, F1:0.254\n",
            "[Epoch: 151 Batch:   106] loss: 0.520, acc: 77.031, test_acc:21.667, F1:0.215\n",
            "[Epoch: 152 Batch:   106] loss: 0.545, acc: 78.327, test_acc:26.667, F1:0.265\n",
            "[Epoch: 153 Batch:   106] loss: 0.521, acc: 77.195, test_acc:30.000, F1:0.292\n",
            "[Epoch: 154 Batch:   106] loss: 0.537, acc: 78.050, test_acc:29.167, F1:0.290\n",
            "[Epoch: 155 Batch:   106] loss: 0.516, acc: 78.931, test_acc:28.333, F1:0.282\n",
            "[Epoch: 156 Batch:   106] loss: 0.496, acc: 79.447, test_acc:25.833, F1:0.251\n",
            "[Epoch: 157 Batch:   106] loss: 0.495, acc: 78.352, test_acc:25.833, F1:0.258\n",
            "[Epoch: 158 Batch:   106] loss: 0.504, acc: 78.365, test_acc:27.500, F1:0.267\n",
            "[Epoch: 159 Batch:   106] loss: 0.525, acc: 75.811, test_acc:22.500, F1:0.218\n",
            "[Epoch: 160 Batch:   106] loss: 0.509, acc: 78.126, test_acc:24.167, F1:0.235\n",
            "[Epoch: 161 Batch:   106] loss: 0.493, acc: 77.975, test_acc:28.333, F1:0.275\n",
            "[Epoch: 162 Batch:   106] loss: 0.496, acc: 78.252, test_acc:25.833, F1:0.255\n",
            "[Epoch: 163 Batch:   106] loss: 0.477, acc: 77.535, test_acc:24.167, F1:0.230\n",
            "[Epoch: 164 Batch:   106] loss: 0.490, acc: 78.553, test_acc:27.500, F1:0.273\n",
            "[Epoch: 165 Batch:   106] loss: 0.493, acc: 76.994, test_acc:30.833, F1:0.304\n",
            "[Epoch: 166 Batch:   106] loss: 0.494, acc: 77.497, test_acc:27.500, F1:0.274\n",
            "[Epoch: 167 Batch:   106] loss: 0.500, acc: 76.465, test_acc:26.667, F1:0.256\n",
            "[Epoch: 168 Batch:   106] loss: 0.500, acc: 77.421, test_acc:29.167, F1:0.278\n",
            "[Epoch: 169 Batch:   106] loss: 0.501, acc: 76.943, test_acc:24.167, F1:0.231\n",
            "[Epoch: 170 Batch:   106] loss: 0.497, acc: 78.692, test_acc:30.000, F1:0.298\n",
            "[Epoch: 171 Batch:   106] loss: 0.500, acc: 77.925, test_acc:26.667, F1:0.260\n",
            "[Epoch: 172 Batch:   106] loss: 0.503, acc: 76.843, test_acc:21.667, F1:0.208\n",
            "[Epoch: 173 Batch:   106] loss: 0.464, acc: 78.075, test_acc:29.167, F1:0.284\n",
            "[Epoch: 174 Batch:   106] loss: 0.453, acc: 77.308, test_acc:21.667, F1:0.212\n",
            "[Epoch: 175 Batch:   106] loss: 0.445, acc: 77.308, test_acc:27.500, F1:0.266\n",
            "[Epoch: 176 Batch:   106] loss: 0.464, acc: 78.113, test_acc:26.667, F1:0.267\n",
            "[Epoch: 177 Batch:   106] loss: 0.448, acc: 77.824, test_acc:29.167, F1:0.276\n",
            "[Epoch: 178 Batch:   106] loss: 0.441, acc: 78.742, test_acc:23.333, F1:0.217\n",
            "[Epoch: 179 Batch:   106] loss: 0.461, acc: 77.509, test_acc:30.833, F1:0.309\n",
            "[Epoch: 180 Batch:   106] loss: 0.498, acc: 77.434, test_acc:28.333, F1:0.281\n",
            "[Epoch: 181 Batch:   106] loss: 0.456, acc: 77.560, test_acc:26.667, F1:0.248\n",
            "[Epoch: 182 Batch:   106] loss: 0.433, acc: 79.233, test_acc:24.167, F1:0.227\n",
            "[Epoch: 183 Batch:   106] loss: 0.429, acc: 78.075, test_acc:26.667, F1:0.262\n",
            "[Epoch: 184 Batch:   106] loss: 0.473, acc: 79.057, test_acc:32.500, F1:0.267\n",
            "[Epoch: 185 Batch:   106] loss: 0.439, acc: 78.767, test_acc:23.333, F1:0.213\n",
            "[Epoch: 186 Batch:   106] loss: 0.423, acc: 79.937, test_acc:25.000, F1:0.238\n",
            "[Epoch: 187 Batch:   106] loss: 0.453, acc: 78.516, test_acc:26.667, F1:0.258\n",
            "[Epoch: 188 Batch:   106] loss: 0.453, acc: 77.145, test_acc:27.500, F1:0.242\n",
            "[Epoch: 189 Batch:   106] loss: 0.424, acc: 79.057, test_acc:33.333, F1:0.299\n",
            "[Epoch: 190 Batch:   106] loss: 0.473, acc: 78.629, test_acc:25.000, F1:0.249\n",
            "[Epoch: 191 Batch:   106] loss: 0.465, acc: 77.384, test_acc:27.500, F1:0.252\n",
            "[Epoch: 192 Batch:   106] loss: 0.417, acc: 79.509, test_acc:27.500, F1:0.224\n",
            "[Epoch: 193 Batch:   106] loss: 0.401, acc: 77.170, test_acc:25.833, F1:0.254\n",
            "[Epoch: 194 Batch:   106] loss: 0.393, acc: 79.258, test_acc:23.333, F1:0.226\n",
            "[Epoch: 195 Batch:   106] loss: 0.439, acc: 79.824, test_acc:29.167, F1:0.292\n",
            "[Epoch: 196 Batch:   106] loss: 0.417, acc: 78.541, test_acc:27.500, F1:0.266\n",
            "[Epoch: 197 Batch:   106] loss: 0.444, acc: 77.899, test_acc:27.500, F1:0.250\n",
            "[Epoch: 198 Batch:   106] loss: 0.437, acc: 79.535, test_acc:27.500, F1:0.272\n",
            "[Epoch: 199 Batch:   106] loss: 0.445, acc: 78.428, test_acc:30.000, F1:0.287\n",
            "[Epoch: 200 Batch:   106] loss: 0.434, acc: 78.201, test_acc:29.167, F1:0.267\n",
            "[Epoch: 201 Batch:   106] loss: 0.392, acc: 79.434, test_acc:26.667, F1:0.266\n",
            "[Epoch: 202 Batch:   106] loss: 0.413, acc: 78.981, test_acc:29.167, F1:0.291\n",
            "[Epoch: 203 Batch:   106] loss: 0.452, acc: 79.031, test_acc:27.500, F1:0.269\n",
            "[Epoch: 204 Batch:   106] loss: 0.430, acc: 78.013, test_acc:23.333, F1:0.222\n",
            "[Epoch: 205 Batch:   106] loss: 0.370, acc: 78.755, test_acc:27.500, F1:0.262\n",
            "[Epoch: 206 Batch:   106] loss: 0.398, acc: 78.516, test_acc:26.667, F1:0.261\n",
            "[Epoch: 207 Batch:   106] loss: 0.364, acc: 81.686, test_acc:28.333, F1:0.255\n",
            "[Epoch: 208 Batch:   106] loss: 0.415, acc: 78.767, test_acc:28.333, F1:0.284\n",
            "[Epoch: 209 Batch:   106] loss: 0.397, acc: 78.591, test_acc:24.167, F1:0.224\n",
            "[Epoch: 210 Batch:   106] loss: 0.370, acc: 80.164, test_acc:27.500, F1:0.259\n",
            "[Epoch: 211 Batch:   106] loss: 0.458, acc: 77.522, test_acc:29.167, F1:0.290\n",
            "[Epoch: 212 Batch:   106] loss: 0.483, acc: 77.572, test_acc:27.500, F1:0.243\n",
            "[Epoch: 213 Batch:   106] loss: 0.451, acc: 77.132, test_acc:27.500, F1:0.259\n",
            "[Epoch: 214 Batch:   106] loss: 0.400, acc: 78.830, test_acc:24.167, F1:0.241\n",
            "[Epoch: 215 Batch:   106] loss: 0.372, acc: 79.585, test_acc:26.667, F1:0.266\n",
            "[Epoch: 216 Batch:   106] loss: 0.359, acc: 79.836, test_acc:25.833, F1:0.239\n",
            "[Epoch: 217 Batch:   106] loss: 0.320, acc: 79.811, test_acc:31.667, F1:0.316\n",
            "[Epoch: 218 Batch:   106] loss: 0.390, acc: 79.371, test_acc:21.667, F1:0.207\n",
            "[Epoch: 219 Batch:   106] loss: 0.366, acc: 77.937, test_acc:21.667, F1:0.205\n",
            "[Epoch: 220 Batch:   106] loss: 0.361, acc: 79.736, test_acc:28.333, F1:0.244\n",
            "[Epoch: 221 Batch:   106] loss: 0.392, acc: 80.000, test_acc:34.167, F1:0.309\n",
            "[Epoch: 222 Batch:   106] loss: 0.429, acc: 78.503, test_acc:25.000, F1:0.242\n",
            "[Epoch: 223 Batch:   106] loss: 0.392, acc: 78.075, test_acc:25.000, F1:0.244\n",
            "[Epoch: 224 Batch:   106] loss: 0.473, acc: 78.604, test_acc:26.667, F1:0.237\n",
            "[Epoch: 225 Batch:   106] loss: 0.381, acc: 80.377, test_acc:28.333, F1:0.278\n",
            "[Epoch: 226 Batch:   106] loss: 0.457, acc: 76.654, test_acc:26.667, F1:0.245\n",
            "[Epoch: 227 Batch:   106] loss: 0.440, acc: 77.283, test_acc:31.667, F1:0.313\n",
            "[Epoch: 228 Batch:   106] loss: 0.370, acc: 78.755, test_acc:24.167, F1:0.226\n",
            "[Epoch: 229 Batch:   106] loss: 0.409, acc: 80.013, test_acc:29.167, F1:0.276\n",
            "[Epoch: 230 Batch:   106] loss: 0.413, acc: 78.063, test_acc:28.333, F1:0.280\n",
            "[Epoch: 231 Batch:   106] loss: 0.364, acc: 77.296, test_acc:22.500, F1:0.223\n",
            "[Epoch: 232 Batch:   106] loss: 0.370, acc: 78.377, test_acc:25.833, F1:0.259\n",
            "[Epoch: 233 Batch:   106] loss: 0.307, acc: 79.522, test_acc:25.833, F1:0.240\n",
            "[Epoch: 234 Batch:   106] loss: 0.355, acc: 79.623, test_acc:25.000, F1:0.218\n",
            "[Epoch: 235 Batch:   106] loss: 0.363, acc: 77.975, test_acc:26.667, F1:0.248\n",
            "[Epoch: 236 Batch:   106] loss: 0.352, acc: 78.717, test_acc:26.667, F1:0.239\n",
            "[Epoch: 237 Batch:   106] loss: 0.362, acc: 79.723, test_acc:21.667, F1:0.189\n",
            "[Epoch: 238 Batch:   106] loss: 0.409, acc: 79.057, test_acc:20.000, F1:0.168\n",
            "[Epoch: 239 Batch:   106] loss: 0.430, acc: 77.119, test_acc:32.500, F1:0.309\n",
            "[Epoch: 240 Batch:   106] loss: 0.399, acc: 80.390, test_acc:28.333, F1:0.266\n",
            "[Epoch: 241 Batch:   106] loss: 0.351, acc: 80.906, test_acc:28.333, F1:0.274\n",
            "[Epoch: 242 Batch:   106] loss: 0.348, acc: 80.717, test_acc:30.000, F1:0.283\n",
            "[Epoch: 243 Batch:   106] loss: 0.359, acc: 79.962, test_acc:25.000, F1:0.246\n",
            "[Epoch: 244 Batch:   106] loss: 0.378, acc: 78.918, test_acc:30.833, F1:0.277\n",
            "[Epoch: 245 Batch:   106] loss: 0.381, acc: 77.925, test_acc:29.167, F1:0.277\n",
            "[Epoch: 246 Batch:   106] loss: 0.402, acc: 79.560, test_acc:26.667, F1:0.261\n",
            "[Epoch: 247 Batch:   106] loss: 0.344, acc: 77.774, test_acc:29.167, F1:0.266\n",
            "[Epoch: 248 Batch:   106] loss: 0.376, acc: 78.314, test_acc:27.500, F1:0.234\n",
            "[Epoch: 249 Batch:   106] loss: 0.438, acc: 77.371, test_acc:30.833, F1:0.304\n",
            "[Epoch: 250 Batch:   106] loss: 0.356, acc: 79.748, test_acc:26.667, F1:0.249\n",
            "[Epoch: 251 Batch:   106] loss: 0.374, acc: 79.635, test_acc:32.500, F1:0.291\n",
            "[Epoch: 252 Batch:   106] loss: 0.435, acc: 75.283, test_acc:31.667, F1:0.286\n",
            "[Epoch: 253 Batch:   106] loss: 0.460, acc: 76.805, test_acc:29.167, F1:0.288\n",
            "[Epoch: 254 Batch:   106] loss: 0.402, acc: 78.893, test_acc:26.667, F1:0.241\n",
            "[Epoch: 255 Batch:   106] loss: 0.358, acc: 77.975, test_acc:22.500, F1:0.228\n",
            "[Epoch: 256 Batch:   106] loss: 0.382, acc: 78.541, test_acc:26.667, F1:0.253\n",
            "[Epoch: 257 Batch:   106] loss: 0.420, acc: 76.088, test_acc:30.833, F1:0.268\n",
            "[Epoch: 258 Batch:   106] loss: 0.366, acc: 77.849, test_acc:26.667, F1:0.234\n",
            "[Epoch: 259 Batch:   106] loss: 0.417, acc: 78.164, test_acc:26.667, F1:0.254\n",
            "[Epoch: 260 Batch:   106] loss: 0.330, acc: 77.686, test_acc:25.833, F1:0.246\n",
            "[Epoch: 261 Batch:   106] loss: 0.326, acc: 79.145, test_acc:30.000, F1:0.265\n",
            "[Epoch: 262 Batch:   106] loss: 0.331, acc: 78.553, test_acc:34.167, F1:0.312\n",
            "[Epoch: 263 Batch:   106] loss: 0.318, acc: 79.509, test_acc:24.167, F1:0.236\n",
            "[Epoch: 264 Batch:   106] loss: 0.304, acc: 78.528, test_acc:30.000, F1:0.263\n",
            "[Epoch: 265 Batch:   106] loss: 0.298, acc: 81.182, test_acc:27.500, F1:0.270\n",
            "[Epoch: 266 Batch:   106] loss: 0.351, acc: 79.220, test_acc:23.333, F1:0.215\n",
            "[Epoch: 267 Batch:   106] loss: 0.309, acc: 80.742, test_acc:28.333, F1:0.250\n",
            "[Epoch: 268 Batch:   106] loss: 0.307, acc: 79.019, test_acc:27.500, F1:0.265\n",
            "[Epoch: 269 Batch:   106] loss: 0.327, acc: 79.912, test_acc:27.500, F1:0.267\n",
            "[Epoch: 270 Batch:   106] loss: 0.368, acc: 79.296, test_acc:30.000, F1:0.261\n",
            "[Epoch: 271 Batch:   106] loss: 0.373, acc: 76.302, test_acc:24.167, F1:0.241\n",
            "[Epoch: 272 Batch:   106] loss: 0.365, acc: 78.491, test_acc:28.333, F1:0.254\n",
            "[Epoch: 273 Batch:   106] loss: 0.395, acc: 77.925, test_acc:23.333, F1:0.231\n",
            "[Epoch: 274 Batch:   106] loss: 0.356, acc: 78.164, test_acc:28.333, F1:0.251\n",
            "[Epoch: 275 Batch:   106] loss: 0.316, acc: 79.950, test_acc:25.833, F1:0.253\n",
            "[Epoch: 276 Batch:   106] loss: 0.350, acc: 78.667, test_acc:32.500, F1:0.314\n",
            "[Epoch: 277 Batch:   106] loss: 0.366, acc: 77.333, test_acc:30.833, F1:0.274\n",
            "[Epoch: 278 Batch:   106] loss: 0.376, acc: 80.101, test_acc:26.667, F1:0.244\n",
            "[Epoch: 279 Batch:   106] loss: 0.342, acc: 77.560, test_acc:25.833, F1:0.251\n",
            "[Epoch: 280 Batch:   106] loss: 0.329, acc: 77.522, test_acc:25.000, F1:0.218\n",
            "[Epoch: 281 Batch:   106] loss: 0.411, acc: 76.088, test_acc:24.167, F1:0.236\n",
            "[Epoch: 282 Batch:   106] loss: 0.383, acc: 78.679, test_acc:33.333, F1:0.304\n",
            "[Epoch: 283 Batch:   106] loss: 0.412, acc: 78.629, test_acc:27.500, F1:0.250\n",
            "[Epoch: 284 Batch:   106] loss: 0.504, acc: 76.176, test_acc:23.333, F1:0.209\n",
            "[Epoch: 285 Batch:   106] loss: 0.439, acc: 78.377, test_acc:25.833, F1:0.256\n",
            "[Epoch: 286 Batch:   106] loss: 0.387, acc: 79.006, test_acc:29.167, F1:0.248\n",
            "[Epoch: 287 Batch:   106] loss: 0.356, acc: 78.088, test_acc:26.667, F1:0.238\n",
            "[Epoch: 288 Batch:   106] loss: 0.351, acc: 78.491, test_acc:28.333, F1:0.277\n",
            "[Epoch: 289 Batch:   106] loss: 0.364, acc: 76.981, test_acc:25.000, F1:0.219\n",
            "[Epoch: 290 Batch:   106] loss: 0.532, acc: 75.635, test_acc:27.500, F1:0.234\n",
            "[Epoch: 291 Batch:   106] loss: 0.484, acc: 76.704, test_acc:26.667, F1:0.251\n",
            "[Epoch: 292 Batch:   106] loss: 0.398, acc: 80.063, test_acc:30.000, F1:0.268\n",
            "[Epoch: 293 Batch:   106] loss: 0.389, acc: 79.925, test_acc:30.000, F1:0.271\n",
            "[Epoch: 294 Batch:   106] loss: 0.341, acc: 76.428, test_acc:28.333, F1:0.248\n",
            "[Epoch: 295 Batch:   106] loss: 0.489, acc: 75.623, test_acc:28.333, F1:0.234\n",
            "[Epoch: 296 Batch:   106] loss: 0.453, acc: 76.918, test_acc:26.667, F1:0.243\n",
            "[Epoch: 297 Batch:   106] loss: 0.362, acc: 78.956, test_acc:29.167, F1:0.221\n",
            "[Epoch: 298 Batch:   106] loss: 0.460, acc: 77.962, test_acc:23.333, F1:0.213\n",
            "[Epoch: 299 Batch:   106] loss: 0.496, acc: 76.050, test_acc:25.833, F1:0.245\n",
            "[Epoch: 300 Batch:   106] loss: 0.412, acc: 77.094, test_acc:30.000, F1:0.263\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  30.0\n",
            "Test F1 Score : 0.2630952380952381\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.48      0.36        33\n",
            "         1.0       0.30      0.40      0.35        42\n",
            "         2.0       0.33      0.07      0.11        45\n",
            "\n",
            "    accuracy                           0.30       120\n",
            "   macro avg       0.31      0.32      0.27       120\n",
            "weighted avg       0.31      0.30      0.26       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[16 15  2]\n",
            " [21 17  4]\n",
            " [18 24  3]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.121415241559347 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  12\n",
            "[Epoch: 1 Batch:   106] loss: 1.091, acc: 38.478, test_acc:24.167, F1:0.244\n",
            "[Epoch: 2 Batch:   106] loss: 1.080, acc: 38.075, test_acc:36.667, F1:0.371\n",
            "[Epoch: 3 Batch:   106] loss: 1.077, acc: 35.610, test_acc:30.000, F1:0.296\n",
            "[Epoch: 4 Batch:   106] loss: 1.076, acc: 36.629, test_acc:30.000, F1:0.305\n",
            "[Epoch: 5 Batch:   106] loss: 1.074, acc: 36.214, test_acc:22.500, F1:0.229\n",
            "[Epoch: 6 Batch:   106] loss: 1.073, acc: 36.252, test_acc:25.000, F1:0.250\n",
            "[Epoch: 7 Batch:   106] loss: 1.070, acc: 38.755, test_acc:23.333, F1:0.234\n",
            "[Epoch: 8 Batch:   106] loss: 1.070, acc: 38.239, test_acc:23.333, F1:0.236\n",
            "[Epoch: 9 Batch:   106] loss: 1.067, acc: 39.472, test_acc:21.667, F1:0.218\n",
            "[Epoch: 10 Batch:   106] loss: 1.067, acc: 39.245, test_acc:21.667, F1:0.223\n",
            "[Epoch: 11 Batch:   106] loss: 1.066, acc: 39.396, test_acc:22.500, F1:0.230\n",
            "[Epoch: 12 Batch:   106] loss: 1.064, acc: 40.302, test_acc:26.667, F1:0.275\n",
            "[Epoch: 13 Batch:   106] loss: 1.062, acc: 40.717, test_acc:25.833, F1:0.257\n",
            "[Epoch: 14 Batch:   106] loss: 1.062, acc: 40.264, test_acc:27.500, F1:0.283\n",
            "[Epoch: 15 Batch:   106] loss: 1.060, acc: 39.987, test_acc:22.500, F1:0.224\n",
            "[Epoch: 16 Batch:   106] loss: 1.058, acc: 42.403, test_acc:24.167, F1:0.245\n",
            "[Epoch: 17 Batch:   106] loss: 1.057, acc: 41.434, test_acc:24.167, F1:0.247\n",
            "[Epoch: 18 Batch:   106] loss: 1.056, acc: 41.774, test_acc:26.667, F1:0.275\n",
            "[Epoch: 19 Batch:   106] loss: 1.057, acc: 40.868, test_acc:27.500, F1:0.278\n",
            "[Epoch: 20 Batch:   106] loss: 1.053, acc: 42.767, test_acc:26.667, F1:0.277\n",
            "[Epoch: 21 Batch:   106] loss: 1.056, acc: 43.132, test_acc:27.500, F1:0.275\n",
            "[Epoch: 22 Batch:   106] loss: 1.052, acc: 43.597, test_acc:25.000, F1:0.253\n",
            "[Epoch: 23 Batch:   106] loss: 1.052, acc: 43.119, test_acc:30.833, F1:0.320\n",
            "[Epoch: 24 Batch:   106] loss: 1.047, acc: 44.075, test_acc:29.167, F1:0.298\n",
            "[Epoch: 25 Batch:   106] loss: 1.045, acc: 44.075, test_acc:24.167, F1:0.251\n",
            "[Epoch: 26 Batch:   106] loss: 1.048, acc: 44.642, test_acc:31.667, F1:0.327\n",
            "[Epoch: 27 Batch:   106] loss: 1.046, acc: 43.824, test_acc:29.167, F1:0.291\n",
            "[Epoch: 28 Batch:   106] loss: 1.043, acc: 45.673, test_acc:30.000, F1:0.314\n",
            "[Epoch: 29 Batch:   106] loss: 1.037, acc: 45.585, test_acc:30.833, F1:0.315\n",
            "[Epoch: 30 Batch:   106] loss: 1.034, acc: 45.182, test_acc:26.667, F1:0.268\n",
            "[Epoch: 31 Batch:   106] loss: 1.034, acc: 45.535, test_acc:25.833, F1:0.271\n",
            "[Epoch: 32 Batch:   106] loss: 1.033, acc: 45.258, test_acc:24.167, F1:0.243\n",
            "[Epoch: 33 Batch:   106] loss: 1.030, acc: 45.585, test_acc:25.000, F1:0.257\n",
            "[Epoch: 34 Batch:   106] loss: 1.032, acc: 46.679, test_acc:25.833, F1:0.261\n",
            "[Epoch: 35 Batch:   106] loss: 1.024, acc: 47.270, test_acc:27.500, F1:0.283\n",
            "[Epoch: 36 Batch:   106] loss: 1.027, acc: 46.277, test_acc:24.167, F1:0.248\n",
            "[Epoch: 37 Batch:   106] loss: 1.019, acc: 47.836, test_acc:27.500, F1:0.287\n",
            "[Epoch: 38 Batch:   106] loss: 1.021, acc: 47.006, test_acc:20.833, F1:0.212\n",
            "[Epoch: 39 Batch:   106] loss: 1.017, acc: 48.377, test_acc:21.667, F1:0.224\n",
            "[Epoch: 40 Batch:   106] loss: 1.012, acc: 47.862, test_acc:23.333, F1:0.242\n",
            "[Epoch: 41 Batch:   106] loss: 1.012, acc: 48.101, test_acc:26.667, F1:0.271\n",
            "[Epoch: 42 Batch:   106] loss: 1.004, acc: 48.843, test_acc:23.333, F1:0.243\n",
            "[Epoch: 43 Batch:   106] loss: 1.003, acc: 49.535, test_acc:29.167, F1:0.306\n",
            "[Epoch: 44 Batch:   106] loss: 1.007, acc: 50.239, test_acc:22.500, F1:0.229\n",
            "[Epoch: 45 Batch:   106] loss: 1.003, acc: 50.667, test_acc:25.833, F1:0.262\n",
            "[Epoch: 46 Batch:   106] loss: 0.997, acc: 50.503, test_acc:25.000, F1:0.260\n",
            "[Epoch: 47 Batch:   106] loss: 0.989, acc: 51.270, test_acc:26.667, F1:0.276\n",
            "[Epoch: 48 Batch:   106] loss: 0.989, acc: 50.792, test_acc:25.000, F1:0.258\n",
            "[Epoch: 49 Batch:   106] loss: 0.988, acc: 51.107, test_acc:25.000, F1:0.253\n",
            "[Epoch: 50 Batch:   106] loss: 0.982, acc: 52.000, test_acc:24.167, F1:0.246\n",
            "[Epoch: 51 Batch:   106] loss: 0.976, acc: 51.698, test_acc:25.833, F1:0.264\n",
            "[Epoch: 52 Batch:   106] loss: 0.983, acc: 51.736, test_acc:27.500, F1:0.278\n",
            "[Epoch: 53 Batch:   106] loss: 0.972, acc: 52.491, test_acc:26.667, F1:0.275\n",
            "[Epoch: 54 Batch:   106] loss: 0.971, acc: 53.220, test_acc:23.333, F1:0.234\n",
            "[Epoch: 55 Batch:   106] loss: 0.972, acc: 53.270, test_acc:21.667, F1:0.228\n",
            "[Epoch: 56 Batch:   106] loss: 0.967, acc: 54.088, test_acc:21.667, F1:0.220\n",
            "[Epoch: 57 Batch:   106] loss: 0.958, acc: 54.491, test_acc:21.667, F1:0.218\n",
            "[Epoch: 58 Batch:   106] loss: 0.959, acc: 55.384, test_acc:21.667, F1:0.217\n",
            "[Epoch: 59 Batch:   106] loss: 0.954, acc: 55.937, test_acc:23.333, F1:0.237\n",
            "[Epoch: 60 Batch:   106] loss: 0.954, acc: 55.069, test_acc:19.167, F1:0.192\n",
            "[Epoch: 61 Batch:   106] loss: 0.946, acc: 54.616, test_acc:23.333, F1:0.237\n",
            "[Epoch: 62 Batch:   106] loss: 0.946, acc: 56.654, test_acc:25.000, F1:0.257\n",
            "[Epoch: 63 Batch:   106] loss: 0.940, acc: 56.818, test_acc:21.667, F1:0.219\n",
            "[Epoch: 64 Batch:   106] loss: 0.935, acc: 56.000, test_acc:24.167, F1:0.243\n",
            "[Epoch: 65 Batch:   106] loss: 0.936, acc: 55.258, test_acc:20.000, F1:0.200\n",
            "[Epoch: 66 Batch:   106] loss: 0.928, acc: 56.541, test_acc:20.833, F1:0.212\n",
            "[Epoch: 67 Batch:   106] loss: 0.928, acc: 58.088, test_acc:23.333, F1:0.235\n",
            "[Epoch: 68 Batch:   106] loss: 0.915, acc: 57.660, test_acc:21.667, F1:0.218\n",
            "[Epoch: 69 Batch:   106] loss: 0.907, acc: 57.912, test_acc:20.000, F1:0.202\n",
            "[Epoch: 70 Batch:   106] loss: 0.908, acc: 58.038, test_acc:22.500, F1:0.226\n",
            "[Epoch: 71 Batch:   106] loss: 0.915, acc: 58.918, test_acc:25.833, F1:0.261\n",
            "[Epoch: 72 Batch:   106] loss: 0.907, acc: 58.956, test_acc:20.833, F1:0.211\n",
            "[Epoch: 73 Batch:   106] loss: 0.900, acc: 59.698, test_acc:24.167, F1:0.243\n",
            "[Epoch: 74 Batch:   106] loss: 0.899, acc: 59.774, test_acc:23.333, F1:0.232\n",
            "[Epoch: 75 Batch:   106] loss: 0.890, acc: 60.667, test_acc:22.500, F1:0.222\n",
            "[Epoch: 76 Batch:   106] loss: 0.891, acc: 60.327, test_acc:24.167, F1:0.245\n",
            "[Epoch: 77 Batch:   106] loss: 0.889, acc: 60.805, test_acc:23.333, F1:0.236\n",
            "[Epoch: 78 Batch:   106] loss: 0.888, acc: 60.403, test_acc:25.000, F1:0.255\n",
            "[Epoch: 79 Batch:   106] loss: 0.873, acc: 61.308, test_acc:25.833, F1:0.265\n",
            "[Epoch: 80 Batch:   106] loss: 0.875, acc: 61.610, test_acc:25.000, F1:0.257\n",
            "[Epoch: 81 Batch:   106] loss: 0.878, acc: 61.774, test_acc:21.667, F1:0.222\n",
            "[Epoch: 82 Batch:   106] loss: 0.872, acc: 62.252, test_acc:26.667, F1:0.270\n",
            "[Epoch: 83 Batch:   106] loss: 0.855, acc: 61.950, test_acc:25.833, F1:0.262\n",
            "[Epoch: 84 Batch:   106] loss: 0.859, acc: 62.352, test_acc:24.167, F1:0.244\n",
            "[Epoch: 85 Batch:   106] loss: 0.846, acc: 64.604, test_acc:30.000, F1:0.300\n",
            "[Epoch: 86 Batch:   106] loss: 0.851, acc: 63.245, test_acc:21.667, F1:0.221\n",
            "[Epoch: 87 Batch:   106] loss: 0.845, acc: 63.497, test_acc:25.833, F1:0.263\n",
            "[Epoch: 88 Batch:   106] loss: 0.841, acc: 63.170, test_acc:24.167, F1:0.244\n",
            "[Epoch: 89 Batch:   106] loss: 0.836, acc: 64.478, test_acc:23.333, F1:0.241\n",
            "[Epoch: 90 Batch:   106] loss: 0.843, acc: 63.635, test_acc:24.167, F1:0.249\n",
            "[Epoch: 91 Batch:   106] loss: 0.829, acc: 64.176, test_acc:20.833, F1:0.214\n",
            "[Epoch: 92 Batch:   106] loss: 0.816, acc: 66.000, test_acc:24.167, F1:0.243\n",
            "[Epoch: 93 Batch:   106] loss: 0.830, acc: 64.013, test_acc:23.333, F1:0.235\n",
            "[Epoch: 94 Batch:   106] loss: 0.819, acc: 66.415, test_acc:23.333, F1:0.240\n",
            "[Epoch: 95 Batch:   106] loss: 0.817, acc: 64.667, test_acc:27.500, F1:0.277\n",
            "[Epoch: 96 Batch:   106] loss: 0.801, acc: 65.686, test_acc:21.667, F1:0.220\n",
            "[Epoch: 97 Batch:   106] loss: 0.810, acc: 66.553, test_acc:30.000, F1:0.308\n",
            "[Epoch: 98 Batch:   106] loss: 0.791, acc: 65.723, test_acc:21.667, F1:0.218\n",
            "[Epoch: 99 Batch:   106] loss: 0.794, acc: 66.654, test_acc:24.167, F1:0.245\n",
            "[Epoch: 100 Batch:   106] loss: 0.774, acc: 67.610, test_acc:27.500, F1:0.280\n",
            "[Epoch: 101 Batch:   106] loss: 0.782, acc: 68.289, test_acc:27.500, F1:0.279\n",
            "[Epoch: 102 Batch:   106] loss: 0.783, acc: 67.082, test_acc:24.167, F1:0.247\n",
            "[Epoch: 103 Batch:   106] loss: 0.766, acc: 68.566, test_acc:27.500, F1:0.280\n",
            "[Epoch: 104 Batch:   106] loss: 0.765, acc: 67.635, test_acc:25.833, F1:0.262\n",
            "[Epoch: 105 Batch:   106] loss: 0.769, acc: 67.660, test_acc:23.333, F1:0.236\n",
            "[Epoch: 106 Batch:   106] loss: 0.764, acc: 68.440, test_acc:21.667, F1:0.221\n",
            "[Epoch: 107 Batch:   106] loss: 0.754, acc: 68.742, test_acc:28.333, F1:0.285\n",
            "[Epoch: 108 Batch:   106] loss: 0.761, acc: 67.459, test_acc:21.667, F1:0.225\n",
            "[Epoch: 109 Batch:   106] loss: 0.758, acc: 68.252, test_acc:26.667, F1:0.271\n",
            "[Epoch: 110 Batch:   106] loss: 0.732, acc: 69.635, test_acc:25.833, F1:0.261\n",
            "[Epoch: 111 Batch:   106] loss: 0.726, acc: 68.767, test_acc:25.000, F1:0.253\n",
            "[Epoch: 112 Batch:   106] loss: 0.739, acc: 68.981, test_acc:25.000, F1:0.259\n",
            "[Epoch: 113 Batch:   106] loss: 0.717, acc: 70.918, test_acc:21.667, F1:0.217\n",
            "[Epoch: 114 Batch:   106] loss: 0.720, acc: 69.157, test_acc:27.500, F1:0.274\n",
            "[Epoch: 115 Batch:   106] loss: 0.702, acc: 70.201, test_acc:22.500, F1:0.224\n",
            "[Epoch: 116 Batch:   106] loss: 0.709, acc: 70.289, test_acc:28.333, F1:0.295\n",
            "[Epoch: 117 Batch:   106] loss: 0.714, acc: 70.038, test_acc:21.667, F1:0.214\n",
            "[Epoch: 118 Batch:   106] loss: 0.714, acc: 69.019, test_acc:20.833, F1:0.213\n",
            "[Epoch: 119 Batch:   106] loss: 0.702, acc: 70.591, test_acc:28.333, F1:0.291\n",
            "[Epoch: 120 Batch:   106] loss: 0.696, acc: 71.723, test_acc:28.333, F1:0.288\n",
            "[Epoch: 121 Batch:   106] loss: 0.690, acc: 71.044, test_acc:21.667, F1:0.227\n",
            "[Epoch: 122 Batch:   106] loss: 0.693, acc: 71.170, test_acc:22.500, F1:0.227\n",
            "[Epoch: 123 Batch:   106] loss: 0.674, acc: 71.950, test_acc:24.167, F1:0.247\n",
            "[Epoch: 124 Batch:   106] loss: 0.680, acc: 71.434, test_acc:22.500, F1:0.233\n",
            "[Epoch: 125 Batch:   106] loss: 0.644, acc: 73.472, test_acc:24.167, F1:0.247\n",
            "[Epoch: 126 Batch:   106] loss: 0.671, acc: 70.591, test_acc:28.333, F1:0.296\n",
            "[Epoch: 127 Batch:   106] loss: 0.662, acc: 72.239, test_acc:25.000, F1:0.256\n",
            "[Epoch: 128 Batch:   106] loss: 0.655, acc: 72.604, test_acc:25.833, F1:0.264\n",
            "[Epoch: 129 Batch:   106] loss: 0.683, acc: 71.132, test_acc:24.167, F1:0.247\n",
            "[Epoch: 130 Batch:   106] loss: 0.646, acc: 73.799, test_acc:20.833, F1:0.219\n",
            "[Epoch: 131 Batch:   106] loss: 0.643, acc: 72.843, test_acc:28.333, F1:0.291\n",
            "[Epoch: 132 Batch:   106] loss: 0.624, acc: 74.264, test_acc:25.833, F1:0.260\n",
            "[Epoch: 133 Batch:   106] loss: 0.646, acc: 72.642, test_acc:26.667, F1:0.281\n",
            "[Epoch: 134 Batch:   106] loss: 0.605, acc: 74.214, test_acc:30.000, F1:0.300\n",
            "[Epoch: 135 Batch:   106] loss: 0.632, acc: 72.818, test_acc:18.333, F1:0.189\n",
            "[Epoch: 136 Batch:   106] loss: 0.655, acc: 71.459, test_acc:28.333, F1:0.282\n",
            "[Epoch: 137 Batch:   106] loss: 0.625, acc: 73.132, test_acc:29.167, F1:0.300\n",
            "[Epoch: 138 Batch:   106] loss: 0.621, acc: 74.553, test_acc:23.333, F1:0.240\n",
            "[Epoch: 139 Batch:   106] loss: 0.632, acc: 72.818, test_acc:22.500, F1:0.229\n",
            "[Epoch: 140 Batch:   106] loss: 0.606, acc: 73.711, test_acc:26.667, F1:0.266\n",
            "[Epoch: 141 Batch:   106] loss: 0.615, acc: 74.918, test_acc:25.000, F1:0.262\n",
            "[Epoch: 142 Batch:   106] loss: 0.596, acc: 74.440, test_acc:28.333, F1:0.285\n",
            "[Epoch: 143 Batch:   106] loss: 0.580, acc: 74.881, test_acc:20.000, F1:0.201\n",
            "[Epoch: 144 Batch:   106] loss: 0.583, acc: 76.025, test_acc:27.500, F1:0.281\n",
            "[Epoch: 145 Batch:   106] loss: 0.568, acc: 73.686, test_acc:22.500, F1:0.231\n",
            "[Epoch: 146 Batch:   106] loss: 0.568, acc: 74.818, test_acc:24.167, F1:0.247\n",
            "[Epoch: 147 Batch:   106] loss: 0.573, acc: 76.918, test_acc:24.167, F1:0.253\n",
            "[Epoch: 148 Batch:   106] loss: 0.548, acc: 77.044, test_acc:25.833, F1:0.262\n",
            "[Epoch: 149 Batch:   106] loss: 0.595, acc: 74.855, test_acc:26.667, F1:0.271\n",
            "[Epoch: 150 Batch:   106] loss: 0.555, acc: 76.352, test_acc:24.167, F1:0.250\n",
            "[Epoch: 151 Batch:   106] loss: 0.532, acc: 75.308, test_acc:25.833, F1:0.264\n",
            "[Epoch: 152 Batch:   106] loss: 0.575, acc: 73.975, test_acc:25.833, F1:0.259\n",
            "[Epoch: 153 Batch:   106] loss: 0.589, acc: 74.465, test_acc:20.833, F1:0.216\n",
            "[Epoch: 154 Batch:   106] loss: 0.563, acc: 74.679, test_acc:29.167, F1:0.297\n",
            "[Epoch: 155 Batch:   106] loss: 0.553, acc: 75.585, test_acc:26.667, F1:0.267\n",
            "[Epoch: 156 Batch:   106] loss: 0.568, acc: 76.252, test_acc:30.000, F1:0.297\n",
            "[Epoch: 157 Batch:   106] loss: 0.529, acc: 76.717, test_acc:21.667, F1:0.221\n",
            "[Epoch: 158 Batch:   106] loss: 0.558, acc: 74.478, test_acc:28.333, F1:0.292\n",
            "[Epoch: 159 Batch:   106] loss: 0.539, acc: 76.327, test_acc:27.500, F1:0.273\n",
            "[Epoch: 160 Batch:   106] loss: 0.520, acc: 76.642, test_acc:30.833, F1:0.296\n",
            "[Epoch: 161 Batch:   106] loss: 0.512, acc: 77.220, test_acc:35.000, F1:0.342\n",
            "[Epoch: 162 Batch:   106] loss: 0.515, acc: 76.541, test_acc:29.167, F1:0.293\n",
            "[Epoch: 163 Batch:   106] loss: 0.488, acc: 78.868, test_acc:30.833, F1:0.310\n",
            "[Epoch: 164 Batch:   106] loss: 0.516, acc: 77.384, test_acc:25.833, F1:0.261\n",
            "[Epoch: 165 Batch:   106] loss: 0.514, acc: 77.623, test_acc:27.500, F1:0.271\n",
            "[Epoch: 166 Batch:   106] loss: 0.552, acc: 76.805, test_acc:29.167, F1:0.291\n",
            "[Epoch: 167 Batch:   106] loss: 0.477, acc: 78.478, test_acc:28.333, F1:0.284\n",
            "[Epoch: 168 Batch:   106] loss: 0.523, acc: 74.390, test_acc:25.000, F1:0.256\n",
            "[Epoch: 169 Batch:   106] loss: 0.524, acc: 77.396, test_acc:25.833, F1:0.265\n",
            "[Epoch: 170 Batch:   106] loss: 0.502, acc: 76.541, test_acc:26.667, F1:0.274\n",
            "[Epoch: 171 Batch:   106] loss: 0.510, acc: 77.849, test_acc:25.000, F1:0.258\n",
            "[Epoch: 172 Batch:   106] loss: 0.494, acc: 77.635, test_acc:29.167, F1:0.300\n",
            "[Epoch: 173 Batch:   106] loss: 0.505, acc: 75.950, test_acc:23.333, F1:0.240\n",
            "[Epoch: 174 Batch:   106] loss: 0.474, acc: 77.019, test_acc:24.167, F1:0.246\n",
            "[Epoch: 175 Batch:   106] loss: 0.463, acc: 76.654, test_acc:27.500, F1:0.257\n",
            "[Epoch: 176 Batch:   106] loss: 0.476, acc: 75.711, test_acc:25.000, F1:0.251\n",
            "[Epoch: 177 Batch:   106] loss: 0.491, acc: 78.289, test_acc:30.833, F1:0.304\n",
            "[Epoch: 178 Batch:   106] loss: 0.450, acc: 78.327, test_acc:26.667, F1:0.254\n",
            "[Epoch: 179 Batch:   106] loss: 0.486, acc: 77.296, test_acc:30.833, F1:0.301\n",
            "[Epoch: 180 Batch:   106] loss: 0.468, acc: 76.616, test_acc:28.333, F1:0.274\n",
            "[Epoch: 181 Batch:   106] loss: 0.466, acc: 78.881, test_acc:25.000, F1:0.254\n",
            "[Epoch: 182 Batch:   106] loss: 0.415, acc: 77.686, test_acc:32.500, F1:0.314\n",
            "[Epoch: 183 Batch:   106] loss: 0.510, acc: 77.358, test_acc:28.333, F1:0.285\n",
            "[Epoch: 184 Batch:   106] loss: 0.451, acc: 77.698, test_acc:29.167, F1:0.290\n",
            "[Epoch: 185 Batch:   106] loss: 0.456, acc: 78.503, test_acc:24.167, F1:0.237\n",
            "[Epoch: 186 Batch:   106] loss: 0.450, acc: 77.484, test_acc:29.167, F1:0.274\n",
            "[Epoch: 187 Batch:   106] loss: 0.434, acc: 78.063, test_acc:26.667, F1:0.270\n",
            "[Epoch: 188 Batch:   106] loss: 0.405, acc: 78.138, test_acc:21.667, F1:0.219\n",
            "[Epoch: 189 Batch:   106] loss: 0.454, acc: 77.799, test_acc:26.667, F1:0.279\n",
            "[Epoch: 190 Batch:   106] loss: 0.451, acc: 76.327, test_acc:29.167, F1:0.281\n",
            "[Epoch: 191 Batch:   106] loss: 0.449, acc: 78.214, test_acc:30.833, F1:0.298\n",
            "[Epoch: 192 Batch:   106] loss: 0.461, acc: 76.277, test_acc:23.333, F1:0.235\n",
            "[Epoch: 193 Batch:   106] loss: 0.455, acc: 77.610, test_acc:25.833, F1:0.260\n",
            "[Epoch: 194 Batch:   106] loss: 0.433, acc: 79.535, test_acc:30.000, F1:0.293\n",
            "[Epoch: 195 Batch:   106] loss: 0.447, acc: 79.019, test_acc:27.500, F1:0.258\n",
            "[Epoch: 196 Batch:   106] loss: 0.439, acc: 76.956, test_acc:29.167, F1:0.287\n",
            "[Epoch: 197 Batch:   106] loss: 0.458, acc: 77.836, test_acc:26.667, F1:0.263\n",
            "[Epoch: 198 Batch:   106] loss: 0.401, acc: 78.478, test_acc:27.500, F1:0.268\n",
            "[Epoch: 199 Batch:   106] loss: 0.420, acc: 78.591, test_acc:30.833, F1:0.301\n",
            "[Epoch: 200 Batch:   106] loss: 0.433, acc: 78.528, test_acc:27.500, F1:0.280\n",
            "[Epoch: 201 Batch:   106] loss: 0.407, acc: 80.050, test_acc:27.500, F1:0.269\n",
            "[Epoch: 202 Batch:   106] loss: 0.410, acc: 78.591, test_acc:29.167, F1:0.282\n",
            "[Epoch: 203 Batch:   106] loss: 0.446, acc: 79.283, test_acc:25.833, F1:0.259\n",
            "[Epoch: 204 Batch:   106] loss: 0.452, acc: 76.981, test_acc:31.667, F1:0.316\n",
            "[Epoch: 205 Batch:   106] loss: 0.439, acc: 76.403, test_acc:25.833, F1:0.261\n",
            "[Epoch: 206 Batch:   106] loss: 0.408, acc: 78.113, test_acc:21.667, F1:0.221\n",
            "[Epoch: 207 Batch:   106] loss: 0.428, acc: 78.918, test_acc:29.167, F1:0.286\n",
            "[Epoch: 208 Batch:   106] loss: 0.414, acc: 77.748, test_acc:32.500, F1:0.309\n",
            "[Epoch: 209 Batch:   106] loss: 0.427, acc: 79.346, test_acc:25.000, F1:0.250\n",
            "[Epoch: 210 Batch:   106] loss: 0.457, acc: 78.176, test_acc:25.833, F1:0.259\n",
            "[Epoch: 211 Batch:   106] loss: 0.428, acc: 77.899, test_acc:25.833, F1:0.258\n",
            "[Epoch: 212 Batch:   106] loss: 0.416, acc: 78.189, test_acc:29.167, F1:0.291\n",
            "[Epoch: 213 Batch:   106] loss: 0.398, acc: 79.509, test_acc:25.000, F1:0.245\n",
            "[Epoch: 214 Batch:   106] loss: 0.406, acc: 76.868, test_acc:25.000, F1:0.232\n",
            "[Epoch: 215 Batch:   106] loss: 0.444, acc: 78.654, test_acc:28.333, F1:0.280\n",
            "[Epoch: 216 Batch:   106] loss: 0.440, acc: 77.132, test_acc:25.833, F1:0.248\n",
            "[Epoch: 217 Batch:   106] loss: 0.398, acc: 78.994, test_acc:29.167, F1:0.268\n",
            "[Epoch: 218 Batch:   106] loss: 0.393, acc: 79.824, test_acc:29.167, F1:0.296\n",
            "[Epoch: 219 Batch:   106] loss: 0.393, acc: 77.748, test_acc:25.833, F1:0.271\n",
            "[Epoch: 220 Batch:   106] loss: 0.386, acc: 78.553, test_acc:29.167, F1:0.291\n",
            "[Epoch: 221 Batch:   106] loss: 0.405, acc: 77.484, test_acc:30.833, F1:0.302\n",
            "[Epoch: 222 Batch:   106] loss: 0.354, acc: 79.132, test_acc:33.333, F1:0.329\n",
            "[Epoch: 223 Batch:   106] loss: 0.391, acc: 78.994, test_acc:35.000, F1:0.354\n",
            "[Epoch: 224 Batch:   106] loss: 0.447, acc: 77.887, test_acc:29.167, F1:0.277\n",
            "[Epoch: 225 Batch:   106] loss: 0.412, acc: 79.975, test_acc:30.833, F1:0.313\n",
            "[Epoch: 226 Batch:   106] loss: 0.362, acc: 78.289, test_acc:26.667, F1:0.277\n",
            "[Epoch: 227 Batch:   106] loss: 0.358, acc: 77.987, test_acc:26.667, F1:0.271\n",
            "[Epoch: 228 Batch:   106] loss: 0.466, acc: 75.862, test_acc:33.333, F1:0.337\n",
            "[Epoch: 229 Batch:   106] loss: 0.414, acc: 77.535, test_acc:29.167, F1:0.289\n",
            "[Epoch: 230 Batch:   106] loss: 0.387, acc: 76.943, test_acc:26.667, F1:0.264\n",
            "[Epoch: 231 Batch:   106] loss: 0.403, acc: 78.553, test_acc:28.333, F1:0.287\n",
            "[Epoch: 232 Batch:   106] loss: 0.439, acc: 77.887, test_acc:30.833, F1:0.315\n",
            "[Epoch: 233 Batch:   106] loss: 0.402, acc: 75.899, test_acc:28.333, F1:0.286\n",
            "[Epoch: 234 Batch:   106] loss: 0.367, acc: 78.591, test_acc:29.167, F1:0.279\n",
            "[Epoch: 235 Batch:   106] loss: 0.355, acc: 79.509, test_acc:26.667, F1:0.255\n",
            "[Epoch: 236 Batch:   106] loss: 0.333, acc: 79.673, test_acc:28.333, F1:0.284\n",
            "[Epoch: 237 Batch:   106] loss: 0.343, acc: 79.396, test_acc:28.333, F1:0.286\n",
            "[Epoch: 238 Batch:   106] loss: 0.354, acc: 78.377, test_acc:30.000, F1:0.303\n",
            "[Epoch: 239 Batch:   106] loss: 0.383, acc: 79.698, test_acc:27.500, F1:0.270\n",
            "[Epoch: 240 Batch:   106] loss: 0.427, acc: 76.528, test_acc:29.167, F1:0.284\n",
            "[Epoch: 241 Batch:   106] loss: 0.385, acc: 77.233, test_acc:25.833, F1:0.251\n",
            "[Epoch: 242 Batch:   106] loss: 0.370, acc: 79.233, test_acc:30.833, F1:0.297\n",
            "[Epoch: 243 Batch:   106] loss: 0.368, acc: 79.371, test_acc:26.667, F1:0.273\n",
            "[Epoch: 244 Batch:   106] loss: 0.341, acc: 77.031, test_acc:31.667, F1:0.316\n",
            "[Epoch: 245 Batch:   106] loss: 0.398, acc: 75.421, test_acc:25.833, F1:0.224\n",
            "[Epoch: 246 Batch:   106] loss: 0.407, acc: 77.774, test_acc:28.333, F1:0.276\n",
            "[Epoch: 247 Batch:   106] loss: 0.382, acc: 78.440, test_acc:28.333, F1:0.285\n",
            "[Epoch: 248 Batch:   106] loss: 0.423, acc: 75.623, test_acc:28.333, F1:0.285\n",
            "[Epoch: 249 Batch:   106] loss: 0.387, acc: 78.541, test_acc:29.167, F1:0.273\n",
            "[Epoch: 250 Batch:   106] loss: 0.475, acc: 78.088, test_acc:30.000, F1:0.281\n",
            "[Epoch: 251 Batch:   106] loss: 0.438, acc: 77.698, test_acc:28.333, F1:0.275\n",
            "[Epoch: 252 Batch:   106] loss: 0.461, acc: 77.912, test_acc:22.500, F1:0.222\n",
            "[Epoch: 253 Batch:   106] loss: 0.325, acc: 79.283, test_acc:30.833, F1:0.310\n",
            "[Epoch: 254 Batch:   106] loss: 0.407, acc: 80.780, test_acc:27.500, F1:0.252\n",
            "[Epoch: 255 Batch:   106] loss: 0.385, acc: 77.723, test_acc:32.500, F1:0.309\n",
            "[Epoch: 256 Batch:   106] loss: 0.314, acc: 79.673, test_acc:33.333, F1:0.319\n",
            "[Epoch: 257 Batch:   106] loss: 0.352, acc: 76.969, test_acc:29.167, F1:0.276\n",
            "[Epoch: 258 Batch:   106] loss: 0.347, acc: 77.409, test_acc:29.167, F1:0.293\n",
            "[Epoch: 259 Batch:   106] loss: 0.370, acc: 77.748, test_acc:27.500, F1:0.256\n",
            "[Epoch: 260 Batch:   106] loss: 0.329, acc: 77.899, test_acc:30.833, F1:0.282\n",
            "[Epoch: 261 Batch:   106] loss: 0.364, acc: 77.698, test_acc:26.667, F1:0.241\n",
            "[Epoch: 262 Batch:   106] loss: 0.341, acc: 79.723, test_acc:32.500, F1:0.318\n",
            "[Epoch: 263 Batch:   106] loss: 0.332, acc: 79.006, test_acc:28.333, F1:0.269\n",
            "[Epoch: 264 Batch:   106] loss: 0.337, acc: 80.893, test_acc:28.333, F1:0.256\n",
            "[Epoch: 265 Batch:   106] loss: 0.400, acc: 78.176, test_acc:26.667, F1:0.267\n",
            "[Epoch: 266 Batch:   106] loss: 0.439, acc: 78.252, test_acc:24.167, F1:0.223\n",
            "[Epoch: 267 Batch:   106] loss: 0.446, acc: 77.358, test_acc:29.167, F1:0.265\n",
            "[Epoch: 268 Batch:   106] loss: 0.501, acc: 74.830, test_acc:25.833, F1:0.243\n",
            "[Epoch: 269 Batch:   106] loss: 0.427, acc: 77.497, test_acc:26.667, F1:0.259\n",
            "[Epoch: 270 Batch:   106] loss: 0.290, acc: 79.220, test_acc:30.000, F1:0.285\n",
            "[Epoch: 271 Batch:   106] loss: 0.371, acc: 78.377, test_acc:26.667, F1:0.260\n",
            "[Epoch: 272 Batch:   106] loss: 0.343, acc: 79.333, test_acc:33.333, F1:0.316\n",
            "[Epoch: 273 Batch:   106] loss: 0.367, acc: 80.239, test_acc:27.500, F1:0.279\n",
            "[Epoch: 274 Batch:   106] loss: 0.360, acc: 78.566, test_acc:28.333, F1:0.282\n",
            "[Epoch: 275 Batch:   106] loss: 0.372, acc: 79.912, test_acc:29.167, F1:0.294\n",
            "[Epoch: 276 Batch:   106] loss: 0.380, acc: 77.761, test_acc:30.000, F1:0.305\n",
            "[Epoch: 277 Batch:   106] loss: 0.517, acc: 75.547, test_acc:31.667, F1:0.290\n",
            "[Epoch: 278 Batch:   106] loss: 0.383, acc: 76.428, test_acc:30.000, F1:0.278\n",
            "[Epoch: 279 Batch:   106] loss: 0.360, acc: 79.006, test_acc:29.167, F1:0.282\n",
            "[Epoch: 280 Batch:   106] loss: 0.327, acc: 79.358, test_acc:24.167, F1:0.239\n",
            "[Epoch: 281 Batch:   106] loss: 0.316, acc: 79.874, test_acc:28.333, F1:0.294\n",
            "[Epoch: 282 Batch:   106] loss: 0.332, acc: 80.579, test_acc:27.500, F1:0.249\n",
            "[Epoch: 283 Batch:   106] loss: 0.436, acc: 76.201, test_acc:30.000, F1:0.263\n",
            "[Epoch: 284 Batch:   106] loss: 0.438, acc: 77.195, test_acc:31.667, F1:0.281\n",
            "[Epoch: 285 Batch:   106] loss: 0.479, acc: 74.704, test_acc:26.667, F1:0.268\n",
            "[Epoch: 286 Batch:   106] loss: 0.415, acc: 78.516, test_acc:28.333, F1:0.270\n",
            "[Epoch: 287 Batch:   106] loss: 0.370, acc: 78.440, test_acc:30.833, F1:0.311\n",
            "[Epoch: 288 Batch:   106] loss: 0.429, acc: 79.308, test_acc:30.000, F1:0.290\n",
            "[Epoch: 289 Batch:   106] loss: 0.449, acc: 78.226, test_acc:26.667, F1:0.268\n",
            "[Epoch: 290 Batch:   106] loss: 0.398, acc: 74.579, test_acc:26.667, F1:0.251\n",
            "[Epoch: 291 Batch:   106] loss: 0.483, acc: 78.050, test_acc:26.667, F1:0.271\n",
            "[Epoch: 292 Batch:   106] loss: 0.384, acc: 79.270, test_acc:33.333, F1:0.290\n",
            "[Epoch: 293 Batch:   106] loss: 0.360, acc: 78.717, test_acc:32.500, F1:0.308\n",
            "[Epoch: 294 Batch:   106] loss: 0.301, acc: 80.151, test_acc:25.000, F1:0.245\n",
            "[Epoch: 295 Batch:   106] loss: 0.318, acc: 77.899, test_acc:31.667, F1:0.262\n",
            "[Epoch: 296 Batch:   106] loss: 0.325, acc: 80.642, test_acc:28.333, F1:0.266\n",
            "[Epoch: 297 Batch:   106] loss: 0.339, acc: 79.585, test_acc:30.833, F1:0.302\n",
            "[Epoch: 298 Batch:   106] loss: 0.369, acc: 78.767, test_acc:31.667, F1:0.298\n",
            "[Epoch: 299 Batch:   106] loss: 0.368, acc: 77.472, test_acc:34.167, F1:0.305\n",
            "[Epoch: 300 Batch:   106] loss: 0.362, acc: 77.748, test_acc:28.333, F1:0.287\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  28.333333333333332\n",
            "Test F1 Score : 0.28680845875139355\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.27      0.26        45\n",
            "         1.0       0.18      0.21      0.19        24\n",
            "         2.0       0.38      0.33      0.35        51\n",
            "\n",
            "    accuracy                           0.28       120\n",
            "   macro avg       0.27      0.27      0.27       120\n",
            "weighted avg       0.29      0.28      0.29       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[12 13 20]\n",
            " [11  5  8]\n",
            " [24 10 17]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.1120577176411945 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  13\n",
            "[Epoch: 1 Batch:   106] loss: 1.086, acc: 37.899, test_acc:30.833, F1:0.304\n",
            "[Epoch: 2 Batch:   106] loss: 1.080, acc: 36.503, test_acc:36.667, F1:0.358\n",
            "[Epoch: 3 Batch:   106] loss: 1.079, acc: 32.214, test_acc:36.667, F1:0.360\n",
            "[Epoch: 4 Batch:   106] loss: 1.078, acc: 35.774, test_acc:40.833, F1:0.395\n",
            "[Epoch: 5 Batch:   106] loss: 1.077, acc: 34.906, test_acc:39.167, F1:0.386\n",
            "[Epoch: 6 Batch:   106] loss: 1.075, acc: 35.308, test_acc:39.167, F1:0.378\n",
            "[Epoch: 7 Batch:   106] loss: 1.074, acc: 35.031, test_acc:35.833, F1:0.357\n",
            "[Epoch: 8 Batch:   106] loss: 1.072, acc: 36.126, test_acc:40.833, F1:0.408\n",
            "[Epoch: 9 Batch:   106] loss: 1.070, acc: 36.277, test_acc:36.667, F1:0.359\n",
            "[Epoch: 10 Batch:   106] loss: 1.066, acc: 38.025, test_acc:35.000, F1:0.351\n",
            "[Epoch: 11 Batch:   106] loss: 1.067, acc: 37.597, test_acc:42.500, F1:0.417\n",
            "[Epoch: 12 Batch:   106] loss: 1.065, acc: 39.107, test_acc:39.167, F1:0.381\n",
            "[Epoch: 13 Batch:   106] loss: 1.064, acc: 38.717, test_acc:33.333, F1:0.321\n",
            "[Epoch: 14 Batch:   106] loss: 1.059, acc: 40.189, test_acc:38.333, F1:0.372\n",
            "[Epoch: 15 Batch:   106] loss: 1.061, acc: 39.509, test_acc:35.833, F1:0.357\n",
            "[Epoch: 16 Batch:   106] loss: 1.058, acc: 39.698, test_acc:34.167, F1:0.334\n",
            "[Epoch: 17 Batch:   106] loss: 1.058, acc: 40.013, test_acc:35.000, F1:0.343\n",
            "[Epoch: 18 Batch:   106] loss: 1.057, acc: 38.679, test_acc:33.333, F1:0.327\n",
            "[Epoch: 19 Batch:   106] loss: 1.054, acc: 40.654, test_acc:32.500, F1:0.316\n",
            "[Epoch: 20 Batch:   106] loss: 1.053, acc: 41.484, test_acc:35.833, F1:0.352\n",
            "[Epoch: 21 Batch:   106] loss: 1.054, acc: 40.516, test_acc:39.167, F1:0.395\n",
            "[Epoch: 22 Batch:   106] loss: 1.051, acc: 41.748, test_acc:33.333, F1:0.329\n",
            "[Epoch: 23 Batch:   106] loss: 1.044, acc: 42.704, test_acc:35.000, F1:0.351\n",
            "[Epoch: 24 Batch:   106] loss: 1.045, acc: 42.302, test_acc:35.000, F1:0.351\n",
            "[Epoch: 25 Batch:   106] loss: 1.046, acc: 43.887, test_acc:37.500, F1:0.375\n",
            "[Epoch: 26 Batch:   106] loss: 1.046, acc: 43.535, test_acc:41.667, F1:0.415\n",
            "[Epoch: 27 Batch:   106] loss: 1.040, acc: 43.082, test_acc:37.500, F1:0.377\n",
            "[Epoch: 28 Batch:   106] loss: 1.036, acc: 42.855, test_acc:40.000, F1:0.402\n",
            "[Epoch: 29 Batch:   106] loss: 1.038, acc: 45.082, test_acc:33.333, F1:0.334\n",
            "[Epoch: 30 Batch:   106] loss: 1.033, acc: 45.132, test_acc:41.667, F1:0.416\n",
            "[Epoch: 31 Batch:   106] loss: 1.034, acc: 44.403, test_acc:42.500, F1:0.428\n",
            "[Epoch: 32 Batch:   106] loss: 1.029, acc: 46.025, test_acc:34.167, F1:0.342\n",
            "[Epoch: 33 Batch:   106] loss: 1.027, acc: 45.170, test_acc:35.000, F1:0.353\n",
            "[Epoch: 34 Batch:   106] loss: 1.022, acc: 47.044, test_acc:35.833, F1:0.359\n",
            "[Epoch: 35 Batch:   106] loss: 1.028, acc: 46.365, test_acc:37.500, F1:0.378\n",
            "[Epoch: 36 Batch:   106] loss: 1.018, acc: 48.013, test_acc:37.500, F1:0.377\n",
            "[Epoch: 37 Batch:   106] loss: 1.012, acc: 47.019, test_acc:35.000, F1:0.351\n",
            "[Epoch: 38 Batch:   106] loss: 1.016, acc: 48.692, test_acc:35.833, F1:0.359\n",
            "[Epoch: 39 Batch:   106] loss: 1.013, acc: 47.836, test_acc:29.167, F1:0.293\n",
            "[Epoch: 40 Batch:   106] loss: 1.010, acc: 47.447, test_acc:37.500, F1:0.375\n",
            "[Epoch: 41 Batch:   106] loss: 1.008, acc: 49.233, test_acc:40.000, F1:0.402\n",
            "[Epoch: 42 Batch:   106] loss: 1.005, acc: 48.918, test_acc:36.667, F1:0.370\n",
            "[Epoch: 43 Batch:   106] loss: 0.998, acc: 49.006, test_acc:34.167, F1:0.343\n",
            "[Epoch: 44 Batch:   106] loss: 1.004, acc: 49.069, test_acc:38.333, F1:0.387\n",
            "[Epoch: 45 Batch:   106] loss: 0.994, acc: 50.767, test_acc:34.167, F1:0.346\n",
            "[Epoch: 46 Batch:   106] loss: 0.992, acc: 51.220, test_acc:36.667, F1:0.369\n",
            "[Epoch: 47 Batch:   106] loss: 0.991, acc: 52.013, test_acc:30.000, F1:0.298\n",
            "[Epoch: 48 Batch:   106] loss: 0.983, acc: 52.113, test_acc:31.667, F1:0.314\n",
            "[Epoch: 49 Batch:   106] loss: 0.984, acc: 51.572, test_acc:36.667, F1:0.368\n",
            "[Epoch: 50 Batch:   106] loss: 0.975, acc: 52.088, test_acc:27.500, F1:0.277\n",
            "[Epoch: 51 Batch:   106] loss: 0.974, acc: 53.258, test_acc:33.333, F1:0.334\n",
            "[Epoch: 52 Batch:   106] loss: 0.972, acc: 53.799, test_acc:35.000, F1:0.353\n",
            "[Epoch: 53 Batch:   106] loss: 0.966, acc: 53.459, test_acc:33.333, F1:0.335\n",
            "[Epoch: 54 Batch:   106] loss: 0.962, acc: 54.906, test_acc:30.000, F1:0.301\n",
            "[Epoch: 55 Batch:   106] loss: 0.964, acc: 53.925, test_acc:36.667, F1:0.370\n",
            "[Epoch: 56 Batch:   106] loss: 0.956, acc: 54.931, test_acc:30.000, F1:0.301\n",
            "[Epoch: 57 Batch:   106] loss: 0.952, acc: 53.874, test_acc:35.000, F1:0.350\n",
            "[Epoch: 58 Batch:   106] loss: 0.943, acc: 54.252, test_acc:34.167, F1:0.344\n",
            "[Epoch: 59 Batch:   106] loss: 0.950, acc: 56.063, test_acc:37.500, F1:0.374\n",
            "[Epoch: 60 Batch:   106] loss: 0.939, acc: 54.314, test_acc:32.500, F1:0.325\n",
            "[Epoch: 61 Batch:   106] loss: 0.932, acc: 55.811, test_acc:31.667, F1:0.317\n",
            "[Epoch: 62 Batch:   106] loss: 0.935, acc: 56.252, test_acc:32.500, F1:0.327\n",
            "[Epoch: 63 Batch:   106] loss: 0.924, acc: 57.270, test_acc:30.833, F1:0.310\n",
            "[Epoch: 64 Batch:   106] loss: 0.923, acc: 57.648, test_acc:35.000, F1:0.351\n",
            "[Epoch: 65 Batch:   106] loss: 0.915, acc: 57.836, test_acc:29.167, F1:0.294\n",
            "[Epoch: 66 Batch:   106] loss: 0.913, acc: 58.528, test_acc:27.500, F1:0.276\n",
            "[Epoch: 67 Batch:   106] loss: 0.907, acc: 57.836, test_acc:28.333, F1:0.283\n",
            "[Epoch: 68 Batch:   106] loss: 0.907, acc: 58.855, test_acc:25.000, F1:0.248\n",
            "[Epoch: 69 Batch:   106] loss: 0.892, acc: 60.038, test_acc:33.333, F1:0.334\n",
            "[Epoch: 70 Batch:   106] loss: 0.887, acc: 60.138, test_acc:29.167, F1:0.288\n",
            "[Epoch: 71 Batch:   106] loss: 0.890, acc: 61.057, test_acc:25.000, F1:0.246\n",
            "[Epoch: 72 Batch:   106] loss: 0.881, acc: 60.478, test_acc:35.833, F1:0.359\n",
            "[Epoch: 73 Batch:   106] loss: 0.878, acc: 62.176, test_acc:32.500, F1:0.326\n",
            "[Epoch: 74 Batch:   106] loss: 0.878, acc: 60.025, test_acc:25.000, F1:0.251\n",
            "[Epoch: 75 Batch:   106] loss: 0.861, acc: 61.975, test_acc:36.667, F1:0.368\n",
            "[Epoch: 76 Batch:   106] loss: 0.877, acc: 61.623, test_acc:28.333, F1:0.284\n",
            "[Epoch: 77 Batch:   106] loss: 0.881, acc: 59.874, test_acc:30.000, F1:0.300\n",
            "[Epoch: 78 Batch:   106] loss: 0.854, acc: 62.252, test_acc:31.667, F1:0.318\n",
            "[Epoch: 79 Batch:   106] loss: 0.848, acc: 63.358, test_acc:33.333, F1:0.330\n",
            "[Epoch: 80 Batch:   106] loss: 0.843, acc: 63.698, test_acc:35.000, F1:0.352\n",
            "[Epoch: 81 Batch:   106] loss: 0.840, acc: 64.038, test_acc:32.500, F1:0.321\n",
            "[Epoch: 82 Batch:   106] loss: 0.831, acc: 63.660, test_acc:27.500, F1:0.276\n",
            "[Epoch: 83 Batch:   106] loss: 0.834, acc: 63.623, test_acc:40.833, F1:0.410\n",
            "[Epoch: 84 Batch:   106] loss: 0.834, acc: 64.478, test_acc:27.500, F1:0.274\n",
            "[Epoch: 85 Batch:   106] loss: 0.824, acc: 64.327, test_acc:32.500, F1:0.325\n",
            "[Epoch: 86 Batch:   106] loss: 0.836, acc: 63.182, test_acc:32.500, F1:0.323\n",
            "[Epoch: 87 Batch:   106] loss: 0.818, acc: 64.629, test_acc:33.333, F1:0.331\n",
            "[Epoch: 88 Batch:   106] loss: 0.806, acc: 66.063, test_acc:33.333, F1:0.333\n",
            "[Epoch: 89 Batch:   106] loss: 0.794, acc: 65.597, test_acc:34.167, F1:0.342\n",
            "[Epoch: 90 Batch:   106] loss: 0.819, acc: 65.082, test_acc:29.167, F1:0.291\n",
            "[Epoch: 91 Batch:   106] loss: 0.808, acc: 65.635, test_acc:30.000, F1:0.301\n",
            "[Epoch: 92 Batch:   106] loss: 0.797, acc: 66.239, test_acc:34.167, F1:0.338\n",
            "[Epoch: 93 Batch:   106] loss: 0.784, acc: 66.176, test_acc:35.000, F1:0.349\n",
            "[Epoch: 94 Batch:   106] loss: 0.785, acc: 67.409, test_acc:29.167, F1:0.292\n",
            "[Epoch: 95 Batch:   106] loss: 0.777, acc: 66.981, test_acc:33.333, F1:0.333\n",
            "[Epoch: 96 Batch:   106] loss: 0.784, acc: 66.063, test_acc:29.167, F1:0.289\n",
            "[Epoch: 97 Batch:   106] loss: 0.778, acc: 66.843, test_acc:30.833, F1:0.306\n",
            "[Epoch: 98 Batch:   106] loss: 0.775, acc: 67.157, test_acc:34.167, F1:0.340\n",
            "[Epoch: 99 Batch:   106] loss: 0.754, acc: 67.824, test_acc:34.167, F1:0.341\n",
            "[Epoch: 100 Batch:   106] loss: 0.767, acc: 67.874, test_acc:35.000, F1:0.350\n",
            "[Epoch: 101 Batch:   106] loss: 0.764, acc: 67.094, test_acc:38.333, F1:0.381\n",
            "[Epoch: 102 Batch:   106] loss: 0.753, acc: 68.730, test_acc:34.167, F1:0.339\n",
            "[Epoch: 103 Batch:   106] loss: 0.746, acc: 69.736, test_acc:30.000, F1:0.296\n",
            "[Epoch: 104 Batch:   106] loss: 0.740, acc: 69.497, test_acc:33.333, F1:0.333\n",
            "[Epoch: 105 Batch:   106] loss: 0.719, acc: 69.635, test_acc:36.667, F1:0.364\n",
            "[Epoch: 106 Batch:   106] loss: 0.741, acc: 69.736, test_acc:35.833, F1:0.355\n",
            "[Epoch: 107 Batch:   106] loss: 0.712, acc: 69.774, test_acc:36.667, F1:0.363\n",
            "[Epoch: 108 Batch:   106] loss: 0.710, acc: 70.000, test_acc:29.167, F1:0.291\n",
            "[Epoch: 109 Batch:   106] loss: 0.728, acc: 70.994, test_acc:32.500, F1:0.320\n",
            "[Epoch: 110 Batch:   106] loss: 0.720, acc: 69.057, test_acc:35.000, F1:0.344\n",
            "[Epoch: 111 Batch:   106] loss: 0.709, acc: 69.182, test_acc:35.833, F1:0.358\n",
            "[Epoch: 112 Batch:   106] loss: 0.716, acc: 69.698, test_acc:36.667, F1:0.356\n",
            "[Epoch: 113 Batch:   106] loss: 0.702, acc: 71.396, test_acc:35.000, F1:0.333\n",
            "[Epoch: 114 Batch:   106] loss: 0.709, acc: 71.107, test_acc:36.667, F1:0.362\n",
            "[Epoch: 115 Batch:   106] loss: 0.709, acc: 71.094, test_acc:31.667, F1:0.318\n",
            "[Epoch: 116 Batch:   106] loss: 0.693, acc: 71.799, test_acc:37.500, F1:0.376\n",
            "[Epoch: 117 Batch:   106] loss: 0.681, acc: 70.541, test_acc:35.000, F1:0.339\n",
            "[Epoch: 118 Batch:   106] loss: 0.685, acc: 71.396, test_acc:32.500, F1:0.321\n",
            "[Epoch: 119 Batch:   106] loss: 0.664, acc: 71.447, test_acc:35.833, F1:0.309\n",
            "[Epoch: 120 Batch:   106] loss: 0.680, acc: 72.478, test_acc:33.333, F1:0.322\n",
            "[Epoch: 121 Batch:   106] loss: 0.692, acc: 71.082, test_acc:35.000, F1:0.342\n",
            "[Epoch: 122 Batch:   106] loss: 0.660, acc: 72.440, test_acc:30.000, F1:0.285\n",
            "[Epoch: 123 Batch:   106] loss: 0.664, acc: 71.560, test_acc:40.833, F1:0.395\n",
            "[Epoch: 124 Batch:   106] loss: 0.643, acc: 72.277, test_acc:35.000, F1:0.349\n",
            "[Epoch: 125 Batch:   106] loss: 0.664, acc: 72.226, test_acc:35.833, F1:0.335\n",
            "[Epoch: 126 Batch:   106] loss: 0.665, acc: 72.126, test_acc:40.833, F1:0.406\n",
            "[Epoch: 127 Batch:   106] loss: 0.640, acc: 73.057, test_acc:36.667, F1:0.346\n",
            "[Epoch: 128 Batch:   106] loss: 0.629, acc: 73.711, test_acc:33.333, F1:0.293\n",
            "[Epoch: 129 Batch:   106] loss: 0.632, acc: 72.679, test_acc:38.333, F1:0.377\n",
            "[Epoch: 130 Batch:   106] loss: 0.631, acc: 74.201, test_acc:40.000, F1:0.354\n",
            "[Epoch: 131 Batch:   106] loss: 0.641, acc: 73.597, test_acc:35.833, F1:0.350\n",
            "[Epoch: 132 Batch:   106] loss: 0.610, acc: 74.553, test_acc:39.167, F1:0.366\n",
            "[Epoch: 133 Batch:   106] loss: 0.616, acc: 74.453, test_acc:39.167, F1:0.380\n",
            "[Epoch: 134 Batch:   106] loss: 0.596, acc: 74.893, test_acc:39.167, F1:0.358\n",
            "[Epoch: 135 Batch:   106] loss: 0.626, acc: 72.013, test_acc:38.333, F1:0.354\n",
            "[Epoch: 136 Batch:   106] loss: 0.613, acc: 74.403, test_acc:36.667, F1:0.336\n",
            "[Epoch: 137 Batch:   106] loss: 0.615, acc: 74.553, test_acc:42.500, F1:0.404\n",
            "[Epoch: 138 Batch:   106] loss: 0.620, acc: 73.396, test_acc:40.000, F1:0.357\n",
            "[Epoch: 139 Batch:   106] loss: 0.617, acc: 73.484, test_acc:33.333, F1:0.306\n",
            "[Epoch: 140 Batch:   106] loss: 0.599, acc: 73.358, test_acc:39.167, F1:0.365\n",
            "[Epoch: 141 Batch:   106] loss: 0.600, acc: 73.925, test_acc:35.833, F1:0.311\n",
            "[Epoch: 142 Batch:   106] loss: 0.584, acc: 73.698, test_acc:38.333, F1:0.333\n",
            "[Epoch: 143 Batch:   106] loss: 0.580, acc: 75.346, test_acc:37.500, F1:0.325\n",
            "[Epoch: 144 Batch:   106] loss: 0.562, acc: 75.145, test_acc:39.167, F1:0.342\n",
            "[Epoch: 145 Batch:   106] loss: 0.576, acc: 73.962, test_acc:40.000, F1:0.361\n",
            "[Epoch: 146 Batch:   106] loss: 0.600, acc: 75.723, test_acc:42.500, F1:0.414\n",
            "[Epoch: 147 Batch:   106] loss: 0.564, acc: 75.057, test_acc:35.833, F1:0.316\n",
            "[Epoch: 148 Batch:   106] loss: 0.566, acc: 75.975, test_acc:34.167, F1:0.308\n",
            "[Epoch: 149 Batch:   106] loss: 0.572, acc: 73.107, test_acc:39.167, F1:0.361\n",
            "[Epoch: 150 Batch:   106] loss: 0.537, acc: 75.321, test_acc:41.667, F1:0.367\n",
            "[Epoch: 151 Batch:   106] loss: 0.546, acc: 76.604, test_acc:36.667, F1:0.325\n",
            "[Epoch: 152 Batch:   106] loss: 0.551, acc: 76.679, test_acc:39.167, F1:0.360\n",
            "[Epoch: 153 Batch:   106] loss: 0.538, acc: 75.635, test_acc:37.500, F1:0.328\n",
            "[Epoch: 154 Batch:   106] loss: 0.514, acc: 78.604, test_acc:35.833, F1:0.305\n",
            "[Epoch: 155 Batch:   106] loss: 0.531, acc: 77.572, test_acc:40.833, F1:0.352\n",
            "[Epoch: 156 Batch:   106] loss: 0.550, acc: 75.371, test_acc:35.000, F1:0.300\n",
            "[Epoch: 157 Batch:   106] loss: 0.516, acc: 77.572, test_acc:39.167, F1:0.336\n",
            "[Epoch: 158 Batch:   106] loss: 0.500, acc: 76.491, test_acc:37.500, F1:0.321\n",
            "[Epoch: 159 Batch:   106] loss: 0.514, acc: 76.528, test_acc:34.167, F1:0.292\n",
            "[Epoch: 160 Batch:   106] loss: 0.501, acc: 76.805, test_acc:36.667, F1:0.303\n",
            "[Epoch: 161 Batch:   106] loss: 0.501, acc: 76.226, test_acc:40.000, F1:0.371\n",
            "[Epoch: 162 Batch:   106] loss: 0.488, acc: 78.302, test_acc:42.500, F1:0.362\n",
            "[Epoch: 163 Batch:   106] loss: 0.528, acc: 77.145, test_acc:40.000, F1:0.341\n",
            "[Epoch: 164 Batch:   106] loss: 0.523, acc: 77.346, test_acc:36.667, F1:0.303\n",
            "[Epoch: 165 Batch:   106] loss: 0.492, acc: 76.616, test_acc:41.667, F1:0.352\n",
            "[Epoch: 166 Batch:   106] loss: 0.487, acc: 76.830, test_acc:38.333, F1:0.328\n",
            "[Epoch: 167 Batch:   106] loss: 0.501, acc: 75.899, test_acc:37.500, F1:0.317\n",
            "[Epoch: 168 Batch:   106] loss: 0.476, acc: 78.113, test_acc:41.667, F1:0.352\n",
            "[Epoch: 169 Batch:   106] loss: 0.501, acc: 77.434, test_acc:34.167, F1:0.261\n",
            "[Epoch: 170 Batch:   106] loss: 0.520, acc: 75.220, test_acc:40.000, F1:0.340\n",
            "[Epoch: 171 Batch:   106] loss: 0.484, acc: 76.692, test_acc:35.000, F1:0.294\n",
            "[Epoch: 172 Batch:   106] loss: 0.486, acc: 76.553, test_acc:37.500, F1:0.323\n",
            "[Epoch: 173 Batch:   106] loss: 0.514, acc: 77.950, test_acc:40.000, F1:0.340\n",
            "[Epoch: 174 Batch:   106] loss: 0.458, acc: 77.811, test_acc:36.667, F1:0.298\n",
            "[Epoch: 175 Batch:   106] loss: 0.493, acc: 76.478, test_acc:33.333, F1:0.285\n",
            "[Epoch: 176 Batch:   106] loss: 0.498, acc: 77.233, test_acc:40.000, F1:0.330\n",
            "[Epoch: 177 Batch:   106] loss: 0.448, acc: 77.635, test_acc:41.667, F1:0.352\n",
            "[Epoch: 178 Batch:   106] loss: 0.430, acc: 79.057, test_acc:41.667, F1:0.374\n",
            "[Epoch: 179 Batch:   106] loss: 0.452, acc: 79.799, test_acc:37.500, F1:0.314\n",
            "[Epoch: 180 Batch:   106] loss: 0.459, acc: 75.987, test_acc:38.333, F1:0.327\n",
            "[Epoch: 181 Batch:   106] loss: 0.434, acc: 77.887, test_acc:33.333, F1:0.276\n",
            "[Epoch: 182 Batch:   106] loss: 0.426, acc: 77.535, test_acc:37.500, F1:0.335\n",
            "[Epoch: 183 Batch:   106] loss: 0.406, acc: 78.956, test_acc:37.500, F1:0.316\n",
            "[Epoch: 184 Batch:   106] loss: 0.416, acc: 78.000, test_acc:34.167, F1:0.292\n",
            "[Epoch: 185 Batch:   106] loss: 0.436, acc: 76.956, test_acc:37.500, F1:0.311\n",
            "[Epoch: 186 Batch:   106] loss: 0.413, acc: 80.730, test_acc:38.333, F1:0.319\n",
            "[Epoch: 187 Batch:   106] loss: 0.420, acc: 78.805, test_acc:37.500, F1:0.320\n",
            "[Epoch: 188 Batch:   106] loss: 0.458, acc: 76.692, test_acc:32.500, F1:0.259\n",
            "[Epoch: 189 Batch:   106] loss: 0.436, acc: 77.057, test_acc:36.667, F1:0.304\n",
            "[Epoch: 190 Batch:   106] loss: 0.425, acc: 79.082, test_acc:35.000, F1:0.289\n",
            "[Epoch: 191 Batch:   106] loss: 0.442, acc: 77.220, test_acc:38.333, F1:0.332\n",
            "[Epoch: 192 Batch:   106] loss: 0.436, acc: 77.107, test_acc:39.167, F1:0.343\n",
            "[Epoch: 193 Batch:   106] loss: 0.410, acc: 77.044, test_acc:41.667, F1:0.349\n",
            "[Epoch: 194 Batch:   106] loss: 0.435, acc: 77.434, test_acc:39.167, F1:0.318\n",
            "[Epoch: 195 Batch:   106] loss: 0.453, acc: 77.270, test_acc:35.000, F1:0.258\n",
            "[Epoch: 196 Batch:   106] loss: 0.437, acc: 78.981, test_acc:35.833, F1:0.313\n",
            "[Epoch: 197 Batch:   106] loss: 0.418, acc: 79.597, test_acc:35.000, F1:0.280\n",
            "[Epoch: 198 Batch:   106] loss: 0.409, acc: 77.748, test_acc:36.667, F1:0.309\n",
            "[Epoch: 199 Batch:   106] loss: 0.422, acc: 77.686, test_acc:37.500, F1:0.318\n",
            "[Epoch: 200 Batch:   106] loss: 0.480, acc: 78.805, test_acc:36.667, F1:0.297\n",
            "[Epoch: 201 Batch:   106] loss: 0.467, acc: 77.975, test_acc:34.167, F1:0.289\n",
            "[Epoch: 202 Batch:   106] loss: 0.423, acc: 77.006, test_acc:38.333, F1:0.320\n",
            "[Epoch: 203 Batch:   106] loss: 0.400, acc: 79.220, test_acc:39.167, F1:0.325\n",
            "[Epoch: 204 Batch:   106] loss: 0.421, acc: 80.013, test_acc:34.167, F1:0.278\n",
            "[Epoch: 205 Batch:   106] loss: 0.368, acc: 79.333, test_acc:39.167, F1:0.301\n",
            "[Epoch: 206 Batch:   106] loss: 0.410, acc: 78.214, test_acc:40.000, F1:0.339\n",
            "[Epoch: 207 Batch:   106] loss: 0.398, acc: 78.289, test_acc:35.000, F1:0.282\n",
            "[Epoch: 208 Batch:   106] loss: 0.374, acc: 79.686, test_acc:37.500, F1:0.306\n",
            "[Epoch: 209 Batch:   106] loss: 0.351, acc: 81.220, test_acc:37.500, F1:0.324\n",
            "[Epoch: 210 Batch:   106] loss: 0.350, acc: 79.195, test_acc:36.667, F1:0.285\n",
            "[Epoch: 211 Batch:   106] loss: 0.374, acc: 79.686, test_acc:35.833, F1:0.287\n",
            "[Epoch: 212 Batch:   106] loss: 0.363, acc: 77.170, test_acc:36.667, F1:0.274\n",
            "[Epoch: 213 Batch:   106] loss: 0.414, acc: 78.491, test_acc:38.333, F1:0.305\n",
            "[Epoch: 214 Batch:   106] loss: 0.412, acc: 77.987, test_acc:36.667, F1:0.281\n",
            "[Epoch: 215 Batch:   106] loss: 0.365, acc: 78.327, test_acc:37.500, F1:0.321\n",
            "[Epoch: 216 Batch:   106] loss: 0.362, acc: 77.824, test_acc:40.000, F1:0.324\n",
            "[Epoch: 217 Batch:   106] loss: 0.386, acc: 78.730, test_acc:40.000, F1:0.333\n",
            "[Epoch: 218 Batch:   106] loss: 0.313, acc: 80.918, test_acc:37.500, F1:0.285\n",
            "[Epoch: 219 Batch:   106] loss: 0.366, acc: 79.371, test_acc:33.333, F1:0.255\n",
            "[Epoch: 220 Batch:   106] loss: 0.339, acc: 81.069, test_acc:40.000, F1:0.330\n",
            "[Epoch: 221 Batch:   106] loss: 0.373, acc: 78.591, test_acc:35.833, F1:0.269\n",
            "[Epoch: 222 Batch:   106] loss: 0.416, acc: 76.226, test_acc:35.833, F1:0.275\n",
            "[Epoch: 223 Batch:   106] loss: 0.381, acc: 77.673, test_acc:35.000, F1:0.288\n",
            "[Epoch: 224 Batch:   106] loss: 0.446, acc: 77.396, test_acc:40.000, F1:0.326\n",
            "[Epoch: 225 Batch:   106] loss: 0.405, acc: 77.723, test_acc:33.333, F1:0.226\n",
            "[Epoch: 226 Batch:   106] loss: 0.458, acc: 76.302, test_acc:37.500, F1:0.314\n",
            "[Epoch: 227 Batch:   106] loss: 0.434, acc: 78.239, test_acc:35.833, F1:0.263\n",
            "[Epoch: 228 Batch:   106] loss: 0.390, acc: 77.182, test_acc:40.000, F1:0.345\n",
            "[Epoch: 229 Batch:   106] loss: 0.504, acc: 76.604, test_acc:34.167, F1:0.253\n",
            "[Epoch: 230 Batch:   106] loss: 0.401, acc: 77.673, test_acc:37.500, F1:0.295\n",
            "[Epoch: 231 Batch:   106] loss: 0.384, acc: 79.346, test_acc:40.000, F1:0.329\n",
            "[Epoch: 232 Batch:   106] loss: 0.359, acc: 78.994, test_acc:35.833, F1:0.262\n",
            "[Epoch: 233 Batch:   106] loss: 0.340, acc: 80.365, test_acc:36.667, F1:0.299\n",
            "[Epoch: 234 Batch:   106] loss: 0.352, acc: 81.094, test_acc:37.500, F1:0.302\n",
            "[Epoch: 235 Batch:   106] loss: 0.381, acc: 80.101, test_acc:37.500, F1:0.312\n",
            "[Epoch: 236 Batch:   106] loss: 0.406, acc: 79.208, test_acc:37.500, F1:0.300\n",
            "[Epoch: 237 Batch:   106] loss: 0.377, acc: 79.836, test_acc:32.500, F1:0.272\n",
            "[Epoch: 238 Batch:   106] loss: 0.403, acc: 78.390, test_acc:34.167, F1:0.259\n",
            "[Epoch: 239 Batch:   106] loss: 0.430, acc: 78.101, test_acc:36.667, F1:0.279\n",
            "[Epoch: 240 Batch:   106] loss: 0.462, acc: 76.931, test_acc:41.667, F1:0.359\n",
            "[Epoch: 241 Batch:   106] loss: 0.354, acc: 78.868, test_acc:35.000, F1:0.251\n",
            "[Epoch: 242 Batch:   106] loss: 0.327, acc: 78.855, test_acc:36.667, F1:0.292\n",
            "[Epoch: 243 Batch:   106] loss: 0.321, acc: 80.075, test_acc:37.500, F1:0.290\n",
            "[Epoch: 244 Batch:   106] loss: 0.437, acc: 77.459, test_acc:37.500, F1:0.300\n",
            "[Epoch: 245 Batch:   106] loss: 0.418, acc: 77.296, test_acc:40.000, F1:0.331\n",
            "[Epoch: 246 Batch:   106] loss: 0.451, acc: 80.717, test_acc:35.833, F1:0.259\n",
            "[Epoch: 247 Batch:   106] loss: 0.379, acc: 79.233, test_acc:33.333, F1:0.234\n",
            "[Epoch: 248 Batch:   106] loss: 0.313, acc: 80.591, test_acc:35.000, F1:0.263\n",
            "[Epoch: 249 Batch:   106] loss: 0.339, acc: 78.516, test_acc:41.667, F1:0.335\n",
            "[Epoch: 250 Batch:   106] loss: 0.389, acc: 79.484, test_acc:37.500, F1:0.312\n",
            "[Epoch: 251 Batch:   106] loss: 0.402, acc: 77.698, test_acc:36.667, F1:0.268\n",
            "[Epoch: 252 Batch:   106] loss: 0.306, acc: 79.459, test_acc:36.667, F1:0.317\n",
            "[Epoch: 253 Batch:   106] loss: 0.444, acc: 79.069, test_acc:34.167, F1:0.247\n",
            "[Epoch: 254 Batch:   106] loss: 0.406, acc: 78.528, test_acc:40.000, F1:0.327\n",
            "[Epoch: 255 Batch:   106] loss: 0.337, acc: 80.692, test_acc:36.667, F1:0.287\n",
            "[Epoch: 256 Batch:   106] loss: 0.298, acc: 80.516, test_acc:35.000, F1:0.265\n",
            "[Epoch: 257 Batch:   106] loss: 0.336, acc: 81.371, test_acc:40.000, F1:0.348\n",
            "[Epoch: 258 Batch:   106] loss: 0.350, acc: 78.440, test_acc:36.667, F1:0.301\n",
            "[Epoch: 259 Batch:   106] loss: 0.416, acc: 79.145, test_acc:40.000, F1:0.322\n",
            "[Epoch: 260 Batch:   106] loss: 0.396, acc: 78.415, test_acc:37.500, F1:0.292\n",
            "[Epoch: 261 Batch:   106] loss: 0.417, acc: 77.786, test_acc:36.667, F1:0.304\n",
            "[Epoch: 262 Batch:   106] loss: 0.370, acc: 77.094, test_acc:37.500, F1:0.294\n",
            "[Epoch: 263 Batch:   106] loss: 0.367, acc: 79.748, test_acc:38.333, F1:0.314\n",
            "[Epoch: 264 Batch:   106] loss: 0.353, acc: 78.415, test_acc:35.833, F1:0.274\n",
            "[Epoch: 265 Batch:   106] loss: 0.333, acc: 81.031, test_acc:35.833, F1:0.277\n",
            "[Epoch: 266 Batch:   106] loss: 0.311, acc: 81.459, test_acc:35.833, F1:0.263\n",
            "[Epoch: 267 Batch:   106] loss: 0.342, acc: 78.755, test_acc:34.167, F1:0.230\n",
            "[Epoch: 268 Batch:   106] loss: 0.359, acc: 79.572, test_acc:33.333, F1:0.226\n",
            "[Epoch: 269 Batch:   106] loss: 0.380, acc: 80.013, test_acc:33.333, F1:0.234\n",
            "[Epoch: 270 Batch:   106] loss: 0.429, acc: 76.931, test_acc:34.167, F1:0.229\n",
            "[Epoch: 271 Batch:   106] loss: 0.398, acc: 79.811, test_acc:37.500, F1:0.328\n",
            "[Epoch: 272 Batch:   106] loss: 0.330, acc: 77.937, test_acc:37.500, F1:0.304\n",
            "[Epoch: 273 Batch:   106] loss: 0.342, acc: 80.906, test_acc:35.000, F1:0.275\n",
            "[Epoch: 274 Batch:   106] loss: 0.301, acc: 81.006, test_acc:35.000, F1:0.242\n",
            "[Epoch: 275 Batch:   106] loss: 0.482, acc: 79.233, test_acc:39.167, F1:0.306\n",
            "[Epoch: 276 Batch:   106] loss: 0.482, acc: 78.881, test_acc:34.167, F1:0.254\n",
            "[Epoch: 277 Batch:   106] loss: 0.424, acc: 78.126, test_acc:40.000, F1:0.317\n",
            "[Epoch: 278 Batch:   106] loss: 0.352, acc: 78.352, test_acc:38.333, F1:0.306\n",
            "[Epoch: 279 Batch:   106] loss: 0.451, acc: 79.447, test_acc:31.667, F1:0.244\n",
            "[Epoch: 280 Batch:   106] loss: 0.419, acc: 76.881, test_acc:37.500, F1:0.306\n",
            "[Epoch: 281 Batch:   106] loss: 0.393, acc: 80.264, test_acc:36.667, F1:0.279\n",
            "[Epoch: 282 Batch:   106] loss: 0.341, acc: 78.491, test_acc:36.667, F1:0.285\n",
            "[Epoch: 283 Batch:   106] loss: 0.255, acc: 81.509, test_acc:34.167, F1:0.230\n",
            "[Epoch: 284 Batch:   106] loss: 0.271, acc: 80.038, test_acc:34.167, F1:0.239\n",
            "[Epoch: 285 Batch:   106] loss: 0.353, acc: 79.019, test_acc:31.667, F1:0.199\n",
            "[Epoch: 286 Batch:   106] loss: 0.308, acc: 82.226, test_acc:35.000, F1:0.276\n",
            "[Epoch: 287 Batch:   106] loss: 0.371, acc: 78.906, test_acc:38.333, F1:0.305\n",
            "[Epoch: 288 Batch:   106] loss: 0.458, acc: 77.937, test_acc:36.667, F1:0.269\n",
            "[Epoch: 289 Batch:   106] loss: 0.430, acc: 79.019, test_acc:33.333, F1:0.295\n",
            "[Epoch: 290 Batch:   106] loss: 0.481, acc: 78.164, test_acc:38.333, F1:0.315\n",
            "[Epoch: 291 Batch:   106] loss: 0.423, acc: 76.239, test_acc:35.833, F1:0.263\n",
            "[Epoch: 292 Batch:   106] loss: 0.318, acc: 80.792, test_acc:38.333, F1:0.322\n",
            "[Epoch: 293 Batch:   106] loss: 0.325, acc: 80.025, test_acc:37.500, F1:0.299\n",
            "[Epoch: 294 Batch:   106] loss: 0.276, acc: 81.748, test_acc:40.833, F1:0.347\n",
            "[Epoch: 295 Batch:   106] loss: 0.309, acc: 80.302, test_acc:37.500, F1:0.289\n",
            "[Epoch: 296 Batch:   106] loss: 0.321, acc: 80.126, test_acc:36.667, F1:0.290\n",
            "[Epoch: 297 Batch:   106] loss: 0.381, acc: 80.566, test_acc:33.333, F1:0.234\n",
            "[Epoch: 298 Batch:   106] loss: 0.303, acc: 81.182, test_acc:35.000, F1:0.276\n",
            "[Epoch: 299 Batch:   106] loss: 0.292, acc: 79.987, test_acc:37.500, F1:0.284\n",
            "[Epoch: 300 Batch:   106] loss: 0.299, acc: 79.623, test_acc:38.333, F1:0.305\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  38.333333333333336\n",
            "Test F1 Score : 0.30468711147948613\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.85      0.52        39\n",
            "         1.0       0.40      0.27      0.32        45\n",
            "         2.0       0.50      0.03      0.05        36\n",
            "\n",
            "    accuracy                           0.38       120\n",
            "   macro avg       0.42      0.38      0.30       120\n",
            "weighted avg       0.42      0.38      0.30       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[33  6  0]\n",
            " [32 12  1]\n",
            " [23 12  1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.049527577559153 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  14\n",
            "[Epoch: 1 Batch:   106] loss: 1.088, acc: 34.704, test_acc:38.333, F1:0.411\n",
            "[Epoch: 2 Batch:   106] loss: 1.083, acc: 37.258, test_acc:41.667, F1:0.442\n",
            "[Epoch: 3 Batch:   106] loss: 1.084, acc: 38.050, test_acc:41.667, F1:0.437\n",
            "[Epoch: 4 Batch:   106] loss: 1.081, acc: 38.239, test_acc:38.333, F1:0.408\n",
            "[Epoch: 5 Batch:   106] loss: 1.082, acc: 38.541, test_acc:43.333, F1:0.454\n",
            "[Epoch: 6 Batch:   106] loss: 1.081, acc: 39.057, test_acc:43.333, F1:0.453\n",
            "[Epoch: 7 Batch:   106] loss: 1.081, acc: 38.164, test_acc:40.000, F1:0.418\n",
            "[Epoch: 8 Batch:   106] loss: 1.078, acc: 38.981, test_acc:33.333, F1:0.365\n",
            "[Epoch: 9 Batch:   106] loss: 1.079, acc: 37.346, test_acc:32.500, F1:0.360\n",
            "[Epoch: 10 Batch:   106] loss: 1.078, acc: 38.717, test_acc:32.500, F1:0.358\n",
            "[Epoch: 11 Batch:   106] loss: 1.076, acc: 37.761, test_acc:37.500, F1:0.401\n",
            "[Epoch: 12 Batch:   106] loss: 1.075, acc: 36.906, test_acc:35.000, F1:0.380\n",
            "[Epoch: 13 Batch:   106] loss: 1.073, acc: 38.780, test_acc:31.667, F1:0.351\n",
            "[Epoch: 14 Batch:   106] loss: 1.072, acc: 38.579, test_acc:32.500, F1:0.352\n",
            "[Epoch: 15 Batch:   106] loss: 1.073, acc: 39.346, test_acc:30.833, F1:0.343\n",
            "[Epoch: 16 Batch:   106] loss: 1.069, acc: 39.434, test_acc:34.167, F1:0.377\n",
            "[Epoch: 17 Batch:   106] loss: 1.067, acc: 39.459, test_acc:26.667, F1:0.296\n",
            "[Epoch: 18 Batch:   106] loss: 1.065, acc: 40.579, test_acc:29.167, F1:0.323\n",
            "[Epoch: 19 Batch:   106] loss: 1.065, acc: 41.396, test_acc:27.500, F1:0.311\n",
            "[Epoch: 20 Batch:   106] loss: 1.062, acc: 41.950, test_acc:28.333, F1:0.329\n",
            "[Epoch: 21 Batch:   106] loss: 1.061, acc: 42.516, test_acc:30.000, F1:0.347\n",
            "[Epoch: 22 Batch:   106] loss: 1.058, acc: 41.937, test_acc:29.167, F1:0.335\n",
            "[Epoch: 23 Batch:   106] loss: 1.057, acc: 42.742, test_acc:30.000, F1:0.347\n",
            "[Epoch: 24 Batch:   106] loss: 1.057, acc: 42.805, test_acc:30.000, F1:0.337\n",
            "[Epoch: 25 Batch:   106] loss: 1.052, acc: 43.660, test_acc:31.667, F1:0.360\n",
            "[Epoch: 26 Batch:   106] loss: 1.052, acc: 44.365, test_acc:32.500, F1:0.367\n",
            "[Epoch: 27 Batch:   106] loss: 1.046, acc: 44.478, test_acc:27.500, F1:0.315\n",
            "[Epoch: 28 Batch:   106] loss: 1.048, acc: 44.138, test_acc:33.333, F1:0.371\n",
            "[Epoch: 29 Batch:   106] loss: 1.042, acc: 44.843, test_acc:31.667, F1:0.366\n",
            "[Epoch: 30 Batch:   106] loss: 1.044, acc: 43.535, test_acc:30.833, F1:0.352\n",
            "[Epoch: 31 Batch:   106] loss: 1.037, acc: 45.723, test_acc:33.333, F1:0.374\n",
            "[Epoch: 32 Batch:   106] loss: 1.038, acc: 45.774, test_acc:31.667, F1:0.350\n",
            "[Epoch: 33 Batch:   106] loss: 1.036, acc: 47.245, test_acc:35.000, F1:0.391\n",
            "[Epoch: 34 Batch:   106] loss: 1.035, acc: 46.755, test_acc:33.333, F1:0.389\n",
            "[Epoch: 35 Batch:   106] loss: 1.034, acc: 46.415, test_acc:33.333, F1:0.379\n",
            "[Epoch: 36 Batch:   106] loss: 1.030, acc: 48.365, test_acc:31.667, F1:0.365\n",
            "[Epoch: 37 Batch:   106] loss: 1.022, acc: 47.962, test_acc:34.167, F1:0.384\n",
            "[Epoch: 38 Batch:   106] loss: 1.023, acc: 47.748, test_acc:35.833, F1:0.396\n",
            "[Epoch: 39 Batch:   106] loss: 1.021, acc: 48.528, test_acc:36.667, F1:0.407\n",
            "[Epoch: 40 Batch:   106] loss: 1.012, acc: 49.585, test_acc:35.000, F1:0.388\n",
            "[Epoch: 41 Batch:   106] loss: 1.019, acc: 49.094, test_acc:30.000, F1:0.341\n",
            "[Epoch: 42 Batch:   106] loss: 1.014, acc: 49.686, test_acc:38.333, F1:0.420\n",
            "[Epoch: 43 Batch:   106] loss: 1.007, acc: 49.748, test_acc:35.833, F1:0.400\n",
            "[Epoch: 44 Batch:   106] loss: 1.007, acc: 49.132, test_acc:32.500, F1:0.368\n",
            "[Epoch: 45 Batch:   106] loss: 0.998, acc: 50.038, test_acc:30.000, F1:0.338\n",
            "[Epoch: 46 Batch:   106] loss: 1.001, acc: 51.145, test_acc:33.333, F1:0.379\n",
            "[Epoch: 47 Batch:   106] loss: 0.993, acc: 50.805, test_acc:31.667, F1:0.368\n",
            "[Epoch: 48 Batch:   106] loss: 0.994, acc: 51.849, test_acc:30.000, F1:0.342\n",
            "[Epoch: 49 Batch:   106] loss: 0.983, acc: 52.717, test_acc:30.833, F1:0.347\n",
            "[Epoch: 50 Batch:   106] loss: 0.984, acc: 52.654, test_acc:30.000, F1:0.345\n",
            "[Epoch: 51 Batch:   106] loss: 0.981, acc: 53.157, test_acc:26.667, F1:0.309\n",
            "[Epoch: 52 Batch:   106] loss: 0.981, acc: 53.333, test_acc:30.000, F1:0.353\n",
            "[Epoch: 53 Batch:   106] loss: 0.967, acc: 53.761, test_acc:29.167, F1:0.337\n",
            "[Epoch: 54 Batch:   106] loss: 0.968, acc: 54.252, test_acc:32.500, F1:0.360\n",
            "[Epoch: 55 Batch:   106] loss: 0.965, acc: 54.013, test_acc:27.500, F1:0.312\n",
            "[Epoch: 56 Batch:   106] loss: 0.966, acc: 53.094, test_acc:29.167, F1:0.339\n",
            "[Epoch: 57 Batch:   106] loss: 0.957, acc: 55.182, test_acc:30.833, F1:0.347\n",
            "[Epoch: 58 Batch:   106] loss: 0.952, acc: 56.277, test_acc:27.500, F1:0.323\n",
            "[Epoch: 59 Batch:   106] loss: 0.952, acc: 56.503, test_acc:24.167, F1:0.288\n",
            "[Epoch: 60 Batch:   106] loss: 0.944, acc: 56.956, test_acc:30.000, F1:0.359\n",
            "[Epoch: 61 Batch:   106] loss: 0.948, acc: 57.044, test_acc:25.833, F1:0.310\n",
            "[Epoch: 62 Batch:   106] loss: 0.943, acc: 56.780, test_acc:30.833, F1:0.365\n",
            "[Epoch: 63 Batch:   106] loss: 0.933, acc: 57.597, test_acc:31.667, F1:0.361\n",
            "[Epoch: 64 Batch:   106] loss: 0.926, acc: 58.327, test_acc:25.833, F1:0.307\n",
            "[Epoch: 65 Batch:   106] loss: 0.923, acc: 57.824, test_acc:27.500, F1:0.327\n",
            "[Epoch: 66 Batch:   106] loss: 0.918, acc: 58.541, test_acc:30.000, F1:0.353\n",
            "[Epoch: 67 Batch:   106] loss: 0.918, acc: 59.660, test_acc:28.333, F1:0.321\n",
            "[Epoch: 68 Batch:   106] loss: 0.912, acc: 59.522, test_acc:25.833, F1:0.304\n",
            "[Epoch: 69 Batch:   106] loss: 0.903, acc: 58.667, test_acc:28.333, F1:0.335\n",
            "[Epoch: 70 Batch:   106] loss: 0.908, acc: 59.723, test_acc:32.500, F1:0.374\n",
            "[Epoch: 71 Batch:   106] loss: 0.905, acc: 59.648, test_acc:30.000, F1:0.356\n",
            "[Epoch: 72 Batch:   106] loss: 0.888, acc: 59.434, test_acc:30.000, F1:0.346\n",
            "[Epoch: 73 Batch:   106] loss: 0.889, acc: 61.220, test_acc:28.333, F1:0.336\n",
            "[Epoch: 74 Batch:   106] loss: 0.886, acc: 61.233, test_acc:30.833, F1:0.354\n",
            "[Epoch: 75 Batch:   106] loss: 0.862, acc: 62.541, test_acc:27.500, F1:0.317\n",
            "[Epoch: 76 Batch:   106] loss: 0.867, acc: 62.868, test_acc:30.000, F1:0.351\n",
            "[Epoch: 77 Batch:   106] loss: 0.855, acc: 63.899, test_acc:34.167, F1:0.394\n",
            "[Epoch: 78 Batch:   106] loss: 0.866, acc: 64.164, test_acc:30.833, F1:0.363\n",
            "[Epoch: 79 Batch:   106] loss: 0.858, acc: 64.113, test_acc:29.167, F1:0.336\n",
            "[Epoch: 80 Batch:   106] loss: 0.854, acc: 63.409, test_acc:28.333, F1:0.325\n",
            "[Epoch: 81 Batch:   106] loss: 0.855, acc: 63.384, test_acc:30.000, F1:0.340\n",
            "[Epoch: 82 Batch:   106] loss: 0.844, acc: 64.893, test_acc:31.667, F1:0.364\n",
            "[Epoch: 83 Batch:   106] loss: 0.853, acc: 63.421, test_acc:29.167, F1:0.345\n",
            "[Epoch: 84 Batch:   106] loss: 0.832, acc: 66.226, test_acc:26.667, F1:0.307\n",
            "[Epoch: 85 Batch:   106] loss: 0.833, acc: 64.931, test_acc:27.500, F1:0.311\n",
            "[Epoch: 86 Batch:   106] loss: 0.818, acc: 66.025, test_acc:32.500, F1:0.355\n",
            "[Epoch: 87 Batch:   106] loss: 0.818, acc: 66.667, test_acc:27.500, F1:0.311\n",
            "[Epoch: 88 Batch:   106] loss: 0.815, acc: 66.931, test_acc:27.500, F1:0.325\n",
            "[Epoch: 89 Batch:   106] loss: 0.795, acc: 66.906, test_acc:26.667, F1:0.311\n",
            "[Epoch: 90 Batch:   106] loss: 0.800, acc: 67.811, test_acc:36.667, F1:0.405\n",
            "[Epoch: 91 Batch:   106] loss: 0.786, acc: 68.239, test_acc:26.667, F1:0.301\n",
            "[Epoch: 92 Batch:   106] loss: 0.782, acc: 68.818, test_acc:30.000, F1:0.345\n",
            "[Epoch: 93 Batch:   106] loss: 0.783, acc: 68.503, test_acc:28.333, F1:0.331\n",
            "[Epoch: 94 Batch:   106] loss: 0.782, acc: 69.195, test_acc:28.333, F1:0.322\n",
            "[Epoch: 95 Batch:   106] loss: 0.780, acc: 67.585, test_acc:30.833, F1:0.347\n",
            "[Epoch: 96 Batch:   106] loss: 0.763, acc: 69.270, test_acc:28.333, F1:0.311\n",
            "[Epoch: 97 Batch:   106] loss: 0.782, acc: 68.566, test_acc:30.833, F1:0.361\n",
            "[Epoch: 98 Batch:   106] loss: 0.750, acc: 69.031, test_acc:28.333, F1:0.319\n",
            "[Epoch: 99 Batch:   106] loss: 0.745, acc: 70.226, test_acc:26.667, F1:0.301\n",
            "[Epoch: 100 Batch:   106] loss: 0.749, acc: 69.447, test_acc:31.667, F1:0.360\n",
            "[Epoch: 101 Batch:   106] loss: 0.735, acc: 70.805, test_acc:30.000, F1:0.347\n",
            "[Epoch: 102 Batch:   106] loss: 0.741, acc: 69.761, test_acc:31.667, F1:0.356\n",
            "[Epoch: 103 Batch:   106] loss: 0.737, acc: 70.792, test_acc:25.833, F1:0.281\n",
            "[Epoch: 104 Batch:   106] loss: 0.740, acc: 69.736, test_acc:33.333, F1:0.378\n",
            "[Epoch: 105 Batch:   106] loss: 0.720, acc: 71.874, test_acc:27.500, F1:0.327\n",
            "[Epoch: 106 Batch:   106] loss: 0.717, acc: 72.151, test_acc:31.667, F1:0.358\n",
            "[Epoch: 107 Batch:   106] loss: 0.713, acc: 72.503, test_acc:31.667, F1:0.342\n",
            "[Epoch: 108 Batch:   106] loss: 0.719, acc: 71.258, test_acc:30.833, F1:0.338\n",
            "[Epoch: 109 Batch:   106] loss: 0.706, acc: 71.560, test_acc:33.333, F1:0.379\n",
            "[Epoch: 110 Batch:   106] loss: 0.692, acc: 72.780, test_acc:33.333, F1:0.382\n",
            "[Epoch: 111 Batch:   106] loss: 0.685, acc: 73.447, test_acc:27.500, F1:0.318\n",
            "[Epoch: 112 Batch:   106] loss: 0.685, acc: 72.340, test_acc:28.333, F1:0.322\n",
            "[Epoch: 113 Batch:   106] loss: 0.678, acc: 73.296, test_acc:35.833, F1:0.387\n",
            "[Epoch: 114 Batch:   106] loss: 0.687, acc: 72.906, test_acc:28.333, F1:0.320\n",
            "[Epoch: 115 Batch:   106] loss: 0.675, acc: 73.409, test_acc:36.667, F1:0.399\n",
            "[Epoch: 116 Batch:   106] loss: 0.651, acc: 73.031, test_acc:31.667, F1:0.356\n",
            "[Epoch: 117 Batch:   106] loss: 0.652, acc: 73.736, test_acc:32.500, F1:0.368\n",
            "[Epoch: 118 Batch:   106] loss: 0.667, acc: 73.170, test_acc:34.167, F1:0.388\n",
            "[Epoch: 119 Batch:   106] loss: 0.639, acc: 74.352, test_acc:27.500, F1:0.315\n",
            "[Epoch: 120 Batch:   106] loss: 0.642, acc: 76.252, test_acc:29.167, F1:0.336\n",
            "[Epoch: 121 Batch:   106] loss: 0.619, acc: 76.327, test_acc:32.500, F1:0.378\n",
            "[Epoch: 122 Batch:   106] loss: 0.628, acc: 75.509, test_acc:29.167, F1:0.329\n",
            "[Epoch: 123 Batch:   106] loss: 0.620, acc: 75.811, test_acc:33.333, F1:0.392\n",
            "[Epoch: 124 Batch:   106] loss: 0.630, acc: 74.767, test_acc:32.500, F1:0.380\n",
            "[Epoch: 125 Batch:   106] loss: 0.622, acc: 75.648, test_acc:32.500, F1:0.372\n",
            "[Epoch: 126 Batch:   106] loss: 0.601, acc: 76.855, test_acc:31.667, F1:0.361\n",
            "[Epoch: 127 Batch:   106] loss: 0.610, acc: 76.516, test_acc:34.167, F1:0.384\n",
            "[Epoch: 128 Batch:   106] loss: 0.599, acc: 76.616, test_acc:29.167, F1:0.315\n",
            "[Epoch: 129 Batch:   106] loss: 0.567, acc: 77.824, test_acc:29.167, F1:0.326\n",
            "[Epoch: 130 Batch:   106] loss: 0.593, acc: 78.579, test_acc:28.333, F1:0.329\n",
            "[Epoch: 131 Batch:   106] loss: 0.598, acc: 76.818, test_acc:33.333, F1:0.384\n",
            "[Epoch: 132 Batch:   106] loss: 0.585, acc: 77.208, test_acc:28.333, F1:0.337\n",
            "[Epoch: 133 Batch:   106] loss: 0.602, acc: 75.308, test_acc:32.500, F1:0.375\n",
            "[Epoch: 134 Batch:   106] loss: 0.560, acc: 76.390, test_acc:29.167, F1:0.348\n",
            "[Epoch: 135 Batch:   106] loss: 0.581, acc: 77.409, test_acc:32.500, F1:0.368\n",
            "[Epoch: 136 Batch:   106] loss: 0.573, acc: 78.843, test_acc:31.667, F1:0.354\n",
            "[Epoch: 137 Batch:   106] loss: 0.564, acc: 77.497, test_acc:27.500, F1:0.300\n",
            "[Epoch: 138 Batch:   106] loss: 0.553, acc: 79.019, test_acc:27.500, F1:0.300\n",
            "[Epoch: 139 Batch:   106] loss: 0.560, acc: 78.264, test_acc:32.500, F1:0.343\n",
            "[Epoch: 140 Batch:   106] loss: 0.551, acc: 78.553, test_acc:27.500, F1:0.293\n",
            "[Epoch: 141 Batch:   106] loss: 0.540, acc: 78.541, test_acc:30.833, F1:0.329\n",
            "[Epoch: 142 Batch:   106] loss: 0.548, acc: 78.176, test_acc:28.333, F1:0.317\n",
            "[Epoch: 143 Batch:   106] loss: 0.534, acc: 78.881, test_acc:32.500, F1:0.365\n",
            "[Epoch: 144 Batch:   106] loss: 0.537, acc: 78.830, test_acc:33.333, F1:0.376\n",
            "[Epoch: 145 Batch:   106] loss: 0.542, acc: 79.585, test_acc:28.333, F1:0.309\n",
            "[Epoch: 146 Batch:   106] loss: 0.525, acc: 80.692, test_acc:25.000, F1:0.266\n",
            "[Epoch: 147 Batch:   106] loss: 0.545, acc: 78.403, test_acc:29.167, F1:0.326\n",
            "[Epoch: 148 Batch:   106] loss: 0.540, acc: 79.094, test_acc:27.500, F1:0.291\n",
            "[Epoch: 149 Batch:   106] loss: 0.507, acc: 79.560, test_acc:25.833, F1:0.297\n",
            "[Epoch: 150 Batch:   106] loss: 0.505, acc: 78.365, test_acc:29.167, F1:0.301\n",
            "[Epoch: 151 Batch:   106] loss: 0.513, acc: 79.925, test_acc:25.833, F1:0.276\n",
            "[Epoch: 152 Batch:   106] loss: 0.525, acc: 76.403, test_acc:25.000, F1:0.255\n",
            "[Epoch: 153 Batch:   106] loss: 0.493, acc: 80.566, test_acc:27.500, F1:0.311\n",
            "[Epoch: 154 Batch:   106] loss: 0.473, acc: 79.509, test_acc:28.333, F1:0.306\n",
            "[Epoch: 155 Batch:   106] loss: 0.494, acc: 79.195, test_acc:35.000, F1:0.363\n",
            "[Epoch: 156 Batch:   106] loss: 0.487, acc: 79.321, test_acc:29.167, F1:0.329\n",
            "[Epoch: 157 Batch:   106] loss: 0.452, acc: 81.698, test_acc:25.000, F1:0.239\n",
            "[Epoch: 158 Batch:   106] loss: 0.505, acc: 80.629, test_acc:23.333, F1:0.234\n",
            "[Epoch: 159 Batch:   106] loss: 0.474, acc: 79.975, test_acc:25.833, F1:0.268\n",
            "[Epoch: 160 Batch:   106] loss: 0.491, acc: 79.811, test_acc:29.167, F1:0.313\n",
            "[Epoch: 161 Batch:   106] loss: 0.466, acc: 79.874, test_acc:25.000, F1:0.244\n",
            "[Epoch: 162 Batch:   106] loss: 0.454, acc: 80.918, test_acc:27.500, F1:0.294\n",
            "[Epoch: 163 Batch:   106] loss: 0.456, acc: 79.686, test_acc:26.667, F1:0.290\n",
            "[Epoch: 164 Batch:   106] loss: 0.456, acc: 80.415, test_acc:26.667, F1:0.312\n",
            "[Epoch: 165 Batch:   106] loss: 0.503, acc: 80.038, test_acc:28.333, F1:0.327\n",
            "[Epoch: 166 Batch:   106] loss: 0.452, acc: 80.352, test_acc:31.667, F1:0.343\n",
            "[Epoch: 167 Batch:   106] loss: 0.460, acc: 81.396, test_acc:30.000, F1:0.323\n",
            "[Epoch: 168 Batch:   106] loss: 0.420, acc: 81.497, test_acc:28.333, F1:0.282\n",
            "[Epoch: 169 Batch:   106] loss: 0.420, acc: 81.925, test_acc:25.833, F1:0.259\n",
            "[Epoch: 170 Batch:   106] loss: 0.445, acc: 80.730, test_acc:30.000, F1:0.314\n",
            "[Epoch: 171 Batch:   106] loss: 0.440, acc: 82.000, test_acc:33.333, F1:0.358\n",
            "[Epoch: 172 Batch:   106] loss: 0.455, acc: 80.327, test_acc:30.000, F1:0.322\n",
            "[Epoch: 173 Batch:   106] loss: 0.498, acc: 79.447, test_acc:32.500, F1:0.368\n",
            "[Epoch: 174 Batch:   106] loss: 0.415, acc: 81.748, test_acc:30.000, F1:0.328\n",
            "[Epoch: 175 Batch:   106] loss: 0.408, acc: 80.164, test_acc:25.000, F1:0.269\n",
            "[Epoch: 176 Batch:   106] loss: 0.429, acc: 82.314, test_acc:25.833, F1:0.256\n",
            "[Epoch: 177 Batch:   106] loss: 0.416, acc: 82.289, test_acc:30.833, F1:0.339\n",
            "[Epoch: 178 Batch:   106] loss: 0.411, acc: 80.503, test_acc:26.667, F1:0.301\n",
            "[Epoch: 179 Batch:   106] loss: 0.403, acc: 79.962, test_acc:28.333, F1:0.324\n",
            "[Epoch: 180 Batch:   106] loss: 0.442, acc: 81.472, test_acc:27.500, F1:0.291\n",
            "[Epoch: 181 Batch:   106] loss: 0.433, acc: 82.063, test_acc:36.667, F1:0.388\n",
            "[Epoch: 182 Batch:   106] loss: 0.411, acc: 81.874, test_acc:27.500, F1:0.297\n",
            "[Epoch: 183 Batch:   106] loss: 0.425, acc: 80.340, test_acc:31.667, F1:0.338\n",
            "[Epoch: 184 Batch:   106] loss: 0.427, acc: 80.327, test_acc:30.833, F1:0.354\n",
            "[Epoch: 185 Batch:   106] loss: 0.400, acc: 82.553, test_acc:31.667, F1:0.338\n",
            "[Epoch: 186 Batch:   106] loss: 0.348, acc: 82.390, test_acc:27.500, F1:0.306\n",
            "[Epoch: 187 Batch:   106] loss: 0.419, acc: 81.220, test_acc:30.000, F1:0.329\n",
            "[Epoch: 188 Batch:   106] loss: 0.392, acc: 81.585, test_acc:27.500, F1:0.287\n",
            "[Epoch: 189 Batch:   106] loss: 0.415, acc: 80.465, test_acc:26.667, F1:0.295\n",
            "[Epoch: 190 Batch:   106] loss: 0.371, acc: 81.245, test_acc:25.833, F1:0.278\n",
            "[Epoch: 191 Batch:   106] loss: 0.409, acc: 81.233, test_acc:32.500, F1:0.358\n",
            "[Epoch: 192 Batch:   106] loss: 0.444, acc: 81.811, test_acc:25.000, F1:0.259\n",
            "[Epoch: 193 Batch:   106] loss: 0.393, acc: 81.497, test_acc:29.167, F1:0.318\n",
            "[Epoch: 194 Batch:   106] loss: 0.348, acc: 82.113, test_acc:30.000, F1:0.342\n",
            "[Epoch: 195 Batch:   106] loss: 0.336, acc: 81.623, test_acc:21.667, F1:0.243\n",
            "[Epoch: 196 Batch:   106] loss: 0.352, acc: 81.774, test_acc:32.500, F1:0.374\n",
            "[Epoch: 197 Batch:   106] loss: 0.435, acc: 78.440, test_acc:27.500, F1:0.310\n",
            "[Epoch: 198 Batch:   106] loss: 0.454, acc: 80.579, test_acc:30.000, F1:0.321\n",
            "[Epoch: 199 Batch:   106] loss: 0.430, acc: 82.465, test_acc:28.333, F1:0.299\n",
            "[Epoch: 200 Batch:   106] loss: 0.472, acc: 79.283, test_acc:32.500, F1:0.345\n",
            "[Epoch: 201 Batch:   106] loss: 0.399, acc: 81.786, test_acc:29.167, F1:0.308\n",
            "[Epoch: 202 Batch:   106] loss: 0.441, acc: 81.660, test_acc:25.000, F1:0.245\n",
            "[Epoch: 203 Batch:   106] loss: 0.465, acc: 79.623, test_acc:28.333, F1:0.314\n",
            "[Epoch: 204 Batch:   106] loss: 0.436, acc: 80.277, test_acc:25.833, F1:0.257\n",
            "[Epoch: 205 Batch:   106] loss: 0.438, acc: 80.528, test_acc:19.167, F1:0.210\n",
            "[Epoch: 206 Batch:   106] loss: 0.419, acc: 80.214, test_acc:30.000, F1:0.297\n",
            "[Epoch: 207 Batch:   106] loss: 0.377, acc: 81.723, test_acc:26.667, F1:0.285\n",
            "[Epoch: 208 Batch:   106] loss: 0.420, acc: 81.623, test_acc:25.833, F1:0.287\n",
            "[Epoch: 209 Batch:   106] loss: 0.427, acc: 79.950, test_acc:24.167, F1:0.256\n",
            "[Epoch: 210 Batch:   106] loss: 0.458, acc: 81.245, test_acc:25.000, F1:0.269\n",
            "[Epoch: 211 Batch:   106] loss: 0.399, acc: 79.887, test_acc:31.667, F1:0.339\n",
            "[Epoch: 212 Batch:   106] loss: 0.400, acc: 79.421, test_acc:21.667, F1:0.267\n",
            "[Epoch: 213 Batch:   106] loss: 0.352, acc: 81.610, test_acc:22.500, F1:0.262\n",
            "[Epoch: 214 Batch:   106] loss: 0.371, acc: 80.528, test_acc:32.500, F1:0.330\n",
            "[Epoch: 215 Batch:   106] loss: 0.376, acc: 81.962, test_acc:24.167, F1:0.245\n",
            "[Epoch: 216 Batch:   106] loss: 0.422, acc: 81.497, test_acc:25.000, F1:0.251\n",
            "[Epoch: 217 Batch:   106] loss: 0.338, acc: 81.711, test_acc:30.833, F1:0.312\n",
            "[Epoch: 218 Batch:   106] loss: 0.373, acc: 81.472, test_acc:29.167, F1:0.312\n",
            "[Epoch: 219 Batch:   106] loss: 0.432, acc: 79.082, test_acc:28.333, F1:0.319\n",
            "[Epoch: 220 Batch:   106] loss: 0.402, acc: 79.195, test_acc:30.833, F1:0.341\n",
            "[Epoch: 221 Batch:   106] loss: 0.365, acc: 80.654, test_acc:24.167, F1:0.247\n",
            "[Epoch: 222 Batch:   106] loss: 0.390, acc: 82.050, test_acc:32.500, F1:0.354\n",
            "[Epoch: 223 Batch:   106] loss: 0.412, acc: 81.333, test_acc:28.333, F1:0.305\n",
            "[Epoch: 224 Batch:   106] loss: 0.357, acc: 82.126, test_acc:28.333, F1:0.321\n",
            "[Epoch: 225 Batch:   106] loss: 0.447, acc: 80.088, test_acc:26.667, F1:0.278\n",
            "[Epoch: 226 Batch:   106] loss: 0.449, acc: 79.409, test_acc:30.833, F1:0.342\n",
            "[Epoch: 227 Batch:   106] loss: 0.390, acc: 80.239, test_acc:25.000, F1:0.315\n",
            "[Epoch: 228 Batch:   106] loss: 0.454, acc: 80.591, test_acc:29.167, F1:0.322\n",
            "[Epoch: 229 Batch:   106] loss: 0.424, acc: 78.755, test_acc:27.500, F1:0.280\n",
            "[Epoch: 230 Batch:   106] loss: 0.374, acc: 79.157, test_acc:29.167, F1:0.308\n",
            "[Epoch: 231 Batch:   106] loss: 0.345, acc: 82.579, test_acc:24.167, F1:0.281\n",
            "[Epoch: 232 Batch:   106] loss: 0.343, acc: 79.874, test_acc:28.333, F1:0.323\n",
            "[Epoch: 233 Batch:   106] loss: 0.342, acc: 81.899, test_acc:25.000, F1:0.286\n",
            "[Epoch: 234 Batch:   106] loss: 0.366, acc: 81.660, test_acc:19.167, F1:0.231\n",
            "[Epoch: 235 Batch:   106] loss: 0.389, acc: 80.075, test_acc:31.667, F1:0.355\n",
            "[Epoch: 236 Batch:   106] loss: 0.333, acc: 82.755, test_acc:25.000, F1:0.282\n",
            "[Epoch: 237 Batch:   106] loss: 0.343, acc: 81.887, test_acc:35.000, F1:0.378\n",
            "[Epoch: 238 Batch:   106] loss: 0.408, acc: 81.409, test_acc:30.000, F1:0.327\n",
            "[Epoch: 239 Batch:   106] loss: 0.347, acc: 82.013, test_acc:30.000, F1:0.320\n",
            "[Epoch: 240 Batch:   106] loss: 0.322, acc: 82.101, test_acc:28.333, F1:0.289\n",
            "[Epoch: 241 Batch:   106] loss: 0.416, acc: 81.484, test_acc:32.500, F1:0.349\n",
            "[Epoch: 242 Batch:   106] loss: 0.366, acc: 81.283, test_acc:27.500, F1:0.273\n",
            "[Epoch: 243 Batch:   106] loss: 0.436, acc: 81.057, test_acc:27.500, F1:0.325\n",
            "[Epoch: 244 Batch:   106] loss: 0.423, acc: 78.843, test_acc:27.500, F1:0.318\n",
            "[Epoch: 245 Batch:   106] loss: 0.412, acc: 80.981, test_acc:31.667, F1:0.334\n",
            "[Epoch: 246 Batch:   106] loss: 0.348, acc: 80.780, test_acc:28.333, F1:0.275\n",
            "[Epoch: 247 Batch:   106] loss: 0.331, acc: 81.962, test_acc:22.500, F1:0.239\n",
            "[Epoch: 248 Batch:   106] loss: 0.352, acc: 81.723, test_acc:29.167, F1:0.326\n",
            "[Epoch: 249 Batch:   106] loss: 0.438, acc: 80.000, test_acc:30.000, F1:0.326\n",
            "[Epoch: 250 Batch:   106] loss: 0.338, acc: 80.465, test_acc:28.333, F1:0.329\n",
            "[Epoch: 251 Batch:   106] loss: 0.438, acc: 80.491, test_acc:24.167, F1:0.279\n",
            "[Epoch: 252 Batch:   106] loss: 0.382, acc: 79.182, test_acc:30.833, F1:0.346\n",
            "[Epoch: 253 Batch:   106] loss: 0.367, acc: 78.918, test_acc:34.167, F1:0.343\n",
            "[Epoch: 254 Batch:   106] loss: 0.334, acc: 81.786, test_acc:30.833, F1:0.320\n",
            "[Epoch: 255 Batch:   106] loss: 0.332, acc: 79.421, test_acc:28.333, F1:0.318\n",
            "[Epoch: 256 Batch:   106] loss: 0.348, acc: 80.327, test_acc:30.000, F1:0.305\n",
            "[Epoch: 257 Batch:   106] loss: 0.368, acc: 81.132, test_acc:28.333, F1:0.289\n",
            "[Epoch: 258 Batch:   106] loss: 0.356, acc: 81.723, test_acc:30.000, F1:0.319\n",
            "[Epoch: 259 Batch:   106] loss: 0.295, acc: 81.434, test_acc:27.500, F1:0.314\n",
            "[Epoch: 260 Batch:   106] loss: 0.270, acc: 83.132, test_acc:31.667, F1:0.334\n",
            "[Epoch: 261 Batch:   106] loss: 0.383, acc: 82.881, test_acc:28.333, F1:0.269\n",
            "[Epoch: 262 Batch:   106] loss: 0.402, acc: 81.220, test_acc:25.833, F1:0.303\n",
            "[Epoch: 263 Batch:   106] loss: 0.493, acc: 78.755, test_acc:21.667, F1:0.253\n",
            "[Epoch: 264 Batch:   106] loss: 0.414, acc: 79.346, test_acc:30.833, F1:0.316\n",
            "[Epoch: 265 Batch:   106] loss: 0.364, acc: 81.208, test_acc:27.500, F1:0.302\n",
            "[Epoch: 266 Batch:   106] loss: 0.496, acc: 78.214, test_acc:31.667, F1:0.308\n",
            "[Epoch: 267 Batch:   106] loss: 0.421, acc: 80.503, test_acc:30.833, F1:0.342\n",
            "[Epoch: 268 Batch:   106] loss: 0.337, acc: 81.925, test_acc:25.833, F1:0.295\n",
            "[Epoch: 269 Batch:   106] loss: 0.287, acc: 81.195, test_acc:30.000, F1:0.330\n",
            "[Epoch: 270 Batch:   106] loss: 0.378, acc: 83.484, test_acc:31.667, F1:0.336\n",
            "[Epoch: 271 Batch:   106] loss: 0.431, acc: 82.377, test_acc:25.833, F1:0.255\n",
            "[Epoch: 272 Batch:   106] loss: 0.504, acc: 77.975, test_acc:30.000, F1:0.325\n",
            "[Epoch: 273 Batch:   106] loss: 0.442, acc: 80.151, test_acc:29.167, F1:0.322\n",
            "[Epoch: 274 Batch:   106] loss: 0.464, acc: 78.289, test_acc:30.833, F1:0.330\n",
            "[Epoch: 275 Batch:   106] loss: 0.390, acc: 81.283, test_acc:30.833, F1:0.351\n",
            "[Epoch: 276 Batch:   106] loss: 0.369, acc: 79.799, test_acc:29.167, F1:0.308\n",
            "[Epoch: 277 Batch:   106] loss: 0.425, acc: 78.478, test_acc:25.833, F1:0.293\n",
            "[Epoch: 278 Batch:   106] loss: 0.372, acc: 80.730, test_acc:32.500, F1:0.354\n",
            "[Epoch: 279 Batch:   106] loss: 0.338, acc: 80.604, test_acc:30.833, F1:0.339\n",
            "[Epoch: 280 Batch:   106] loss: 0.297, acc: 83.447, test_acc:29.167, F1:0.339\n",
            "[Epoch: 281 Batch:   106] loss: 0.307, acc: 82.088, test_acc:27.500, F1:0.296\n",
            "[Epoch: 282 Batch:   106] loss: 0.334, acc: 82.164, test_acc:28.333, F1:0.295\n",
            "[Epoch: 283 Batch:   106] loss: 0.391, acc: 81.069, test_acc:32.500, F1:0.347\n",
            "[Epoch: 284 Batch:   106] loss: 0.433, acc: 79.358, test_acc:25.000, F1:0.296\n",
            "[Epoch: 285 Batch:   106] loss: 0.369, acc: 81.182, test_acc:26.667, F1:0.304\n",
            "[Epoch: 286 Batch:   106] loss: 0.419, acc: 79.484, test_acc:24.167, F1:0.279\n",
            "[Epoch: 287 Batch:   106] loss: 0.417, acc: 81.673, test_acc:26.667, F1:0.310\n",
            "[Epoch: 288 Batch:   106] loss: 0.370, acc: 80.792, test_acc:25.833, F1:0.299\n",
            "[Epoch: 289 Batch:   106] loss: 0.377, acc: 81.434, test_acc:30.000, F1:0.331\n",
            "[Epoch: 290 Batch:   106] loss: 0.438, acc: 78.277, test_acc:27.500, F1:0.302\n",
            "[Epoch: 291 Batch:   106] loss: 0.357, acc: 80.742, test_acc:29.167, F1:0.322\n",
            "[Epoch: 292 Batch:   106] loss: 0.478, acc: 78.528, test_acc:35.833, F1:0.375\n",
            "[Epoch: 293 Batch:   106] loss: 0.581, acc: 77.358, test_acc:27.500, F1:0.318\n",
            "[Epoch: 294 Batch:   106] loss: 0.512, acc: 77.686, test_acc:27.500, F1:0.298\n",
            "[Epoch: 295 Batch:   106] loss: 0.490, acc: 78.440, test_acc:31.667, F1:0.341\n",
            "[Epoch: 296 Batch:   106] loss: 0.388, acc: 79.824, test_acc:25.833, F1:0.292\n",
            "[Epoch: 297 Batch:   106] loss: 0.405, acc: 81.396, test_acc:32.500, F1:0.323\n",
            "[Epoch: 298 Batch:   106] loss: 0.360, acc: 81.484, test_acc:25.833, F1:0.281\n",
            "[Epoch: 299 Batch:   106] loss: 0.323, acc: 81.937, test_acc:31.667, F1:0.343\n",
            "[Epoch: 300 Batch:   106] loss: 0.305, acc: 81.421, test_acc:34.167, F1:0.347\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  34.166666666666664\n",
            "Test F1 Score : 0.3472288862232885\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.18      0.24        57\n",
            "         1.0       0.07      0.33      0.11         6\n",
            "         2.0       0.45      0.51      0.48        57\n",
            "\n",
            "    accuracy                           0.34       120\n",
            "   macro avg       0.30      0.34      0.28       120\n",
            "weighted avg       0.41      0.34      0.35       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[10 14 33]\n",
            " [ 1  2  3]\n",
            " [14 14 29]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.148045281569163 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  15\n",
            "[Epoch: 1 Batch:   106] loss: 1.087, acc: 37.874, test_acc:38.333, F1:0.382\n",
            "[Epoch: 2 Batch:   106] loss: 1.084, acc: 36.868, test_acc:37.500, F1:0.349\n",
            "[Epoch: 3 Batch:   106] loss: 1.080, acc: 37.157, test_acc:34.167, F1:0.325\n",
            "[Epoch: 4 Batch:   106] loss: 1.077, acc: 35.899, test_acc:35.000, F1:0.342\n",
            "[Epoch: 5 Batch:   106] loss: 1.076, acc: 36.742, test_acc:34.167, F1:0.340\n",
            "[Epoch: 6 Batch:   106] loss: 1.074, acc: 36.679, test_acc:33.333, F1:0.335\n",
            "[Epoch: 7 Batch:   106] loss: 1.072, acc: 37.182, test_acc:35.833, F1:0.355\n",
            "[Epoch: 8 Batch:   106] loss: 1.070, acc: 37.937, test_acc:34.167, F1:0.344\n",
            "[Epoch: 9 Batch:   106] loss: 1.069, acc: 38.553, test_acc:36.667, F1:0.360\n",
            "[Epoch: 10 Batch:   106] loss: 1.067, acc: 39.346, test_acc:33.333, F1:0.328\n",
            "[Epoch: 11 Batch:   106] loss: 1.066, acc: 39.447, test_acc:35.000, F1:0.340\n",
            "[Epoch: 12 Batch:   106] loss: 1.065, acc: 41.421, test_acc:36.667, F1:0.359\n",
            "[Epoch: 13 Batch:   106] loss: 1.066, acc: 39.384, test_acc:36.667, F1:0.346\n",
            "[Epoch: 14 Batch:   106] loss: 1.060, acc: 41.132, test_acc:37.500, F1:0.353\n",
            "[Epoch: 15 Batch:   106] loss: 1.061, acc: 40.013, test_acc:40.000, F1:0.382\n",
            "[Epoch: 16 Batch:   106] loss: 1.063, acc: 40.302, test_acc:38.333, F1:0.368\n",
            "[Epoch: 17 Batch:   106] loss: 1.057, acc: 40.692, test_acc:42.500, F1:0.408\n",
            "[Epoch: 18 Batch:   106] loss: 1.057, acc: 41.145, test_acc:34.167, F1:0.331\n",
            "[Epoch: 19 Batch:   106] loss: 1.056, acc: 41.585, test_acc:41.667, F1:0.403\n",
            "[Epoch: 20 Batch:   106] loss: 1.055, acc: 41.560, test_acc:40.833, F1:0.399\n",
            "[Epoch: 21 Batch:   106] loss: 1.055, acc: 41.245, test_acc:35.833, F1:0.341\n",
            "[Epoch: 22 Batch:   106] loss: 1.051, acc: 41.673, test_acc:41.667, F1:0.396\n",
            "[Epoch: 23 Batch:   106] loss: 1.050, acc: 41.736, test_acc:41.667, F1:0.402\n",
            "[Epoch: 24 Batch:   106] loss: 1.049, acc: 43.019, test_acc:39.167, F1:0.383\n",
            "[Epoch: 25 Batch:   106] loss: 1.050, acc: 42.314, test_acc:38.333, F1:0.368\n",
            "[Epoch: 26 Batch:   106] loss: 1.047, acc: 43.170, test_acc:41.667, F1:0.406\n",
            "[Epoch: 27 Batch:   106] loss: 1.043, acc: 42.063, test_acc:40.833, F1:0.394\n",
            "[Epoch: 28 Batch:   106] loss: 1.045, acc: 43.421, test_acc:42.500, F1:0.415\n",
            "[Epoch: 29 Batch:   106] loss: 1.042, acc: 44.679, test_acc:41.667, F1:0.403\n",
            "[Epoch: 30 Batch:   106] loss: 1.038, acc: 44.503, test_acc:43.333, F1:0.424\n",
            "[Epoch: 31 Batch:   106] loss: 1.038, acc: 44.805, test_acc:43.333, F1:0.427\n",
            "[Epoch: 32 Batch:   106] loss: 1.041, acc: 45.119, test_acc:38.333, F1:0.375\n",
            "[Epoch: 33 Batch:   106] loss: 1.033, acc: 45.132, test_acc:42.500, F1:0.415\n",
            "[Epoch: 34 Batch:   106] loss: 1.032, acc: 45.421, test_acc:40.000, F1:0.390\n",
            "[Epoch: 35 Batch:   106] loss: 1.028, acc: 45.761, test_acc:36.667, F1:0.354\n",
            "[Epoch: 36 Batch:   106] loss: 1.031, acc: 45.824, test_acc:35.000, F1:0.339\n",
            "[Epoch: 37 Batch:   106] loss: 1.022, acc: 47.044, test_acc:37.500, F1:0.364\n",
            "[Epoch: 38 Batch:   106] loss: 1.025, acc: 46.843, test_acc:34.167, F1:0.332\n",
            "[Epoch: 39 Batch:   106] loss: 1.023, acc: 46.868, test_acc:38.333, F1:0.375\n",
            "[Epoch: 40 Batch:   106] loss: 1.020, acc: 47.082, test_acc:38.333, F1:0.385\n",
            "[Epoch: 41 Batch:   106] loss: 1.011, acc: 48.591, test_acc:43.333, F1:0.431\n",
            "[Epoch: 42 Batch:   106] loss: 1.012, acc: 48.893, test_acc:40.000, F1:0.395\n",
            "[Epoch: 43 Batch:   106] loss: 1.007, acc: 50.390, test_acc:41.667, F1:0.417\n",
            "[Epoch: 44 Batch:   106] loss: 1.009, acc: 48.264, test_acc:38.333, F1:0.374\n",
            "[Epoch: 45 Batch:   106] loss: 1.007, acc: 48.818, test_acc:40.833, F1:0.405\n",
            "[Epoch: 46 Batch:   106] loss: 1.008, acc: 49.950, test_acc:39.167, F1:0.391\n",
            "[Epoch: 47 Batch:   106] loss: 1.002, acc: 50.553, test_acc:32.500, F1:0.324\n",
            "[Epoch: 48 Batch:   106] loss: 0.995, acc: 50.679, test_acc:35.833, F1:0.352\n",
            "[Epoch: 49 Batch:   106] loss: 0.996, acc: 51.145, test_acc:40.000, F1:0.393\n",
            "[Epoch: 50 Batch:   106] loss: 0.993, acc: 50.365, test_acc:35.833, F1:0.350\n",
            "[Epoch: 51 Batch:   106] loss: 0.991, acc: 51.384, test_acc:35.000, F1:0.351\n",
            "[Epoch: 52 Batch:   106] loss: 0.984, acc: 51.308, test_acc:35.000, F1:0.349\n",
            "[Epoch: 53 Batch:   106] loss: 0.982, acc: 51.346, test_acc:39.167, F1:0.389\n",
            "[Epoch: 54 Batch:   106] loss: 0.972, acc: 53.245, test_acc:36.667, F1:0.366\n",
            "[Epoch: 55 Batch:   106] loss: 0.973, acc: 52.969, test_acc:40.833, F1:0.408\n",
            "[Epoch: 56 Batch:   106] loss: 0.964, acc: 53.975, test_acc:35.000, F1:0.350\n",
            "[Epoch: 57 Batch:   106] loss: 0.965, acc: 54.755, test_acc:40.833, F1:0.409\n",
            "[Epoch: 58 Batch:   106] loss: 0.967, acc: 53.975, test_acc:40.000, F1:0.399\n",
            "[Epoch: 59 Batch:   106] loss: 0.956, acc: 54.579, test_acc:42.500, F1:0.424\n",
            "[Epoch: 60 Batch:   106] loss: 0.958, acc: 54.893, test_acc:36.667, F1:0.363\n",
            "[Epoch: 61 Batch:   106] loss: 0.950, acc: 55.258, test_acc:33.333, F1:0.332\n",
            "[Epoch: 62 Batch:   106] loss: 0.948, acc: 56.365, test_acc:40.833, F1:0.409\n",
            "[Epoch: 63 Batch:   106] loss: 0.951, acc: 56.138, test_acc:35.000, F1:0.354\n",
            "[Epoch: 64 Batch:   106] loss: 0.945, acc: 56.566, test_acc:45.000, F1:0.450\n",
            "[Epoch: 65 Batch:   106] loss: 0.938, acc: 55.786, test_acc:43.333, F1:0.434\n",
            "[Epoch: 66 Batch:   106] loss: 0.936, acc: 56.553, test_acc:34.167, F1:0.348\n",
            "[Epoch: 67 Batch:   106] loss: 0.929, acc: 57.635, test_acc:35.000, F1:0.354\n",
            "[Epoch: 68 Batch:   106] loss: 0.922, acc: 58.025, test_acc:36.667, F1:0.367\n",
            "[Epoch: 69 Batch:   106] loss: 0.922, acc: 57.962, test_acc:34.167, F1:0.346\n",
            "[Epoch: 70 Batch:   106] loss: 0.916, acc: 57.950, test_acc:43.333, F1:0.434\n",
            "[Epoch: 71 Batch:   106] loss: 0.910, acc: 59.572, test_acc:34.167, F1:0.342\n",
            "[Epoch: 72 Batch:   106] loss: 0.903, acc: 59.862, test_acc:34.167, F1:0.344\n",
            "[Epoch: 73 Batch:   106] loss: 0.897, acc: 58.642, test_acc:38.333, F1:0.390\n",
            "[Epoch: 74 Batch:   106] loss: 0.896, acc: 59.346, test_acc:30.833, F1:0.315\n",
            "[Epoch: 75 Batch:   106] loss: 0.896, acc: 59.170, test_acc:36.667, F1:0.369\n",
            "[Epoch: 76 Batch:   106] loss: 0.875, acc: 61.736, test_acc:28.333, F1:0.285\n",
            "[Epoch: 77 Batch:   106] loss: 0.886, acc: 61.082, test_acc:37.500, F1:0.377\n",
            "[Epoch: 78 Batch:   106] loss: 0.873, acc: 61.321, test_acc:36.667, F1:0.371\n",
            "[Epoch: 79 Batch:   106] loss: 0.863, acc: 61.371, test_acc:30.000, F1:0.300\n",
            "[Epoch: 80 Batch:   106] loss: 0.869, acc: 62.742, test_acc:35.000, F1:0.358\n",
            "[Epoch: 81 Batch:   106] loss: 0.866, acc: 62.050, test_acc:37.500, F1:0.377\n",
            "[Epoch: 82 Batch:   106] loss: 0.854, acc: 62.478, test_acc:30.833, F1:0.316\n",
            "[Epoch: 83 Batch:   106] loss: 0.855, acc: 62.906, test_acc:39.167, F1:0.393\n",
            "[Epoch: 84 Batch:   106] loss: 0.846, acc: 62.176, test_acc:30.000, F1:0.300\n",
            "[Epoch: 85 Batch:   106] loss: 0.843, acc: 63.560, test_acc:30.000, F1:0.301\n",
            "[Epoch: 86 Batch:   106] loss: 0.830, acc: 62.931, test_acc:42.500, F1:0.425\n",
            "[Epoch: 87 Batch:   106] loss: 0.832, acc: 63.711, test_acc:34.167, F1:0.342\n",
            "[Epoch: 88 Batch:   106] loss: 0.826, acc: 64.805, test_acc:37.500, F1:0.379\n",
            "[Epoch: 89 Batch:   106] loss: 0.825, acc: 64.830, test_acc:37.500, F1:0.373\n",
            "[Epoch: 90 Batch:   106] loss: 0.831, acc: 64.201, test_acc:38.333, F1:0.386\n",
            "[Epoch: 91 Batch:   106] loss: 0.833, acc: 63.597, test_acc:37.500, F1:0.380\n",
            "[Epoch: 92 Batch:   106] loss: 0.808, acc: 64.780, test_acc:33.333, F1:0.330\n",
            "[Epoch: 93 Batch:   106] loss: 0.803, acc: 66.000, test_acc:30.833, F1:0.313\n",
            "[Epoch: 94 Batch:   106] loss: 0.791, acc: 66.289, test_acc:31.667, F1:0.321\n",
            "[Epoch: 95 Batch:   106] loss: 0.804, acc: 65.220, test_acc:30.833, F1:0.310\n",
            "[Epoch: 96 Batch:   106] loss: 0.797, acc: 65.836, test_acc:35.833, F1:0.357\n",
            "[Epoch: 97 Batch:   106] loss: 0.787, acc: 66.881, test_acc:34.167, F1:0.347\n",
            "[Epoch: 98 Batch:   106] loss: 0.783, acc: 67.597, test_acc:32.500, F1:0.333\n",
            "[Epoch: 99 Batch:   106] loss: 0.766, acc: 67.094, test_acc:38.333, F1:0.384\n",
            "[Epoch: 100 Batch:   106] loss: 0.763, acc: 68.101, test_acc:35.000, F1:0.354\n",
            "[Epoch: 101 Batch:   106] loss: 0.759, acc: 66.453, test_acc:34.167, F1:0.342\n",
            "[Epoch: 102 Batch:   106] loss: 0.770, acc: 66.629, test_acc:34.167, F1:0.345\n",
            "[Epoch: 103 Batch:   106] loss: 0.760, acc: 67.447, test_acc:32.500, F1:0.325\n",
            "[Epoch: 104 Batch:   106] loss: 0.753, acc: 69.208, test_acc:32.500, F1:0.330\n",
            "[Epoch: 105 Batch:   106] loss: 0.760, acc: 68.025, test_acc:35.000, F1:0.351\n",
            "[Epoch: 106 Batch:   106] loss: 0.754, acc: 68.805, test_acc:32.500, F1:0.325\n",
            "[Epoch: 107 Batch:   106] loss: 0.740, acc: 69.522, test_acc:32.500, F1:0.328\n",
            "[Epoch: 108 Batch:   106] loss: 0.735, acc: 70.629, test_acc:30.833, F1:0.309\n",
            "[Epoch: 109 Batch:   106] loss: 0.726, acc: 69.321, test_acc:31.667, F1:0.328\n",
            "[Epoch: 110 Batch:   106] loss: 0.729, acc: 70.830, test_acc:30.000, F1:0.304\n",
            "[Epoch: 111 Batch:   106] loss: 0.719, acc: 70.528, test_acc:36.667, F1:0.367\n",
            "[Epoch: 112 Batch:   106] loss: 0.725, acc: 70.000, test_acc:33.333, F1:0.334\n",
            "[Epoch: 113 Batch:   106] loss: 0.717, acc: 71.283, test_acc:41.667, F1:0.416\n",
            "[Epoch: 114 Batch:   106] loss: 0.698, acc: 71.057, test_acc:37.500, F1:0.378\n",
            "[Epoch: 115 Batch:   106] loss: 0.711, acc: 72.000, test_acc:32.500, F1:0.322\n",
            "[Epoch: 116 Batch:   106] loss: 0.696, acc: 71.686, test_acc:37.500, F1:0.382\n",
            "[Epoch: 117 Batch:   106] loss: 0.705, acc: 70.956, test_acc:31.667, F1:0.313\n",
            "[Epoch: 118 Batch:   106] loss: 0.701, acc: 70.893, test_acc:40.833, F1:0.407\n",
            "[Epoch: 119 Batch:   106] loss: 0.692, acc: 70.277, test_acc:40.000, F1:0.403\n",
            "[Epoch: 120 Batch:   106] loss: 0.699, acc: 70.352, test_acc:32.500, F1:0.326\n",
            "[Epoch: 121 Batch:   106] loss: 0.685, acc: 71.006, test_acc:35.000, F1:0.353\n",
            "[Epoch: 122 Batch:   106] loss: 0.677, acc: 72.792, test_acc:38.333, F1:0.380\n",
            "[Epoch: 123 Batch:   106] loss: 0.676, acc: 72.302, test_acc:34.167, F1:0.341\n",
            "[Epoch: 124 Batch:   106] loss: 0.680, acc: 72.340, test_acc:30.833, F1:0.313\n",
            "[Epoch: 125 Batch:   106] loss: 0.676, acc: 71.421, test_acc:33.333, F1:0.335\n",
            "[Epoch: 126 Batch:   106] loss: 0.669, acc: 72.189, test_acc:32.500, F1:0.320\n",
            "[Epoch: 127 Batch:   106] loss: 0.652, acc: 73.069, test_acc:35.833, F1:0.362\n",
            "[Epoch: 128 Batch:   106] loss: 0.649, acc: 72.667, test_acc:35.833, F1:0.354\n",
            "[Epoch: 129 Batch:   106] loss: 0.642, acc: 73.736, test_acc:37.500, F1:0.367\n",
            "[Epoch: 130 Batch:   106] loss: 0.648, acc: 73.107, test_acc:37.500, F1:0.380\n",
            "[Epoch: 131 Batch:   106] loss: 0.645, acc: 74.893, test_acc:35.833, F1:0.357\n",
            "[Epoch: 132 Batch:   106] loss: 0.649, acc: 73.547, test_acc:32.500, F1:0.325\n",
            "[Epoch: 133 Batch:   106] loss: 0.649, acc: 72.918, test_acc:35.000, F1:0.341\n",
            "[Epoch: 134 Batch:   106] loss: 0.624, acc: 74.063, test_acc:39.167, F1:0.384\n",
            "[Epoch: 135 Batch:   106] loss: 0.626, acc: 73.308, test_acc:34.167, F1:0.340\n",
            "[Epoch: 136 Batch:   106] loss: 0.652, acc: 72.189, test_acc:35.833, F1:0.361\n",
            "[Epoch: 137 Batch:   106] loss: 0.630, acc: 73.698, test_acc:35.833, F1:0.356\n",
            "[Epoch: 138 Batch:   106] loss: 0.589, acc: 75.887, test_acc:31.667, F1:0.318\n",
            "[Epoch: 139 Batch:   106] loss: 0.624, acc: 72.201, test_acc:39.167, F1:0.396\n",
            "[Epoch: 140 Batch:   106] loss: 0.597, acc: 76.050, test_acc:37.500, F1:0.373\n",
            "[Epoch: 141 Batch:   106] loss: 0.604, acc: 74.000, test_acc:34.167, F1:0.331\n",
            "[Epoch: 142 Batch:   106] loss: 0.603, acc: 74.616, test_acc:36.667, F1:0.368\n",
            "[Epoch: 143 Batch:   106] loss: 0.608, acc: 74.868, test_acc:38.333, F1:0.383\n",
            "[Epoch: 144 Batch:   106] loss: 0.621, acc: 75.572, test_acc:35.833, F1:0.357\n",
            "[Epoch: 145 Batch:   106] loss: 0.606, acc: 74.516, test_acc:34.167, F1:0.340\n",
            "[Epoch: 146 Batch:   106] loss: 0.617, acc: 73.887, test_acc:38.333, F1:0.386\n",
            "[Epoch: 147 Batch:   106] loss: 0.571, acc: 74.931, test_acc:36.667, F1:0.359\n",
            "[Epoch: 148 Batch:   106] loss: 0.599, acc: 74.252, test_acc:35.833, F1:0.357\n",
            "[Epoch: 149 Batch:   106] loss: 0.585, acc: 75.283, test_acc:39.167, F1:0.386\n",
            "[Epoch: 150 Batch:   106] loss: 0.612, acc: 75.786, test_acc:31.667, F1:0.309\n",
            "[Epoch: 151 Batch:   106] loss: 0.589, acc: 76.855, test_acc:37.500, F1:0.351\n",
            "[Epoch: 152 Batch:   106] loss: 0.574, acc: 75.572, test_acc:35.000, F1:0.345\n",
            "[Epoch: 153 Batch:   106] loss: 0.560, acc: 76.226, test_acc:35.833, F1:0.347\n",
            "[Epoch: 154 Batch:   106] loss: 0.585, acc: 75.006, test_acc:38.333, F1:0.371\n",
            "[Epoch: 155 Batch:   106] loss: 0.576, acc: 76.050, test_acc:35.000, F1:0.347\n",
            "[Epoch: 156 Batch:   106] loss: 0.575, acc: 75.497, test_acc:35.000, F1:0.344\n",
            "[Epoch: 157 Batch:   106] loss: 0.568, acc: 76.541, test_acc:35.833, F1:0.357\n",
            "[Epoch: 158 Batch:   106] loss: 0.558, acc: 76.302, test_acc:32.500, F1:0.330\n",
            "[Epoch: 159 Batch:   106] loss: 0.567, acc: 76.516, test_acc:40.000, F1:0.395\n",
            "[Epoch: 160 Batch:   106] loss: 0.531, acc: 76.780, test_acc:37.500, F1:0.372\n",
            "[Epoch: 161 Batch:   106] loss: 0.557, acc: 76.302, test_acc:40.000, F1:0.404\n",
            "[Epoch: 162 Batch:   106] loss: 0.556, acc: 77.535, test_acc:36.667, F1:0.358\n",
            "[Epoch: 163 Batch:   106] loss: 0.555, acc: 78.289, test_acc:34.167, F1:0.338\n",
            "[Epoch: 164 Batch:   106] loss: 0.570, acc: 74.377, test_acc:33.333, F1:0.334\n",
            "[Epoch: 165 Batch:   106] loss: 0.541, acc: 76.730, test_acc:39.167, F1:0.394\n",
            "[Epoch: 166 Batch:   106] loss: 0.519, acc: 77.082, test_acc:37.500, F1:0.374\n",
            "[Epoch: 167 Batch:   106] loss: 0.525, acc: 78.214, test_acc:35.833, F1:0.357\n",
            "[Epoch: 168 Batch:   106] loss: 0.532, acc: 78.252, test_acc:29.167, F1:0.284\n",
            "[Epoch: 169 Batch:   106] loss: 0.497, acc: 79.270, test_acc:28.333, F1:0.277\n",
            "[Epoch: 170 Batch:   106] loss: 0.521, acc: 78.201, test_acc:35.000, F1:0.349\n",
            "[Epoch: 171 Batch:   106] loss: 0.549, acc: 76.428, test_acc:37.500, F1:0.380\n",
            "[Epoch: 172 Batch:   106] loss: 0.513, acc: 75.950, test_acc:38.333, F1:0.374\n",
            "[Epoch: 173 Batch:   106] loss: 0.530, acc: 74.931, test_acc:36.667, F1:0.363\n",
            "[Epoch: 174 Batch:   106] loss: 0.495, acc: 78.063, test_acc:35.000, F1:0.341\n",
            "[Epoch: 175 Batch:   106] loss: 0.512, acc: 75.547, test_acc:34.167, F1:0.330\n",
            "[Epoch: 176 Batch:   106] loss: 0.501, acc: 77.623, test_acc:35.833, F1:0.345\n",
            "[Epoch: 177 Batch:   106] loss: 0.492, acc: 78.289, test_acc:32.500, F1:0.323\n",
            "[Epoch: 178 Batch:   106] loss: 0.524, acc: 77.358, test_acc:38.333, F1:0.386\n",
            "[Epoch: 179 Batch:   106] loss: 0.484, acc: 77.472, test_acc:39.167, F1:0.385\n",
            "[Epoch: 180 Batch:   106] loss: 0.504, acc: 77.233, test_acc:35.000, F1:0.348\n",
            "[Epoch: 181 Batch:   106] loss: 0.476, acc: 77.597, test_acc:35.833, F1:0.352\n",
            "[Epoch: 182 Batch:   106] loss: 0.509, acc: 75.484, test_acc:38.333, F1:0.380\n",
            "[Epoch: 183 Batch:   106] loss: 0.537, acc: 75.987, test_acc:38.333, F1:0.379\n",
            "[Epoch: 184 Batch:   106] loss: 0.481, acc: 77.434, test_acc:33.333, F1:0.333\n",
            "[Epoch: 185 Batch:   106] loss: 0.515, acc: 76.818, test_acc:36.667, F1:0.372\n",
            "[Epoch: 186 Batch:   106] loss: 0.488, acc: 77.321, test_acc:30.000, F1:0.299\n",
            "[Epoch: 187 Batch:   106] loss: 0.512, acc: 76.579, test_acc:39.167, F1:0.385\n",
            "[Epoch: 188 Batch:   106] loss: 0.493, acc: 77.862, test_acc:38.333, F1:0.384\n",
            "[Epoch: 189 Batch:   106] loss: 0.518, acc: 79.497, test_acc:36.667, F1:0.363\n",
            "[Epoch: 190 Batch:   106] loss: 0.521, acc: 76.893, test_acc:34.167, F1:0.335\n",
            "[Epoch: 191 Batch:   106] loss: 0.503, acc: 77.673, test_acc:34.167, F1:0.336\n",
            "[Epoch: 192 Batch:   106] loss: 0.485, acc: 77.170, test_acc:37.500, F1:0.371\n",
            "[Epoch: 193 Batch:   106] loss: 0.504, acc: 77.082, test_acc:35.000, F1:0.346\n",
            "[Epoch: 194 Batch:   106] loss: 0.488, acc: 77.560, test_acc:38.333, F1:0.378\n",
            "[Epoch: 195 Batch:   106] loss: 0.533, acc: 75.182, test_acc:36.667, F1:0.363\n",
            "[Epoch: 196 Batch:   106] loss: 0.512, acc: 74.830, test_acc:36.667, F1:0.360\n",
            "[Epoch: 197 Batch:   106] loss: 0.469, acc: 76.252, test_acc:40.000, F1:0.404\n",
            "[Epoch: 198 Batch:   106] loss: 0.461, acc: 78.201, test_acc:32.500, F1:0.311\n",
            "[Epoch: 199 Batch:   106] loss: 0.444, acc: 76.654, test_acc:35.833, F1:0.355\n",
            "[Epoch: 200 Batch:   106] loss: 0.537, acc: 75.774, test_acc:42.500, F1:0.394\n",
            "[Epoch: 201 Batch:   106] loss: 0.443, acc: 77.597, test_acc:29.167, F1:0.295\n",
            "[Epoch: 202 Batch:   106] loss: 0.503, acc: 77.245, test_acc:45.000, F1:0.431\n",
            "[Epoch: 203 Batch:   106] loss: 0.476, acc: 76.704, test_acc:36.667, F1:0.365\n",
            "[Epoch: 204 Batch:   106] loss: 0.463, acc: 76.164, test_acc:38.333, F1:0.353\n",
            "[Epoch: 205 Batch:   106] loss: 0.451, acc: 77.472, test_acc:39.167, F1:0.387\n",
            "[Epoch: 206 Batch:   106] loss: 0.439, acc: 76.956, test_acc:42.500, F1:0.416\n",
            "[Epoch: 207 Batch:   106] loss: 0.435, acc: 78.327, test_acc:32.500, F1:0.314\n",
            "[Epoch: 208 Batch:   106] loss: 0.480, acc: 79.145, test_acc:35.833, F1:0.353\n",
            "[Epoch: 209 Batch:   106] loss: 0.462, acc: 79.195, test_acc:34.167, F1:0.350\n",
            "[Epoch: 210 Batch:   106] loss: 0.446, acc: 76.805, test_acc:35.000, F1:0.356\n",
            "[Epoch: 211 Batch:   106] loss: 0.502, acc: 76.566, test_acc:32.500, F1:0.326\n",
            "[Epoch: 212 Batch:   106] loss: 0.458, acc: 76.453, test_acc:40.000, F1:0.389\n",
            "[Epoch: 213 Batch:   106] loss: 0.433, acc: 76.956, test_acc:34.167, F1:0.332\n",
            "[Epoch: 214 Batch:   106] loss: 0.468, acc: 76.742, test_acc:33.333, F1:0.336\n",
            "[Epoch: 215 Batch:   106] loss: 0.414, acc: 77.572, test_acc:36.667, F1:0.343\n",
            "[Epoch: 216 Batch:   106] loss: 0.411, acc: 79.686, test_acc:40.833, F1:0.385\n",
            "[Epoch: 217 Batch:   106] loss: 0.451, acc: 77.899, test_acc:35.833, F1:0.348\n",
            "[Epoch: 218 Batch:   106] loss: 0.423, acc: 78.528, test_acc:36.667, F1:0.366\n",
            "[Epoch: 219 Batch:   106] loss: 0.427, acc: 78.805, test_acc:33.333, F1:0.326\n",
            "[Epoch: 220 Batch:   106] loss: 0.462, acc: 76.717, test_acc:36.667, F1:0.362\n",
            "[Epoch: 221 Batch:   106] loss: 0.457, acc: 76.818, test_acc:32.500, F1:0.324\n",
            "[Epoch: 222 Batch:   106] loss: 0.487, acc: 77.296, test_acc:40.000, F1:0.402\n",
            "[Epoch: 223 Batch:   106] loss: 0.428, acc: 77.472, test_acc:41.667, F1:0.395\n",
            "[Epoch: 224 Batch:   106] loss: 0.437, acc: 76.629, test_acc:40.833, F1:0.387\n",
            "[Epoch: 225 Batch:   106] loss: 0.427, acc: 79.925, test_acc:40.833, F1:0.388\n",
            "[Epoch: 226 Batch:   106] loss: 0.459, acc: 78.767, test_acc:34.167, F1:0.298\n",
            "[Epoch: 227 Batch:   106] loss: 0.428, acc: 77.836, test_acc:41.667, F1:0.413\n",
            "[Epoch: 228 Batch:   106] loss: 0.485, acc: 75.296, test_acc:34.167, F1:0.340\n",
            "[Epoch: 229 Batch:   106] loss: 0.426, acc: 77.736, test_acc:38.333, F1:0.387\n",
            "[Epoch: 230 Batch:   106] loss: 0.432, acc: 77.170, test_acc:39.167, F1:0.366\n",
            "[Epoch: 231 Batch:   106] loss: 0.451, acc: 78.591, test_acc:37.500, F1:0.361\n",
            "[Epoch: 232 Batch:   106] loss: 0.419, acc: 77.748, test_acc:40.833, F1:0.406\n",
            "[Epoch: 233 Batch:   106] loss: 0.421, acc: 78.239, test_acc:36.667, F1:0.353\n",
            "[Epoch: 234 Batch:   106] loss: 0.460, acc: 78.981, test_acc:37.500, F1:0.371\n",
            "[Epoch: 235 Batch:   106] loss: 0.449, acc: 77.723, test_acc:39.167, F1:0.385\n",
            "[Epoch: 236 Batch:   106] loss: 0.489, acc: 77.434, test_acc:38.333, F1:0.374\n",
            "[Epoch: 237 Batch:   106] loss: 0.463, acc: 78.843, test_acc:31.667, F1:0.323\n",
            "[Epoch: 238 Batch:   106] loss: 0.446, acc: 76.151, test_acc:35.000, F1:0.343\n",
            "[Epoch: 239 Batch:   106] loss: 0.431, acc: 76.314, test_acc:38.333, F1:0.377\n",
            "[Epoch: 240 Batch:   106] loss: 0.400, acc: 79.031, test_acc:39.167, F1:0.393\n",
            "[Epoch: 241 Batch:   106] loss: 0.397, acc: 78.214, test_acc:34.167, F1:0.323\n",
            "[Epoch: 242 Batch:   106] loss: 0.426, acc: 77.836, test_acc:33.333, F1:0.325\n",
            "[Epoch: 243 Batch:   106] loss: 0.401, acc: 78.730, test_acc:33.333, F1:0.324\n",
            "[Epoch: 244 Batch:   106] loss: 0.421, acc: 77.371, test_acc:38.333, F1:0.367\n",
            "[Epoch: 245 Batch:   106] loss: 0.384, acc: 77.962, test_acc:39.167, F1:0.397\n",
            "[Epoch: 246 Batch:   106] loss: 0.411, acc: 77.245, test_acc:34.167, F1:0.338\n",
            "[Epoch: 247 Batch:   106] loss: 0.462, acc: 78.013, test_acc:35.833, F1:0.344\n",
            "[Epoch: 248 Batch:   106] loss: 0.379, acc: 78.390, test_acc:40.833, F1:0.407\n",
            "[Epoch: 249 Batch:   106] loss: 0.419, acc: 79.811, test_acc:34.167, F1:0.344\n",
            "[Epoch: 250 Batch:   106] loss: 0.435, acc: 76.289, test_acc:36.667, F1:0.369\n",
            "[Epoch: 251 Batch:   106] loss: 0.455, acc: 75.937, test_acc:36.667, F1:0.359\n",
            "[Epoch: 252 Batch:   106] loss: 0.445, acc: 77.862, test_acc:39.167, F1:0.395\n",
            "[Epoch: 253 Batch:   106] loss: 0.479, acc: 77.535, test_acc:38.333, F1:0.381\n",
            "[Epoch: 254 Batch:   106] loss: 0.567, acc: 75.346, test_acc:36.667, F1:0.346\n",
            "[Epoch: 255 Batch:   106] loss: 0.520, acc: 76.629, test_acc:37.500, F1:0.363\n",
            "[Epoch: 256 Batch:   106] loss: 0.419, acc: 76.226, test_acc:41.667, F1:0.397\n",
            "[Epoch: 257 Batch:   106] loss: 0.425, acc: 79.472, test_acc:36.667, F1:0.364\n",
            "[Epoch: 258 Batch:   106] loss: 0.468, acc: 74.767, test_acc:35.833, F1:0.343\n",
            "[Epoch: 259 Batch:   106] loss: 0.480, acc: 77.170, test_acc:38.333, F1:0.363\n",
            "[Epoch: 260 Batch:   106] loss: 0.464, acc: 77.635, test_acc:38.333, F1:0.377\n",
            "[Epoch: 261 Batch:   106] loss: 0.411, acc: 78.340, test_acc:37.500, F1:0.366\n",
            "[Epoch: 262 Batch:   106] loss: 0.373, acc: 80.692, test_acc:43.333, F1:0.430\n",
            "[Epoch: 263 Batch:   106] loss: 0.356, acc: 79.987, test_acc:36.667, F1:0.355\n",
            "[Epoch: 264 Batch:   106] loss: 0.386, acc: 79.610, test_acc:40.833, F1:0.400\n",
            "[Epoch: 265 Batch:   106] loss: 0.407, acc: 77.182, test_acc:38.333, F1:0.377\n",
            "[Epoch: 266 Batch:   106] loss: 0.421, acc: 78.377, test_acc:40.000, F1:0.392\n",
            "[Epoch: 267 Batch:   106] loss: 0.412, acc: 77.220, test_acc:39.167, F1:0.393\n",
            "[Epoch: 268 Batch:   106] loss: 0.444, acc: 76.717, test_acc:38.333, F1:0.381\n",
            "[Epoch: 269 Batch:   106] loss: 0.407, acc: 77.925, test_acc:42.500, F1:0.404\n",
            "[Epoch: 270 Batch:   106] loss: 0.440, acc: 76.201, test_acc:35.000, F1:0.339\n",
            "[Epoch: 271 Batch:   106] loss: 0.437, acc: 76.390, test_acc:43.333, F1:0.418\n",
            "[Epoch: 272 Batch:   106] loss: 0.392, acc: 77.145, test_acc:43.333, F1:0.423\n",
            "[Epoch: 273 Batch:   106] loss: 0.390, acc: 78.226, test_acc:40.000, F1:0.385\n",
            "[Epoch: 274 Batch:   106] loss: 0.438, acc: 75.572, test_acc:37.500, F1:0.369\n",
            "[Epoch: 275 Batch:   106] loss: 0.418, acc: 77.069, test_acc:48.333, F1:0.458\n",
            "[Epoch: 276 Batch:   106] loss: 0.400, acc: 76.943, test_acc:34.167, F1:0.331\n",
            "[Epoch: 277 Batch:   106] loss: 0.396, acc: 78.101, test_acc:40.833, F1:0.387\n",
            "[Epoch: 278 Batch:   106] loss: 0.375, acc: 76.780, test_acc:36.667, F1:0.376\n",
            "[Epoch: 279 Batch:   106] loss: 0.448, acc: 77.145, test_acc:38.333, F1:0.373\n",
            "[Epoch: 280 Batch:   106] loss: 0.389, acc: 77.723, test_acc:41.667, F1:0.405\n",
            "[Epoch: 281 Batch:   106] loss: 0.417, acc: 76.943, test_acc:40.833, F1:0.390\n",
            "[Epoch: 282 Batch:   106] loss: 0.418, acc: 76.805, test_acc:40.833, F1:0.411\n",
            "[Epoch: 283 Batch:   106] loss: 0.432, acc: 75.082, test_acc:37.500, F1:0.386\n",
            "[Epoch: 284 Batch:   106] loss: 0.411, acc: 79.057, test_acc:40.833, F1:0.398\n",
            "[Epoch: 285 Batch:   106] loss: 0.441, acc: 77.648, test_acc:40.000, F1:0.383\n",
            "[Epoch: 286 Batch:   106] loss: 0.393, acc: 78.918, test_acc:47.500, F1:0.464\n",
            "[Epoch: 287 Batch:   106] loss: 0.434, acc: 76.189, test_acc:41.667, F1:0.410\n",
            "[Epoch: 288 Batch:   106] loss: 0.457, acc: 76.327, test_acc:42.500, F1:0.412\n",
            "[Epoch: 289 Batch:   106] loss: 0.443, acc: 78.126, test_acc:36.667, F1:0.368\n",
            "[Epoch: 290 Batch:   106] loss: 0.358, acc: 79.472, test_acc:40.833, F1:0.400\n",
            "[Epoch: 291 Batch:   106] loss: 0.583, acc: 77.082, test_acc:38.333, F1:0.393\n",
            "[Epoch: 292 Batch:   106] loss: 0.460, acc: 77.233, test_acc:41.667, F1:0.408\n",
            "[Epoch: 293 Batch:   106] loss: 0.395, acc: 75.082, test_acc:40.833, F1:0.400\n",
            "[Epoch: 294 Batch:   106] loss: 0.397, acc: 77.031, test_acc:38.333, F1:0.379\n",
            "[Epoch: 295 Batch:   106] loss: 0.370, acc: 79.031, test_acc:43.333, F1:0.411\n",
            "[Epoch: 296 Batch:   106] loss: 0.345, acc: 78.025, test_acc:38.333, F1:0.388\n",
            "[Epoch: 297 Batch:   106] loss: 0.358, acc: 78.126, test_acc:41.667, F1:0.400\n",
            "[Epoch: 298 Batch:   106] loss: 0.397, acc: 79.371, test_acc:45.000, F1:0.432\n",
            "[Epoch: 299 Batch:   106] loss: 0.374, acc: 78.138, test_acc:40.833, F1:0.393\n",
            "[Epoch: 300 Batch:   106] loss: 0.378, acc: 77.623, test_acc:41.667, F1:0.412\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  41.66666666666667\n",
            "Test F1 Score : 0.4122230774731122\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.54      0.43        39\n",
            "         1.0       0.21      0.15      0.18        33\n",
            "         2.0       0.63      0.50      0.56        48\n",
            "\n",
            "    accuracy                           0.42       120\n",
            "   macro avg       0.40      0.40      0.39       120\n",
            "weighted avg       0.43      0.42      0.41       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[21 10  8]\n",
            " [22  5  6]\n",
            " [15  9 24]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.129265097777049 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  16\n",
            "[Epoch: 1 Batch:   106] loss: 1.086, acc: 34.616, test_acc:43.333, F1:0.430\n",
            "[Epoch: 2 Batch:   106] loss: 1.082, acc: 38.000, test_acc:40.000, F1:0.392\n",
            "[Epoch: 3 Batch:   106] loss: 1.079, acc: 37.296, test_acc:41.667, F1:0.418\n",
            "[Epoch: 4 Batch:   106] loss: 1.077, acc: 36.453, test_acc:40.000, F1:0.401\n",
            "[Epoch: 5 Batch:   106] loss: 1.075, acc: 36.780, test_acc:37.500, F1:0.375\n",
            "[Epoch: 6 Batch:   106] loss: 1.073, acc: 37.069, test_acc:33.333, F1:0.341\n",
            "[Epoch: 7 Batch:   106] loss: 1.070, acc: 37.057, test_acc:35.833, F1:0.364\n",
            "[Epoch: 8 Batch:   106] loss: 1.069, acc: 37.899, test_acc:32.500, F1:0.330\n",
            "[Epoch: 9 Batch:   106] loss: 1.067, acc: 38.579, test_acc:33.333, F1:0.340\n",
            "[Epoch: 10 Batch:   106] loss: 1.066, acc: 38.189, test_acc:35.833, F1:0.365\n",
            "[Epoch: 11 Batch:   106] loss: 1.066, acc: 38.730, test_acc:35.000, F1:0.357\n",
            "[Epoch: 12 Batch:   106] loss: 1.063, acc: 39.623, test_acc:30.000, F1:0.306\n",
            "[Epoch: 13 Batch:   106] loss: 1.060, acc: 39.623, test_acc:32.500, F1:0.331\n",
            "[Epoch: 14 Batch:   106] loss: 1.061, acc: 39.119, test_acc:34.167, F1:0.348\n",
            "[Epoch: 15 Batch:   106] loss: 1.059, acc: 40.302, test_acc:31.667, F1:0.320\n",
            "[Epoch: 16 Batch:   106] loss: 1.057, acc: 40.453, test_acc:42.500, F1:0.433\n",
            "[Epoch: 17 Batch:   106] loss: 1.055, acc: 40.340, test_acc:37.500, F1:0.382\n",
            "[Epoch: 18 Batch:   106] loss: 1.056, acc: 39.547, test_acc:33.333, F1:0.330\n",
            "[Epoch: 19 Batch:   106] loss: 1.054, acc: 41.421, test_acc:34.167, F1:0.346\n",
            "[Epoch: 20 Batch:   106] loss: 1.052, acc: 41.270, test_acc:35.833, F1:0.364\n",
            "[Epoch: 21 Batch:   106] loss: 1.050, acc: 41.094, test_acc:33.333, F1:0.336\n",
            "[Epoch: 22 Batch:   106] loss: 1.050, acc: 41.031, test_acc:30.833, F1:0.309\n",
            "[Epoch: 23 Batch:   106] loss: 1.048, acc: 42.755, test_acc:33.333, F1:0.342\n",
            "[Epoch: 24 Batch:   106] loss: 1.052, acc: 41.245, test_acc:30.833, F1:0.315\n",
            "[Epoch: 25 Batch:   106] loss: 1.043, acc: 42.226, test_acc:28.333, F1:0.290\n",
            "[Epoch: 26 Batch:   106] loss: 1.043, acc: 41.824, test_acc:29.167, F1:0.297\n",
            "[Epoch: 27 Batch:   106] loss: 1.043, acc: 44.692, test_acc:31.667, F1:0.320\n",
            "[Epoch: 28 Batch:   106] loss: 1.040, acc: 43.509, test_acc:32.500, F1:0.332\n",
            "[Epoch: 29 Batch:   106] loss: 1.039, acc: 43.132, test_acc:34.167, F1:0.349\n",
            "[Epoch: 30 Batch:   106] loss: 1.037, acc: 43.560, test_acc:29.167, F1:0.302\n",
            "[Epoch: 31 Batch:   106] loss: 1.034, acc: 43.824, test_acc:37.500, F1:0.386\n",
            "[Epoch: 32 Batch:   106] loss: 1.035, acc: 44.365, test_acc:34.167, F1:0.352\n",
            "[Epoch: 33 Batch:   106] loss: 1.031, acc: 44.541, test_acc:32.500, F1:0.326\n",
            "[Epoch: 34 Batch:   106] loss: 1.025, acc: 45.371, test_acc:30.000, F1:0.306\n",
            "[Epoch: 35 Batch:   106] loss: 1.025, acc: 45.623, test_acc:25.833, F1:0.257\n",
            "[Epoch: 36 Batch:   106] loss: 1.024, acc: 47.006, test_acc:26.667, F1:0.277\n",
            "[Epoch: 37 Batch:   106] loss: 1.021, acc: 45.799, test_acc:30.000, F1:0.305\n",
            "[Epoch: 38 Batch:   106] loss: 1.021, acc: 46.516, test_acc:31.667, F1:0.327\n",
            "[Epoch: 39 Batch:   106] loss: 1.017, acc: 47.396, test_acc:26.667, F1:0.275\n",
            "[Epoch: 40 Batch:   106] loss: 1.012, acc: 47.522, test_acc:28.333, F1:0.294\n",
            "[Epoch: 41 Batch:   106] loss: 1.009, acc: 47.522, test_acc:36.667, F1:0.382\n",
            "[Epoch: 42 Batch:   106] loss: 1.008, acc: 48.176, test_acc:30.000, F1:0.301\n",
            "[Epoch: 43 Batch:   106] loss: 1.003, acc: 48.843, test_acc:33.333, F1:0.347\n",
            "[Epoch: 44 Batch:   106] loss: 0.997, acc: 49.358, test_acc:30.833, F1:0.322\n",
            "[Epoch: 45 Batch:   106] loss: 0.997, acc: 50.126, test_acc:29.167, F1:0.300\n",
            "[Epoch: 46 Batch:   106] loss: 0.992, acc: 51.220, test_acc:34.167, F1:0.351\n",
            "[Epoch: 47 Batch:   106] loss: 0.981, acc: 52.818, test_acc:30.000, F1:0.312\n",
            "[Epoch: 48 Batch:   106] loss: 0.990, acc: 51.862, test_acc:33.333, F1:0.343\n",
            "[Epoch: 49 Batch:   106] loss: 0.984, acc: 52.176, test_acc:28.333, F1:0.291\n",
            "[Epoch: 50 Batch:   106] loss: 0.979, acc: 52.981, test_acc:29.167, F1:0.299\n",
            "[Epoch: 51 Batch:   106] loss: 0.974, acc: 52.780, test_acc:28.333, F1:0.290\n",
            "[Epoch: 52 Batch:   106] loss: 0.976, acc: 53.484, test_acc:29.167, F1:0.299\n",
            "[Epoch: 53 Batch:   106] loss: 0.967, acc: 54.201, test_acc:29.167, F1:0.303\n",
            "[Epoch: 54 Batch:   106] loss: 0.967, acc: 53.258, test_acc:29.167, F1:0.297\n",
            "[Epoch: 55 Batch:   106] loss: 0.958, acc: 54.679, test_acc:30.000, F1:0.303\n",
            "[Epoch: 56 Batch:   106] loss: 0.964, acc: 53.094, test_acc:32.500, F1:0.337\n",
            "[Epoch: 57 Batch:   106] loss: 0.958, acc: 54.591, test_acc:29.167, F1:0.300\n",
            "[Epoch: 58 Batch:   106] loss: 0.947, acc: 54.201, test_acc:25.833, F1:0.256\n",
            "[Epoch: 59 Batch:   106] loss: 0.941, acc: 55.799, test_acc:31.667, F1:0.323\n",
            "[Epoch: 60 Batch:   106] loss: 0.942, acc: 55.421, test_acc:30.000, F1:0.312\n",
            "[Epoch: 61 Batch:   106] loss: 0.942, acc: 55.686, test_acc:30.000, F1:0.301\n",
            "[Epoch: 62 Batch:   106] loss: 0.934, acc: 57.321, test_acc:32.500, F1:0.331\n",
            "[Epoch: 63 Batch:   106] loss: 0.927, acc: 57.987, test_acc:27.500, F1:0.267\n",
            "[Epoch: 64 Batch:   106] loss: 0.927, acc: 57.761, test_acc:34.167, F1:0.349\n",
            "[Epoch: 65 Batch:   106] loss: 0.922, acc: 57.962, test_acc:32.500, F1:0.330\n",
            "[Epoch: 66 Batch:   106] loss: 0.921, acc: 58.843, test_acc:29.167, F1:0.301\n",
            "[Epoch: 67 Batch:   106] loss: 0.912, acc: 59.623, test_acc:31.667, F1:0.328\n",
            "[Epoch: 68 Batch:   106] loss: 0.901, acc: 58.566, test_acc:35.000, F1:0.355\n",
            "[Epoch: 69 Batch:   106] loss: 0.900, acc: 58.931, test_acc:35.833, F1:0.364\n",
            "[Epoch: 70 Batch:   106] loss: 0.899, acc: 59.283, test_acc:35.000, F1:0.356\n",
            "[Epoch: 71 Batch:   106] loss: 0.895, acc: 60.013, test_acc:28.333, F1:0.292\n",
            "[Epoch: 72 Batch:   106] loss: 0.882, acc: 60.289, test_acc:30.000, F1:0.308\n",
            "[Epoch: 73 Batch:   106] loss: 0.885, acc: 61.547, test_acc:28.333, F1:0.288\n",
            "[Epoch: 74 Batch:   106] loss: 0.867, acc: 61.019, test_acc:30.000, F1:0.306\n",
            "[Epoch: 75 Batch:   106] loss: 0.864, acc: 61.774, test_acc:26.667, F1:0.271\n",
            "[Epoch: 76 Batch:   106] loss: 0.861, acc: 62.491, test_acc:35.833, F1:0.368\n",
            "[Epoch: 77 Batch:   106] loss: 0.869, acc: 61.107, test_acc:32.500, F1:0.330\n",
            "[Epoch: 78 Batch:   106] loss: 0.861, acc: 63.937, test_acc:37.500, F1:0.391\n",
            "[Epoch: 79 Batch:   106] loss: 0.840, acc: 64.440, test_acc:35.000, F1:0.360\n",
            "[Epoch: 80 Batch:   106] loss: 0.838, acc: 64.164, test_acc:30.000, F1:0.307\n",
            "[Epoch: 81 Batch:   106] loss: 0.842, acc: 64.063, test_acc:33.333, F1:0.342\n",
            "[Epoch: 82 Batch:   106] loss: 0.834, acc: 63.950, test_acc:33.333, F1:0.339\n",
            "[Epoch: 83 Batch:   106] loss: 0.831, acc: 63.887, test_acc:34.167, F1:0.348\n",
            "[Epoch: 84 Batch:   106] loss: 0.828, acc: 64.868, test_acc:32.500, F1:0.336\n",
            "[Epoch: 85 Batch:   106] loss: 0.822, acc: 64.981, test_acc:33.333, F1:0.338\n",
            "[Epoch: 86 Batch:   106] loss: 0.810, acc: 65.648, test_acc:39.167, F1:0.402\n",
            "[Epoch: 87 Batch:   106] loss: 0.810, acc: 66.465, test_acc:34.167, F1:0.351\n",
            "[Epoch: 88 Batch:   106] loss: 0.802, acc: 66.038, test_acc:32.500, F1:0.335\n",
            "[Epoch: 89 Batch:   106] loss: 0.808, acc: 65.484, test_acc:30.833, F1:0.318\n",
            "[Epoch: 90 Batch:   106] loss: 0.788, acc: 67.119, test_acc:39.167, F1:0.403\n",
            "[Epoch: 91 Batch:   106] loss: 0.791, acc: 68.314, test_acc:35.833, F1:0.363\n",
            "[Epoch: 92 Batch:   106] loss: 0.790, acc: 67.057, test_acc:35.833, F1:0.377\n",
            "[Epoch: 93 Batch:   106] loss: 0.760, acc: 68.327, test_acc:37.500, F1:0.391\n",
            "[Epoch: 94 Batch:   106] loss: 0.778, acc: 68.239, test_acc:36.667, F1:0.376\n",
            "[Epoch: 95 Batch:   106] loss: 0.763, acc: 67.849, test_acc:45.833, F1:0.465\n",
            "[Epoch: 96 Batch:   106] loss: 0.771, acc: 67.509, test_acc:33.333, F1:0.344\n",
            "[Epoch: 97 Batch:   106] loss: 0.761, acc: 68.767, test_acc:35.833, F1:0.370\n",
            "[Epoch: 98 Batch:   106] loss: 0.761, acc: 68.088, test_acc:39.167, F1:0.412\n",
            "[Epoch: 99 Batch:   106] loss: 0.759, acc: 68.642, test_acc:34.167, F1:0.353\n",
            "[Epoch: 100 Batch:   106] loss: 0.736, acc: 69.723, test_acc:42.500, F1:0.435\n",
            "[Epoch: 101 Batch:   106] loss: 0.738, acc: 69.082, test_acc:41.667, F1:0.424\n",
            "[Epoch: 102 Batch:   106] loss: 0.741, acc: 70.541, test_acc:34.167, F1:0.345\n",
            "[Epoch: 103 Batch:   106] loss: 0.717, acc: 70.642, test_acc:31.667, F1:0.324\n",
            "[Epoch: 104 Batch:   106] loss: 0.725, acc: 70.465, test_acc:38.333, F1:0.393\n",
            "[Epoch: 105 Batch:   106] loss: 0.714, acc: 71.648, test_acc:33.333, F1:0.346\n",
            "[Epoch: 106 Batch:   106] loss: 0.707, acc: 72.013, test_acc:40.000, F1:0.410\n",
            "[Epoch: 107 Batch:   106] loss: 0.714, acc: 70.981, test_acc:42.500, F1:0.436\n",
            "[Epoch: 108 Batch:   106] loss: 0.692, acc: 72.075, test_acc:40.000, F1:0.401\n",
            "[Epoch: 109 Batch:   106] loss: 0.689, acc: 71.132, test_acc:29.167, F1:0.304\n",
            "[Epoch: 110 Batch:   106] loss: 0.731, acc: 72.101, test_acc:37.500, F1:0.386\n",
            "[Epoch: 111 Batch:   106] loss: 0.703, acc: 72.327, test_acc:36.667, F1:0.375\n",
            "[Epoch: 112 Batch:   106] loss: 0.696, acc: 71.358, test_acc:29.167, F1:0.297\n",
            "[Epoch: 113 Batch:   106] loss: 0.694, acc: 70.717, test_acc:37.500, F1:0.389\n",
            "[Epoch: 114 Batch:   106] loss: 0.698, acc: 71.220, test_acc:40.833, F1:0.416\n",
            "[Epoch: 115 Batch:   106] loss: 0.683, acc: 72.000, test_acc:33.333, F1:0.344\n",
            "[Epoch: 116 Batch:   106] loss: 0.666, acc: 73.874, test_acc:39.167, F1:0.399\n",
            "[Epoch: 117 Batch:   106] loss: 0.670, acc: 73.937, test_acc:35.000, F1:0.358\n",
            "[Epoch: 118 Batch:   106] loss: 0.659, acc: 71.711, test_acc:40.833, F1:0.417\n",
            "[Epoch: 119 Batch:   106] loss: 0.648, acc: 73.434, test_acc:34.167, F1:0.348\n",
            "[Epoch: 120 Batch:   106] loss: 0.639, acc: 73.220, test_acc:38.333, F1:0.392\n",
            "[Epoch: 121 Batch:   106] loss: 0.633, acc: 74.440, test_acc:40.000, F1:0.411\n",
            "[Epoch: 122 Batch:   106] loss: 0.652, acc: 72.994, test_acc:33.333, F1:0.343\n",
            "[Epoch: 123 Batch:   106] loss: 0.640, acc: 74.239, test_acc:37.500, F1:0.383\n",
            "[Epoch: 124 Batch:   106] loss: 0.628, acc: 73.484, test_acc:37.500, F1:0.384\n",
            "[Epoch: 125 Batch:   106] loss: 0.656, acc: 73.686, test_acc:39.167, F1:0.397\n",
            "[Epoch: 126 Batch:   106] loss: 0.632, acc: 73.874, test_acc:37.500, F1:0.382\n",
            "[Epoch: 127 Batch:   106] loss: 0.633, acc: 75.245, test_acc:40.000, F1:0.408\n",
            "[Epoch: 128 Batch:   106] loss: 0.610, acc: 75.447, test_acc:43.333, F1:0.438\n",
            "[Epoch: 129 Batch:   106] loss: 0.608, acc: 74.918, test_acc:35.000, F1:0.353\n",
            "[Epoch: 130 Batch:   106] loss: 0.622, acc: 74.956, test_acc:38.333, F1:0.395\n",
            "[Epoch: 131 Batch:   106] loss: 0.620, acc: 75.535, test_acc:32.500, F1:0.329\n",
            "[Epoch: 132 Batch:   106] loss: 0.627, acc: 74.830, test_acc:41.667, F1:0.423\n",
            "[Epoch: 133 Batch:   106] loss: 0.577, acc: 76.692, test_acc:35.833, F1:0.369\n",
            "[Epoch: 134 Batch:   106] loss: 0.599, acc: 76.755, test_acc:35.833, F1:0.367\n",
            "[Epoch: 135 Batch:   106] loss: 0.592, acc: 75.912, test_acc:35.000, F1:0.362\n",
            "[Epoch: 136 Batch:   106] loss: 0.602, acc: 76.151, test_acc:40.000, F1:0.403\n",
            "[Epoch: 137 Batch:   106] loss: 0.581, acc: 76.302, test_acc:36.667, F1:0.374\n",
            "[Epoch: 138 Batch:   106] loss: 0.564, acc: 76.453, test_acc:30.000, F1:0.310\n",
            "[Epoch: 139 Batch:   106] loss: 0.573, acc: 75.560, test_acc:36.667, F1:0.377\n",
            "[Epoch: 140 Batch:   106] loss: 0.576, acc: 76.038, test_acc:40.833, F1:0.400\n",
            "[Epoch: 141 Batch:   106] loss: 0.582, acc: 75.597, test_acc:36.667, F1:0.380\n",
            "[Epoch: 142 Batch:   106] loss: 0.568, acc: 75.547, test_acc:31.667, F1:0.319\n",
            "[Epoch: 143 Batch:   106] loss: 0.595, acc: 73.296, test_acc:36.667, F1:0.372\n",
            "[Epoch: 144 Batch:   106] loss: 0.550, acc: 77.384, test_acc:38.333, F1:0.394\n",
            "[Epoch: 145 Batch:   106] loss: 0.541, acc: 75.170, test_acc:35.000, F1:0.340\n",
            "[Epoch: 146 Batch:   106] loss: 0.551, acc: 76.201, test_acc:40.833, F1:0.415\n",
            "[Epoch: 147 Batch:   106] loss: 0.517, acc: 76.893, test_acc:32.500, F1:0.331\n",
            "[Epoch: 148 Batch:   106] loss: 0.549, acc: 76.579, test_acc:33.333, F1:0.343\n",
            "[Epoch: 149 Batch:   106] loss: 0.561, acc: 76.943, test_acc:39.167, F1:0.405\n",
            "[Epoch: 150 Batch:   106] loss: 0.514, acc: 75.899, test_acc:40.833, F1:0.415\n",
            "[Epoch: 151 Batch:   106] loss: 0.558, acc: 77.170, test_acc:32.500, F1:0.331\n",
            "[Epoch: 152 Batch:   106] loss: 0.530, acc: 75.962, test_acc:38.333, F1:0.396\n",
            "[Epoch: 153 Batch:   106] loss: 0.510, acc: 76.541, test_acc:39.167, F1:0.400\n",
            "[Epoch: 154 Batch:   106] loss: 0.536, acc: 79.220, test_acc:40.000, F1:0.398\n",
            "[Epoch: 155 Batch:   106] loss: 0.539, acc: 75.925, test_acc:34.167, F1:0.344\n",
            "[Epoch: 156 Batch:   106] loss: 0.530, acc: 77.082, test_acc:36.667, F1:0.374\n",
            "[Epoch: 157 Batch:   106] loss: 0.524, acc: 77.547, test_acc:43.333, F1:0.440\n",
            "[Epoch: 158 Batch:   106] loss: 0.547, acc: 76.063, test_acc:42.500, F1:0.433\n",
            "[Epoch: 159 Batch:   106] loss: 0.512, acc: 79.396, test_acc:39.167, F1:0.395\n",
            "[Epoch: 160 Batch:   106] loss: 0.530, acc: 77.220, test_acc:37.500, F1:0.378\n",
            "[Epoch: 161 Batch:   106] loss: 0.513, acc: 75.849, test_acc:37.500, F1:0.387\n",
            "[Epoch: 162 Batch:   106] loss: 0.511, acc: 76.943, test_acc:38.333, F1:0.390\n",
            "[Epoch: 163 Batch:   106] loss: 0.486, acc: 76.931, test_acc:44.167, F1:0.448\n",
            "[Epoch: 164 Batch:   106] loss: 0.512, acc: 76.403, test_acc:39.167, F1:0.398\n",
            "[Epoch: 165 Batch:   106] loss: 0.534, acc: 76.730, test_acc:39.167, F1:0.397\n",
            "[Epoch: 166 Batch:   106] loss: 0.538, acc: 76.189, test_acc:39.167, F1:0.401\n",
            "[Epoch: 167 Batch:   106] loss: 0.484, acc: 78.830, test_acc:40.833, F1:0.416\n",
            "[Epoch: 168 Batch:   106] loss: 0.490, acc: 77.660, test_acc:35.833, F1:0.355\n",
            "[Epoch: 169 Batch:   106] loss: 0.497, acc: 77.849, test_acc:32.500, F1:0.334\n",
            "[Epoch: 170 Batch:   106] loss: 0.460, acc: 78.528, test_acc:40.000, F1:0.412\n",
            "[Epoch: 171 Batch:   106] loss: 0.477, acc: 77.094, test_acc:38.333, F1:0.382\n",
            "[Epoch: 172 Batch:   106] loss: 0.482, acc: 78.453, test_acc:34.167, F1:0.346\n",
            "[Epoch: 173 Batch:   106] loss: 0.480, acc: 78.063, test_acc:35.833, F1:0.368\n",
            "[Epoch: 174 Batch:   106] loss: 0.456, acc: 77.635, test_acc:40.833, F1:0.418\n",
            "[Epoch: 175 Batch:   106] loss: 0.488, acc: 77.698, test_acc:40.833, F1:0.419\n",
            "[Epoch: 176 Batch:   106] loss: 0.519, acc: 75.673, test_acc:40.833, F1:0.410\n",
            "[Epoch: 177 Batch:   106] loss: 0.451, acc: 78.767, test_acc:43.333, F1:0.440\n",
            "[Epoch: 178 Batch:   106] loss: 0.497, acc: 77.686, test_acc:41.667, F1:0.427\n",
            "[Epoch: 179 Batch:   106] loss: 0.467, acc: 77.560, test_acc:37.500, F1:0.386\n",
            "[Epoch: 180 Batch:   106] loss: 0.478, acc: 76.239, test_acc:39.167, F1:0.400\n",
            "[Epoch: 181 Batch:   106] loss: 0.473, acc: 78.101, test_acc:41.667, F1:0.423\n",
            "[Epoch: 182 Batch:   106] loss: 0.479, acc: 77.447, test_acc:40.000, F1:0.407\n",
            "[Epoch: 183 Batch:   106] loss: 0.488, acc: 77.346, test_acc:40.833, F1:0.413\n",
            "[Epoch: 184 Batch:   106] loss: 0.528, acc: 76.340, test_acc:36.667, F1:0.366\n",
            "[Epoch: 185 Batch:   106] loss: 0.493, acc: 77.811, test_acc:37.500, F1:0.383\n",
            "[Epoch: 186 Batch:   106] loss: 0.486, acc: 76.579, test_acc:37.500, F1:0.380\n",
            "[Epoch: 187 Batch:   106] loss: 0.451, acc: 77.899, test_acc:37.500, F1:0.381\n",
            "[Epoch: 188 Batch:   106] loss: 0.439, acc: 76.918, test_acc:39.167, F1:0.398\n",
            "[Epoch: 189 Batch:   106] loss: 0.449, acc: 80.214, test_acc:35.000, F1:0.345\n",
            "[Epoch: 190 Batch:   106] loss: 0.489, acc: 77.862, test_acc:43.333, F1:0.445\n",
            "[Epoch: 191 Batch:   106] loss: 0.499, acc: 77.245, test_acc:40.000, F1:0.409\n",
            "[Epoch: 192 Batch:   106] loss: 0.436, acc: 78.579, test_acc:33.333, F1:0.322\n",
            "[Epoch: 193 Batch:   106] loss: 0.447, acc: 76.667, test_acc:35.833, F1:0.362\n",
            "[Epoch: 194 Batch:   106] loss: 0.439, acc: 78.000, test_acc:35.833, F1:0.362\n",
            "[Epoch: 195 Batch:   106] loss: 0.379, acc: 77.057, test_acc:36.667, F1:0.378\n",
            "[Epoch: 196 Batch:   106] loss: 0.416, acc: 77.597, test_acc:35.833, F1:0.367\n",
            "[Epoch: 197 Batch:   106] loss: 0.445, acc: 76.881, test_acc:39.167, F1:0.396\n",
            "[Epoch: 198 Batch:   106] loss: 0.404, acc: 79.006, test_acc:39.167, F1:0.397\n",
            "[Epoch: 199 Batch:   106] loss: 0.421, acc: 78.239, test_acc:30.000, F1:0.302\n",
            "[Epoch: 200 Batch:   106] loss: 0.409, acc: 78.591, test_acc:32.500, F1:0.329\n",
            "[Epoch: 201 Batch:   106] loss: 0.437, acc: 78.503, test_acc:40.000, F1:0.400\n",
            "[Epoch: 202 Batch:   106] loss: 0.469, acc: 78.377, test_acc:36.667, F1:0.375\n",
            "[Epoch: 203 Batch:   106] loss: 0.419, acc: 78.403, test_acc:38.333, F1:0.378\n",
            "[Epoch: 204 Batch:   106] loss: 0.436, acc: 76.704, test_acc:34.167, F1:0.345\n",
            "[Epoch: 205 Batch:   106] loss: 0.398, acc: 78.994, test_acc:40.000, F1:0.409\n",
            "[Epoch: 206 Batch:   106] loss: 0.420, acc: 77.082, test_acc:45.000, F1:0.443\n",
            "[Epoch: 207 Batch:   106] loss: 0.466, acc: 76.528, test_acc:35.833, F1:0.364\n",
            "[Epoch: 208 Batch:   106] loss: 0.443, acc: 76.818, test_acc:35.000, F1:0.354\n",
            "[Epoch: 209 Batch:   106] loss: 0.434, acc: 78.704, test_acc:30.833, F1:0.313\n",
            "[Epoch: 210 Batch:   106] loss: 0.438, acc: 76.340, test_acc:33.333, F1:0.332\n",
            "[Epoch: 211 Batch:   106] loss: 0.448, acc: 79.220, test_acc:30.833, F1:0.318\n",
            "[Epoch: 212 Batch:   106] loss: 0.461, acc: 76.855, test_acc:36.667, F1:0.374\n",
            "[Epoch: 213 Batch:   106] loss: 0.447, acc: 78.969, test_acc:34.167, F1:0.350\n",
            "[Epoch: 214 Batch:   106] loss: 0.468, acc: 77.623, test_acc:41.667, F1:0.429\n",
            "[Epoch: 215 Batch:   106] loss: 0.458, acc: 77.849, test_acc:37.500, F1:0.387\n",
            "[Epoch: 216 Batch:   106] loss: 0.433, acc: 79.182, test_acc:37.500, F1:0.375\n",
            "[Epoch: 217 Batch:   106] loss: 0.432, acc: 78.541, test_acc:34.167, F1:0.351\n",
            "[Epoch: 218 Batch:   106] loss: 0.434, acc: 78.365, test_acc:41.667, F1:0.413\n",
            "[Epoch: 219 Batch:   106] loss: 0.426, acc: 79.270, test_acc:40.833, F1:0.408\n",
            "[Epoch: 220 Batch:   106] loss: 0.437, acc: 78.176, test_acc:35.000, F1:0.363\n",
            "[Epoch: 221 Batch:   106] loss: 0.374, acc: 77.711, test_acc:43.333, F1:0.435\n",
            "[Epoch: 222 Batch:   106] loss: 0.362, acc: 80.403, test_acc:40.833, F1:0.415\n",
            "[Epoch: 223 Batch:   106] loss: 0.402, acc: 78.075, test_acc:33.333, F1:0.338\n",
            "[Epoch: 224 Batch:   106] loss: 0.428, acc: 78.126, test_acc:39.167, F1:0.400\n",
            "[Epoch: 225 Batch:   106] loss: 0.481, acc: 76.881, test_acc:41.667, F1:0.425\n",
            "[Epoch: 226 Batch:   106] loss: 0.467, acc: 77.736, test_acc:40.000, F1:0.405\n",
            "[Epoch: 227 Batch:   106] loss: 0.415, acc: 79.623, test_acc:32.500, F1:0.305\n",
            "[Epoch: 228 Batch:   106] loss: 0.408, acc: 78.767, test_acc:35.000, F1:0.358\n",
            "[Epoch: 229 Batch:   106] loss: 0.351, acc: 78.314, test_acc:37.500, F1:0.382\n",
            "[Epoch: 230 Batch:   106] loss: 0.361, acc: 78.289, test_acc:42.500, F1:0.433\n",
            "[Epoch: 231 Batch:   106] loss: 0.414, acc: 78.805, test_acc:32.500, F1:0.321\n",
            "[Epoch: 232 Batch:   106] loss: 0.520, acc: 76.730, test_acc:35.833, F1:0.366\n",
            "[Epoch: 233 Batch:   106] loss: 0.400, acc: 78.164, test_acc:37.500, F1:0.382\n",
            "[Epoch: 234 Batch:   106] loss: 0.438, acc: 79.283, test_acc:36.667, F1:0.367\n",
            "[Epoch: 235 Batch:   106] loss: 0.429, acc: 77.912, test_acc:35.833, F1:0.355\n",
            "[Epoch: 236 Batch:   106] loss: 0.440, acc: 78.855, test_acc:38.333, F1:0.388\n",
            "[Epoch: 237 Batch:   106] loss: 0.388, acc: 78.491, test_acc:40.000, F1:0.412\n",
            "[Epoch: 238 Batch:   106] loss: 0.392, acc: 77.824, test_acc:32.500, F1:0.328\n",
            "[Epoch: 239 Batch:   106] loss: 0.418, acc: 78.491, test_acc:35.833, F1:0.367\n",
            "[Epoch: 240 Batch:   106] loss: 0.427, acc: 76.943, test_acc:36.667, F1:0.372\n",
            "[Epoch: 241 Batch:   106] loss: 0.425, acc: 78.491, test_acc:37.500, F1:0.379\n",
            "[Epoch: 242 Batch:   106] loss: 0.353, acc: 78.906, test_acc:41.667, F1:0.423\n",
            "[Epoch: 243 Batch:   106] loss: 0.405, acc: 76.994, test_acc:33.333, F1:0.331\n",
            "[Epoch: 244 Batch:   106] loss: 0.385, acc: 78.692, test_acc:40.000, F1:0.404\n",
            "[Epoch: 245 Batch:   106] loss: 0.374, acc: 77.937, test_acc:32.500, F1:0.325\n",
            "[Epoch: 246 Batch:   106] loss: 0.355, acc: 78.931, test_acc:42.500, F1:0.427\n",
            "[Epoch: 247 Batch:   106] loss: 0.378, acc: 80.491, test_acc:27.500, F1:0.258\n",
            "[Epoch: 248 Batch:   106] loss: 0.497, acc: 75.786, test_acc:35.833, F1:0.366\n",
            "[Epoch: 249 Batch:   106] loss: 0.457, acc: 76.893, test_acc:35.000, F1:0.357\n",
            "[Epoch: 250 Batch:   106] loss: 0.433, acc: 77.358, test_acc:33.333, F1:0.323\n",
            "[Epoch: 251 Batch:   106] loss: 0.448, acc: 78.050, test_acc:28.333, F1:0.281\n",
            "[Epoch: 252 Batch:   106] loss: 0.484, acc: 79.509, test_acc:32.500, F1:0.333\n",
            "[Epoch: 253 Batch:   106] loss: 0.507, acc: 74.252, test_acc:40.833, F1:0.416\n",
            "[Epoch: 254 Batch:   106] loss: 0.392, acc: 78.956, test_acc:39.167, F1:0.397\n",
            "[Epoch: 255 Batch:   106] loss: 0.396, acc: 76.918, test_acc:37.500, F1:0.385\n",
            "[Epoch: 256 Batch:   106] loss: 0.380, acc: 79.044, test_acc:34.167, F1:0.340\n",
            "[Epoch: 257 Batch:   106] loss: 0.374, acc: 77.547, test_acc:40.833, F1:0.404\n",
            "[Epoch: 258 Batch:   106] loss: 0.361, acc: 80.717, test_acc:36.667, F1:0.374\n",
            "[Epoch: 259 Batch:   106] loss: 0.405, acc: 78.541, test_acc:35.000, F1:0.356\n",
            "[Epoch: 260 Batch:   106] loss: 0.324, acc: 78.767, test_acc:35.833, F1:0.359\n",
            "[Epoch: 261 Batch:   106] loss: 0.312, acc: 78.843, test_acc:40.833, F1:0.415\n",
            "[Epoch: 262 Batch:   106] loss: 0.318, acc: 82.151, test_acc:35.000, F1:0.355\n",
            "[Epoch: 263 Batch:   106] loss: 0.367, acc: 79.132, test_acc:37.500, F1:0.382\n",
            "[Epoch: 264 Batch:   106] loss: 0.326, acc: 80.730, test_acc:32.500, F1:0.320\n",
            "[Epoch: 265 Batch:   106] loss: 0.348, acc: 80.075, test_acc:35.000, F1:0.355\n",
            "[Epoch: 266 Batch:   106] loss: 0.486, acc: 77.723, test_acc:37.500, F1:0.385\n",
            "[Epoch: 267 Batch:   106] loss: 0.484, acc: 74.327, test_acc:35.833, F1:0.365\n",
            "[Epoch: 268 Batch:   106] loss: 0.500, acc: 77.157, test_acc:43.333, F1:0.435\n",
            "[Epoch: 269 Batch:   106] loss: 0.513, acc: 77.308, test_acc:40.000, F1:0.408\n",
            "[Epoch: 270 Batch:   106] loss: 0.416, acc: 77.824, test_acc:42.500, F1:0.428\n",
            "[Epoch: 271 Batch:   106] loss: 0.422, acc: 80.491, test_acc:40.000, F1:0.401\n",
            "[Epoch: 272 Batch:   106] loss: 0.375, acc: 79.673, test_acc:37.500, F1:0.381\n",
            "[Epoch: 273 Batch:   106] loss: 0.385, acc: 77.346, test_acc:38.333, F1:0.393\n",
            "[Epoch: 274 Batch:   106] loss: 0.377, acc: 79.509, test_acc:38.333, F1:0.389\n",
            "[Epoch: 275 Batch:   106] loss: 0.359, acc: 78.101, test_acc:33.333, F1:0.340\n",
            "[Epoch: 276 Batch:   106] loss: 0.295, acc: 79.057, test_acc:38.333, F1:0.387\n",
            "[Epoch: 277 Batch:   106] loss: 0.304, acc: 78.176, test_acc:37.500, F1:0.380\n",
            "[Epoch: 278 Batch:   106] loss: 0.365, acc: 78.365, test_acc:32.500, F1:0.331\n",
            "[Epoch: 279 Batch:   106] loss: 0.353, acc: 79.208, test_acc:34.167, F1:0.340\n",
            "[Epoch: 280 Batch:   106] loss: 0.398, acc: 78.503, test_acc:38.333, F1:0.386\n",
            "[Epoch: 281 Batch:   106] loss: 0.317, acc: 78.541, test_acc:36.667, F1:0.369\n",
            "[Epoch: 282 Batch:   106] loss: 0.397, acc: 77.233, test_acc:35.000, F1:0.356\n",
            "[Epoch: 283 Batch:   106] loss: 0.349, acc: 77.132, test_acc:35.833, F1:0.369\n",
            "[Epoch: 284 Batch:   106] loss: 0.406, acc: 77.145, test_acc:33.333, F1:0.339\n",
            "[Epoch: 285 Batch:   106] loss: 0.404, acc: 77.824, test_acc:37.500, F1:0.380\n",
            "[Epoch: 286 Batch:   106] loss: 0.388, acc: 78.893, test_acc:30.000, F1:0.303\n",
            "[Epoch: 287 Batch:   106] loss: 0.394, acc: 78.792, test_acc:35.833, F1:0.362\n",
            "[Epoch: 288 Batch:   106] loss: 0.509, acc: 76.780, test_acc:42.500, F1:0.430\n",
            "[Epoch: 289 Batch:   106] loss: 0.461, acc: 78.642, test_acc:30.833, F1:0.308\n",
            "[Epoch: 290 Batch:   106] loss: 0.447, acc: 78.541, test_acc:30.833, F1:0.310\n",
            "[Epoch: 291 Batch:   106] loss: 0.404, acc: 81.220, test_acc:37.500, F1:0.373\n",
            "[Epoch: 292 Batch:   106] loss: 0.378, acc: 79.447, test_acc:35.000, F1:0.356\n",
            "[Epoch: 293 Batch:   106] loss: 0.365, acc: 79.597, test_acc:30.833, F1:0.313\n",
            "[Epoch: 294 Batch:   106] loss: 0.290, acc: 79.824, test_acc:36.667, F1:0.367\n",
            "[Epoch: 295 Batch:   106] loss: 0.314, acc: 81.107, test_acc:34.167, F1:0.345\n",
            "[Epoch: 296 Batch:   106] loss: 0.312, acc: 79.698, test_acc:35.000, F1:0.354\n",
            "[Epoch: 297 Batch:   106] loss: 0.414, acc: 78.755, test_acc:36.667, F1:0.372\n",
            "[Epoch: 298 Batch:   106] loss: 0.444, acc: 77.509, test_acc:33.333, F1:0.339\n",
            "[Epoch: 299 Batch:   106] loss: 0.400, acc: 78.767, test_acc:32.500, F1:0.332\n",
            "[Epoch: 300 Batch:   106] loss: 0.452, acc: 78.277, test_acc:32.500, F1:0.334\n",
            "------------------------------------------------------\n",
            "Training has finished\n",
            "Test Accuracy:  32.5\n",
            "Test F1 Score : 0.3341101834064003\n",
            "All :               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.49      0.33      0.40        60\n",
            "         1.0       0.26      0.37      0.31        30\n",
            "         2.0       0.22      0.27      0.24        30\n",
            "\n",
            "    accuracy                           0.33       120\n",
            "   macro avg       0.32      0.32      0.31       120\n",
            "weighted avg       0.36      0.33      0.33       120\n",
            "\n",
            "Confusion Matrix :\n",
            "[[20 23 17]\n",
            " [ 7 11 12]\n",
            " [14  8  8]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x230.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pre-processing time  validation sets --- 7.02007155418396 minutes ---\n",
            "Training Features (2640, 2, 28, 28)\n",
            "Training Labels (2640,)\n",
            "Training Features (120, 2, 28, 28)\n",
            "Training Labels (120,)\n",
            "Trainf torch.Size([2640, 2, 28, 28])\n",
            "Trainl torch.Size([2640])\n",
            "Testf torch.Size([120, 2, 28, 28])\n",
            "Testl torch.Size([120])\n",
            "Participant :  17\n",
            "[Epoch: 1 Batch:   106] loss: 1.090, acc: 34.101, test_acc:35.000, F1:0.344\n",
            "[Epoch: 2 Batch:   106] loss: 1.086, acc: 36.830, test_acc:39.167, F1:0.382\n",
            "[Epoch: 3 Batch:   106] loss: 1.081, acc: 37.799, test_acc:37.500, F1:0.363\n",
            "[Epoch: 4 Batch:   106] loss: 1.079, acc: 36.390, test_acc:35.000, F1:0.334\n",
            "[Epoch: 5 Batch:   106] loss: 1.075, acc: 37.635, test_acc:35.000, F1:0.337\n",
            "[Epoch: 6 Batch:   106] loss: 1.076, acc: 37.270, test_acc:35.000, F1:0.351\n",
            "[Epoch: 7 Batch:   106] loss: 1.073, acc: 37.195, test_acc:36.667, F1:0.368\n",
            "[Epoch: 8 Batch:   106] loss: 1.069, acc: 38.264, test_acc:35.000, F1:0.351\n",
            "[Epoch: 9 Batch:   106] loss: 1.071, acc: 38.126, test_acc:35.833, F1:0.359\n",
            "[Epoch: 10 Batch:   106] loss: 1.068, acc: 39.371, test_acc:36.667, F1:0.356\n",
            "[Epoch: 11 Batch:   106] loss: 1.066, acc: 39.107, test_acc:35.833, F1:0.355\n",
            "[Epoch: 12 Batch:   106] loss: 1.065, acc: 39.044, test_acc:34.167, F1:0.338\n",
            "[Epoch: 13 Batch:   106] loss: 1.065, acc: 40.101, test_acc:35.000, F1:0.350\n",
            "[Epoch: 14 Batch:   106] loss: 1.063, acc: 39.950, test_acc:34.167, F1:0.330\n",
            "[Epoch: 15 Batch:   106] loss: 1.061, acc: 39.321, test_acc:35.000, F1:0.337\n",
            "[Epoch: 16 Batch:   106] loss: 1.063, acc: 38.994, test_acc:35.833, F1:0.344\n",
            "[Epoch: 17 Batch:   106] loss: 1.058, acc: 40.390, test_acc:33.333, F1:0.325\n",
            "[Epoch: 18 Batch:   106] loss: 1.056, acc: 39.950, test_acc:36.667, F1:0.367\n",
            "[Epoch: 19 Batch:   106] loss: 1.053, acc: 40.541, test_acc:33.333, F1:0.331\n",
            "[Epoch: 20 Batch:   106] loss: 1.052, acc: 41.686, test_acc:34.167, F1:0.338\n",
            "[Epoch: 21 Batch:   106] loss: 1.049, acc: 41.975, test_acc:34.167, F1:0.341\n",
            "[Epoch: 22 Batch:   106] loss: 1.049, acc: 41.748, test_acc:35.833, F1:0.354\n",
            "[Epoch: 23 Batch:   106] loss: 1.045, acc: 42.377, test_acc:30.833, F1:0.309\n",
            "[Epoch: 24 Batch:   106] loss: 1.046, acc: 43.094, test_acc:33.333, F1:0.330\n",
            "[Epoch: 25 Batch:   106] loss: 1.043, acc: 42.692, test_acc:35.000, F1:0.343\n",
            "[Epoch: 26 Batch:   106] loss: 1.038, acc: 42.239, test_acc:30.000, F1:0.300\n",
            "[Epoch: 27 Batch:   106] loss: 1.044, acc: 43.296, test_acc:28.333, F1:0.277\n",
            "[Epoch: 28 Batch:   106] loss: 1.039, acc: 44.918, test_acc:30.833, F1:0.305\n",
            "[Epoch: 29 Batch:   106] loss: 1.040, acc: 43.635, test_acc:31.667, F1:0.311\n",
            "[Epoch: 30 Batch:   106] loss: 1.036, acc: 43.610, test_acc:34.167, F1:0.341\n",
            "[Epoch: 31 Batch:   106] loss: 1.033, acc: 43.925, test_acc:34.167, F1:0.335\n",
            "[Epoch: 32 Batch:   106] loss: 1.028, acc: 45.635, test_acc:33.333, F1:0.335\n",
            "[Epoch: 33 Batch:   106] loss: 1.028, acc: 46.692, test_acc:31.667, F1:0.317\n",
            "[Epoch: 34 Batch:   106] loss: 1.028, acc: 46.704, test_acc:25.833, F1:0.258\n",
            "[Epoch: 35 Batch:   106] loss: 1.025, acc: 45.736, test_acc:31.667, F1:0.315\n",
            "[Epoch: 36 Batch:   106] loss: 1.020, acc: 46.365, test_acc:36.667, F1:0.367\n",
            "[Epoch: 37 Batch:   106] loss: 1.025, acc: 47.333, test_acc:33.333, F1:0.334\n",
            "[Epoch: 38 Batch:   106] loss: 1.021, acc: 47.572, test_acc:27.500, F1:0.277\n",
            "[Epoch: 39 Batch:   106] loss: 1.018, acc: 47.208, test_acc:29.167, F1:0.284\n",
            "[Epoch: 40 Batch:   106] loss: 1.016, acc: 48.038, test_acc:35.833, F1:0.361\n",
            "[Epoch: 41 Batch:   106] loss: 1.014, acc: 47.849, test_acc:34.167, F1:0.340\n",
            "[Epoch: 42 Batch:   106] loss: 1.006, acc: 48.478, test_acc:34.167, F1:0.342\n",
            "[Epoch: 43 Batch:   106] loss: 1.015, acc: 49.145, test_acc:36.667, F1:0.366\n",
            "[Epoch: 44 Batch:   106] loss: 1.012, acc: 49.925, test_acc:28.333, F1:0.283\n",
            "[Epoch: 45 Batch:   106] loss: 0.999, acc: 50.792, test_acc:35.833, F1:0.357\n",
            "[Epoch: 46 Batch:   106] loss: 1.000, acc: 50.805, test_acc:33.333, F1:0.334\n",
            "[Epoch: 47 Batch:   106] loss: 0.997, acc: 50.327, test_acc:34.167, F1:0.340\n",
            "[Epoch: 48 Batch:   106] loss: 0.995, acc: 51.497, test_acc:38.333, F1:0.385\n",
            "[Epoch: 49 Batch:   106] loss: 0.987, acc: 50.780, test_acc:35.000, F1:0.349\n",
            "[Epoch: 50 Batch:   106] loss: 0.990, acc: 52.013, test_acc:40.833, F1:0.405\n",
            "[Epoch: 51 Batch:   106] loss: 0.984, acc: 52.591, test_acc:37.500, F1:0.376\n",
            "[Epoch: 52 Batch:   106] loss: 0.979, acc: 51.799, test_acc:34.167, F1:0.342\n",
            "[Epoch: 53 Batch:   106] loss: 0.974, acc: 52.943, test_acc:37.500, F1:0.376\n",
            "[Epoch: 54 Batch:   106] loss: 0.973, acc: 54.025, test_acc:35.000, F1:0.350\n",
            "[Epoch: 55 Batch:   106] loss: 0.967, acc: 55.132, test_acc:36.667, F1:0.365\n",
            "[Epoch: 56 Batch:   106] loss: 0.963, acc: 53.925, test_acc:30.833, F1:0.308\n",
            "[Epoch: 57 Batch:   106] loss: 0.961, acc: 54.365, test_acc:38.333, F1:0.385\n",
            "[Epoch: 58 Batch:   106] loss: 0.953, acc: 55.673, test_acc:24.167, F1:0.243\n",
            "[Epoch: 59 Batch:   106] loss: 0.954, acc: 54.868, test_acc:37.500, F1:0.375\n",
            "[Epoch: 60 Batch:   106] loss: 0.948, acc: 56.553, test_acc:30.833, F1:0.308\n",
            "[Epoch: 61 Batch:   106] loss: 0.945, acc: 56.050, test_acc:30.833, F1:0.308\n",
            "[Epoch: 62 Batch:   106] loss: 0.931, acc: 56.415, test_acc:37.500, F1:0.373\n",
            "[Epoch: 63 Batch:   106] loss: 0.930, acc: 57.522, test_acc:32.500, F1:0.324\n",
            "[Epoch: 64 Batch:   106] loss: 0.932, acc: 57.170, test_acc:40.000, F1:0.397\n",
            "[Epoch: 65 Batch:   106] loss: 0.932, acc: 56.981, test_acc:36.667, F1:0.364\n",
            "[Epoch: 66 Batch:   106] loss: 0.920, acc: 57.786, test_acc:37.500, F1:0.375\n",
            "[Epoch: 67 Batch:   106] loss: 0.914, acc: 58.553, test_acc:35.833, F1:0.357\n",
            "[Epoch: 68 Batch:   106] loss: 0.915, acc: 58.126, test_acc:39.167, F1:0.387\n",
            "[Epoch: 69 Batch:   106] loss: 0.908, acc: 59.182, test_acc:26.667, F1:0.267\n",
            "[Epoch: 70 Batch:   106] loss: 0.909, acc: 59.409, test_acc:35.000, F1:0.351\n",
            "[Epoch: 71 Batch:   106] loss: 0.897, acc: 60.151, test_acc:35.833, F1:0.353\n",
            "[Epoch: 72 Batch:   106] loss: 0.896, acc: 59.182, test_acc:35.000, F1:0.350\n",
            "[Epoch: 73 Batch:   106] loss: 0.878, acc: 61.723, test_acc:33.333, F1:0.328\n",
            "[Epoch: 74 Batch:   106] loss: 0.883, acc: 61.358, test_acc:24.167, F1:0.239\n",
            "[Epoch: 75 Batch:   106] loss: 0.876, acc: 61.912, test_acc:31.667, F1:0.317\n",
            "[Epoch: 76 Batch:   106] loss: 0.874, acc: 61.497, test_acc:30.833, F1:0.305\n",
            "[Epoch: 77 Batch:   106] loss: 0.881, acc: 62.390, test_acc:35.833, F1:0.353\n",
            "[Epoch: 78 Batch:   106] loss: 0.865, acc: 61.748, test_acc:32.500, F1:0.324\n",
            "[Epoch: 79 Batch:   106] loss: 0.862, acc: 64.767, test_acc:33.333, F1:0.334\n",
            "[Epoch: 80 Batch:   106] loss: 0.854, acc: 63.094, test_acc:26.667, F1:0.269\n",
            "[Epoch: 81 Batch:   106] loss: 0.861, acc: 62.943, test_acc:31.667, F1:0.318\n",
            "[Epoch: 82 Batch:   106] loss: 0.839, acc: 63.522, test_acc:29.167, F1:0.294\n",
            "[Epoch: 83 Batch:   106] loss: 0.849, acc: 64.642, test_acc:29.167, F1:0.296\n",
            "[Epoch: 84 Batch:   106] loss: 0.836, acc: 64.478, test_acc:31.667, F1:0.319\n",
            "[Epoch: 85 Batch:   106] loss: 0.830, acc: 63.912, test_acc:28.333, F1:0.283\n",
            "[Epoch: 86 Batch:   106] loss: 0.817, acc: 65.648, test_acc:28.333, F1:0.283\n",
            "[Epoch: 87 Batch:   106] loss: 0.827, acc: 65.509, test_acc:33.333, F1:0.335\n",
            "[Epoch: 88 Batch:   106] loss: 0.826, acc: 65.849, test_acc:30.833, F1:0.308\n",
            "[Epoch: 89 Batch:   106] loss: 0.822, acc: 66.113, test_acc:40.000, F1:0.398\n",
            "[Epoch: 90 Batch:   106] loss: 0.817, acc: 65.522, test_acc:29.167, F1:0.289\n",
            "[Epoch: 91 Batch:   106] loss: 0.795, acc: 67.421, test_acc:34.167, F1:0.343\n",
            "[Epoch: 92 Batch:   106] loss: 0.798, acc: 67.132, test_acc:40.000, F1:0.400\n",
            "[Epoch: 93 Batch:   106] loss: 0.798, acc: 67.434, test_acc:35.833, F1:0.358\n",
            "[Epoch: 94 Batch:   106] loss: 0.793, acc: 66.755, test_acc:34.167, F1:0.342\n",
            "[Epoch: 95 Batch:   106] loss: 0.792, acc: 67.145, test_acc:27.500, F1:0.275\n",
            "[Epoch: 96 Batch:   106] loss: 0.774, acc: 68.214, test_acc:40.000, F1:0.400\n",
            "[Epoch: 97 Batch:   106] loss: 0.774, acc: 67.811, test_acc:29.167, F1:0.291\n",
            "[Epoch: 98 Batch:   106] loss: 0.772, acc: 68.101, test_acc:30.000, F1:0.297\n",
            "[Epoch: 99 Batch:   106] loss: 0.778, acc: 68.478, test_acc:33.333, F1:0.334\n",
            "[Epoch: 100 Batch:   106] loss: 0.773, acc: 67.698, test_acc:31.667, F1:0.321\n",
            "[Epoch: 101 Batch:   106] loss: 0.761, acc: 69.736, test_acc:36.667, F1:0.368\n",
            "[Epoch: 102 Batch:   106] loss: 0.757, acc: 69.006, test_acc:32.500, F1:0.326\n",
            "[Epoch: 103 Batch:   106] loss: 0.737, acc: 69.975, test_acc:37.500, F1:0.373\n",
            "[Epoch: 104 Batch:   106] loss: 0.749, acc: 69.119, test_acc:36.667, F1:0.368\n",
            "[Epoch: 105 Batch:   106] loss: 0.751, acc: 70.352, test_acc:38.333, F1:0.385\n",
            "[Epoch: 106 Batch:   106] loss: 0.747, acc: 69.358, test_acc:31.667, F1:0.317\n",
            "[Epoch: 107 Batch:   106] loss: 0.752, acc: 69.849, test_acc:30.000, F1:0.297\n",
            "[Epoch: 108 Batch:   106] loss: 0.726, acc: 71.660, test_acc:28.333, F1:0.277\n",
            "[Epoch: 109 Batch:   106] loss: 0.720, acc: 72.088, test_acc:30.833, F1:0.309\n",
            "[Epoch: 110 Batch:   106] loss: 0.722, acc: 71.635, test_acc:29.167, F1:0.293\n",
            "[Epoch: 111 Batch:   106] loss: 0.716, acc: 71.522, test_acc:29.167, F1:0.288\n",
            "[Epoch: 112 Batch:   106] loss: 0.711, acc: 72.969, test_acc:32.500, F1:0.325\n",
            "[Epoch: 113 Batch:   106] loss: 0.707, acc: 71.899, test_acc:28.333, F1:0.278\n",
            "[Epoch: 114 Batch:   106] loss: 0.729, acc: 71.371, test_acc:32.500, F1:0.326\n",
            "[Epoch: 115 Batch:   106] loss: 0.693, acc: 72.491, test_acc:41.667, F1:0.417\n",
            "[Epoch: 116 Batch:   106] loss: 0.689, acc: 71.962, test_acc:34.167, F1:0.342\n",
            "[Epoch: 117 Batch:   106] loss: 0.695, acc: 72.843, test_acc:30.000, F1:0.299\n",
            "[Epoch: 118 Batch:   106] loss: 0.692, acc: 72.088, test_acc:35.833, F1:0.358\n",
            "[Epoch: 119 Batch:   106] loss: 0.685, acc: 72.201, test_acc:33.333, F1:0.333\n",
            "[Epoch: 120 Batch:   106] loss: 0.654, acc: 74.541, test_acc:33.333, F1:0.326\n",
            "[Epoch: 121 Batch:   106] loss: 0.676, acc: 72.717, test_acc:35.833, F1:0.358\n",
            "[Epoch: 122 Batch:   106] loss: 0.653, acc: 74.075, test_acc:31.667, F1:0.316\n",
            "[Epoch: 123 Batch:   106] loss: 0.653, acc: 73.069, test_acc:30.833, F1:0.299\n",
            "[Epoch: 124 Batch:   106] loss: 0.661, acc: 74.830, test_acc:33.333, F1:0.330\n",
            "[Epoch: 125 Batch:   106] loss: 0.654, acc: 73.950, test_acc:39.167, F1:0.392\n",
            "[Epoch: 126 Batch:   106] loss: 0.636, acc: 74.931, test_acc:27.500, F1:0.267\n",
            "[Epoch: 127 Batch:   106] loss: 0.652, acc: 74.503, test_acc:34.167, F1:0.339\n",
            "[Epoch: 128 Batch:   106] loss: 0.613, acc: 75.648, test_acc:33.333, F1:0.335\n",
            "[Epoch: 129 Batch:   106] loss: 0.663, acc: 75.270, test_acc:26.667, F1:0.264\n",
            "[Epoch: 130 Batch:   106] loss: 0.654, acc: 74.805, test_acc:34.167, F1:0.342\n",
            "[Epoch: 131 Batch:   106] loss: 0.652, acc: 74.843, test_acc:36.667, F1:0.369\n",
            "[Epoch: 132 Batch:   106] loss: 0.642, acc: 75.044, test_acc:27.500, F1:0.274\n",
            "[Epoch: 133 Batch:   106] loss: 0.635, acc: 74.126, test_acc:32.500, F1:0.323\n",
            "[Epoch: 134 Batch:   106] loss: 0.610, acc: 75.220, test_acc:26.667, F1:0.254\n",
            "[Epoch: 135 Batch:   106] loss: 0.613, acc: 75.434, test_acc:32.500, F1:0.325\n",
            "[Epoch: 136 Batch:   106] loss: 0.598, acc: 77.522, test_acc:30.000, F1:0.298\n",
            "[Epoch: 137 Batch:   106] loss: 0.606, acc: 77.145, test_acc:34.167, F1:0.343\n",
            "[Epoch: 138 Batch:   106] loss: 0.606, acc: 77.119, test_acc:33.333, F1:0.326\n",
            "[Epoch: 139 Batch:   106] loss: 0.587, acc: 75.245, test_acc:33.333, F1:0.321\n",
            "[Epoch: 140 Batch:   106] loss: 0.607, acc: 75.660, test_acc:33.333, F1:0.333\n",
            "[Epoch: 141 Batch:   106] loss: 0.588, acc: 75.711, test_acc:27.500, F1:0.259\n",
            "[Epoch: 142 Batch:   106] loss: 0.586, acc: 77.057, test_acc:32.500, F1:0.320\n",
            "[Epoch: 143 Batch:   106] loss: 0.564, acc: 77.472, test_acc:33.333, F1:0.326\n",
            "[Epoch: 144 Batch:   106] loss: 0.568, acc: 76.943, test_acc:32.500, F1:0.323\n",
            "[Epoch: 145 Batch:   106] loss: 0.564, acc: 76.755, test_acc:35.833, F1:0.358\n",
            "[Epoch: 146 Batch:   106] loss: 0.571, acc: 76.365, test_acc:28.333, F1:0.278\n",
            "[Epoch: 147 Batch:   106] loss: 0.574, acc: 76.843, test_acc:25.833, F1:0.245\n",
            "[Epoch: 148 Batch:   106] loss: 0.587, acc: 77.572, test_acc:27.500, F1:0.270\n",
            "[Epoch: 149 Batch:   106] loss: 0.578, acc: 77.384, test_acc:30.833, F1:0.309\n",
            "[Epoch: 150 Batch:   106] loss: 0.535, acc: 78.264, test_acc:28.333, F1:0.263\n",
            "[Epoch: 151 Batch:   106] loss: 0.552, acc: 76.868, test_acc:38.333, F1:0.384\n",
            "[Epoch: 152 Batch:   106] loss: 0.542, acc: 78.063, test_acc:30.833, F1:0.305\n",
            "[Epoch: 153 Batch:   106] loss: 0.533, acc: 76.302, test_acc:32.500, F1:0.318\n",
            "[Epoch: 154 Batch:   106] loss: 0.569, acc: 77.019, test_acc:30.833, F1:0.303\n",
            "[Epoch: 155 Batch:   106] loss: 0.534, acc: 76.113, test_acc:35.833, F1:0.360\n",
            "[Epoch: 156 Batch:   106] loss: 0.523, acc: 79.283, test_acc:32.500, F1:0.284\n",
            "[Epoch: 157 Batch:   106] loss: 0.537, acc: 76.516, test_acc:30.000, F1:0.284\n",
            "[Epoch: 158 Batch:   106] loss: 0.544, acc: 76.239, test_acc:34.167, F1:0.303\n",
            "[Epoch: 159 Batch:   106] loss: 0.501, acc: 78.516, test_acc:31.667, F1:0.288\n",
            "[Epoch: 160 Batch:   106] loss: 0.520, acc: 77.887, test_acc:34.167, F1:0.319\n",
            "[Epoch: 161 Batch:   106] loss: 0.536, acc: 77.182, test_acc:37.500, F1:0.358\n",
            "[Epoch: 162 Batch:   106] loss: 0.525, acc: 77.597, test_acc:37.500, F1:0.360\n",
            "[Epoch: 163 Batch:   106] loss: 0.517, acc: 77.610, test_acc:31.667, F1:0.315\n",
            "[Epoch: 164 Batch:   106] loss: 0.518, acc: 77.799, test_acc:34.167, F1:0.332\n",
            "[Epoch: 165 Batch:   106] loss: 0.482, acc: 78.679, test_acc:31.667, F1:0.314\n",
            "[Epoch: 166 Batch:   106] loss: 0.515, acc: 78.767, test_acc:29.167, F1:0.278\n",
            "[Epoch: 167 Batch:   106] loss: 0.530, acc: 77.585, test_acc:31.667, F1:0.303\n",
            "[Epoch: 168 Batch:   106] loss: 0.526, acc: 77.157, test_acc:35.000, F1:0.340\n",
            "[Epoch: 169 Batch:   106] loss: 0.498, acc: 78.440, test_acc:41.667, F1:0.402\n",
            "[Epoch: 170 Batch:   106] loss: 0.513, acc: 79.107, test_acc:32.500, F1:0.296\n",
            "[Epoch: 171 Batch:   106] loss: 0.466, acc: 79.484, test_acc:26.667, F1:0.260\n",
            "[Epoch: 172 Batch:   106] loss: 0.488, acc: 79.145, test_acc:30.833, F1:0.300\n",
            "[Epoch: 173 Batch:   106] loss: 0.486, acc: 78.176, test_acc:32.500, F1:0.276\n",
            "[Epoch: 174 Batch:   106] loss: 0.477, acc: 78.956, test_acc:29.167, F1:0.275\n",
            "[Epoch: 175 Batch:   106] loss: 0.509, acc: 78.189, test_acc:31.667, F1:0.294\n",
            "[Epoch: 176 Batch:   106] loss: 0.516, acc: 77.874, test_acc:32.500, F1:0.307\n",
            "[Epoch: 177 Batch:   106] loss: 0.512, acc: 78.000, test_acc:32.500, F1:0.291\n",
            "[Epoch: 178 Batch:   106] loss: 0.508, acc: 77.799, test_acc:33.333, F1:0.320\n",
            "[Epoch: 179 Batch:   106] loss: 0.496, acc: 78.704, test_acc:31.667, F1:0.304\n",
            "[Epoch: 180 Batch:   106] loss: 0.480, acc: 80.453, test_acc:30.000, F1:0.291\n",
            "[Epoch: 181 Batch:   106] loss: 0.454, acc: 79.623, test_acc:33.333, F1:0.295\n",
            "[Epoch: 182 Batch:   106] loss: 0.508, acc: 78.717, test_acc:30.833, F1:0.293\n",
            "[Epoch: 183 Batch:   106] loss: 0.451, acc: 79.522, test_acc:35.000, F1:0.316\n",
            "[Epoch: 184 Batch:   106] loss: 0.464, acc: 78.063, test_acc:35.000, F1:0.339\n",
            "[Epoch: 185 Batch:   106] loss: 0.435, acc: 79.220, test_acc:33.333, F1:0.305\n",
            "[Epoch: 186 Batch:   106] loss: 0.472, acc: 79.170, test_acc:29.167, F1:0.269\n",
            "[Epoch: 187 Batch:   106] loss: 0.492, acc: 78.516, test_acc:31.667, F1:0.304\n",
            "[Epoch: 188 Batch:   106] loss: 0.435, acc: 78.679, test_acc:35.000, F1:0.338\n",
            "[Epoch: 189 Batch:   106] loss: 0.430, acc: 80.365, test_acc:33.333, F1:0.300\n",
            "[Epoch: 190 Batch:   106] loss: 0.454, acc: 78.717, test_acc:36.667, F1:0.338\n",
            "[Epoch: 191 Batch:   106] loss: 0.425, acc: 80.264, test_acc:33.333, F1:0.284\n",
            "[Epoch: 192 Batch:   106] loss: 0.434, acc: 79.245, test_acc:35.833, F1:0.325\n",
            "[Epoch: 193 Batch:   106] loss: 0.443, acc: 79.094, test_acc:35.000, F1:0.327\n",
            "[Epoch: 194 Batch:   106] loss: 0.487, acc: 78.642, test_acc:28.333, F1:0.271\n",
            "[Epoch: 195 Batch:   106] loss: 0.469, acc: 78.579, test_acc:33.333, F1:0.295\n",
            "[Epoch: 196 Batch:   106] loss: 0.433, acc: 78.906, test_acc:33.333, F1:0.316\n",
            "[Epoch: 197 Batch:   106] loss: 0.471, acc: 78.201, test_acc:36.667, F1:0.338\n",
            "[Epoch: 198 Batch:   106] loss: 0.484, acc: 76.528, test_acc:32.500, F1:0.285\n",
            "[Epoch: 199 Batch:   106] loss: 0.433, acc: 79.296, test_acc:33.333, F1:0.317\n",
            "[Epoch: 200 Batch:   106] loss: 0.413, acc: 79.107, test_acc:32.500, F1:0.310\n",
            "[Epoch: 201 Batch:   106] loss: 0.466, acc: 80.000, test_acc:27.500, F1:0.255\n",
            "[Epoch: 202 Batch:   106] loss: 0.429, acc: 78.906, test_acc:30.833, F1:0.277\n",
            "[Epoch: 203 Batch:   106] loss: 0.519, acc: 75.459, test_acc:32.500, F1:0.308\n",
            "[Epoch: 204 Batch:   106] loss: 0.474, acc: 79.208, test_acc:36.667, F1:0.361\n",
            "[Epoch: 205 Batch:   106] loss: 0.448, acc: 78.868, test_acc:29.167, F1:0.267\n",
            "[Epoch: 206 Batch:   106] loss: 0.414, acc: 78.780, test_acc:35.000, F1:0.338\n",
            "[Epoch: 207 Batch:   106] loss: 0.448, acc: 77.824, test_acc:31.667, F1:0.255\n",
            "[Epoch: 208 Batch:   106] loss: 0.417, acc: 78.528, test_acc:38.333, F1:0.357\n",
            "[Epoch: 209 Batch:   106] loss: 0.424, acc: 78.503, test_acc:31.667, F1:0.277\n",
            "[Epoch: 210 Batch:   106] loss: 0.431, acc: 80.566, test_acc:36.667, F1:0.360\n",
            "[Epoch: 211 Batch:   106] loss: 0.485, acc: 78.189, test_acc:34.167, F1:0.340\n",
            "[Epoch: 212 Batch:   106] loss: 0.518, acc: 79.409, test_acc:33.333, F1:0.321\n",
            "[Epoch: 213 Batch:   106] loss: 0.472, acc: 79.094, test_acc:28.333, F1:0.258\n",
            "[Epoch: 214 Batch:   106] loss: 0.433, acc: 80.013, test_acc:30.833, F1:0.292\n",
            "[Epoch: 215 Batch:   106] loss: 0.505, acc: 78.377, test_acc:35.000, F1:0.349\n",
            "[Epoch: 216 Batch:   106] loss: 0.388, acc: 80.277, test_acc:33.333, F1:0.310\n",
            "[Epoch: 217 Batch:   106] loss: 0.384, acc: 80.654, test_acc:36.667, F1:0.357\n",
            "[Epoch: 218 Batch:   106] loss: 0.447, acc: 79.409, test_acc:32.500, F1:0.317\n",
            "[Epoch: 219 Batch:   106] loss: 0.413, acc: 80.352, test_acc:30.833, F1:0.288\n",
            "[Epoch: 220 Batch:   106] loss: 0.425, acc: 79.799, test_acc:33.333, F1:0.302\n",
            "[Epoch: 221 Batch:   106] loss: 0.401, acc: 78.478, test_acc:31.667, F1:0.300\n",
            "[Epoch: 222 Batch:   106] loss: 0.440, acc: 79.761, test_acc:28.333, F1:0.252\n",
            "[Epoch: 223 Batch:   106] loss: 0.439, acc: 81.774, test_acc:31.667, F1:0.300\n",
            "[Epoch: 224 Batch:   106] loss: 0.454, acc: 79.572, test_acc:32.500, F1:0.312\n",
            "[Epoch: 225 Batch:   106] loss: 0.416, acc: 79.208, test_acc:35.000, F1:0.331\n",
            "[Epoch: 226 Batch:   106] loss: 0.374, acc: 80.491, test_acc:30.833, F1:0.285\n",
            "[Epoch: 227 Batch:   106] loss: 0.368, acc: 80.981, test_acc:33.333, F1:0.306\n",
            "[Epoch: 228 Batch:   106] loss: 0.441, acc: 77.950, test_acc:32.500, F1:0.291\n",
            "[Epoch: 229 Batch:   106] loss: 0.401, acc: 79.811, test_acc:31.667, F1:0.267\n",
            "[Epoch: 230 Batch:   106] loss: 0.380, acc: 80.717, test_acc:32.500, F1:0.313\n",
            "[Epoch: 231 Batch:   106] loss: 0.369, acc: 78.390, test_acc:28.333, F1:0.278\n",
            "[Epoch: 232 Batch:   106] loss: 0.370, acc: 79.346, test_acc:34.167, F1:0.319\n",
            "[Epoch: 233 Batch:   106] loss: 0.406, acc: 81.434, test_acc:30.833, F1:0.280\n",
            "[Epoch: 234 Batch:   106] loss: 0.383, acc: 80.038, test_acc:33.333, F1:0.268\n",
            "[Epoch: 235 Batch:   106] loss: 0.370, acc: 80.101, test_acc:36.667, F1:0.338\n",
            "[Epoch: 236 Batch:   106] loss: 0.451, acc: 78.881, test_acc:34.167, F1:0.322\n",
            "[Epoch: 237 Batch:   106] loss: 0.547, acc: 77.660, test_acc:33.333, F1:0.313\n",
            "[Epoch: 238 Batch:   106] loss: 0.451, acc: 78.302, test_acc:32.500, F1:0.280\n",
            "[Epoch: 239 Batch:   106] loss: 0.390, acc: 81.044, test_acc:33.333, F1:0.315\n",
            "[Epoch: 240 Batch:   106] loss: 0.424, acc: 78.956, test_acc:35.000, F1:0.325\n",
            "[Epoch: 241 Batch:   106] loss: 0.495, acc: 77.547, test_acc:31.667, F1:0.288\n",
            "[Epoch: 242 Batch:   106] loss: 0.360, acc: 81.459, test_acc:29.167, F1:0.267\n",
            "[Epoch: 243 Batch:   106] loss: 0.441, acc: 78.579, test_acc:33.333, F1:0.303\n",
            "[Epoch: 244 Batch:   106] loss: 0.378, acc: 78.063, test_acc:35.000, F1:0.292\n",
            "[Epoch: 245 Batch:   106] loss: 0.358, acc: 79.560, test_acc:34.167, F1:0.302\n",
            "[Epoch: 246 Batch:   106] loss: 0.362, acc: 80.264, test_acc:34.167, F1:0.330\n",
            "[Epoch: 247 Batch:   106] loss: 0.549, acc: 78.101, test_acc:30.000, F1:0.271\n",
            "[Epoch: 248 Batch:   106] loss: 0.405, acc: 79.270, test_acc:31.667, F1:0.306\n",
            "[Epoch: 249 Batch:   106] loss: 0.452, acc: 79.132, test_acc:34.167, F1:0.312\n",
            "[Epoch: 250 Batch:   106] loss: 0.415, acc: 79.195, test_acc:28.333, F1:0.219\n",
            "[Epoch: 251 Batch:   106] loss: 0.462, acc: 79.472, test_acc:30.000, F1:0.294\n",
            "[Epoch: 252 Batch:   106] loss: 0.400, acc: 80.881, test_acc:32.500, F1:0.310\n",
            "[Epoch: 253 Batch:   106] loss: 0.393, acc: 80.038, test_acc:35.000, F1:0.318\n",
            "[Epoch: 254 Batch:   106] loss: 0.376, acc: 82.352, test_acc:31.667, F1:0.310\n",
            "[Epoch: 255 Batch:   106] loss: 0.412, acc: 79.434, test_acc:35.833, F1:0.324\n",
            "[Epoch: 256 Batch:   106] loss: 0.417, acc: 78.138, test_acc:35.833, F1:0.337\n",
            "[Epoch: 257 Batch:   106] loss: 0.386, acc: 78.579, test_acc:32.500, F1:0.310\n",
            "[Epoch: 258 Batch:   106] loss: 0.369, acc: 80.390, test_acc:30.000, F1:0.272\n",
            "[Epoch: 259 Batch:   106] loss: 0.402, acc: 80.289, test_acc:37.500, F1:0.360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXcTopvJpBsG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}