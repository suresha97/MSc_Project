{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Kts4G8Re9lexF0rZOC-zipkUf_Sew2Up",
      "authorship_tag": "ABX9TyN0vmvvllRiolcSA+ARgLiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresha97/MSc_Project/blob/main/CNN_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_YOU1RxHPD"
      },
      "source": [
        "# Setup Workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IO13abESYHx"
      },
      "source": [
        "#load packages\n",
        "import scipy\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "from IPython import display\n",
        "import copy \n",
        "import pickle\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Normalize, Resize, ToTensor\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TreaId9rKbDe"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxW9oK5yIegb"
      },
      "source": [
        "#Function to extract windowed segments of spectrograms\n",
        "def overlap_windows(data, overlap_rate, window_size):\n",
        "    '''Returns windowed segments of spectrogram\n",
        "\n",
        "    Args:\n",
        "        data : spectrogram to segemnts\n",
        "        window_size : length of each segment\n",
        "        overlap_rate : subsequent segments have overlap_rates of (1-overlap_rate)%\n",
        "\n",
        "    '''\n",
        "    window_list = []\n",
        "    start = 0\n",
        "    end = window_size\n",
        "    remain_length = len(data)\n",
        "    \n",
        "    while remain_length>=window_size:\n",
        "        window_list.append(data[:,int(round(start+0.01)):int(round(end+0.01))])\n",
        "        start += overlap_rate*window_size #start and end overlap 1\n",
        "        end += overlap_rate*window_size\n",
        "        remain_length -= overlap_rate*window_size \n",
        "    \n",
        "    return window_list\n",
        "\n",
        "def make_data(olr, window_size, augment, fusion):\n",
        "  '''Loads spectrograms and performace augmentation and or preparation for specifc training metods\n",
        "\n",
        "  Args:\n",
        "      olr : specify overlap rate for augment = True\n",
        "      window_size : specify length of each segment if augment = True\n",
        "      augment : True for spectrogram augmentation\n",
        "      fusion : None for single signal or FUSE 1, 'two_channel' for FUSE 2, 'alpha_blend' for FUSE 3#\n",
        "\n",
        "  '''\n",
        "\n",
        "  #List of strings for each particiapnt\n",
        "  parts = []\n",
        "  nums = [str(x) for x in range(1,10,1)]\n",
        "  ten = ['0'+x for x in nums]\n",
        "  others = [str(x) for x in range(10,24,1)]\n",
        "  participants = ten+others\n",
        "\n",
        "  ppg_full_list = [] # 32 elements of 40 x 80 x 80 arrays\n",
        "  resp_full_list = []\n",
        "\n",
        "  #Load spectorgrams of PPG and RESP signals for each particiapnt\n",
        "  for part in participants: \n",
        "    l_ppg = np.load('/content/drive/My Drive/PHYSIO/Generated_Specs/PPG_120/ppg_spec_{}_120.npy'.format(part)) #40 x 80 x 80\n",
        "    l_resp = np.load('/content/drive/My Drive/PHYSIO/Generated_Specs/20RESP_120/20resp_spec_{}_120.npy'.format(part)) #40 x 80 x 80 \n",
        "    \n",
        "    ppg_full_list.append(l_ppg)\n",
        "    resp_full_list.append(l_resp)\n",
        "\n",
        "  ppg_full_array = np.vstack(ppg_full_list)\n",
        "  resp_full_array = np.vstack(resp_full_list)\n",
        "\n",
        "  print(\"PPG:\",ppg_full_array.shape)\n",
        "  print(\"RESP:\",resp_full_array.shape)\n",
        "\n",
        "  if augment == True:\n",
        "    #Define resize dimensions for extracted segments\n",
        "    composed1 = transforms.Compose([ Resize(size=(120,120)),\n",
        "                                    ToTensor()])\n",
        "\n",
        "    composed2 = transforms.Compose([ Resize(size=(28,28)),\n",
        "                                    ToTensor()])\n",
        "    ppg_aug = []\n",
        "    resp_aug = []\n",
        "\n",
        "    #For each sample\n",
        "    for i in range(len(ppg_full_array)):\n",
        "\n",
        "      #Extract windowed segemnts for current spectrograms for each signal \n",
        "      test_win = overlap_windows(ppg_full_array[i], olr, window_size) \n",
        "      test_win2 = overlap_windows(resp_full_array[i], olr, window_size) \n",
        "      spec_list = []\n",
        "      spec_list2 = []\n",
        "\n",
        "      #Resise current PPG spectrogram segments to 120 x 120 then 28 x 28\n",
        "      for spec in test_win: \n",
        "        out2 = composed1(Image.fromarray(spec))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        out2 = composed2(Image.fromarray(out2))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        spec_list.append(out2)\n",
        "\n",
        "      #Resise current RESP spectrogram segments to 120 x 120 then 28 x 28\n",
        "      for spec2 in test_win2: \n",
        "        out2 = composed1(Image.fromarray(spec2))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        out2 = composed2(Image.fromarray(out2))\n",
        "        out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "        out2 = out2[:,:,0]\n",
        "        spec_list2.append(out2)\n",
        "      \n",
        "      ppg_aug.append(np.asarray(spec_list))\n",
        "      resp_aug.append(np.asarray(spec_list2))\n",
        "\n",
        "    ppg_aug_array = np.vstack(ppg_aug)\n",
        "    resp_aug_array = np.vstack(resp_aug)\n",
        "    print(\"PPG Augmented :\",ppg_aug_array.shape)\n",
        "    print(\"RESP Augmented :\",resp_aug_array.shape)\n",
        "    ppg_full_array = ppg_aug_array\n",
        "    resp_full_array = resp_aug_array\n",
        "\n",
        "  if fusion == 'two_channel':\n",
        "    to_stack = [ppg_full_array, resp_full_array]\n",
        "    two_sig = np.stack(np.asarray(to_stack), axis = 1)\n",
        "    print(\"Multi Channel Data:\",two_sig.shape)\n",
        "\n",
        "    return two_sig\n",
        "\n",
        "  if fusion == 'alpha_blend':\n",
        "    blend = np.load('/content/drive/My Drive/PHYSIO/spec_alpha_blend.npy')\n",
        "\n",
        "    if augment == True:\n",
        "      blend_array = []\n",
        "      for i in range(len(blend)):\n",
        "\n",
        "        #Extract windowed segemnts for current spectrograms for each signal \n",
        "        test_win = overlap_windows(blend[i], overlap_rate, window_size) \n",
        "        spec_list = []\n",
        "\n",
        "        #Resise current PPG spectrogram segments to 120 x 120 then 28 x 28\n",
        "        for spec in test_win: \n",
        "          out2 = composed1(Image.fromarray(spec))\n",
        "          out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "          out2 = out2[:,:,0]\n",
        "          out2 = composed2(Image.fromarray(out2))\n",
        "          out2 = np.transpose(out2.data.numpy(), (1, 2, 0))\n",
        "          out2 = out2[:,:,0]\n",
        "          spec_list.append(out2)\n",
        "\n",
        "        blend_array.append(np.asarray(spec_list))\n",
        "\n",
        "      blend_aug = np.vstack(blend_array)\n",
        "      blend = blend_aug\n",
        "\n",
        "    print(\"Alpha-blended Data :\",blend.shape)\n",
        "    return blend\n",
        "\n",
        "  return ppg_full_array, resp_full_array\n",
        "\n",
        "def make_labels(file_name,rating,aug_num):\n",
        "  '''Load lables for training and perform augmentation if necessary\n",
        "\n",
        "  Args:\n",
        "      file_name : all_labels for K-means, all_labels_threshold_5.0 for manual thresholding\n",
        "      rating : string specifying rating  i.e 'val', 'aro', 'val3' ,'aro3', 'class_4' for 4-class K-means\n",
        "      aug_num : total number of spectrograms after augmentation\n",
        "\n",
        "  '''\n",
        "  labels_tdf = pd.read_csv(\"/content/drive/My Drive/PHYSIO/Generated_Specs/{}.csv\".format(file_name)) \n",
        "  data_Y = labels_tdf[rating].to_numpy()[0:920]\n",
        "\n",
        "  if rating == 'class_4':\n",
        "    #Label encoding for clusterins with quadrant names as labels\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    data_Y = le.fit_transform(data_Y)\n",
        "\n",
        "  #Augment labels to match spectrograms\n",
        "  aug_labs = []\n",
        "  for ele in data_Y:\n",
        "    t_list = [ele]*int(aug_num/920)\n",
        "    aug_labs.extend(t_list)\n",
        "\n",
        "  aug_labs = np.asarray(aug_labs)\n",
        "  print(\"Labels:\",aug_labs.shape)\n",
        "\n",
        "  return aug_labs\n",
        "\n",
        "#Accuracy function\n",
        "def accuracy(features1,features2, labels,task, fuse):\n",
        "  '''Forward pass through model and return accuracy\n",
        "\n",
        "  Args:\n",
        "      features1 : featueres to forward pass \n",
        "      features2 : only relevant for FUSE 1\n",
        "      labels : ground truth classes \n",
        "      task : 'binary' for binary classification, 'multi' for all others\n",
        "      fuse : 1 if FUSE 1 else None\n",
        "      \n",
        "  '''\n",
        "  #Get predictions from model\n",
        "\n",
        "  if fuse == 1:\n",
        "    outputs = net.forward(features1, features2)\n",
        "  else:\n",
        "    outputs = net.forward(features1)\n",
        "\n",
        "  if task == 'multi':\n",
        "    outputs = F.softmax(outputs, dim = 0)\n",
        "    _, preds = torch.max(outputs.data,1)\n",
        "\n",
        "  if task == 'binary':\n",
        "    preds = []\n",
        "    for el in outputs.data:\n",
        "      if el >= 0.5:\n",
        "        preds.append(1)\n",
        "      elif el < 0.5:\n",
        "        preds.append(0)\n",
        "\n",
        "  preds = np.array(preds)\n",
        "\n",
        "  #Find number that are coorect and accuracy\n",
        "  num_correct = (torch.tensor(preds).int() == labels.int()).sum().numpy()\n",
        "  accuracy = num_correct/(labels.size()[0])\n",
        "\n",
        "  return accuracy*100, preds"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7bP3tD0KkM8"
      },
      "source": [
        "# CNN Architecures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ5v164mxhD9"
      },
      "source": [
        "## Baseline CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZEAbfzJohAC"
      },
      "source": [
        "\n",
        "\n",
        "class Single_Net(nn.Module):\n",
        "    \n",
        "    # Define the neural network layers\n",
        "    def __init__(self,fcsize,in_channel,num_c1, num_c2,outsize, task):\n",
        "        \n",
        "        super(Single_Net, self).__init__()\n",
        "        self.fcsize = fcsize\n",
        "        self.task = task\n",
        "        self.in_channel = in_channel\n",
        "        self.num_c1 = num_c1\n",
        "        self.num_c2 = num_c2\n",
        "        self.outsize = outsize\n",
        "\n",
        "        #Conv layer\n",
        "        self.conv1 = nn.Conv2d(self.in_channel, self.num_c1, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(self.num_c1, self.num_c2, kernel_size=5)\n",
        "\n",
        "        #FC layers\n",
        "        self.fc1 = nn.Linear(self.fcsize, self.outsize)\n",
        "        self.fc2 = nn.Linear(self.fcsize*2,1)\n",
        "\n",
        "\n",
        "    # Define the forward pass.    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #Conv1 Block 1 - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv1(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #Conv1 Block 2 - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv2(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #Flatten array\n",
        "        x = x.view(-1, self.fcsize)\n",
        "\n",
        "        if self.task == 'binary':\n",
        "          x = torch.sigmoid(self.fc1(x))\n",
        "        if self.task == 'multi':\n",
        "          x = self.fc1(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JCutdM1xi-V"
      },
      "source": [
        "## Baseline CNN for FUSE 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQN2vA2Qdigg"
      },
      "source": [
        "'''For Fusion Method 1 (FUSE 1 )'''\n",
        "class Multi_Net(nn.Module):\n",
        "    \n",
        "    # Define the neural network layers\n",
        "    def __init__(self,fcsize,in_channel,num_c1, num_c2,outsize,task):\n",
        "        \n",
        "        super(Multi_Net, self).__init__()\n",
        "        self.fcsize = fcsize\n",
        "        self.task = task\n",
        "        self.in_channel = in_channel\n",
        "        self.num_c1 = num_c1\n",
        "        self.num_c2 = num_c2\n",
        "        self.outsize = outsize\n",
        "\n",
        "        #Conv layer\n",
        "        self.conv1 = nn.Conv2d(self.in_channel, self.num_c1, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(self.num_c1, self.num_c2, kernel_size=5)\n",
        "\n",
        "        #FC layers\n",
        "        self.fc1 = nn.Linear(self.fcsize, self.outsize)\n",
        "        self.fc2 = nn.Linear(self.fcsize*2,self.outsize)\n",
        "\n",
        "    # Define the forward pass.    \n",
        "    \n",
        "    def forward(self, x, x2):\n",
        "    \n",
        "        #Conv1 Block 1 (Singal 1) - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv1(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        #Conv1 Block 2 (Singal 1) - Convolution + Pooling + Non-linearity\n",
        "        x = F.max_pool2d(self.conv2(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #Conv1 Block 1 (Singal 2) - Convolution + Pooling + Non-linearity\n",
        "        x2 = F.max_pool2d(self.conv1(x2), 2)\n",
        "        x2 = F.relu(x2)\n",
        "        \n",
        "        #Conv1 Block 2 (Singal 2) - Convolution + Pooling + Non-linearity\n",
        "        x2 = F.max_pool2d(self.conv2(x2), 2)\n",
        "        x2 = F.relu(x2)\n",
        "        \n",
        "        #Flatten layers for both signal\n",
        "        x = x.view(-1, self.fcsize)\n",
        "        x2 = x2.view(-1, self.fcsize)\n",
        "\n",
        "        #Concatenate features extracted from both spectrograms\n",
        "        x_combined = torch.cat((x,x2),dim=1)\n",
        "\n",
        "        #FC layers, non-linearities and predcition layers\n",
        "        if self.task == 'binary':\n",
        "          x_combined = torch.sigmoid(self.fc2(x_combined))\n",
        "\n",
        "        if self.task == 'multi':\n",
        "          x_combined = self.fc2(x_combined)\n",
        "        \n",
        "        return x_combined"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gafaSKwxxl93"
      },
      "source": [
        "## Attention Model 1 (Att 1) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJyvZ06pxbCr"
      },
      "source": [
        "np.random.seed(3)\n",
        "\n",
        "#Module is a base class for all neural network modules\n",
        "class Attention_Net2(nn.Module):\n",
        "    \n",
        "    # Define the neural network layers\n",
        "    def __init__(self,fcsize,in_channel,num_c1, num_c2,outsize,task):\n",
        "        \n",
        "        super(Single_Net, self).__init__()\n",
        "        self.fcsize = fcsize\n",
        "        self.task = task\n",
        "        self.in_channel = in_channel\n",
        "        self.num_c1 = num_c1\n",
        "        self.num_c2 = num_c2\n",
        "        self.outsize = outsize\n",
        "\n",
        "        #Conv layers\n",
        "        self.conv1 = nn.Conv2d(self.in_channel, self.num_c1, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(self._num_c1, self.num_c2, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(self.fcsize, self.outsize)\n",
        "  \n",
        "        self.project = nn.Conv2d(self.num_c1, self.fcsize, kernel_size = 1) \n",
        "        self.comp = nn.Conv2d(self.fcsize, 1, kernel_size = 1) \n",
        "\n",
        "\n",
        "    # Define the forward pass.    \n",
        "    def forward(self, x):\n",
        "        #Conv1 Block 1 - Convolution + Pooling + Non-linearity\n",
        "        a_l = self.conv1(x)\n",
        "\n",
        "        x = F.max_pool2d(a_l, 2, stride = 2)\n",
        "        x = torch.sigmoid(x)\n",
        "\n",
        "        x = F.max_pool2d(self.conv2(x), 2, stride = 2)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        #Save global output of CNN to another variable\n",
        "        N,_,_,_ = x.size()\n",
        "        g = x.view(N,288,1,1)\n",
        "\n",
        "        #Project features onto same dimesnion as global output and add the two\n",
        "        p_l = self.project(a_l)  \n",
        "        N,C,W,H = p_l.size()\n",
        "        comb = p_l+g\n",
        "\n",
        "        #Get Compatability scores and Normalise to get attention map\n",
        "        c = self.comp(comb)\n",
        "        a = F.softmax(c.view(N,1,-1), dim =2).view(N,1,W,H)\n",
        "        \n",
        "        #Sum feature vectors extracted after conv1, wieghted with attention map\n",
        "        g_a = torch.mul(a.expand_as(p_l),p_l)\n",
        "        g_a = g_a.view(N,C,-1).sum(dim=2)\n",
        "\n",
        "        if self.task == 'binary':\n",
        "          g_a = torch.sigmoid(self.fc1(g_a))\n",
        "\n",
        "        if self.task == 'multi':\n",
        "          g_a = self.fc1(g_a)\n",
        "        \n",
        "        return g_a\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rlYCksxxpLN"
      },
      "source": [
        "## Attention Model 2 (Att 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vicZ6tVXiHox"
      },
      "source": [
        "np.random.seed(3)\n",
        "\n",
        "#Module is a base class for all neural network modules\n",
        "class Attention_Net2(nn.Module):\n",
        "    \n",
        "    # Define the neural network layers\n",
        "    def __init__(self,fcsize,in_channel,num_c1, num_c2,outsize,task):\n",
        "        \n",
        "        super(Attention_Net2, self).__init__()\n",
        "        self.fcsize = fcsize\n",
        "        self.task = task\n",
        "        self.in_channel = in_channel\n",
        "        self.num_c1 = num_c1\n",
        "        self.num_c2 = num_c2\n",
        "        self.outsize = outsize\n",
        "\n",
        "        #Conv layers\n",
        "        self.conv1 = nn.Conv2d(self.in_channel, self.num_c1, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(self.num_c1, self.num_c2, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(self.num_c2, 1)\n",
        "\n",
        "        self.tanlayer = nn.Conv2d(self.num_c2,self.num_c2, kernel_size = 1)\n",
        "        self.comp = nn.Conv2d(self.num_c2, 1, kernel_size = 1) \n",
        "      \n",
        "    # Define the forward pass.    \n",
        "    def forward(self, x):\n",
        "        #Conv1 Block 1 - Convolution + Pooling + Non-linearity\n",
        "        a_l = self.conv1(x)\n",
        "\n",
        "        x = F.max_pool2d(a_l, 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = F.max_pool2d(self.conv2(x), 2, stride = 2)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        #Save global output of CNN to another variable\n",
        "        N,C,W,H = x.size()\n",
        "        A = x\n",
        "\n",
        "        #New representation of CNN output vectors\n",
        "        # sending each vector throguh MLP by passing through conv layer with kernel size 1 and same number of output channels.\n",
        "        new_A = F.tanh(self.tanlayer(A)) \n",
        "        new_A = new_A*0.3 #lambda\n",
        "\n",
        "        #Get normalised compatiability scores\n",
        "        E = self.comp(new_A)\n",
        "        alpha = F.softmax(E.view(N,1,-1), dim =2).view(N,1,W,H)\n",
        "\n",
        "        #Sum feature vectors extracted after conv1, wieghted with attention map\n",
        "        alpha = torch.mul(alpha.expand_as(A),A)\n",
        "        c = alpha.view(N,C,-1).sum(dim=2)\n",
        "\n",
        "        if self.task == 'binary':\n",
        "          c = torch.sigmoid(self.fc1(c))\n",
        "\n",
        "        if self.task == 'multi':\n",
        "          c = self.fc1(c)\n",
        "\n",
        "        \n",
        "        return c\n",
        "        "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBF0reCbsVOH"
      },
      "source": [
        "# Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtQZrRwXoooX"
      },
      "source": [
        "# Train the CNN\n",
        "def train_net(train_set, no_epochs, lr, m, opt, task, fuse):\n",
        "\n",
        "    #Define tloss functionhe loss\n",
        "    if task == 'multi':\n",
        "      loss_func = nn.CrossEntropyLoss()\n",
        "    if task == 'binary':\n",
        "      loss_func = nn.BCELoss()\n",
        "\n",
        "    #Define Optimiser\n",
        "    if opt == 'ADAM':\n",
        "      optimizer = optim.AdamW(net.parameters(), lr = lr)\n",
        "    elif opt == 'SGD':\n",
        "      optimizer=optim.SGD(net.parameters(), lr = lr, momentum = m, nesterov = True)\n",
        "\n",
        "    best_val_loss = 10000\n",
        "    best_epoch = 0\n",
        "    best_val_acc = 0\n",
        "\n",
        "    losses_train = []\n",
        "    losses_val = []\n",
        "\n",
        "    # Loop over the number of epochs\n",
        "    for epoch in range(no_epochs):\n",
        "\n",
        "        #Initialise loss and acc\n",
        "        current_loss = 0.0\n",
        "        current_accuracy = 0.0\n",
        "\n",
        "        # Loop over each mini-batch\n",
        "        for batch_index, training_batch in enumerate(train_set, 0):\n",
        "  \n",
        "            #Load the mini-batch and wrap with variable\n",
        "            if fuse == 1:\n",
        "              inputs, inputs2, labels = training_batch\n",
        "              inputs, inputs2, labels = inputs, inputs2, labels\n",
        "            else:\n",
        "              inputs, labels = training_batch\n",
        "              inputs,  labels = inputs, labels\n",
        "\n",
        "            #Initalise parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #Forward pass\n",
        " \n",
        "            if fuse == 1:\n",
        "              outputs = net.forward(inputs, inputs2)\n",
        "            else:\n",
        "              outputs = net.forward(inputs)\n",
        "\n",
        "            if task == 'multi':\n",
        "              labels = labels.long()\n",
        "\n",
        "            loss = loss_func(outputs, labels)\n",
        "            \n",
        "            #Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #Add loss \n",
        "            current_loss += loss.item()\n",
        "\n",
        "            #Add accuracy to the overall accuracy\n",
        "\n",
        "            if fuse == 1:\n",
        "              current_accuracy += accuracy(inputs,inputs2,labels, task, fuse)[0]\n",
        "            else:\n",
        "              current_accuracy += accuracy(inputs,'_',labels, task, fuse)[0]\n",
        "\n",
        "\n",
        "        print('[Epoch: %d Batch: %5d] loss: %.3f, acc: %.3f' % (epoch + 1, batch_index+1, current_loss/batchsize, current_accuracy/batchsize))\n",
        "        losses_train.append(current_loss/batchsize)\n",
        "\n",
        "    print(\"------------------------------------------------------\")\n",
        "    print('Training has finished')\n",
        "\n",
        "\n",
        "    if fuse == 1:\n",
        "      test_ac, preds = accuracy(testf_tensor, testf_tensor2, testl_tensor, task, fuse)\n",
        "    else:\n",
        "      test_ac, preds = accuracy(testf_tensor, '_', testl_tensor, task, fuse)\n",
        "\n",
        "    print('Test Accuracy: ',test_ac)\n",
        "\n",
        "    #Test F1 score\n",
        "    true_y = testl_tensor.detach().numpy()\n",
        "    F1_test = sklearn.metrics.f1_score(true_y, preds, average = 'weighted')\n",
        "    print('Test F1 Score :', F1_test)\n",
        "    print(\"All :\",sklearn.metrics.classification_report(true_y, preds))\n",
        "    print(\"Confusion Matrix :\")\n",
        "    print(sklearn.metrics.confusion_matrix(true_y, preds))\n",
        "    #sklearn.metrics.plot_confusion_matrix(best_model, testf_tensor)\n",
        "    \n",
        "    #Plot learning curves\n",
        "    fig = plt.figure(figsize=(5,5), dpi= 80, facecolor='w', edgecolor='k')\n",
        "    length = np.arange(0,len(losses_train),1)\n",
        "    plt.plot(length,losses_train,'r',linewidth = 2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return test_ac, F1_test, sklearn.metrics.confusion_matrix(true_y, preds)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0m8BzMJphMV"
      },
      "source": [
        "# Load and make Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Po1FlS5pfWV",
        "outputId": "24c8b293-0061-4f8a-bd30-81525da821dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "#Choose spectrogram files\n",
        "\n",
        "#Choose data augmentation parameters for running augment = True\n",
        "window_size = 40\n",
        "overlap_rate = 1\n",
        "\n",
        "print(\"----------- Single Input -----------\")\n",
        "#Choose clustering strategy and rating to load \n",
        "file_n = 'all_labels_threshold_5.0' #all_labels for k-means, all_labels_threshold_5.0 for manual threhsold, class_4 only in all_labels\n",
        "ratings = 'val' #val/aro for binary classification, val3/aro3 for multiclass, class_4 for 4 class classification\n",
        "num_participants = 23\n",
        "\n",
        "#Split data by particiapnts for LOSO CV *ALSO NEED FILEN_NAME FOR SPECTROGRAM FILES*\n",
        "ppg_array, resp_array = make_data(overlap_rate, window_size, augment=True, fusion = None)\n",
        "sub_splits_ppg = np.split(ppg_array, num_participants)\n",
        "sub_splits_resp = np.split(resp_array, num_participants)\n",
        "\n",
        "print()\n",
        "print(\"----------- FUSE 2 -----------\")\n",
        "\n",
        "'''For Fusion Method 2 (FUSE 2)'''\n",
        "two_s = make_data(overlap_rate, window_size, augment=True, fusion ='two_channel')\n",
        "sub_splits_both = np.split(two_s, 23)\n",
        "\n",
        "print()\n",
        "print(\"----------- FUSE 3 -----------\")\n",
        "'''For Fusion Method 3 (FUSE 3)'''\n",
        "alpha_s = make_data(overlap_rate, window_size, augment=True, fusion = 'alpha_blend')\n",
        "sub_splits_alpha = np.split(alpha_s, 23)\n",
        "\n",
        "print()\n",
        "print(\"----------- Labels -----------\")\n",
        "len_aug = len(ppg_array)\n",
        "labs = make_labels(file_n, ratings, len_aug)\n",
        "sub_splits_labs = np.split(labs, 23)\n",
        "\n",
        "print()\n",
        "print(\"----------- LOSO -----------\")\n",
        "print(\"LOSO Single Signal Features:\",np.asarray(sub_splits_resp).shape)\n",
        "print(\"LOSO Multi-channel Features :\",np.asarray(sub_splits_both).shape)\n",
        "print(\"LOSO Alpha-blend Features:\",np.asarray(sub_splits_alpha).shape)\n",
        "print(\"LOSO Labels:\",np.asarray(sub_splits_labs).shape)\n",
        "\n",
        "\n",
        "#Choose input method (PPG, RESP, FUSE 2, FUSE 3)\n",
        "dat = sub_splits_ppg\n",
        "#dat2 = sub_splits_resp"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------- Single Input -----------\n",
            "PPG: (920, 120, 120)\n",
            "RESP: (920, 120, 120)\n",
            "PPG Augmented : (2760, 28, 28)\n",
            "RESP Augmented : (2760, 28, 28)\n",
            "\n",
            "----------- FUSE 2 -----------\n",
            "PPG: (920, 120, 120)\n",
            "RESP: (920, 120, 120)\n",
            "PPG Augmented : (2760, 28, 28)\n",
            "RESP Augmented : (2760, 28, 28)\n",
            "Multi Channel Data: (2760, 2, 28, 28)\n",
            "\n",
            "----------- FUSE 3 -----------\n",
            "PPG: (920, 120, 120)\n",
            "RESP: (920, 120, 120)\n",
            "PPG Augmented : (2760, 28, 28)\n",
            "RESP Augmented : (2760, 28, 28)\n",
            "Alpha-blended Data : (2760, 28, 28)\n",
            "\n",
            "----------- Labels -----------\n",
            "Labels: (2760,)\n",
            "\n",
            "----------- LOSO -----------\n",
            "LOSO Single Signal Features: (23, 120, 28, 28)\n",
            "LOSO Multi-channel Features : (23, 120, 2, 28, 28)\n",
            "LOSO Alpha-blend Features: (23, 120, 28, 28)\n",
            "LOSO Labels: (23, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqZtYBcmpkfn"
      },
      "source": [
        "# Train Model using LOSO CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riR7whNoo8Ww"
      },
      "source": [
        "image_size = np.asarray(dat).shape[2]\n",
        "subjects = [x for x in range(0,23,1)]\n",
        "\n",
        "accuracies_test = []\n",
        "f1s = []\n",
        "cf_list = []\n",
        "#Train model 23 times - differnet particiapnt data each time \n",
        "for s in subjects:\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_inds = np.where(np.asarray(subjects) != s)[0]\n",
        "  train_feats = np.take(np.asarray(dat), train_inds, axis = 0)\n",
        "  train_feats = np.vstack(train_feats)\n",
        "  \n",
        "  train_labs = np.take(np.asarray(sub_splits_labs), train_inds, axis = 0)\n",
        "  train_labs = np.reshape(train_labs, (train_feats.shape[0]))\n",
        "  print(\"Training Features\",train_feats.shape)\n",
        "  print(\"Training Labels\",train_labs.shape)\n",
        "\n",
        "  #Get test fold\n",
        "  test_feats = np.take(np.asarray(dat), s, axis = 0)  \n",
        "  test_labs = np.take(np.asarray(sub_splits_labs), s, axis = 0)\n",
        "  test_labs = np.reshape(test_labs, (test_feats.shape[0]))\n",
        "  print(\"Training Features\",test_feats.shape)\n",
        "  print(\"Training Labels\",test_labs.shape)\n",
        "\n",
        "  #Reshape train and test arrays to specify number of input chanenels\n",
        "  train_feats = train_feats.reshape(len(train_feats),1,image_size,image_size)\n",
        "  test_feats = test_feats.reshape(len(test_feats),1,image_size,image_size)\n",
        "\n",
        "  #Convert to torch tensors\n",
        "  trainf_tensor = torch.tensor(train_feats, dtype=torch.float)\n",
        "  trainl_tensor = torch.tensor(train_labs, dtype=torch.float)\n",
        "  testf_tensor = torch.tensor(test_feats, requires_grad=False, dtype=torch.float)\n",
        " \n",
        "  testl_tensor = torch.tensor(test_labs, requires_grad=False, dtype=torch.float)\n",
        "  print(\"Trainf\",trainf_tensor.shape)\n",
        "  print(\"Trainl\",trainl_tensor.shape)\n",
        "  print(\"Testf\",testf_tensor.shape)\n",
        "  print(\"Testl\",testl_tensor.shape)\n",
        "\n",
        "  ''' For Fusion Method 1 (FUSE 1)'''\n",
        "  # train_feats2 = np.take(np.asarray(dat2), train_inds, axis = 0)\n",
        "  # train_feats2 = np.vstack(train_feats2)\n",
        "  # test_feats2 = np.take(np.asarray(dat2), s, axis = 0)\n",
        "  # train_feats2 = train_feats.reshape(len(train_feats2),1,image_size,image_size)\n",
        "  # test_feats2 = test_feats.reshape(len(test_feats2),1,image_size,image_size)\n",
        "  # trainf_tensor2 = torch.tensor(train_feats2, dtype=torch.float)\n",
        "  # testf_tensor2 = torch.tensor(test_feats2, requires_grad=False, dtype=torch.float)\n",
        "  # print(\"Trainf\",trainf_tensor2.shape)\n",
        "\n",
        "  #Batchify training data using trainloader\n",
        "  batch_size = 25\n",
        "  trainset = torch.utils.data.TensorDataset(trainf_tensor, trainl_tensor)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  batchsize = len(trainloader)\n",
        "\n",
        "  print(\"Participant : \",s+1)\n",
        "\n",
        "  #Change num_c1 to 12 and num_c2 to 24 for FUSE 1/3. Change in_channel to 2 for and fuse to 2 for FUSE 1. fcsize 288 or 384 or 480]\n",
        "  #net = Single_Net(fcsize = 480, in_channel = 1, num_c1 = 15, num_c2 = 30, outsize = 4, task = 'multi' )\n",
        "  #net = Multi_Net(fcsize = 384, in_channel = 1, num_c1 = 12, num_c2 = 24, outsize = 3, task = 'multi' )\n",
        "  #net = Attention_Net1(fcsize = 288, in_channel = 1, num_c1 = 9, num_c2 = 18, outsize = 1, task = 'binary' )\n",
        "  net = Attention_Net2(fcsize = 288, in_channel = 1, num_c1 = 9, num_c2 = 18, outsize = 1, task = 'binary' )\n",
        "  test_accuracy,testf1,cf = train_net(trainloader, no_epochs = 10, lr = 0.001, m = 0.0, opt = 'ADAM', task = 'binary', fuse = None)    \n",
        "  accuracies_test.append(test_accuracy) \n",
        "  f1s.append(testf1)\n",
        "  cf_list.append(cf)\n",
        "  print(\"Pre-processing time  validation sets --- %s minutes ---\" % (((time.time() - start_time)/60)))\n",
        "\n",
        "#Print average metrics across all participants\n",
        "avg_acc = sum(accuracies_test)/len(accuracies_test)\n",
        "print(\"Accuracies :\", accuracies_test)\n",
        "print(\"Average test accuracy: {}%\".format(round(avg_acc,2)))\n",
        "print(\"Average test F1 Score :\", sum(f1s)/len(f1s))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}